import streamlit as st
import pandas as pd
import re
from openai import OpenAI
import anthropic
import time
import hashlib
import math
import json
import google.generativeai as genai

# --- í˜ì´ì§€ ì„¤ì • ---
st.set_page_config(page_title="ğŸ“„ ë…¼ë¬¸ ìŠ¤í¬ë¦¬ë‹ ë„ìš°ë¯¸", layout="wide")
st.title("ğŸ“‘ LLM ê¸°ë°˜ ë…¼ë¬¸ ìŠ¤í¬ë¦¬ë‹ ì§€ì› ë„êµ¬")

# --- âœ… ì‚¬ì´ë“œë°”: í•­ìƒ í‘œì‹œ ---
st.sidebar.header("âš™ï¸ ëª¨ë¸ ì„¤ì •")
model_choice = st.sidebar.selectbox(
    "ëª¨ë¸ ì„ íƒ",
    [
        "gpt-4.1-mini",
        "gpt-4.1-nano",
        "gpt-5-mini",
        "gpt-5-nano",
        "claude-sonnet-4-5",
        "claude-haiku-4-5",
        "gemini-2.5-flash-lite"
    ]
)
temperature = st.sidebar.slider("Temperature", 0.0, 1.5, 0.7, 0.1)
max_tokens = st.sidebar.slider("Max tokens", 100, 4000, 800, 100)
show_reason = True  # ê³„ì† Trueë¡œ ì‚¬ìš©

# --- CSV ì—…ë¡œë“œ ---
uploaded_file = st.file_uploader("ë…¼ë¬¸ ëª©ë¡ CSV ì—…ë¡œë“œ", type=["csv"])

if uploaded_file:
    # âœ… íŒŒì¼ ë‚´ìš© ê¸°ë°˜ í•´ì‹œ ê³„ì‚°
    file_bytes = uploaded_file.getvalue()
    file_hash = hashlib.md5(file_bytes).hexdigest()

    # ğŸ” íŒŒì¼ ë‚´ìš© ë³€ê²½ ê°ì§€ â†’ ì„¸ì…˜ ì´ˆê¸°í™”
    if "uploaded_file_hash" not in st.session_state or st.session_state["uploaded_file_hash"] != file_hash:
        st.session_state["uploaded_file_hash"] = file_hash
        st.session_state.pop("df", None)
        st.session_state.pop("results", None)
        st.session_state.pop("completion_message", None)
        st.session_state.pop("error_count", None)

    df = pd.read_csv(uploaded_file)

    # ì„ íƒ ì»¬ëŸ¼ ì¶”ê°€
    if "select" not in df.columns:
        df.insert(0, "select", False)

    # --- ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” ---
    if "df" not in st.session_state:
        st.session_state.df = df.copy()

    # --- ì‚¬ìš©ì ì…ë ¥ ì§ˆë¬¸ ---
    st.subheader("ğŸ” Screening ì§ˆë¬¸ ì…ë ¥")
    user_question = st.text_input(
        "ì´ ë…¼ë¬¸ì´ í¬í•¨ ê¸°ì¤€ì— ë¶€í•©í•˜ëŠ”ì§€ ë¬»ê³  ì‹¶ì€ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”:",
        placeholder="ì´ ë…¼ë¬¸ì—ì„œ LLM ëª¨ë¸ì„ ì´ìš©í•œ ì‹¤í—˜ì„ í•˜ê³  ìˆëŠ” ì§€ ì•Œë ¤ ì¤˜.",
        key="screening_question_input"
    )

    # --- ê²°ê³¼ ì»¬ëŸ¼ ì´ë¦„ ì…ë ¥ ---
    result_col_name = st.text_input(
        "íŒë‹¨ ê²°ê³¼ ì»¬ëŸ¼ ì´ë¦„ ì§€ì • (ì…ë ¥í•˜ì§€ ì•Šìœ¼ë©´ ì§ˆë¬¸ì´ ìë™ìœ¼ë¡œ ì‚¬ìš©ë©ë‹ˆë‹¤)",
        value="screening_result",
        key="result_col_name_input"
    )

    # --- ì „ì²´ ì„ íƒ / í•´ì œ ë²„íŠ¼ ---
    col1, col2 = st.columns([1, 1])
    with col1:
        if st.button("âœ… ì „ì²´ ì„ íƒ"):
            st.session_state.df["select"] = True
    with col2:
        if st.button("âŒ ì „ì²´ í•´ì œ"):
            st.session_state.df["select"] = False

    # --- ë°ì´í„° í…Œì´ë¸” í‘œì‹œ ---
    st.subheader("ğŸ“‹ ë…¼ë¬¸ ëª©ë¡ (ì™¼ìª½ ì²´í¬ë°•ìŠ¤ë¡œ ì„ íƒ)")
    edited_df = st.data_editor(
        st.session_state.df,
        use_container_width=True,
        height=500,
        column_config={
            "select": st.column_config.CheckboxColumn("ì„ íƒ", help="ìŠ¤í¬ë¦¬ë‹í•  ë…¼ë¬¸ ì„ íƒ"),
        },
        hide_index=True,
    )

    # í¸ì§‘ ë‚´ìš© ì €ì¥
    st.session_state.df = edited_df
    selected_rows = edited_df[edited_df["select"] == True]

    # --- ì„ íƒëœ ë…¼ë¬¸ í‘œì‹œ ---
    st.subheader("âœ… ì„ íƒëœ ë…¼ë¬¸")
    if selected_rows.empty:
        st.info("ë¨¼ì € ìŠ¤í¬ë¦¬ë‹í•  ë…¼ë¬¸ì„ ì„ íƒí•˜ì„¸ìš”.")
    elif not user_question.strip():
        st.warning("Screening ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    else:
        st.dataframe(selected_rows, use_container_width=True, height=300)

        # --- LLM íŒë‹¨ ì‹¤í–‰ ---
        if st.button("ğŸ§  Screening ì‹¤í–‰"):
            total = len(selected_rows)

            # â± ì‹œì‘ ì‹œê°„ ê¸°ë¡
            start_time = time.perf_counter()

            progress_text = st.empty()
            progress_bar = st.progress(0)
            st.info(f"{total}ê°œì˜ ë…¼ë¬¸ì— ëŒ€í•´ LLM íŒë‹¨ ì¤‘...")

            # ê²°ê³¼ ì»¬ëŸ¼ ì¤€ë¹„
            if result_col_name not in st.session_state.df.columns:
                st.session_state.df[result_col_name] = ""
            reason_col_name = f"{result_col_name}_reason"
            if show_reason and reason_col_name not in st.session_state.df.columns:
                st.session_state.df[reason_col_name] = ""

            results = []
            error_count = 0

            for i, (idx, row) in enumerate(selected_rows.iterrows(), start=1):
                title = str(row.get("Title", "ì œëª© ì •ë³´ ì—†ìŒ")).strip()
                abstract = str(row.get("Abstract", "ì´ˆë¡ ì •ë³´ ì—†ìŒ")).strip()

                prompt = f"""
ë‹¹ì‹ ì€ ì—°êµ¬ ë…¼ë¬¸ì„ ìŠ¤í¬ë¦¬ë‹í•˜ëŠ” ë³´ì¡°ìì…ë‹ˆë‹¤.
ì£¼ì–´ì§„ ë…¼ë¬¸ ì •ë³´ì™€ ì´ˆë¡ì„ ê¸°ë°˜ìœ¼ë¡œ ì•„ë˜ ì§ˆë¬¸ì— ëŒ€í•´ "Yes" ë˜ëŠ” "No"ë¡œ íŒë‹¨í•˜ì„¸ìš”.

[ì§ˆë¬¸]
{user_question}

[ë…¼ë¬¸ ì œëª©]
{title}

[ë…¼ë¬¸ ì´ˆë¡]
{abstract}

[ì¶œë ¥ í˜•ì‹]
result: "Yes" ë˜ëŠ” "No" ì¤‘ í•˜ë‚˜
reason: íŒë‹¨ ì´ìœ ë¥¼ 2~3ë¬¸ì¥ìœ¼ë¡œ ì„¤ëª…
"""

                try:
                    reply = ""

                    # --- ëª¨ë¸ë³„ í˜¸ì¶œ ---
                    if model_choice.startswith("gpt-4.1-mini"):
                        client = OpenAI(api_key=st.secrets["API"]["OPENAI_API_KEY"])
                        completion = client.responses.create(
                            model="gpt-4.1-mini",
                            input=prompt,
                            temperature=temperature,
                            max_output_tokens=max_tokens,
                        )
                        reply = completion.output_text
                    elif model_choice.startswith("gpt-4.1-nano"):
                        client = OpenAI(api_key=st.secrets["API"]["OPENAI_API_KEY"])
                        completion = client.responses.create(
                            model="gpt-4.1-nano",
                            input=prompt,
                            temperature=temperature,
                            max_output_tokens=max_tokens,
                        )
                        reply = completion.output_text
                    elif model_choice.startswith("gpt-5-mini"):
                        client = OpenAI(api_key=st.secrets["API"]["OPENAI_API_KEY"])
                        completion = client.responses.create(
                            model="gpt-4.1-mini",
                            input=prompt,
                            temperature=temperature,
                            max_output_tokens=max_tokens,
                        )
                        reply = completion.output_text
                    elif model_choice.startswith("gpt-5-nano"):
                        client = OpenAI(api_key=st.secrets["API"]["OPENAI_API_KEY"])
                        completion = client.responses.create(
                            model="gpt-4.1-mini",
                            input=prompt,
                            temperature=temperature,
                            max_output_tokens=max_tokens,
                        )
                        reply = completion.output_text
                    elif model_choice.startswith("claude-sonnet-4-5"):
                        client = anthropic.Anthropic(api_key=st.secrets["API"]["ANTHROPIC_API_KEY"])
                        completion = client.messages.create(
                            model="claude-sonnet-4-5",
                            max_tokens=max_tokens,
                            temperature=temperature,
                            messages=[{"role": "user", "content": prompt}],
                        )
                        reply = completion.content[0].text
                    elif model_choice.startswith("claude-haiku-4-5"):
                        client = anthropic.Anthropic(api_key=st.secrets["API"]["ANTHROPIC_API_KEY"])
                        completion = client.messages.create(
                            model="claude-sonnet-4-5",
                            max_tokens=max_tokens,
                            temperature=temperature,
                            messages=[{"role": "user", "content": prompt}],
                        )
                        reply = completion.content[0].text
                    elif model_choice.startswith("gemini-2.5-flash-lite"):
                        genai.configure(api_key=st.secrets["API"]["GEMINI_API_KEY"])
                        model = genai.GenerativeModel(
                            "gemini-2.5-flash-lite",
                            generation_config={
                                "temperature": temperature,
                                "max_output_tokens": max_tokens,
                            },
                        )
                        completion = model.generate_content(prompt)
                        reply = completion.text

                    # --- ê²°ê³¼ ì¶”ì¶œ ---
                    result_value = "Yes" if "yes" in reply.lower() else "No"
                    reason_text = ""
                    if show_reason:
                        match = re.search(r"reason\s*[:ï¼š]\s*(.*)", reply, re.IGNORECASE | re.DOTALL)
                        if match:
                            reason_text = match.group(1).strip()
                        else:
                            reason_text = re.sub(r"result\s*[:ï¼š]\s*(yes|no)", "", reply, flags=re.IGNORECASE).strip()

                    # --- ê²°ê³¼ ë°˜ì˜ ---
                    st.session_state.df.loc[idx, result_col_name] = result_value
                    if show_reason:
                        st.session_state.df.loc[idx, reason_col_name] = reason_text

                    results.append({
                        "index": idx,
                        "title": title,
                        "abstract": abstract,
                        result_col_name: result_value,
                        "reason": reason_text,
                    })

                except Exception:
                    # âœ… ì˜¤ë¥˜ ì‹œ: í•´ë‹¹ í–‰ì˜ ê²°ê³¼ ì»¬ëŸ¼ì— ì˜¤ë¥˜ë¥¼ ì§ì ‘ ê¸°ë¡í•˜ê³  ê³„ì† ì§„í–‰
                    error_count += 1
                    st.session_state.df.loc[idx, result_col_name] = "Error"
                    if show_reason:
                        st.session_state.df.loc[idx, reason_col_name] = "LLM ëª¨ë¸ ë™ì‘ ì¤‘ ì—ëŸ¬ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤"

                    results.append({
                        "index": idx,
                        "title": title,
                        "abstract": abstract,
                        result_col_name: "Error",
                        "reason": "LLM ëª¨ë¸ ë™ì‘ ì¤‘ ì—ëŸ¬ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤",
                    })

                # âœ… ì§„í–‰ë¥  ì—…ë°ì´íŠ¸ (ì„±ê³µ/ì˜¤ë¥˜ì™€ ë¬´ê´€í•˜ê²Œ ì—…ë°ì´íŠ¸)
                percent = int(i / total * 100)
                progress_bar.progress(percent / 100)
                progress_text.markdown(f"**ì§„í–‰ ì¤‘:** {i}/{total} ({percent}%) ì™„ë£Œ")
                time.sleep(0.05)

            # â± ê²½ê³¼ ì‹œê°„ ê³„ì‚°
            end_time = time.perf_counter()
            elapsed = end_time - start_time
            minutes = int(elapsed // 60)
            seconds = int(elapsed % 60)

            # ìƒíƒœ ì €ì¥
            st.session_state["results"] = results
            st.session_state["error_count"] = error_count

            progress_bar.empty()

            if error_count > 0:
                progress_text.markdown("âš ï¸ **ì²˜ë¦¬ ì™„ë£Œ (ì˜¤ë¥˜ í¬í•¨)** â€” ì¼ë¶€ ë…¼ë¬¸ì—ì„œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ê²°ê³¼ ì»¬ëŸ¼ì—ì„œ 'Error'ë¡œ í™•ì¸í•˜ì„¸ìš”.")
                st.warning(
                    f"âš ï¸ ì²˜ë¦¬ ì™„ë£Œ: ì´ {total}ê°œ ì¤‘ {error_count}ê°œì—ì„œ ì˜¤ë¥˜ ë°œìƒ â€” (ê²½ê³¼ ì‹œê°„: {minutes:02d}:{seconds:02d}, ì•½ {elapsed:.1f}ì´ˆ)"
                )
            else:
                progress_text.markdown("âœ… **ëª¨ë“  ë…¼ë¬¸ ì²˜ë¦¬ ì™„ë£Œ!**")
                st.success(
                    f"âœ… ëª¨ë“  ë…¼ë¬¸ ì²˜ë¦¬ ì™„ë£Œ! Screening ê²°ê³¼ê°€ ì›ë³¸ CSVì˜ ì˜¤ë¥¸ìª½ì— ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤. (ê²½ê³¼ ì‹œê°„: {minutes:02d}:{seconds:02d}, ì•½ {elapsed:.1f}ì´ˆ)"
                )

    # --- ê²°ê³¼ í‘œì‹œ & ì¦‰ì‹œ CSV ë‹¤ìš´ë¡œë“œ ì˜ì—­ ---
    if "results" in st.session_state and st.session_state["results"]:
        st.subheader("ğŸ“Š Screening ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸°")
        st.dataframe(st.session_state.df, use_container_width=True, height=400)

        # âœ… CSV ë‹¤ìš´ë¡œë“œ
        st.subheader("ğŸ“¥ ê²°ê³¼ CSV ë‹¤ìš´ë¡œë“œ")
        include_reason_csv = st.checkbox("ê²°ê³¼ CSVì— íŒë‹¨ ì´ìœ (reason) í¬í•¨", value=True)
        export_df = st.session_state.df.copy()
        export_df = export_df.drop(columns=["select"], errors="ignore")
        if not include_reason_csv:
            reason_cols = [c for c in export_df.columns if c.endswith("_reason")]
            export_df = export_df.drop(columns=reason_cols)
        csv = export_df.to_csv(index=False).encode("utf-8-sig")

        st.download_button("â¬‡ï¸ CSV ë‹¤ìš´ë¡œë“œ", csv, "screening_results.csv", "text/csv")

        # âœ… ì„¸ë¶€ ê·¼ê±°/í˜ì´ì§€ë„¤ì´ì…˜
        total_items = len(st.session_state["results"])
        page_size = 50
        total_pages = max(1, math.ceil(total_items / page_size))

        if "current_page" not in st.session_state or not isinstance(st.session_state["current_page"], int):
            st.session_state["current_page"] = 1

        current_page = max(1, min(st.session_state["current_page"], total_pages))
        start_idx = (current_page - 1) * page_size
        end_idx = min(start_idx + page_size, total_items)

        st.subheader("ğŸ” ì„¸ë¶€ íŒë‹¨ ê·¼ê±° ë³´ê¸°")
        st.caption(
            f"ì´ {total_items}ê°œ ì¤‘ {start_idx + 1}â€“{end_idx} í‘œì‹œ (í˜ì´ì§€ {current_page}/{total_pages}, í˜ì´ì§€ë‹¹ {page_size}ê°œ)"
        )

        page_slice = st.session_state["results"][start_idx:end_idx]
        for r in page_slice:
            color = "ğŸŸ©" if r[result_col_name] == "Yes" else ("ğŸŸ¥" if r[result_col_name] == "No" else "ğŸŸ¨")
            st.markdown(f"### {color} **{r[result_col_name]}** â€” {r['title']}")
            st.markdown(f"ğŸ“„ **Abstract:** {r['abstract'][:300]}{'...' if len(r['abstract']) > 300 else ''}")
            if show_reason and "reason" in r:
                with st.expander("ğŸ’¡ íŒë‹¨ ê·¼ê±° ë³´ê¸°"):
                    st.write(r["reason"])
            st.divider()

        # âœ… í˜ì´ì§€ ë²„íŠ¼
        st.write("í˜ì´ì§€:")
        pages_per_row = 10
        rows = math.ceil(total_pages / pages_per_row)
        for row in range(rows):
            start = row * pages_per_row + 1
            end = min((row + 1) * pages_per_row, total_pages)
            cols = st.columns(end - start + 1)
            for i, p in enumerate(range(start, end + 1)):
                with cols[i]:
                    if st.button(f"{p}", key=f"page_{p}"):
                        st.session_state["current_page"] = p
                        st.rerun()

        # âœ… ì´ì „/ë‹¤ìŒ/ì²˜ìŒ/ë§ˆì§€ë§‰
        c1, c2, c3, c4 = st.columns(4)
        with c1:
            if st.button("â® ì²˜ìŒ"):
                if current_page != 1:
                    st.session_state["current_page"] = 1
                    st.rerun()
        with c2:
            if st.button("â—€ ì´ì „"):
                if current_page > 1:
                    st.session_state["current_page"] = current_page - 1
                    st.rerun()
        with c3:
            if st.button("ë‹¤ìŒ â–¶"):
                if current_page < total_pages:
                    st.session_state["current_page"] = current_page + 1
                    st.rerun()
        with c4:
            if st.button("ë§ˆì§€ë§‰ â­"):
                if current_page != total_pages:
                    st.session_state["current_page"] = total_pages
                    st.rerun()

else:
    st.info("ğŸ“‚ CSV íŒŒì¼ì„ ì—…ë¡œë“œí•˜ë©´ ë…¼ë¬¸ ìŠ¤í¬ë¦¬ë‹ì„ ì‹œì‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
