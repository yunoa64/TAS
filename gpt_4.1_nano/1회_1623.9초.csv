Title,URL/DOI,Abstract,screening_result,screening_result_reason
Metrics of Success: Evaluating User Satisfaction in AI Chatbots,https://doi.org/10.1145/3704137.3704182,"The rapid advancement of Artificial Intelligence (AI), particularly through Large Language Models (LLMs), has catalysed a technological revolution, leading to the widespread adoption of AI-driven chatbots across industries. OpenAI’s customisable generative pre-trained transformer (GPT) offerings have popularised generative AI, enabling organisations of all sizes to implement chatbots for customer support. This development presents an opportunity for businesses to offer 24/7, cost-efficient customer service that can overcome the historical limitations of chatbots that lack a ""human element."" However, despite the proliferation of AI chatbots, there remains a crucial need to evaluate their effectiveness in meeting user needs and preferences for human-like interaction. Current service quality assessment tools, such as SERVQUAL and E-SERVQUAL, are unable to evaluate AI-specific capabilities like language intelligence and recognition. Existing research also lacks information on factors that affect user satisfaction and the continued use of AI chatbots. Based on a mixed-methods study, this paper proposes a new instrument for measuring user satisfaction with AI chatbots, specifically for customer support roles. Using the Stanford five-step Design Thinking Process, this study devised a customer support AI chatbot evaluation instrument through a literature review, Cheatstorming, and SCAMPER techniques, followed by testing in a Danish company. The research employs Prentice and Nguyen’s three-stage scale development process to ensure content, reliability, and construct validity, addressing gaps in current scholarship and advancing understanding of AI chatbot user satisfaction.",Yes,"논문 초록에서 사용자 만족도를 측정하기 위한 새로운 평가 도구를 개발하고, 이를 검증하는 과정을 포함하고 있음을 명확히 언급하고 있습니다. 또한, 연구는 정량적 평가를 위해 신뢰성과 타당성을 확보하는 방법론을 사용했다고 설명하고 있습니다."
Design Principles for Generative AI Applications,https://doi.org/10.1145/3613904.3642466,"Generative AI applications present unique design challenges. As generative AI technologies are increasingly being incorporated into mainstream applications, there is an urgent need for guidance on how to design user experiences that foster effective and safe use. We present six principles for the design of generative AI applications that address unique characteristics of generative AI UX and offer new interpretations and extensions of known issues in the design of AI applications. Each principle is coupled with a set of design strategies for implementing that principle via UX capabilities or through the design process. The principles and strategies were developed through an iterative process involving literature review, feedback from design practitioners, validation against real-world generative AI applications, and incorporation into the design process of two generative AI applications. We anticipate the principles to usefully inform the design of generative AI applications by driving actionable design recommendations.",No,"논문 초록에서는 정량적 평가를 실시했다는 언급이 없으며, 주로 설계 원칙과 전략을 제시하는 내용에 초점이 맞춰져 있습니다. 따라서, 이 논문이 정량적 평가를 수행했다고 보기 어렵습니다."
The Human Side of XAI: Bridging the Gap between AI and Non-expert Audiences,https://doi.org/10.1145/3615335.3623062,"Machine Learning is widely used by practitioners to solve complex challenges. However, despite being trusted by 76% of the public, scientists struggle to explain the rationale behind machine learning-based decisions. This is concerning because research has shown that people often rely on inaccurate machine learning recommendations, even when the system is not confident or they have prior knowledge. To address these issues, there is a crucial need for greater transparency and education around machine learning decision making. In this work, we propose a set of guidelines and design implications to communicate eXplainable Artificial Intelligence models to the general audience. We do this through a literature review of the latest and eXplainable Artificial Intelligence methods and validate these insights through a user study encompassing the participants’ interpretations of the eXplainable Artificial Intelligence solutions. Combining the insights from this mixed-method study, we identify seven main communication guidelines for improving machine learning models understanding. This study contributes to the broader discussion of ethical implications surrounding opaque machine learning models in decision-making. Through the development of guidelines, we hope to bridge the gap between machine learning experts and the public, enabling a better common understanding of its increasing importance in our lives.",Yes,"논문 초록에서 사용자 연구를 통해 통찰을 검증하는 과정을 언급하며, 이를 통해 제시된 가이드라인의 유효성을 평가하는 것으로 보입니다. 또한, 다양한 연구 방법을 활용하여 데이터를 수집하고 분석하는 정량적 또는 정성적 평가를 실시했음을 시사합니다."
What do we know about Hugging Face? A systematic literature review and quantitative validation of qualitative claims,https://doi.org/10.1145/3674805.3686665,"Background: Software Package Registries (SPRs) are an integral part of the software supply chain. These collaborative platforms unite contributors, users, and code for streamlined package management. Prior work has characterized the SPRs associated with traditional software, such as NPM (JavaScript) and PyPI (Python). Pre-Trained Model (PTM) Registries are an emerging class of SPR of increasing importance, because they support the deep learning supply chain. A growing body of empirical research has examined PTM registries from various angles, such as vulnerabilities, reuse processes, and evolution. However, no synthesis provides a systematic understanding of current knowledge. Furthermore, much of the existing research includes non-quantified qualitative observations. Aims: First, we aim to provide a systematic knowledge synthesis. Second, we quantify qualitative claims. Methods: We conducted a systematic literature review (SLR). We then observed that some of the claims are qualitative, lacking quantitative evidence. We identify quantifiable metrics associated with those claims, and measure in order to substantiate these claims. Results: We identify 12 claims about PTM reuse on the HuggingFace platform, 4 of which lack quantitative support. We tested 3 of these claims through a quantitative analysis, and directly compare the fourth with traditional software. Our most notable findings are: (1) PTMs have a significantly higher turnover rate than traditional software, indicating more rapid evolution; and (2) There is a strong correlation between documentation quality and PTM popularity. Conclusions: Our findings validate several qualitative research claims with concrete metrics, confirming prior research. Our measures motivate further research on the dynamics of PTM reuse.",Yes,"논문은 정량적 평가를 수행하기 위해 관련 지표를 식별하고, 이를 통해 4개의 정성적 주장 중 3개를 검증하는 양적 분석을 실시하였음을 명시하고 있습니다. 따라서, 정량적 평가가 이루어지고 있다고 판단됩니다."
AI Integration in the IT Professional Workplace: A Scoping Review and Interview Study with Implications for Education and Professional Competencies,https://doi.org/10.1145/3689187.3709607,"As Artificial Intelligence (AI) continues transforming workplaces globally, particularly within the Information Technology (IT) industry, understanding its impact on IT professionals and computing curricula is crucial. This research builds on joint work from two countries, addressing concerns about AI's increasing influence in IT sector workplaces and its implications for tertiary education. The study focuses on AI technologies such as generative AI (GenAI) and large language models (LLMs). It examines how they are perceived and adopted and their effects on workplace dynamics, task allocation, and human-system interaction. IT professionals, noted as early adopters of AI, offer valuable insights into the interplay between AI and work engagement, highlighting the significant competencies required for digital workplaces. This study employs a dual-method approach, combining a systematic and multi-vocal literature review and qualitative research methods. These included a thematic analysis of a set of 47 interviews conducted between March and May of 2024 with IT professionals in two countries (New Zealand and Sweden). The research aimed to understand the implications for computing students, education curricula, and the assessment of emerging professional competencies. The literature review found insufficient evidence addressing comprehensive AI practice methodologies, highlighting the need to both develop and regulate professional competencies for effective AI integration. Key interview findings revealed diverse levels of GenAI adoption, ranging from individual experimentation to institutional integration. Participants generally expressed positive attitudes toward the technology and were actively pursuing self-learning despite some concerns. The themes emerging from the interviews included AI's role in augmenting human tasks, privacy and security concerns, productivity enhancements, legal and ethical challenges, and the evolving need for new competencies in the workplace. The study underscores the critical role of competency frameworks in guiding professional development and ensuring preparedness for an AI-driven environment. Additionally, it highlights the need for educational institutions to adapt curricula to address these emerging demands effectively.",Yes,"논문은 정량적 연구 방법인 인터뷰를 통해 데이터를 수집하고 분석했으며, 47명의 IT 전문가와의 인터뷰를 통해 다양한 수준의 AI 도입 현황과 관련 태도, 인식 등을 정량적으로 파악하고 있습니다. 이러한 인터뷰 분석은 정량적 평가의 일환으로 볼 수 있습니다."
The impact of Artificial Intelligence on the Socioeconomic factors in the UAE,https://doi.org/10.1145/3639592.3639609,"Artificial Intelligence (AI) is rapidly transforming industries worldwide, including the United Arab Emirates (UAE). As the UAE aims to become a leader in AI adoption and deployment, it is crucial to understand its impact on the country's socioeconomic factors. This research proposal aims to investigate the impact of AI on employment, wage inequality, productivity, innovation, and ethical implications in the UAE. The research will adopt a mixed-methods approach combining a systematic literature review and a quantitative survey to gather and assess data. The literature review will identify relevant literature to establish the research framework, while the survey will target leaders, employees, and end-users of organizations operating in the UAE across various sectors. A sample size of no less than 250 respondents who are predominantly leadership executives will be used, and the survey will consist of 30 questions, including demographic questions, and a 5-point Likert scale to measure respondents’ level of agreement or disagreement with the statements presented. Ethical considerations, including informed consent and anonymity, will be addressed. The findings from this research will contribute to a better understanding of the impact of AI on the socioeconomic factors in the UAE and help inform the development of appropriate policies and strategies for the responsible adoption and deployment of AI technologies in the country. The research proposal presents an exciting opportunity to explore a relevant and timely topic that will shed light on the potential impact of AI on the UAE's socioeconomic development.",Yes,"논문 초록에서 설문조사를 통한 정량적 데이터를 수집하는 방법이 명확히 언급되어 있으며, 5점 Likert 척도를 사용하여 응답자의 의견을 수치화하는 정량적 평가가 실시되고 있음을 알 수 있습니다. 따라서 정량적 평가를 수행하는 것으로 판단됩니다."
Using Generative AI Chatbot for enhancing people's digital participation,https://doi.org/10.1145/3680127.3680194,"Aiming to improve communication and increase the access to available channels and tools, chatbots, or conversational agents, are being used to support people´s digital participation and foster civic engagement. However, conversational agents attend only expected cases of participation, that is, those based on e-consulting, e-decision making and e-informing. Hence, chatbots don´t concern non mapped cases of self-mobilization, besides there are problems in human-computer communication and in the transmission of information caused by digital divide that hinder peoples ‘participation. Literature review indicates that generative AI chatbot shall be used in non-expected interactions between human and conversational agents. Therefore, this paper discusses how chatbots could interact within self-mobilizations’ types of digital participation, concerning obstacles like lack of infrastructure and digital illiteracy. Using design science research, we propose the GenPart, a generative AI-chatbot model for enhancing people´s digital participation. We claim that this artifact can be used by researchers and practitioners who want to promote the integration between people, organizations, and information in digital platforms, promoting citizen participation and civic engagement.",No,"논문 초록에서는 제안된 AI 챗봇 모델인 GenPart의 설계와 활용 방안에 대해 논의하고 있지만, 구체적인 정량적 평가 방법이나 실험 결과에 대한 언급이 없습니다. 따라서 정량적 평가를 실시했다고 보기 어렵습니다."
Using Artificial intelligence for Recycling- A Case Study in Taiwan's Resource Recycling Industry,https://doi.org/10.1145/3624875.3624897,"Resource recycling industries are restricted by the mixed composition of waste, the ratio of recycled material dependent on experience, and the quality inspection relies on physical assessment, resulting in problems such as the inability to optimize manufacturing process parameters and unstable product quality. Artificial Intelligence (AI) has developed rapidly in recent years and adopted in various industries. From literature review, AI is being increasingly used in the resource recycling industry to optimize processes, improve efficiency, and enhance sustainability. This study used machine learning, an AI technology, to conduct model training and identify optimal model validation in Taiwan's resource recycling industry. A case example was implemented to reduce the cost by AI's recommendation of more accurate borax blending ratios. By accepting AI's recommendation of accurate borax blending ratios, it can reduce the non-compliance rate by 45% and at the same time reduce the raw material usage by approximately 2∼3%, saving approximately N.T.D. 1-2 million per year. This study pioneered artificial intelligence technology to improve manufacturing process efficiency and optimization of product quality in the resource recycling industry. The empirical results demonstrate that the application of AI technology contributes to the improvement of traditional manufacturing process problems and enhances the industry's overall production efficiency and quality.",Yes,"논문 초록에서 머신러닝을 활용한 모델 훈련과 검증, 그리고 최적화된 모델의 적용 사례를 언급하며 정량적 평가를 실시했음을 보여줍니다. 또한, AI 추천으로 인한 비용 절감과 품질 향상 등 구체적인 수치와 성과를 제시하고 있어 정량적 평가가 수행된 것으로 판단됩니다."
Ethical Tensions in Applications of AI for Addressing Human Trafficking: A Human Rights Perspective,https://doi.org/10.1145/3555186,"In the last two decades, human trafficking (where individuals are forcibly exploited for the profits of another) has seen increased attention from the artificial intelligence (AI) community. Clear focus on the ethical risks of this research is critical given that those risks are disproportionately born by already vulnerable populations. To understand and subsequently address these risks, we conducted a systematic literature review of computing research leveraging AI to combat human trafficking and apply a framework using principles from international human rights law to categorize ethical risks. This paper uncovers a number of ethical tensions including bias endemic in datasets, privacy risks stemming from data collection and reporting, and issues concerning potential misuse. We conclude by highlighting four suggestions for future research: broader use of participatory design; engaging with other forms of trafficking; developing best practices for harm prevention; and including transparent ethics disclosures in research. We find that there are significant gaps in what aspects of human trafficking researchers have focused on. Most research to date focuses on aiding criminal investigations in cases of sex trafficking, but more work is needed to support other anti-trafficking activities like supporting survivors, adequately address labor trafficking, and support more diverse survivor populations including transgender and nonbinary individuals.",Yes,"논문 초록에서 윤리적 위험을 평가하기 위해 국제 인권법 원칙을 적용하는 프레임워크를 사용했다고 명시되어 있으며, 데이터 편향, 프라이버시 위험, 오용 가능성 등 윤리적 문제를 분석하는 과정이 언급되어 있습니다. 이는 정량적 평가뿐만 아니라 체계적인 분석과 평가를 수행했음을 시사합니다."
A maturity assessment framework for conversational AI development platforms,https://dl.acm.org/doi/10.1145/3412841.3442046,"Conversational Artificial Intelligence (AI) systems have recently sky-rocketed in popularity and are now used in many applications, from car assistants to customer support. The development of conversational AI systems is supported by a large variety of software platforms, all with similar goals, but different focus points and functionalities. A systematic foundation for classifying conversational AI platforms is currently lacking. We propose a framework for assessing the maturity level of conversational AI development platforms. Our framework is based on a systematic literature review, in which we extracted common and distinguishing features of various open-source and commercial (or in-house) platforms. Inspired by language reference frameworks, we identify different maturity levels that a conversational AI development platform may exhibit in understanding and responding to user inputs. Our framework can guide organizations in selecting a conversational AI development platform according to their needs, as well as helping researchers and platform developers improving the maturity of their platforms.",Yes,논문 초록에서 제안하는 프레임워크는 대화형 AI 개발 플랫폼의 성숙도 수준을 평가하는 정량적 평가 방법을 포함하고 있음을 시사합니다. 이를 통해 플랫폼의 성숙도를 체계적으로 측정하고 평가하는 평가 기준이 마련되어 있음을 알 수 있습니다.
Scalable Machine Learning Architectures for IPA-Driven Maintenance Task Allocation in Large-Scale Building Portfolios,https://doi.org/10.1145/3700706.3700734,"This research presents a groundbreaking approach to Building Maintenance Management (BMM) by introducing an Intelligent Process Automation (IPA)-Driven Building Maintenance Management (IBMM) model. This innovative model harnesses the synergies between Artificial Intelligence (AI), Machine Learning (ML), and Internet of Things (IoT) technologies to transition from reactive to proactive and predictive building maintenance strategies. The study highlights the critical gap in current BMM practices—the absence of intelligent systems for anticipating and addressing maintenance issues before they escalate. Through an extensive literature review, the transformative potential of AI and IoT for enhancing building maintenance management within smart cities is explored, establishing a foundation for the IBMM model's application. The core of this research lies in its novel application of scalable machine learning architectures to automate and optimize maintenance task allocation in large-scale building portfolios. The practicality of the IBMM model is demonstrated via a proof of concept (POC) in an industrial setting, evidencing its capacity to improve efficiency, reduce costs, and bolster sustainability in building maintenance operations. The model epitomizes a paradigm shift in BMM by integrating IPA, which combines AI and ML, facilitating automated, intelligent decision-making and task allocation. Among its advancements, the IBMM model introduces enhanced predictive maintenance through real-time data analysis, adaptive learning and optimization, automated decision-making, and human-machine collaboration, contributing to energy efficiency and alignment with smart city objectives. The paper delineates the methodology, design, and implementation of a machine learning model for engineer task assignments, culminating in a case study that validates the model's efficacy. This research not only signifies a significant advancement in BMM by leveraging IPA technologies for autonomous process refinement but also proposes a unique IPA-driven procedure that incorporates IoT technology and a novel smart device fixer to guide BMM processes. Anticipated outcomes include more accurate maintenance scheduling, cost efficiency, enhanced performance, and the fostering of a collaborative community through an open online documentation platform for BMM. Looking forward, the research aims to refine the IBMM model further by exploring advanced AI algorithms for more precise predictive maintenance and integrating real-time data analytics and IoT networks for improved maintenance strategy responsiveness. This work pioneers a smarter, more efficient, and sustainable approach to building maintenance, marking a new era in the management of urban infrastructure.",Yes,"논문 초록에서 머신러닝 아키텍처를 활용한 정량적 평가와 실험적 검증이 언급되어 있으며, 특히 사례 연구를 통해 모델의 효능을 검증하는 내용이 포함되어 있습니다. 이는 정량적 평가가 수행되고 있음을 시사합니다."
Image-based detection and classification of Android malware through CNN models,https://doi.org/10.1145/3664476.3670441,"Convolutional Neural Networks (CNNs) are artificial deep learning networks widely used in computer vision and image recognition for their highly efficient capability of extracting input image features. In the literature, such a successful tool has been leveraged for detection/classification purposes in several application domains where input data are converted into images. In this work, we consider the application of CNN models, developed by employing standard Python libraries, to detect and then classify Android-based malware applications. Different models are tested, even in combination with machine learning-based classifiers, with respect to two datasets of 5000 applications each. To emphasize the adequacy of the various CNN implementations, several performance metrics are considered, as also stressed by a comprehensive comparison with related work.",Yes,"논문 초록에서 다양한 CNN 모델의 성능 평가를 위해 여러 성능 지표를 고려했다고 명시되어 있어, 정량적 평가가 실시되고 있음을 알 수 있습니다. 따라서, 이 연구는 정량적 평가를 수행하는 것으로 판단됩니다."
"Societal, Economic, Political and Environmental: A Review of Benchmarks and AI-assisted Systematic Literature Review of Impact of Open Government Data",https://doi.org/10.1145/3657054.3657121,"The purpose of this research is to review the impact on open government data in evaluation at world level and research in academia. First, six most renowned open government data evaluations are reviewed with their impact section. Then, a systematic literature review on the impact of open government data is conducted with test of AI-assisted software using Preferred Reporting Items for Systematic Review and Meta-Analysis (PRISMA) Protocol, to find the current status of realized open government data impact research. Only four out of six evaluations of open government data have covered impact explicitly, and their criteria counting toward true impact is blur at best. AI-assisted software saves around 30∼40% of reviewing time in this research. Political, social, and economic impacts are all included research topics, however, no environmental impact research. Political impact outperformed other impact, both in quality and quantity. Political capital, not social capital shows more social impact on open government data. Economic impact research of open government data is scarce, and more about the open government data helps urban innovation in China. This research contributes to the open government data research in three ways. First, it reviews impact section major open government data evaluations. Second, it tests the AI-assisted software on the impact of open government data. Third, it sheds light on new research direction for impact of open government data on case study, qualitative research and mixed method.",Yes,"논문은 AI-assisted 소프트웨어를 활용하여 오픈 정부 데이터의 영향을 정량적으로 평가하는 연구를 수행하고 있으며, 평가 기준과 연구 현황을 체계적으로 검토하는 내용을 포함하고 있습니다. 이를 통해 정량적 평가가 실시되고 있음을 알 수 있습니다."
Supporting systematic literature reviews using deep-learning-based language models,https://doi.org/10.1145/3528588.3528658,"Background: Systematic Literature Reviews are an important research method for gathering and evaluating the available evidence regarding a specific research topic. However, the process of conducting a Systematic Literature Review manually can be difficult and time-consuming. For this reason, researchers aim to semi-automate this process or some of its phases. Aim: We aimed at using a deep-learning based contextualized embeddings clustering technique involving transformer-based language models and a weighted scheme to accelerate the conduction phase of Systematic Literature Reviews for efficiently scanning the initial set of retrieved publications. Method: We performed an experiment using two manually conducted SLRs to evaluate the performance of two deep-learning-based clustering models. These models build on transformer-based deep language models (i.e., BERT and S-BERT) to extract contextualized embeddings on different text levels along with a weighted scheme to cluster similar publications. Results: Our primary results show that clustering based on embedding at paragraph-level using S-BERT-paragraph represents the best performing model setting in terms of optimizing the required parameters such as correctly identifying primary studies, number of additional documents identified as part of the relevant cluster and the execution time of the experiments. Conclusions: The findings indicate that using natural-language-based deep-learning architectures for semi-automating the selection of primary studies can accelerate the scanning and identification process. While our results represent first insights only, such a technique seems to enhance SLR process, promising to help researchers identify the most relevant publications more quickly and efficiently.",Yes,"논문 초록에서 두 가지 딥러닝 기반 클러스터링 모델을 평가하는 실험을 수행했다고 명시되어 있으며, 이를 통해 정량적 평가가 이루어졌음을 알 수 있습니다. 따라서, 논문은 정량적 평가를 실시하고 있다고 판단됩니다."
Responsible AI Pattern Catalogue: A Collection of Best Practices for AI Governance and Engineering,https://doi.org/10.1145/3626234,"Responsible Artificial Intelligence (RAI) is widely considered as one of the greatest scientific challenges of our time and is key to increase the adoption of Artificial Intelligence (AI). Recently, a number of AI ethics principles frameworks have been published. However, without further guidance on best practices, practitioners are left with nothing much beyond truisms. In addition, significant efforts have been placed at algorithm level rather than system level, mainly focusing on a subset of mathematics-amenable ethical principles, such as fairness. Nevertheless, ethical issues can arise at any step of the development lifecycle, cutting across many AI and non-AI components of systems beyond AI algorithms and models. To operationalize RAI from a system perspective, in this article, we present an RAI Pattern Catalogue based on the results of a multivocal literature review. Rather than staying at the principle or algorithm level, we focus on patterns that AI system stakeholders can undertake in practice to ensure that the developed AI systems are responsible throughout the entire governance and engineering lifecycle. The RAI Pattern Catalogue classifies the patterns into three groups: multi-level governance patterns, trustworthy process patterns, and RAI-by-design product patterns. These patterns provide systematic and actionable guidance for stakeholders to implement RAI.",No,"논문 초록에서는 책임 있는 AI를 위한 패턴 카탈로그를 제시하며, 이를 기반으로 실천 가능한 가이드라인을 제공한다고 언급하고 있지만, 정량적 평가 방법이나 구체적인 평가 지표에 대한 언급은 없습니다. 따라서, 정량적 평가를 실시하고 있다고 보기 어렵습니다."
Human Factors in the Design of Chatbot Interactions: Conversational Design Practices,https://doi.org/10.1145/3702038.3702083,"Context: Chatbots are intelligent agents that mimic human behavior to carry on meaningful conversations. The conversational nature of chatbots poses challenges to designers since their development is different from other software and requires investigating new practices in the context of human-AI interaction and their impact on user experience. Since human dialogue involves several variables beyond verbalizing words, it is vital to design well-thought dialogues for chatbots to provide a humanized and optimal interaction. Objective: The main objective of this work is to unveil textual, visual, or interactive design practices from text-based chatbot interactions and how they can potentiate or weaken some perceptions and feelings of users, such as satisfaction, engagement, and trust, for the creation of the Guidelines for Chatbot Conversational Design (GCCD) guide. Method: We used multiple research methods to generate and validate the guide. First, we conducted a Systematic Literature Review (SRL) to identify conversational design practices and their impacts. These practices were inserted into the GCCD guide through qualitative analysis and coding of SLR results. Then, the guide was validated quantitatively through a survey and qualitatively through a case study. The survey aimed to assess the guide’s clarity and usefulness based on the reading of the guide by the participants and their responses to a questionnaire adapted from the Technology Acceptance Model. The case study aimed to assess the guide’s usefulness based on its practical application by participants in a situation that simulates a real scenario and follow-up interviews. Results: The survey showed that software developers with different levels of experience strongly agreed that the guide could induce greater user satisfaction and engagement. Furthermore, they also strongly agreed that the guide is clear, understandable, flexible, and easy to use. Although participants suggested some improvements, they reported that the guide’s main strengths are objectivity and clarity. The case study confirmed the survey findings, as participants reported positive feelings toward the guide and an intention to use it. Their extensive perceptions given through the conducted interviews unveiled that their previous experiences with chatbots and in specific software development positions influenced their design and adoption of practices. Conclusion: The guide proved to be useful for developers with different levels of knowledge, with the potential to become a strong ally for developers in the conversational design process.",Yes,"논문은 설문조사와 사례 연구를 통해 정량적 평가를 실시하였음을 명확히 언급하고 있으며, 설문조사를 통해 가이드의 명확성과 유용성을 수치로 평가하는 과정을 포함하고 있습니다. 따라서 정량적 평가가 수행된 것으로 판단됩니다."
Six usable privacy heuristics,https://doi.org/10.1145/3638067.3638111,"Enhancing privacy policy interfaces is crucial for improving users’ trust in technology and ensuring compliance with legislation. This thesis focused on developing usable interfaces that enable laypeople to protect their online privacy. Through a comprehensive analysis, including literature review, thematic and cluster analysis, and empirical evaluation, six usable privacy heuristics (push#) are established. These heuristics effectively identify catastrophic problems in privacy policy interfaces for laypeople. Additionally, preliminary usable privacy guidelines (pug#) are created, and a new process for developing usability criteria is proposed. Future research directions are suggested, including the application of these heuristics and guidelines to domains like human-robot interaction and human-artificial intelligence interaction.",Yes,"논문 초록에서 ""empirical evaluation""이라는 표현이 포함되어 있어, 정량적 평가를 실시했음을 시사합니다. 또한, 개발된 휴리스틱과 가이드라인의 유효성을 검증하기 위해 실험적 평가가 수행되었을 가능성이 높습니다."
A Survey of Trustworthy Representation Learning Across Domains,https://doi.org/10.1145/3657301,"As AI systems have obtained significant performance to be deployed widely in our daily lives and human society, people both enjoy the benefits brought by these technologies and suffer many social issues induced by these systems. To make AI systems good enough and trustworthy, plenty of researches have been done to build guidelines for trustworthy AI systems. Machine learning is one of the most important parts of AI systems, and representation learning is the fundamental technology in machine learning. How to make representation learning trustworthy in real-world application, e.g., cross domain scenarios, is very valuable and necessary for both machine learning and AI system fields. Inspired by the concepts in trustworthy AI, we proposed the first trustworthy representation learning across domains framework, which includes four concepts, i.e., robustness, privacy, fairness, and explainability, to give a comprehensive literature review on this research direction. Specifically, we first introduce the details of the proposed trustworthy framework for representation learning across domains. Second, we provide basic notions and comprehensively summarize existing methods for the trustworthy framework from four concepts. Finally, we conclude this survey with insights and discussions on future research directions.",No,"논문 초록에서는 신뢰성 있는 표현 학습에 대한 개념적 프레임워크와 기존 연구들을 종합적으로 검토하는 내용을 다루고 있으며, 구체적인 정량적 평가 방법이나 실험 결과에 대한 언급이 없습니다. 따라서 정량적 평가를 실시하고 있다고 보기 어렵습니다."
A Reproducibility and Generalizability Study of Large Language Models for Query Generation,https://doi.org/10.1145/3673791.3698432,"Systematic literature reviews (SLRs) are a cornerstone of academic research, yet they are often labour-intensive and time-consuming due to the detailed literature curation process. The advent of generative AI and large language models (LLMs) promises to revolutionize this process by assisting researchers in several tedious tasks, one of them being the generation of effective Boolean queries that will select the publications to consider including in a review. This paper presents an extensive study of Boolean query generation using LLMs for systematic reviews, reproducing and extending the work of Wang et al. and Alaniz et al. Our study investigates the replicability and reliability of results achieved using ChatGPT and compares its performance with open-source alternatives like Mistral and Zephyr to provide a more comprehensive analysis of LLMs for query generation. Therefore, we implemented a pipeline, which automatically creates a Boolean query for a given review topic by using a previously defined LLM, retrieves all documents for this query from the PubMed database and then evaluates the results. With this pipeline we first assess whether the results obtained using ChatGPT for query generation are reproducible and consistent. We then generalize our results by analyzing and evaluating open-source models and evaluating their efficacy in generating Boolean queries. Finally, we conduct a failure analysis to identify and discuss the limitations and shortcomings of using LLMs for Boolean query generation. This examination helps to understand the gaps and potential areas for improvement in the application of LLMs to information retrieval tasks. Our findings highlight the strengths, limitations, and potential of LLMs in the domain of information retrieval and literature review automation. Our code is available online.",Yes,"논문 초록에서 LLMs의 성능을 평가하기 위해 재현성, 신뢰성, 효율성 등을 분석하는 과정을 언급하며, 이를 위해 실험적 평가와 비교 분석이 수행되었음을 알 수 있습니다. 이러한 평가 과정은 정량적 평가를 포함하는 것으로 보입니다."
AI-Powered Digital Media Platform and Its Applications,https://doi.org/10.1145/3433996.3434018,"Previously, the main method to create digital media such as animation was by humans. With the development of artificial intelligence technology, the work of making media content from raw materials is gradually replaced by computers. In this paper, we conceive a digital media production and interaction platform supported by artificial intelligence, based on some existing artificial intelligence and virtual reality display technologies. We also discuss the feasibility of some possible application scenarios for this platform.Based on our literature review and feasibility analysis, we conclude that current technology development is capable of supporting the AI-powered digital media platform that we propose in this paper.",No,"논문 초록에서는 정량적 평가에 대한 구체적인 언급이 없으며, 기술 개발과 가능성에 대한 논의에 초점이 맞춰져 있습니다. 따라서, 이 논문이 정량적 평가를 실시했다고 보기 어렵습니다."
Intelligent Food Recommendation Framework Based on Social Media Behavioral Data,https://doi.org/10.1145/3660853.3660883,"This research introduces an Intelligent Food Recommendation Framework leveraging social media Behavioral Data, explicitly focusing on Instagram. It posits that users' engagements with food-related content on Instagram offer insights into their food preferences, thereby enhancing the precision of food type recommendations. The investigation aims to substantiate this assertion through a thorough literature review, data source selection, comparison of food assessment surveys, exploration of image recognition methodologies, and deployment and validation of the proposed solution framework utilizing deep learning models. Through interdisciplinary efforts, the study seeks to advance personalized recommendation systems in the context of food consumption.",Yes,"논문 초록에서 딥러닝 모델을 활용한 검증과 평가를 언급하며, 제안된 프레임워크의 배포와 검증 과정을 포함하고 있음을 시사합니다. 이는 정량적 평가가 수행되고 있음을 의미합니다."
Research on Artistic Design Methods for Chinese Traditional Font Elements Based on AIGC Technology,https://doi.org/10.1145/3677892.3677966,"This study explores the integration of traditional Chinese font elements with Artificial Intelligence Generated Content technology, aiming to develop innovative design workflow. The research investigates three key aspects: analyzing the visual features and cultural significance of traditional Chinese fonts, exploring the application of AIGC technology in font art design, and proposing an artistic design workflow based on the Stable Diffusion algorithm. The methodology involves: (1) conduct a literature review to study the background of AIGC technology, (2) establishing a project direction, (3) exploring traditional font elements through interdisciplinary collaboration, (4) creating font prototypes, (5) utilizing a locally deployed Stable Diffusion model to generate stylized font designs. (6) Evaluates the practical effects of these designs, highlighting both the advantages and limitations of the design workflow. The results showed that the design methodology workflow largely met the expected outcomes in cultural relevance, diversity, practicality, and creativity. However, the stability rating was lower, primarily due to Stable Diffusion's current limitations in recognizing traditional Chinese elements, leading to instability in generating details of Chinese traditional font elements. This issue was particularly evident in Chinese ink painting styles, brushstroke fonts, and color rendering, highlighting the necessity for further training in these areas.",Yes,"논문 초록에서 ""evaluates the practical effects of these designs""와 같은 표현을 통해 정량적 평가가 수행되었음을 시사하며, 또한 디자인의 안정성 평가와 한계 분석이 포함되어 있어 정량적 평가가 실시된 것으로 판단됩니다."
Unmasking Data Secrets: An Empirical Investigation into Data Smells and Their Impact on Data Quality,https://doi.org/10.1145/3644815.3644960,"Artificial Intelligence (AI) is rapidly advancing with a data-centered approach suitable for various domains. Nevertheless, AI faces significant challenges, particularly in data quality. Data collection from diverse sources can introduce quality issues that may threaten the development of AI-enabled systems. A growing concern in this context is the emergence of data smells - issues specific to the data used in building AI models, which can have long-term consequences. In this paper, we aim at enlarging the current body of knowledge on data smells, by proposing a two-step investigation into the matter. First, we updated an existing literature review in an effort of cataloguing the currently existing data smells and the tools to detect them. Afterward, we assess the prevalence of data smells and their correlation with data quality metrics. We identify a novel set composed of 12 data smells distributed across three additional categories. Secondly, we observe that the correlation between data smells and data quality is notably impactful, exhibiting a pronounced and substantial effect, especially in highly diffused data smell instances. This research sheds light on the complex relationship between data smells and data quality, providing valuable insights into the challenges of maintaining AI-enabled systems.",Yes,"논문은 데이터 냄새와 데이터 품질 지표 간의 상관관계를 평가하는 정량적 분석을 수행하고 있습니다. 또한, 데이터 냄새의 유병률과 그 영향력을 수치적으로 측정하는 연구를 포함하고 있어 정량적 평가를 실시하고 있음을 알 수 있습니다."
Bridging Multimedia Modalities: Enhanced Multimodal AI Understanding and Intelligent Agents,https://doi.org/10.1145/3577190.3614225,"With the increasing availability of multimodal data, especially in the sports and medical domains, there is growing interest in developing Artificial Intelligence (AI) models capable of comprehending the world in a more holistic manner. Nevertheless, various challenges exist in multimodal understanding, including the integration of multiple modalities and the resolution of semantic gaps between them. The proposed research aims to leverage multiple input modalities for the multimodal understanding of AI models, enhancing their reasoning, generation, and intelligent behavior. The research objectives focus on developing novel methods for multimodal AI, integrating them into conversational agents with optimizations for domain-specific requirements. The research methodology encompasses literature review, data curation, model development and implementation, evaluation and performance analysis, domain-specific applications, and documentation and reporting. Ethical considerations will be thoroughly addressed, and a comprehensive research plan is outlined to provide guidance. The research contributes to the field of multimodal AI understanding and the advancement of sophisticated AI systems by experimenting with multimodal data to enhance the performance of state-of-the-art neural networks.",No,"초록에서는 다양한 연구 방법론이 언급되고 있지만, 구체적인 정량적 평가 방법이나 실험 결과에 대한 언급이 포함되어 있지 않습니다. 따라서 논문이 정량적 평가를 실시하는지 여부를 확실히 판단하기 어렵습니다."
GANs in the Panorama of Synthetic Data Generation Methods,https://doi.org/10.1145/3657294,"This article focuses on the creation and evaluation of synthetic data to address the challenges of imbalanced datasets in machine learning (ML) applications, using fake news detection as a case study. We conducted a thorough literature review on generative adversarial networks (GANs) for tabular data, synthetic data generation methods, and synthetic data quality assessment. By augmenting a public news dataset with synthetic data generated by different GAN architectures, we demonstrate the potential of synthetic data to improve ML models’ performance in fake news detection. Our results show a significant improvement in classification performance, especially in the underrepresented class. We also modify and extend a data usage approach to evaluate the quality of synthetic data and investigate the relationship between synthetic data quality and data augmentation performance in classification tasks. We found a positive correlation between synthetic data quality and performance in the underrepresented class, highlighting the importance of high-quality synthetic data for effective data augmentation.",Yes,"논문 초록에서 다양한 GAN 아키텍처를 이용한 합성 데이터의 품질 평가와 데이터 증강 성능 간의 관계를 조사했다고 명시되어 있습니다. 또한, 데이터 품질과 분류 성능 간의 상관관계를 분석하는 등 정량적 평가를 실시한 것으로 보입니다."
Formalizing Multimedia Recommendation through Multimodal Deep Learning,https://doi.org/10.1145/3662738,"Recommender systems (RSs) provide customers with a personalized navigation experience within the vast catalogs of products and services offered on popular online platforms. Despite the substantial success of traditional RSs, recommendation remains a highly challenging task, especially in specific scenarios and domains. For example, human affinity for items described through multimedia content (e.g., images, audio, and text), such as fashion products, movies, and music, is multi-faceted and primarily driven by their diverse characteristics. Therefore, by leveraging all available signals in such scenarios, multimodality enables us to tap into richer information sources and construct more refined user/item profiles for recommendations. Despite the growing number of multimodal techniques proposed for multimedia recommendation, the existing literature lacks a shared and universal schema for modeling and solving the recommendation problem through the lens of multimodality. Given the recent advances in multimodal deep learning for other tasks and scenarios where precise theoretical and applicative procedures exist, we also consider it imperative to formalize a general multimodal schema for multimedia recommendation. In this work, we first provide a comprehensive literature review of multimodal approaches for multimedia recommendation from the last eight years. Second, we outline the theoretical foundations of a multimodal pipeline for multimedia recommendation by identifying and formally organizing recurring solutions/patterns; at the same time, we demonstrate its rationale by conceptually applying it to selected state-of-the-art approaches in multimedia recommendation. Third, we conduct a benchmarking analysis of recent algorithms for multimedia recommendation within Elliot, a rigorous framework for evaluating recommender systems, where we re-implement such multimedia recommendation approaches. Finally, we highlight the significant unresolved challenges in multimodal deep learning for multimedia recommendation and suggest possible avenues for addressing them. The primary aim of this work is to provide guidelines for designing and implementing the next generation of multimodal approaches in multimedia recommendation.",Yes,"논문 초록에서 ""benchmarking analysis""와 ""re-implement""라는 표현을 통해 여러 최신 알고리즘을 평가하는 정량적 실험이 수행되었음을 시사합니다. 또한, ""rigorous framework""와 ""formalize""라는 용어를 사용하여 정량적 평가와 관련된 체계적인 방법론이 포함되어 있음을 알 수 있습니다."
Study of sustainable supply chain management in the healthcare industry,https://doi.org/10.1145/3625469.3625480,"Objective -The Objective of this research is to identify the key attributes of a sustainable health care supply chain. This paper presents a new, four-dimensional model, consisting of social, economic, environmental and technological dimensions. Design/Methodology/Approach-The proposed research methodology involved four independent variables leading to an efficient, sustainable SCM framework for the healthcare industry, which were identified based on the research gaps, solidly supported by latest quality literature review. The data are gathered using a Likert scale questionnaire together with a scheduled interview. The study adopted a quantitative survey approach to randomly collect and analyzed the primary data from a large sample of 400 supply chain and health care executives and was analyzed statistically using Adanco 2.3.2. The findings were further analyzed to search for areas that necessitate research to understand a sustainable SCM framework to gain a competitive edge and operational efficiency, reduce costs and improve profitability with societal impact on socio-economic, environmental factors and technological factors. Quantitative analysis tools include reliability indicators, convergent validity, discriminant validity, multicollinearity etc. All are supported by structural equation model (SEM) justifying the hypothesis formulated. Findings & Research Outcome- The goals of green supply chain management are to eliminate or minimize waste, reduce environmental impacts (air and water pollution) and avoid wasting resources. It has a significant positive outcome on costs, waste disposal, resource consumption and greenhouse emissions. Technology was found to have a positive outcome on supply chain management through customized information technology, use of block chain, Artificial intelligence (AI) and machine learning, smart practices implementation, sophisticated IT applications and user-friendly smartphone interface. The use of technology improves automation, reduces counterfeit medicines and ensures secure data storage. Social dimension was found to have positive outcome on sustainable supply management through perceived value preposition, customer satisfaction index, informational quality, fair operating practices and Involvement and relationship level, which are measured by outcome of achievement of social sustainability.",Yes,"논문은 설문조사와 통계 분석을 통해 정량적 데이터를 수집하고, 신뢰도, 타당도 검증, 구조 방정식 모델(SEM) 등을 활용하여 정량적 평가를 실시하고 있음을 명확히 제시하고 있습니다. 이러한 방법들은 정량적 평가의 핵심 요소를 충족합니다."
Measuring the Desirability of an Intelligent Advisor for Predicting the Perceived Quality of News Articles,https://doi.org/10.1145/3609987.3610009,"Abstract. This paper presents the initial findings of the iQJournalism system’s prototype, an effort to create an intelligent advisor for predicting the perceived quality of news articles. Accordingly, artificial intelligence methodologies are utilized, with the purpose of providing real-time recommendations to journalists looking to improve the overall quality and engagement of their articles. The iQJournalism is designed using a user-centered design approach, in order to facilitate the specific needs of the journalists and editors using it. In this paper we discuss preliminary results of a study that was conducted with 20 users. Following an extensive literature review and the insights of a focus group with 10 professional journalists and MSc students, we created an interactive prototype of the iQJournalism system. The main aim is to facilitate the interaction of the users with the computational layer of the system for estimating the perceived quality of an article before its release. We organized a moderated desirability (light usability) study, in order to capture the users’ feedback. We used user experience and usability measurement tools like UEQ, SUS, Product reaction cards, perceived satisfaction and system adoption items, and open-ended questions to collect more comprehensive insights around the acceptance and usefulness of our prototype. Initial results show an overall favorable user experience, effective and efficient interaction when users engage with a series of situation-specific tasks.",Yes,"논문 초록에서 사용자 경험과 유용성 평가를 위해 UEQ, SUS, 제품 반응 카드, 인지된 만족도, 시스템 채택 항목 등 정량적 평가 도구를 사용했다고 명시되어 있습니다. 따라서, 정량적 평가를 실시하고 있다고 판단됩니다."
Supporting Novice Researchers to Write Literature Review using Language Models,https://doi.org/10.1145/3613905.3650787,"A literature review requires more than summarization. While language model-based services and systems increasingly assist in analyzing accurate content in papers, their role in supporting novice researchers to develop independent perspectives on literature remains underexplored. We propose the design and evaluation of a system that supports the writing of argumentative narratives from literature. Based on the barriers faced by novice researchers before, during, and after writing, identified through semi-structured interviews, we propose a prototype of a language-model-assisted academic writing system that scaffolds the literature review writing process. A series of workshop studies revealed that novice researchers found the support valuable as they could initiate writing, co-create satisfying contents, and develop agency and confidence through a long-term dynamic partnership with the AI.",No,"논문 초록에서는 언어 모델을 활용한 시스템의 설계와 평가에 대해 언급하고 있지만, 정량적 평가를 실시했다는 구체적인 언급은 없습니다. 대신 워크숍 연구와 지원의 가치에 대한 언급이 주를 이루고 있어, 정량적 평가의 실시 여부를 확실히 알 수 없습니다."
Integrating Ethics within Machine Learning Courses,https://doi.org/10.1145/3341164,"This article establishes and addresses opportunities for ethics integration into Machine-learning (ML) courses. Following a survey of the history of computing ethics and the current need for ethical consideration within ML, we consider the current state of ML ethics education via an exploratory analysis of course syllabi in computing programs. The results reveal that though ethics is part of the overall educational landscape in these programs, it is not frequently a part of core technical ML courses. To help address this gap, we offer a preliminary framework, developed via a systematic literature review, of relevant ethics questions that should be addressed within an ML project. A pilot study with 85 students confirms that this framework helped them identify and articulate key ethical considerations within their ML projects. Building from this work, we also provide three example ML course modules that bring ethical thinking directly into learning core ML content. Collectively, this research demonstrates: (1) the need for ethics to be taught as integrated within ML coursework, (2) a structured set of questions useful for identifying and addressing potential issues within an ML project, and (3) novel course models that provide examples for how to practically teach ML ethics without sacrificing core course content. An additional by-product of this research is the collection and integration of recent publications in the emerging field of ML ethics education.",No,"논문 초록에서는 정량적 평가를 실시한 사례가 언급되지 않으며, 주로 윤리 교육의 필요성과 프레임워크 개발, 그리고 파일럿 스터디에 대한 설명이 중심입니다. 따라서 정량적 평가를 수행했다고 보기 어렵습니다."
Fighting organized crime by automatically detecting money laundering-related financial transactions,https://dl.acm.org/doi/abs/10.1145/3465481.3469196,"Money laundering is the set of operations aimed at giving a legitimate appearance to capital whose origin is illegal, thus making it more difficult to identify and subsequently recover it. It is one of the phenomena on which the so-called underground economy relies and therefore constitutes a crime for which the charge for money laundering applies. For supporting the fight against this phenomenon, the interest towards analysis models for Anti-Money Laundering (AML) based on a combined use of automatic tools and artificial intelligence (AI) techniques increases, as it is also shown by the European Central Bank (ECB) during recent press conferences. Following this direction, this paper proposes a model for enhancing the detection of suspicious transactions related to money laundering. It is based on a set of features that are defined by considering different aspects such as the time, the amount of money, number of transactions, type of operations and level of internationalization. An AI-based computational approach centered on Machine Learning (ML) techniques has been adopted to evaluate the goodness of such feature-based model, in supporting the automatic detection of suspicious transactions, by experimenting 5 different classifiers. From the experiments emerged that the Random Forest provided the best performance not only among the classifiers tested within the paper, but also in comparison to those presented in the related work with an accuracy, a recall and f1-score greater than 94% by decreasing the False Positive Rate (FPR). Furthermore, an analysis on the feature importance has been provided, to understand which feature, among the proposed ones, plays the major role in such application domain.",Yes,"논문 초록에서 여러 머신러닝 분류기를 실험하여 성능 평가를 수행했다고 명확히 언급하고 있으며, 정확도, 재현율, F1-스코어 등 정량적 지표를 제시하고 있습니다. 이는 정량적 평가가 실시되고 있음을 보여줍니다."
Evaluation of an Ensemble Technique for Prediction of Crop Yield,https://doi.org/10.1145/3647444.3647833,"Crop yield prediction plays a crucial role in agricultural management and decision-making processes. Traditional approaches to crop yield prediction often face limitations in terms of accuracy and robustness due to the complex and dynamic nature of agricultural systems. Machine learning is an emerging technology to understand practical and real world use cases for agricultural production. Machine learning is a supporting tool for the agricultural production which helps to make decisions on what crops to be cultivated, crop yield prediction and crop management practices. In this research paper, we propose ensemble techniques to improve crop yield prediction accuracy. Ensemble methods such as bagging, boosting, and stacking that combine multiple models to improve their predictive power which have shown promising results in various domains. We collected a comprehensive dataset consisting of historical crop yield data, weather information, and soil characteristics. The data underwent pre-processing steps, including cleaning, normalization, and feature engineering. We developed an ensemble model architecture, selecting appropriate base models and training them using a validation process. To evaluate the effectiveness of an ensemble technique for predicting crop yield, several factors should be considered such as data, ensemble composition, evaluation metrics, generalizability and interpretability. Important parameters related to climatic conditions such as rainfall, humidity, soil type and temperature were taken into consideration for crop yield prediction. From literature review, it is understanding that Decision Tree, Random Forest and Neural Networks are the algorithms mostly used. The proposed work compared Random Forest and Boosting algorithms based on the score like Mean Squared Error (MSE), Mean Absolute Error (MAE) and R2 score to improve the weak learner for most expected outcome. Finally concluded that ensemble of Random Forest with Gradient Boosting Regressor achieved more accuracy and most expected outcome. At the same time, Mean Squared Error(MSE), Mean Absolute Error(MAE) were smaller in the proposed work. The results demonstrated that the ensemble technique consistently outperformed individual models, achieving higher prediction accuracy and reducing prediction errors. Our findings suggest that ensemble techniques are promising for improving crop yield prediction, offering more robust and accurate insights for agricultural planning and decision-making.",Yes,"논문 초록에서 여러 평가 지표(예: MSE, MAE, R2 score)를 사용하여 앙상블 기법의 성능을 정량적으로 평가했다고 명확히 언급하고 있습니다. 또한, 다양한 모델과 방법의 비교를 통해 예측 정확도를 수치로 제시하며 평가를 수행하고 있음을 알 수 있습니다."
SOTERIA: Preserving Privacy in Distributed Machine Learning,https://doi.org/10.1145/3555776.3578591,"We propose Soteria, a system for distributed privacy-preserving Machine Learning (ML) that leverages Trusted Execution Environments (e.g. Intel SGX) to run code in isolated containers (enclaves). Unlike previous work, where all ML-related computation is performed at trusted enclaves, we introduce a hybrid scheme, combining computation done inside and outside these enclaves. The conducted experimental evaluation validates that our approach reduces the runtime of ML algorithms by up to 41%, when compared to previous related work. Our protocol is accompanied by a security proof, as well as a discussion regarding resilience against a wide spectrum of ML attacks.",Yes,"논문 초록에서 실험 평가를 통해 ML 알고리즘의 실행 시간을 비교하는 내용을 언급하고 있으며, 구체적인 성능 향상 수치(최대 41% 감소)를 제시하고 있어 정량적 평가를 실시하고 있음을 알 수 있습니다."
Witnessing Erosion of Membership Inference Defenses: Understanding Effects of Data Drift in Membership Privacy,https://doi.org/10.1145/3607199.3607224,"Data drift is the phenomenon when the input data distribution in testing time is different from the training time. This strengthens the generalization gap in a model, which is known to severely deteriorate the model’s performance. Meanwhile, previous studies state that membership inference attacks (MIA) take advantage of the generalization gap of a machine learning model. By transitive logic, we can deduce that data drift would affect these privacy attacks. In this work, we consider data drift when applied to the privacy threat of MIA. As the first work to explore the detrimental extent of data drift on membership privacy, we conduct a literature review on current MIA defense works under selected dimensions associated with data drift. Our study reveals that not only has data drift never been tested in MIA defense, but there is also no infrastructure to juxtapose data drift with MIA defense. We overcome this by proposing a design for simulating authentic and synthetic data drift and evaluate the benchmark MIA defense methods on various settings. The evaluation shows that data drift strongly enhances the attack success rate of MIA, regardless of defense. In this, we propose MIAdapt, a proof of concept of a MIA defense that allows update in data drift. From this evaluation, we provide security insight into possible solutions in negating the effects of data drift. We hope our work brings attention to the threat of data drift and instigates the development of MIA defense that are adaptable to data drift.",Yes,"논문은 다양한 설정에서 MIA 방어 방법들을 평가하기 위해 벤치마크 실험을 수행하며, 평가 결과를 통해 데이터 드리프트가 공격 성공률에 미치는 영향을 분석하고 있습니다. 이를 통해 정량적 평가가 이루어지고 있음을 알 수 있습니다."
Context sight: model understanding and debugging via interpretable context,https://doi.org/10.1145/3546930.3547502,"Model interpretation is increasingly important for successful model development and deployment. In recent years, many explanation methods are introduced to help humans understand how a machine learning model makes a decision on a specific instance. Recent studies show that contextualizing an individual model decision within a set of relevant examples can improve the model understanding. However, there is a lack of systematic study on what factors are considered when generating and using the context examples to explain model predictions, and how context examples help with model understanding and debugging in practice. In this work, we first identify a taxonomy of context generation and summarization through literature review. We then present Context Sight, a visual analytics system that integrates customized context generation and multiple-level context summarization to assist context exploration and interpretation. We evaluate the usefulness of the system through a detailed use case. This work is an initial step for a set of systematic research on how contextualization can help data scientists and practitioners understand and diagnose model behaviors, based on which we will gain a better understanding of the usage of context.",No,"논문 초록에서는 모델 이해와 디버깅을 돕기 위한 시각적 분석 시스템인 Context Sight를 제안하고 있으며, 주로 설명 방법과 시스템 개발에 초점을 맞추고 있다. 정량적 평가에 대한 구체적인 언급이 없으며, 시스템의 유용성을 평가하는 방법이 상세히 설명되지 않아 정량적 평가를 실시했다고 보기 어렵다."
Open-ended questions automated evaluation: proposal of a new generation,https://doi.org/10.1145/3632971.3632980,"Abstract. Exams grading for the knowledge validation to recognise competences is an essential element for any learning process. There are two main modes for their evaluation: subjective and automated. Subjective evaluation is accused of many flaws such as the inconsistency of the human corrector and the time it requires. Automating the assessment of open-ended questions saves a lot of time, provides quick feedback to learners and ensures the consistency expected from the human correctors. However, this is a challenging problem to implement because the computer does not have the same faculties as a human. To address this issue, we conducted a literature review on open-ended questions automated evaluation to implement an automatic exam grading system with similar or even higher accuracy than a human corrector. This study allows us to classify the different approaches in three generations: “bag of words” based approaches, classical semantic similarity-based approaches and machine learning based approaches. The third generation offers the best state-of-the-art results despite criticism of it. These approaches rely on neural networks which need to have a large dataset for effective training. To tackle this handicap, we propose a fourth generation (section 3). This contribution relies on the use of pre-trained models for which a dataset for training is not necessary knowing that they are zero-shot-learners. After implementing our architecture, we conducted our experiments with the three main French-speaking models available on Hugging Face. The best model agrees with the human corrector at 96%.",Yes,"논문 초록에서 자동 평가 시스템의 정확도를 높이기 위해 다양한 접근 방식을 제시하고 있으며, 특히 neural networks와 pre-trained models를 활용한 방법을 통해 정량적 평가를 실시하고 있음을 언급하고 있습니다. 이러한 내용은 정량적 평가의 수행을 의미합니다."
Accessible Web Development: Opportunities to Improve the Education and Practice of web Development with a Screen Reader,https://doi.org/10.1145/3458024,"There are a growing number of jobs related to web development, yet there is little formal literature about the accessibility of web development with a screen reader. This article describes research to explore (1) web development accessibility issues and their impact on blind learners and programmers; (2) tools and strategies used to address issues; and (3) opportunities for creating inclusive web development curriculum and supportive tools. We conducted a Comprehensive Literature Review (CLR) to formulate accessibility issue categories, then interviewed 12 blind programmers to validate and expand on both issues in education and practice. The CLR yielded five issue categories: (1) visual information without an accessible equivalent, (2) orienting, (3) navigating, (4) lack of support, and (5) knowledge and use of supportive technologies. Our interview findings validated the use of CLR-derived categories and revealed nuances specific to learning and practicing web development. Blind web developers grapple with the inaccessibility of demonstrations and explanations of web design concepts, wireframing software, independent verification of computed Cascading Style Sheets (CSS), and navigating browser-based developer tool interfaces. Tools and strategies include seeking out alternative education materials to learn independently, use of CSS frameworks, collaboration with sighted colleagues, and avoidance of design and front-end development. This work contributes to our understanding of accessibility issues specific to web development and the strategies that blind web developers employ in both educational and applied contexts. We identify areas in which greater awareness and application of accessibility best practices are required in Web education, a need to disseminate existing screen reader strategies and accessible tools, and to develop new tools that support Web design and validation of CSS. Finally, this research signals future directions for the development of accessible web curriculum and supportive tools, including solutions that leverage artificial intelligence, tactile graphics, and supportive-online communities of practice.",No,"논문 초록에서는 웹 개발 접근성 문제와 관련된 연구를 설명하고 있지만, 정량적 평가를 수행했음을 나타내는 구체적인 언급이나 데이터 분석 내용이 포함되어 있지 않습니다. 주로 문헌 검토와 인터뷰를 통한 질적 연구 방법이 강조되고 있습니다."
A Machine Learning Based Load Value Approximator Guided by the Tightened Value Locality,https://doi.org/10.1145/3583781.3590207,"This paper addresses two essential memory bottlenecks: 1) memory wall, and 2) bandwidth wall. To accomplish this objective, we propose a machine learning (ML) based model that estimates the values to be loaded from the memory by a wide range of error-resilient applications. The proposed model exploits the feature of tightened value locality, which consists of a periodic load of few unique values. The proposed ML-based load value approximator (LVA) requires minimal overhead as it relies on a hash that encodes the history of events, e.g., history of accessed addresses, and values that can be extracted from the load instruction to be approximated. The proposed LVA completely eliminates memory accesses, i.e., 100% of accesses, in runtime and thus addresses the issue of memory wall and bandwidth wall. Compared to related work, our LVA delivers a maximum accuracy of 95.16% while offering a higher reduction in memory accesses.",Yes,"논문 초록에서 ""maximum accuracy of 95.16%""라는 표현을 통해 정량적 평가를 실시하고 있음을 알 수 있습니다. 또한, 제안된 모델의 성능을 수치로 제시하여 평가하고 있음을 확인할 수 있습니다."
A Design Space for Intelligent Dialogue Augmentation,https://doi.org/10.1145/3708359.3712096,"The use of intelligent agents in communication is a growing trend aimed at enhancing the efficiency and quality of interactions. As such, dialogue augmentation systems—text processing systems that interactively enhance ongoing written or spoken communication—are gaining significant popularity across domains. While technical limitations had previously inhibited their real-time usage for effective communication augmentation, recent developments in language processing have improved their capabilities to contribute to dialogue as intelligent, emancipated, and proactive agents. While other works on dialogue augmentation focus on evaluating design considerations for specific applications of these systems, we lack a unified understanding of the broader design principles that apply to dialogue more generally. Through a literature review and mixed-methods analysis of 78 existing systems, we iteratively define a comprehensive design space for intelligent dialogue augmentation systems. To further ground our analysis, we interweave Clark’s [27] models of dialogue with concepts in human-AI collaboration and discuss trends in the evolving role of dialogue augmentation systems along five dimensions—dialogue context, augmentation context, task, interaction, and model. Based on the identified trends, we discuss concrete challenges for broader adoption, highlighting the need to design trusted, seamless, and timely, and accessible augmentations. The design space contributes as a mechanism for researchers to facilitate defining design choices during development, situate their systems in the current landscape of works, and understand opportunities for future research.",Yes,"논문 초록에서 ""mixed-methods analysis""와 ""define a comprehensive design space""라는 표현을 통해 정량적 평가와 분석이 수행되었음을 알 수 있습니다. 이러한 방법들은 데이터를 수집하고 분석하여 평가하는 정량적 평가의 일환으로 볼 수 있습니다."
An Enhanced Random Forests Approach to Predict Heart Failure From Small Imbalanced Gene Expression Data,https://doi.org/10.1109/TCBB.2020.3041527,"Myocardial infarctions and heart failure are the cause of more than 17 million deaths annually worldwide. ST-segment elevation myocardial infarctions (STEMI) require timely treatment, because delays of minutes have serious clinical impacts. Machine learning can provide alternative ways to predict heart failure and identify genes involved in heart failure. For these scopes, we applied a Random Forests classifier enhanced with feature elimination to microarray gene expression of 111 patients diagnosed with STEMI, and measured the classification performance through standard metrics such as the Matthews correlation coefficient (MCC) and area under the receiver operating characteristic curve (ROC AUC). Afterwards, we used the same approach to rank all genes by importance, and to detect the genes more strongly associated with heart failure. We validated this ranking by literature review and gene set enrichment analysis. Our classifier employed to predict heart failure achieved MCC = +0.87 and ROC AUC = 0.918, and our analysis identified KLHL22, WDR11, OR4Q3, GPATCH3, and FAH as top five protein-coding genes related to heart failure. Our results confirm the effectiveness of machine learning feature elimination in predicting heart failure from gene expression, and the top genes found by our approach will be able to help biologists and cardiologists further our understanding of heart failure.",Yes,논문 초록에서 분류 성능 평가를 위해 Matthews correlation coefficient (MCC)와 ROC AUC와 같은 정량적 지표를 사용했다고 명확히 언급하고 있습니다. 이는 정량적 평가를 실시하고 있음을 보여줍니다.
Use of Artificial Intelligence in the Personalisation of In-vehicle Interaction Interfaces,https://doi.org/10.1145/3672919.3672950,"This study proposes a theoretical architecture model of an AI-driven in-vehicle interactive system, optimizing and adjusting key aspects such as target group selection, driving stages, consumer needs, interaction modes, and interface design through detailed demonstration. It emphasizes the personalization factor and proposes a model more aligned with the user's personalized needs by subdividing the driving stages and analyzing consumer needs. In terms of interaction modes, attention is paid to the integration of clicks, voice control, gestures, sliding, and other interaction methods to improve the flexibility of the user's operating experience. In terms of interface design, through elements such as colour, icons, typography, and fonts, combined with the automatic optimization of AI, personalized design is achieved to adapt better to the user's driving situation and preferences. Overall, this model aims to improve in-vehicle interactive systems' performance and user experience and provide a valuable reference for the future intelligent driving field. The study also profoundly explores the application of AI in the personalized design of vehicle interactive interfaces through a literature review and empirical cases, providing critical insights into achieving personalization and intelligence for future vehicle interaction design.",No,"논문 초록에서는 AI 기반 시스템의 설계와 사용자 맞춤화에 대한 이론적 모델과 사례 분석을 제시하고 있지만, 구체적인 정량적 평가 방법이나 실험 데이터에 대한 언급은 없습니다. 따라서 정량적 평가를 실시했다고 보기 어렵습니다."
A Weight-Based Channel Pruning Algorithm for Depth-Wise Separable Convolution Unit,https://doi.org/10.1145/3508546.3508568,"Deep learning has become the hotspot of academia and industry, and has found its wide applications in many fields, especially computer vision. However, the computational and storage cost of the CNN model is now a headache to researchers. The famous model structures such as AlexNet, VGG and ResNet, are all going wider and deeper. Then it becomes hard to deploy these models on mobile and embedded devices. Accordingly, the model lightweight method is desiderated. This paper adapts the channel pruning method to features of the depth-wise separable convolution unit and its variant. By using the united prune ratio setting, the additional sparsity restraint, and the certain dataset preprocessing, our experiments show higher accuracy on the CIFAR-10 dataset than related work in some cases.",No,"초록에서는 제안된 방법이 채널 가지치기와 관련된 실험을 수행했음을 언급하지만, 구체적인 정량적 평가 방법이나 수치적 성과 지표에 대한 언급이 없습니다. 따라서 논문이 정량적 평가를 실시했는지 여부를 확실히 판단하기 어렵습니다."
Influence of MRI modality on accuracy of deep learning segmentation of abdominal organs,https://doi.org/10.1145/3441369.3441379,"Learning to segment MRI sequences is an exciting current application of deep learning networks. Most recent related work on this issue propose architecture modifications and ensembles with voting to try to improve the quality of the result. One relevant issue that also deserves further investigation is how the MRI modality influences quality of segmentation. In this paper we discuss two well-known MRI modalities (T1-DUAL and T2-SPIR) and compare the quality of segmentation with each. We build and train three segmentation network architectures, then evaluate them with the two modalities to evaluate. We conclude that segmentation of T1-DUAL modality achieves around 6% higher IoU than T2-SPIR for our experimental dataset. Based on the results we conclude that, from the perspective of segmentation performance, T1-DUAL exhibits better contrast to individualize abdominal organs.",Yes,논문 초록에서 두 가지 MRI 모달리티(T1-DUAL과 T2-SPIR)를 비교하여 정량적 평가 지표인 IoU(Intersection over Union)를 사용하여 성능 차이를 분석하고 있음을 명확히 언급하고 있습니다. 이를 통해 정량적 평가가 실시되고 있음을 알 수 있습니다.
Sojourn Time Minimization of Successful Jobs,https://doi.org/10.1145/3561074.3561083,"Due to a growing interest in deep learning applications [5], compute-intensive and long-running (hours to days) training jobs have become a significant component of datacenter workloads. A large fraction of these jobs is often exploratory, with the goal of determining the best model structure (e.g., the number of layers and channels in a convolutional neural network), hyperparameters (e.g., the learning rate), and data augmentation strategies for the target application. Notably, training jobs are often terminated early if their learning metrics (e.g., training and validation accuracy) are not converging, with only a few completing successfully. For this motivating application, we consider the problem of scheduling a set of jobs that can be terminated at predetermined checkpoints with known probabilities estimated from historical data. We prove that, in order to minimize the time to complete the first K successful jobs on a single server, optimal scheduling does not require preemption (even when preemption overhead is negligible) and provide an optimal policy; advantages of this policy are quantified through simulation. Related Work. While job scheduling has been investigated extensively in many scenarios (see [6] and [2] for a survey of recent result), most policies require that the cost of waiting times of each job be known at scheduling time; in contrast, in our setting the scheduler does not know which job will be the K-th successful job, and sojourn times of subsequent jobs do not contribute to the target metric. For example, [4, 3] minimize makespan (i.e., the time to complete all jobs) for known execution times and waiting time costs; similarly, Gittins index [1] and SR rank [7] minimize expected sojourn time of all jobs, i.e., both successfully completed jobs and jobs terminated early. Unfortunately, scheduling policies not distinguishing between these two types of jobs may favor jobs where the next stage is short and leads to early termination with high probability, which is an undesirable outcome in our applications of interest.",No,"논문 초록에서는 성공적인 작업의 소요 시간을 최소화하는 최적 정책을 제시하고 시뮬레이션을 통해 그 효과를 정량적으로 평가하는 내용을 포함하고 있지만, 구체적인 정량적 평가 방법이나 수치적 결과를 명시적으로 수행하는지에 대한 언급은 없습니다. 따라서, 정량적 평가를 실시하고 있다고 확실히 판단하기 어렵습니다."
Current methods for quality control in manufacturing companies in the Czech Republic,https://doi.org/10.1145/3361785.3361788,"The fourth industrial revolution (Industry 4.0) fundamentally transforms modern production, thanks to new technological achievements including digitalization, robotization, artificial intelligence, etc. With the advent of the Industry 4.0 concept, many new technologies are coming into the field of production. Technologies such as the Internet of Things, autonomous robots, big data, additive manufacturing or QR codes have emerged. These modern technologies can be implemented to different areas of production but we are mainly focused on big data and following data mining application in quality management, especially product quality control. Academic literature is paying increased attention to this topic but the question arises: Are these modern methods also already deployed for quality control in the real manufacturing companies in the Czech Republic? The paper aims to respond to this and several more questions. For the purpose of this research, a structured questionnaire has been distributed to manufacturing companies from various specializations and different sizes in the Czech Republic. In the first part of this study, we made a comparison of current trends in manufacturing (mainly in quality control) according to the critical literature review and findings from the questionnaires describing the real situation of the companies. We investigated that only 7.73% of asked companies use some of data mining methods for quality control. On the 5% success rate we say that used methods can probably depend on the company's location, the Chi-square test proved it by result of 0.9153. Contrariwisely we found out that used methods do not depend on company's size based on results from the Chi-square test value (5.108e-05).",Yes,"논문 초록에서 데이터 마이닝 방법이 품질 관리를 위해 사용되고 있는지에 대한 조사와 분석이 이루어졌으며, 이를 정량적으로 평가하기 위해 통계적 검증(Chi-square test)을 실시한 내용이 포함되어 있습니다. 따라서, 정량적 평가가 수행되고 있다고 판단됩니다."
SOVEREIGN - Towards a Holistic Approach to Critical Infrastructure Protection,https://doi.org/10.1145/3664476.3671410,"In the digital age, cyber-threats are a growing concern for individuals, businesses, and governments alike. These threats can range from data breaches and identity theft to large-scale attacks on critical infrastructure. The consequences of such attacks can be severe, leading to financial losses, threats to national security, and the loss of lives. This paper presents a holistic approach to increase the security of critical infrastructures. For that, we propose an open, self-configurable, and AI-based automated cyber-defense platform that runs on specifically hardened devices and own hardware, can be deeply embedded in critical infrastructures and provides full visibility on network, endpoints, and software. In this paper, starting from a thorough analysis of related work, we describe the vision of our SOVEREIGN platform in the form of an architecture, discuss individual building blocks, and evaluate it qualitatively with respect to our requirements.",No,"The abstract mentions that the proposed system is evaluated qualitatively, but it does not indicate that any quantitative assessment or measurement has been conducted. Therefore, based on the provided information, the paper does not appear to include a quantitative evaluation."
Reconstruction-based anomaly detection for the cloud: A comparison on the Yahoo! Webscope S5 dataset,https://doi.org/10.1145/3416921.3416934,"The detection of anomalies in cloud metrics is an important way to identify suspicious data instances that indicate a system problem such as hardware failures, performance bottlenecks or intrusions. Yet, especially in a cloud computing infrastructure where the amount and variety of services is constantly increasing, it is getting more and more challenging to monitor and maintain the system manually. Thus, it is beneficial to use machine learning to detect anomalies at least partially in an automated way. The contribution of this paper is two-folded: firstly, we evaluate three unsupervised, reconstruction-based methods for anomaly detection (PCA, Autoencoder, LSTM-Encoder-Decoder) on the Yahoo! Webscope S5 benchmark dataset. Secondly, we compare our chosen models to a widely-used density-based approach and show that our reconstruction-based approaches outperform the related work.",Yes,"논문 초록에서 세 가지 재구성 기반 방법(PCA, Autoencoder, LSTM-Encoder-Decoder)을 평가했다고 명시되어 있으며, 이들 방법의 성능을 비교하는 과정에서 정량적 평가가 이루어졌음을 알 수 있습니다. 따라서, 논문은 정량적 평가를 실시하고 있다고 판단됩니다."
A Flexible Toolflow for Mapping CNN Models to High Performance FPGA-based Accelerators,https://doi.org/10.1145/3543622.3573131,"There have been many studies on developing automatic tools for mapping CNN models onto FPGAs. However, challenges remain in designing an easy-to-use toolflow. First, the toolflow should be able to handle models exported from various deep learning frameworks and models with different topologies. Second, the hardware architecture should make better use of on-chip resources to achieve high performance. In this work, we build a toolflow upon Open Neural Network Exchange (ONNX) IR to support different DL frameworks. We also try to maximize the overall throughput via multiple hardware-level efforts. We propose to accelerate the convolution operation by applying parallelism not only at the input and output channel level, but also at the output feature map level. Several on-chip buffers and corresponding management algorithms are also designed to leverage abundant memory resources. Moreover, we employ a fully pipelined systolic array running at 400 MHz as the convolution engine, and develop a dedicated bus to implement the im2col algorithm and provide feature inputs to the systolic array. We generated 4 accelerators with different systolic array shapes and compiled 12 CNN models for each accelerator. Deployed on a Xilinx VCU118 evaluation board, the performance of convolutional layers can reach 3267.61 GOPS, which is 99.72% of the ideal throughput (3276.8 GOPS). We also achieve an overall throughput of up to 2424.73 GOPS. Compared with previous studies, our toolflow is more user-friendly. The end-to-end performance of the generated accelerators is also better than that of related work at the same DSP utilization.",Yes,"논문 초록에서 성능 측정 결과와 성능 지표(GOPS 등)를 제시하며, 다양한 CNN 모델과 하드웨어 구성에 대해 정량적 평가를 수행했음을 보여줍니다. 이를 통해 논문이 정량적 평가를 실시하고 있음을 알 수 있습니다."
Fairify: Fairness Verification of Neural Networks,https://doi.org/10.1109/ICSE48619.2023.00134,"Fairness of machine learning (ML) software has become a major concern in the recent past. Although recent research on testing and improving fairness have demonstrated impact on real-world software, providing fairness guarantee in practice is still lacking. Certification of ML models is challenging because of the complex decision-making process of the models. In this paper, we proposed Fairify, an SMT-based approach to verify individual fairness property in neural network (NN) models. Individual fairness ensures that any two similar individuals get similar treatment irrespective of their protected attributes e.g., race, sex, age. Verifying this fairness property is hard because of the global checking and non-linear computation nodes in NN. We proposed sound approach to make individual fairness verification tractable for the developers. The key idea is that many neurons in the NN always remain inactive when a smaller part of the input domain is considered. So, Fairify leverages white-box access to the models in production and then apply formal analysis based pruning. Our approach adopts input partitioning and then prunes the NN for each partition to provide fairness certification or counterexample. We leveraged interval arithmetic and activation heuristic of the neurons to perform the pruning as necessary. We evaluated Fairify on 25 real-world neural networks collected from four different sources, and demonstrated the effectiveness, scalability and performance over baseline and closely related work. Fairify is also configurable based on the domain and size of the NN. Our novel formulation of the problem can answer targeted verification queries with relaxations and counterexamples, which have practical implications.",Yes,"논문은 신경망 모델의 개별 공정성 검증을 위해 SMT 기반의 정량적 분석 방법을 제안하고 있으며, 이를 통해 공정성 인증 또는 반례를 제공하는 정량적 평가를 실시하고 있습니다. 또한, 평가 결과를 통해 방법의 효과성과 성능을 검증하는 실험도 수행하고 있어 정량적 평가가 이루어지고 있음을 알 수 있습니다."
Spatial-Net: A Self-Adaptive and Model-Agnostic Deep Learning Framework for Spatially Heterogeneous Datasets,https://doi.org/10.1145/3474717.3483970,"Knowledge discovery from spatial data is essential for many important societal applications including crop monitoring, solar energy estimation, traffic prediction and public health. This paper aims to tackle a key challenge posed by spatial data - the intrinsic spatial heterogeneity commonly embedded in their generation processes - in the context of deep learning. In related work, the early rise of convolutional neural networks showed the promising value of explicit spatial-awareness in deep architectures (i.e., preservation of spatial structure among input cells and the use of local connection). However, the issue of spatial heterogeneity has not been sufficiently explored. While recent developments have tried to incorporate awareness of spatial variability (e.g., SVANN), these methods either rely on manually-defined space partitioning or only support very limited partitions (e.g., two) due to reduction of training data. To address these limitations, we propose a Spatial-Net to simultaneously learn a space-partitioning scheme and a deep network architecture with a Significance-based Grow-and-Collapse (SIG-GAC) framework. SIG-GAC allows collaborative training between partitions and uses an exponential reduction tree to control the network size. Experiments using real-world datasets show that Spatial-Net can automatically learn the pattern underlying heterogeneous spatial process and greatly improve model performance.",No,"논문 초록에서는 Spatial-Net이 공간적 이질성을 학습하는 데 초점을 맞추고 있으며, 실험을 통해 성능 향상을 보여주고 있지만, 정량적 평가 방법이나 구체적인 평가 지표에 대한 언급은 없습니다. 따라서 정량적 평가를 실시했다고 확실히 판단하기 어렵습니다."
Machine learning for accessible web navigation,https://doi.org/10.1145/3493612.3520463,"This research looks at the application of Machine Learning to Web Accessibility. It considers how Machine Learning (ML) can be used to help make the processes of Web Navigation more accessible in line with Web Content Accessibility Guideline (WCAG) 2.4 Navigable, which demands that ways be provided ""to help users navigate, find content, and determine where they are."" ML techniques such as reinforcement learning have been applied to website navigation in diverse ways. These include goal-directed search to answer questions and task-oriented problems such as booking a flight. Related work includes Web Automation and Testing. These techniques typically involve a state space exploration where actions such as clicking links, filling forms, and pressing buttons move the agent to a new state. The search space can be represented as a directed graph whose nodes represent the state. The choice of action involves a reward in reinforcement learning, which is used to learn behavior. Sequences of actions are collected into policies and the objective is to identify the best policy. For many websites, the potential search space is exceptionally large, and these techniques can provide ways of navigating them more efficiently. While the outcomes of these approaches can help to make the processes of search and task completion easier and thereby help accessibility, it is not the primary focus. The question under consideration is whether these techniques can be adapted to improve the website's navigability from an accessibility perspective. The approach seems promising. The state-space can be explored automatically, and the state representation can then be mined using ML techniques for structure, content and other information, which has the potential to improve accessibility Examples of the application of these approaches, which reflect the goals of the success criteria around WCAG Guideline 2.1 would include the generation of good anchor text for links where this is not provided, optimizing pathways to website functionality, and optimizing the processes of querying the website. There are open questions about how state representation can be enhanced to improve the prospects of reaching goal states. For example, can the process of calculating reward exploit features such as Search Engine Optimization information, which is designed to reflect the purpose of the page directly? Indexing techniques from Information science can serve a similar purpose. From an accessibility standpoint, there are exciting directions to explore. For example, what role can accessibility features, e.g., Headings, Anchor Text, and alternative text, play in calculating rewards. By way of illustration, a case study on one of these page enhancement techniques, DocTTTTTQuery, will be presented. This enhances a document by generating potential queries from its content. The system is trained by matching these generated questions against a set of historical questions asked of the site. This knowledge can then be exploited to lead the user more directly to potential answers to queries. Other studies have shown the effectiveness of this approach. Augmenting the page with these queries has shown improved search performance.",Yes,"논문 초록에서는 강화 학습과 같은 머신러닝 기법을 활용하여 웹 탐색의 효율성을 높이고, 접근성을 개선하는 방법을 연구하고 있음을 언급하며, 이러한 평가 방법이 포함될 가능성을 시사합니다. 또한, 페이지 향상 기술과 관련된 사례 연구를 통해 구체적인 실험이나 평가가 수행되었음을 암시하므로 정량적 평가가 실시되고 있다고 판단됩니다."
Predictive analytics in healthcare epileptic seizure recognition,https://dl.acm.org/doi/10.5555/3291291.3291327,"Introduction Clinical applications of electroencephalography (EEG) span a very broad range of diagnostic conditions. Epileptic seizure is the fourth most common neurological disorder in that. Related Work There has been considerable progress in clinical understanding of epilepsy, however many aspects of seizure prevention are still a mystery. Predictive modeling of EEG can provide significant value addition to substantiate the diagnosis of epilepsy. Methodology Machine learning algorithms are applied to predict the probability of epileptic seizure using an open source multi-class dataset. Results and Discussion Comparing the F-score from different classifiers, it is found that XGBoost gives the best performance in binary classification and Random Forest provides the best performance in multinomial classification. Conclusion Our results show that it is possible to predict epileptic seizure with significant accuracy from non-epileptic parameters using a suitable machine learning algorithm. We also observe that binary classification methods have higher prediction accuracy.",Yes,"논문 초록에서 여러 머신러닝 알고리즘의 성능을 비교하는 과정이 언급되어 있으며, F-score와 같은 정량적 평가 지표를 사용하여 모델의 성능을 평가했다고 명시되어 있습니다. 따라서, 정량적 평가를 실시하고 있다고 판단됩니다."
The challenge of detecting sophisticated attacks: Insights from SOC Analysts,https://doi.org/10.1145/3230833.3233280,"The ever-increasing rate of sophisticated cyber-attacks and its subsequent impact on networks has remained a menace to the security community. Existing network security solutions, including those applying machine learning algorithms, often centre their detection on the identification of threats in individual network events, which is proven inadequate in detecting sophisticated multi-stage attacks. Similarly, SOC analysts whose roles involve detecting advanced threats are faced with a significant amount of false-positive alerts from the existing tools. Their ability to detect novel attacks or variants of existing ones is limited by the lack of expert input from SOC analysts in their creation of the tools; and the use of features that are closely linked to the structure of specific malware which detection models aim to identify. In this work, we conduct a literature review on malware detection tools, reflect on the features used in these approaches and extend the feature-set with novel ones identified by interviewing experienced SOC analysts. We conduct thematic analysis to the qualitative data obtained from the interviews, and our results indicate not only the presence novel generic malware characteristics based on network and application events (web proxy, firewall, DNS), but identify valuable lessons for developing effective SOCs regarding their structure and processes.",No,"논문 초록은 주로 문헌 검토, 인터뷰 및 정성적 분석을 통해 특징을 확장하고, SOC 분석가의 역할과 구조에 대한 통찰을 제공하는 연구임을 보여줍니다. 정량적 평가 또는 수치 데이터를 기반으로 한 실험이나 평가가 언급되지 않아 정량적 평가를 실시하고 있다고 보기 어렵습니다."
Evaluating visual analytics for text information retrieval,https://doi.org/10.1145/3472301.3484320,"Retrieving information from document collections is necessary in many contexts, for example, researchers wish to retrieve papers on a research topic, physicians search for patient records related to a certain condition, police investigators seek for relationships in criminal reports. Common to these scenarios are users in need of identifying relevant textual information in a document collection. The task is challenging, especially when users hope for a retrieval process that misses none or very few of the relevant documents. Visual Analytics (VA) approaches are often advocated to support document retrieval tasks. VA relies on integrating interactive visualizations and machine learning algorithms so that a domain expert can gradually steer a system into identifying the relevant documents. As an example, TRIVIR is a state-of-the-art system that allows exploring a corpus while providing feedback to a classifier that suggests potentially relevant documents to a reference query document. Assessing VA-supported Information Retrieval (IR) strategies is also challenging, as using these systems typically involves many conceptual and practical aspects and text retrieval tasks can demand considerable cognitive effort. In this paper, we present results from observational studies on VA-supported text information retrieval. We conducted sessions with graduate students and researchers using TRIVIR to explore scientific papers for purposes of literature review. A first study allowed us to collect opinions and identify some usability issues and practical limitations of the available implementation. After handling some critical issues observed at the interface level, we conducted a second round of sessions in order to collect further user opinions regarding a retrieval process assisted with VA. We concluded that most users have a very positive view of the system's usability and its ability to facilitate their retrieval tasks. Nonetheless, we also learnt that a proper introduction to the role of the interface elements is important and that conveying the underlying conceptual model and its limitations can be difficult. We observed considerable variation in user assessment of the specific functionalities and some users may face practical difficulties in using the system autonomously in an optimal way.",Yes,"논문 초록에서 VA 지원 텍스트 정보 검색의 평가를 위해 관찰 연구를 수행했다고 명시되어 있으며, 사용자 의견 수집과 시스템의 유용성 평가를 통해 정량적 또는 정성적 평가를 실시했음을 시사합니다. 따라서, 논문은 정량적 평가를 포함하고 있다고 판단됩니다."
UX Research on Conversational Human-AI Interaction: A Literature Review of the ACM Digital Library,https://doi.org/10.1145/3491102.3501855,"Early conversational agents (CAs) focused on dyadic human-AI interaction between humans and the CAs, followed by the increasing popularity of polyadic human-AI interaction, in which CAs are designed to mediate human-human interactions. CAs for polyadic interactions are unique because they encompass hybrid social interactions, i.e., human-CA, human-to-human, and human-to-group behaviors. However, research on polyadic CAs is scattered across different fields, making it challenging to identify, compare, and accumulate existing knowledge. To promote the future design of CA systems, we conducted a literature review of ACM publications and identified a set of works that conducted UX (user experience) research. We qualitatively synthesized the effects of polyadic CAs into four aspects of human-human interactions, i.e., communication, engagement, connection, and relationship maintenance. Through a mixed-method analysis of the selected polyadic and dyadic CA studies, we developed a suite of evaluation measurements on the effects. Our findings show that designing with social boundaries, such as privacy, disclosure, and identification, is crucial for ethical polyadic CAs. Future research should also advance usability testing methods and trust-building guidelines for conversational AI.",Yes,"논문 초록에서 ""a suite of evaluation measurements""를 개발했다고 언급하며, 이를 통해 정량적 평가를 실시하고 있음을 시사합니다. 또한, ""mixed-method analysis""를 통해 다양한 평가 방법을 활용한 것으로 보입니다."
Discovering important source code terms,https://doi.org/10.1145/2889160.2891037,"Terms in source code have become extremely important in Software Engineering research. These ""important"" terms are typically used as input to research tools. Therefore, the quality of the output of these tools will depend on the quality of the term extraction technique. Currently, there is no definitive best technique for predicting the importance of terms during program comprehension. In my work, I perform a literature review of several techniques. I then propose a unified importance prediction model based on a machine learning algorithm. I evaluate my model in a field study involving professional programmers, as well as a standard 10-fold synthetic study. I found that my model predicts the top quartile of most-important source code terms with approximately 50% precision and recall, outperforming tf/idf and other popular techniques. Furthermore, I found that, during actual program comprehension tasks, the predictions from my model help programmers equivalent to a real set of most-important terms.",Yes,"논문은 머신러닝 알고리즘을 기반으로 한 중요도 예측 모델을 평가하는 실험을 수행하고 있으며, 정밀도와 재현율을 측정하는 정량적 평가를 실시하고 있습니다. 또한, 표준 10-폴드 교차 검증과 현장 연구를 통해 평가 결과를 제시하고 있어 정량적 평가가 이루어지고 있음을 알 수 있습니다."
Social Transparency in Network Monitoring and Security Systems,https://dl.acm.org/doi/abs/10.1145/3626705.3627773,"System administrators (sysadmins) are key to keeping computer networks safe. As networks grow in size and complexity, partial workflow automation with the help of AI has been introduced to assist them. However, AI-aided tools often lack transparency, which may lead to the sysadmin’s reluctance to use the new software, slower response time in case of a security breach, and increasing errors. Related work suggests that the concept of social transparency (ST), when applied to the IT-security context, enables peer support and could provide the missing knowledge to the user facilitating explainability of the system and improving human-AI trust. In this paper, we investigate the profile of sysadmins and confirm that ST can indeed yield benefits for them but only when coupled with relevant contextual information and only when it adheres to the sysadmins’ quality standards. Finally, we contribute design recommendations for incorporating ST into the existing workflows of sysadmins.",No,"The abstract primarily discusses the concept of social transparency and its potential benefits for system administrators, but it does not mention any specific quantitative evaluation or measurement methods. Therefore, it does not indicate that a quantitative assessment was conducted in the study."
Agents in the Computing Continuum: the MLSysOps Perspective,https://dl.acm.org/doi/10.5555/3639940.3639991,"Multi-agent systems (MASs) have gained considerable attention in the field of distributed computing due to their ability to provide technical interoperability, resource sharing and flexible coordination. Consequently, MAS are well-suited to address the challenges posed by the distributed and heterogeneous nodes within the device-edge-cloud continuum, including orchestration and standardization, optimal resource allocation,micro service placement policies, security and privacy.The objective of this study is to introduce the MLSysOps project, which aims at the autonomous management of the entire continuum tackling some of the challenges mentioned before. MLSysOps utilizes a hierarchical agent-based AI architecture to interface with the underlying resource management and application deployment/orchestration mechanisms. A comparative analysis is conducted between the existing related work and the proposed framework, highlighting the peculiarities and advantages of our approach.",No,"논문 초록에서는 정량적 평가에 대한 언급이 없으며, 주로 시스템의 개념적 소개와 비교 분석에 초점을 맞추고 있다. 따라서, 이 논문이 정량적 평가를 실시하고 있다고 보기 어렵다."
Towards smartphone-based sensing of social interaction for ambulatory assessment,https://doi.org/10.1145/2800835.2801642,"In ambulatory assessment, especially when handling subjects with personality disorders, it is important to monitor the subject's social interactions. Smartphones are already applied to assess information via self-reports. Related work also uses them to log context information or prompt event-specific self-reports. We see a high potential for them to be used for monitoring social interactions in in-field studies as they are constant companions in real life and a platform for virtual interactions. Our system will apply pattern recognition and machine learning algorithms to physical sensor measurements such as microphone and radio signals, but also to virtual sensor information such as call and message history and activity of messaging apps. We will evaluate to which extent and how well our system can automatically and unobtrusively find indicators for social interactions and, based on them, identify anomalies in the subject's behavior.",Yes,논문 초록에서 패턴 인식과 머신러닝 알고리즘을 적용하여 사회적 상호작용의 지표를 자동으로 찾고 이상 행동을 식별하는 평가를 수행한다고 명시되어 있습니다. 이는 정량적 평가를 실시하는 것으로 해석할 수 있습니다.
A Clairvoyant Approach to Evaluating Software (In)Security,https://doi.org/10.1145/3102980.3102991,"Nearly all modern software has security flaws---either known or unknown by the users. However, metrics for evaluating software security (or lack thereof) are noisy at best. Common evaluation methods include counting the past vulnerabilities of the program, or comparing the size of the Trusted Computing Base (TCB), measured in lines of code (LoC) or binary size. Other than deleting large swaths of code from project, it is difficult to assess whether a code change decreased the likelihood of a future security vulnerability. Developers need a practical, constructive way of evaluating security. This position paper argues that we actually have all the tools needed to design a better, empirical method of security evaluation. We discuss related work that estimates the severity and vulnerability of certain attack vectors based on code properties that can be determined via static analysis. This paper proposes a grand, unified model that can predict the risk and severity of vulnerabilities in a program. Our prediction model uses machine learning to correlate these code features of open-source applications with the history of vulnerabilities reported in the CVE (Common Vulnerabilities and Exposures) database. Based on this model, one can incorporate an analysis into the standard development cycle that predicts whether the code is becoming more or less prone to vulnerabilities.",Yes,"논문 초록에서 머신러닝을 활용한 예측 모델을 제안하며, 이를 통해 소프트웨어 취약성의 위험과 심각도를 정량적으로 평가하는 방법을 논의하고 있기 때문에 정량적 평가를 실시하고 있다고 판단됩니다."
Cognitive Discovery: Accelerating Technical R&amp;D with AI,https://doi.org/10.1145/3369583.3393610,"Cognitive Discovery is an overarching framework that uses AI to achieve scientific knowledge extraction and representation, to intelligently design and guide simulations, in order to drastically accelerate the pace of scientific discovery. Cognitive Discovery targets to accelerate scientific workflows in technical disciplines and provide a new generation of tools. The workflows follow the cycle: a) Massive literature review in order to understand the problem at hand. Literature refers to all aspects such as mathematical modelling, solution methods, actual computer models and HPC deployment. b) Enrichment of literature data with experimental data and formation of hypotheses. c) Running simulations to test hypotheses and generate new knowledge in order to close any knowledge gaps. All three phases suffer today major disruptions. Simply put: the volume of new literature is exploding (e.g. roughly 450K new publications in materials science are published every year, tens of thousands of papers in numerical and HPC methods need to be reviewed). IoT advances as well as advances in measuring all aspects of HPC systems create an explosion of data. High fidelity models lead to massive configuration spaces the complexity of which clearly outpaces our capability to scale and efficiently run modern HPC systems. We will showcase how AI can help dramatically improve this setting and lead to a massive acceleration for scientific discovery.",No,"논문 초록에서는 AI를 활용한 과학적 지식 추출, 시뮬레이션 설계 및 가이드에 대해 설명하고 있지만, 구체적인 정량적 평가 방법이나 실험이 수행되었다는 언급은 없습니다. 따라서 정량적 평가를 실시하고 있다고 보기 어렵습니다."
AI Governor for the Quality and the Strength of Bridges,https://doi.org/10.1145/3407982.3408020,"Construction architectures draw a new world pattern. Designing innovative shapes and their building cost a fortune and investors expect the relevant return in money and population benefits. Some of the representative examples of expensive constructive creativity are wide highways, bridges, skyscrapers, grand halls, malls, tall flats, etc. Each newly started or finalized construction must operate with a smart fault-tolerant risk management mechanism because the world has been a witness of many construction failures. They lead to additional reversible and irreversible damages, some of which cost people's lives. In 2018 the road viaduct in Genoa collapsed. As a result of the tragedy, at least thirty-eight people died, thirty-five cars and three trucks fall. In the basement of that collapse are a wrong construction project, the neglected need for reconstruction and the lack of a system to inform citizens about the bridge condition. Such accidents bear the question of how to prevent similar situations in advanced. Bridge engineering is difficult for standardization, therefore there is a need for a new technique to handle the issue. The authors of the report examine the way modern information and communication technologies impact quality control. The researchers make a relevant scientific literature review. They explore qualitative, quantitative and statistical methods of evaluation and apply computer comparison and modelling to create a new form for measuring and controlling the quality and strength of bridges. The new model introduces an AI governor for bridge management and a self-learning machine to adapt existing construction standards and to create new ones according to the situation and environmental conditions. The proposed solution incorporates real-time data analyses.",Yes,"논문 초록에서 ""qualitative, quantitative and statistical methods of evaluation""을 언급하며, 이를 활용한 평가 방법을 적용하고 있다고 명시되어 있습니다. 또한, 실시간 데이터 분석과 컴퓨터 비교 및 모델링을 통해 품질과 강도를 측정하는 새로운 모델을 제안하고 있어 정량적 평가를 실시하고 있음을 알 수 있습니다."
Critical-Reflective Human-AI Collaboration: Exploring Computational Tools for Art Historical Image Retrieval,https://dl.acm.org/doi/10.1145/3610054,"Just as other disciplines, the humanities explore how computational research approaches and tools can meaningfully contribute to scholarly knowledge production. Building on related work from the areas of CSCW and HCI, we approach the design of computational tools through the analytical lens of 'human-AI collaboration.' Such work investigates how human competencies and computational capabilities can be effectively and meaningfully combined. However, there is no generalizable concept of what constitutes 'meaningful' human-AI collaboration. In terms of genuinely human competencies, we consider criticality and reflection as guiding principles of scholarly knowledge production and as deeply embedded in the methodologies and practices of the humanities. Although (designing for) reflection is a recurring topic in CSCW and HCI discourses, it has not been centered in work on human-AI collaboration. We posit that integrating both concepts is a viable approach to supporting 'meaningful' human-AI collaboration in the humanities and other qualitative, interpretivist, and hermeneutic research areas. Our research, thus, is guided by the question of how critical reflection can be enabled in human-AI collaboration. We address this question with a use case that centers on computer vision (CV) tools for art historical image retrieval. Specifically, we conducted a qualitative interview study with art historians to explore a) what potentials and affordances art historians ascribe to human-AI collaboration and CV in particular, and b) in what ways art historians conceptualize critical reflection in the context of human-AI collaboration. We extended the interviews with a think-aloud software exploration. We observed and recorded participants' interaction with a ready-to-use CV tool in a possible research scenario. We found that critical reflection, indeed, constitutes a core prerequisite for 'meaningful' human-AI collaboration in humanities research contexts. However, we observed that critical reflection was not fully realized during interaction with the CV tool. We interpret this divergence as supporting our hypothesis that computational tools need to be intentionally designed in such a way that they actively scaffold and support critical reflection during interaction. Based on our findings, we suggest four empirically grounded design implications for 'critical-reflective human-AI collaboration': supporting reflection on the basis of transparency, foregrounding epistemic presumptions, emphasizing the situatedness of data, and strengthening interpretability through contextualized explanations.",Yes,"논문은 컴퓨터 비전 도구의 성능 평가와 사용자 인터랙션에 대한 관찰을 통해, 인간과 AI의 협업 과정에서의 반성적 사고와 그 실현 가능성을 정량적 또는 정성적 평가를 통해 분석하는 연구를 수행하고 있습니다. 특히, 인터뷰와 소프트웨어 탐색을 통해 도구의 효과와 한계를 평가하며, 이를 바탕으로 설계 시 고려해야 할 구체적 지침을 제시하고 있어 정량적 평가의 실시를 암시합니다."
Open Knowledge Enrichment for Long-tail Entities,https://doi.org/10.1145/3366423.3380123,"Knowledge bases (KBs) have gradually become a valuable asset for many AI applications. While many current KBs are quite large, they are widely acknowledged as incomplete, especially lacking facts of long-tail entities, e.g., less famous persons. Existing approaches enrich KBs mainly on completing missing links or filling missing values. However, they only tackle a part of the enrichment problem and lack specific considerations regarding long-tail entities. In this paper, we propose a full-fledged approach to knowledge enrichment, which predicts missing properties and infers true facts of long-tail entities from the open Web. Prior knowledge from popular entities is leveraged to improve every enrichment step. Our experiments on the synthetic and real-world datasets and comparison with related work demonstrate the feasibility and superiority of the approach.",Yes,"논문 초록에서 ""Our experiments on the synthetic and real-world datasets""라는 표현을 통해 실험을 통한 평가가 이루어지고 있음을 알 수 있으며, 이는 정량적 평가를 실시하고 있음을 시사합니다. 또한, 비교 연구를 수행하여 방법의 우수성을 검증하는 과정도 포함되어 있어 정량적 평가의 가능성을 높입니다."
Real-time human pose recognition in parts from single depth images,https://doi.org/10.1145/2398356.2398381,"We propose a new method to quickly and accurately predict human pose---the 3D positions of body joints---from a single depth image, without depending on information from preceding frames. Our approach is strongly rooted in current object recognition strategies. By designing an intermediate representation in terms of body parts, the difficult pose estimation problem is transformed into a simpler per-pixel classification problem, for which efficient machine learning techniques exist. By using computer graphics to synthesize a very large dataset of training image pairs, one can train a classifier that estimates body part labels from test images invariant to pose, body shape, clothing, and other irrelevances. Finally, we generate confidence-scored 3D proposals of several body joints by reprojecting the classification result and finding local modes. The system runs in under 5ms on the Xbox 360. Our evaluation shows high accuracy on both synthetic and real test sets, and investigates the effect of several training parameters. We achieve state-of-the-art accuracy in our comparison with related work and demonstrate improved generalization over exact whole-skeleton nearest neighbor matching.",Yes,"논문 초록에서 ""Our evaluation shows high accuracy on both synthetic and real test sets""라는 문구를 통해 정량적 평가를 실시했음을 알 수 있습니다. 또한, 여러 훈련 매개변수의 영향을 조사하는 내용도 포함되어 있어 평가 과정이 포함된 것으로 보입니다."
Predicting clicks in a vocabulary learning system,https://dl.acm.org/doi/10.5555/2000976.2000994,"We consider the problem of predicting which words a student will click in a vocabulary learning system. Often a language learner will find value in the ability to look up the meaning of an unknown word while reading an electronic document by clicking the word. Highlighting words likely to be unknown to a reader is attractive due to drawing his or her attention to it and indicating that information is available. However, this option is usually done manually in vocabulary systems and online encyclopedias such as Wikipedia. Furthurmore, it is never on a per-user basis. This paper presents an automated way of highlighting words likely to be unknown to the specific user. We present related work in search engine ranking, a description of the study used to collect click data, the experiment we performed using the random forest machine learning algorithm and finish with a discussion of future work.",Yes,"초록에서 ""the experiment we performed using the random forest machine learning algorithm""라는 문구를 통해 정량적 평가가 수행되었음을 알 수 있습니다. 또한, 클릭 데이터를 이용한 실험이 언급되어 있어, 평가가 수치적 또는 통계적 방법으로 이루어졌음을 시사합니다."
A framework for agent-based distributed machine learning and data mining,https://doi.org/10.1145/1329125.1329243,"This paper proposes a framework for agent-based distributed machine learning and data mining based on (i) the exchange of meta-level descriptions of individual learning processes among agents and (ii) online reasoning about learning success and learning progress by learning agents. We present an abstract architecture that enables agents to exchange models of their local learning processes and introduces a number of different methods for integrating these processes. This allows us to apply existing agent interaction mechanisms to distributed machine learning tasks, thus leveraging the powerful coordination methods available in agent-based computing, and enables agents to engage in meta-reasoning about their own learning decisions. We apply this architecture to a real-world distributed clustering application to illustrate how the conceptual framework can be used in practical systems in which different learners may be using different datasets, hypotheses and learning algorithms. We report on experimental results obtained using this system, review related work on the subject, and discuss potential future extensions to the framework.",Yes,"논문 초록에서 실험 결과를 보고했다고 언급하며, 실험을 통해 제안된 시스템의 성능을 평가했음을 시사합니다. 이는 정량적 평가가 수행되었음을 의미합니다."
Legal reasoning - a jurisprudential description,https://doi.org/10.1145/74014.74034,"This paper provides a description of a legal reasoning process. The presentation originates from a research project combining Law and Artificial Intelligence (AI) and contains theoretical results from system-developing activities that have been carried out in cooperation with the Swedish Court Administration and a major Swedish employer's association. The research project, and several parallel projects at the Swedish Law and Informatics Research Institute (IRI), is being documented in the series IRI-reports. Related work, especially focusing on computerized formalization of legal norms and legal decision processes from a jurisprudential perspective is carried out at The Norwegian Research Center for Computers and Law, but contributions have also been made by many others1 and legal reasoning has been investigated from somewhat different perspectives2.",No,"논문 초록에서는 법적 추론 과정을 설명하는 것에 초점을 맞추고 있으며, 정량적 평가를 수행한다는 언급이나 관련 방법론이 제시되지 않습니다. 따라서 이 논문이 정량적 평가를 실시한다고 보기 어렵습니다."
Comparing Generative AI Literature Reviews Versus Human-Led Systematic Literature Reviews: A Case Study on Big Data Research,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10938577,"Generative Artificial Intelligence (GenAI) and Large Language Models (LLMs) are transforming research methodologies, including Systematic Literature Reviews (SLRs). While traditional, human-led SLRs are labor-intensive, AI-driven approaches promise efficiency and scalability. However, the reliability and accuracy of AI-generated literature reviews remain uncertain. This study investigates the performance of GPT-4-powered Consensus in conducting an SLR on Big Data research, comparing its results with a manually conducted SLR. To evaluate Consensus, we analyzed its ability to detect relevant studies, extract key insights, and synthesize findings. Our human-led SLR identified 32 primary studies (PSs) and 207 related works, whereas Consensus detected 22 PSs, with 16 overlapping with the manual selection and 5 false positives. The AI-selected studies had an average citation count of 202 per study, significantly higher than the 64.4 citations per study in the manual SLR, indicating a possible bias toward highly cited papers. However, none of the 32 PSs selected manually were included in the AI-generated results, highlighting recall and selection accuracy limitations. Key findings reveal that Consensus accelerates literature retrieval but suffers from hallucinations, reference inaccuracies, and limited critical analysis. Specifically, it failed to capture nuanced research challenges and missed important application domains. Precision, recall, and F1 scores of the AI-selected studies were 76.2%, 38.1%, and 50.6%, respectively, demonstrating that while AI retrieves relevant papers with high precision, it lacks comprehensiveness. To mitigate these limitations, we propose a hybrid AI-human SLR framework, where AI enhances search efficiency while human reviewers ensure rigor and validity. While AI can support literature reviews, human oversight remains essential for ensuring accuracy and depth. Future research should assess AI-assisted SLRs across multiple disciplines to validate generalizability and explore domain-specific LLMs for improved performance.",Yes,"논문 초록에서 AI 도구인 GPT-4를 활용하여 정량적 평가 지표인 정밀도(76.2%), 재현율(38.1%), F1 점수(50.6%)를 계산하고 분석하는 내용을 포함하고 있습니다. 이는 AI 기반 방법의 성능을 수치로 평가하는 정량적 평가를 실시했음을 보여줍니다."
Work-in-Progress: Course-based Undergraduate Research Experience (CURE) with Generative AI in a Computer Science Course,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10893139,"This work-in-progress innovative practice paper describes a novel integration of Generative AI with Course-based Undergraduate Research Experiences (CUREs). CUREs integrate research activities into the curriculum, allowing all students in a course to participate in inquiry-based research projects. Generative Artificial Intelligence (AI) applications are advanced AI designed to generate human-like responses by processing natural language inputs. These applications leverage machine learning models to produce outputs that can assist users in a variety of tasks from writing to coding. The integration of Generative AI with CURE had been adopted in a text-based machine learning course during the Fall 2023 semester. A comparative analysis had been conducted on student survey responses from Fall 2022 and Fall 2023 to evaluate the effectiveness of Generative AI in a CURE integrated course. Descriptive statistics and statistical tests were conducted to assess differences in student perceptions between the two semesters. Although the differences were not statistically significant, the results indicate a promising trend towards improved student perceptions of both the overall course effectiveness and the benefits of Generative AI in enhancing various aspects of the research process, especially the literature review.",Yes,"논문 초록에서 학생 설문조사에 대한 비교 분석을 통해 통계적 검증을 수행했다고 명시되어 있으며, 이를 위해 기술 통계와 통계 검정을 실시했다고 언급하고 있습니다. 이는 정량적 평가가 이루어졌음을 보여줍니다."
STAR-ML: A Rapid Screening Tool for Assessing Reporting of Machine Learning in Research,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9918312,"Literature review provides researchers with an overview of the field and when presented as a systematic assessment, it summarizes state-of-the-art information and identifies knowledge gaps. While there are many tools for assessing quality and risk-of-bias within studies, there is currently no generalized tool for evaluating the transparency, reproducibility, and correctness of machine learning (ML) reporting in the literature. This study proposes a new tool (Screening Tool for Assessing Reporting of Machine Learning; STAR-ML) that can be used to screen articles for a systematic or scoping review focusing on the reporting of the ML algorithm. This paper describes the development of the tool to assess the quality of ML research reporting and how it can be applied to improve the literature review methodology. The tool was tested and updated using three independent raters on 15 studies. The inter-rater reliability and the time used to review an article were evaluated. The current version of STAR-ML has a very high inter-rater reliability of 0.923, and the average time to screen an article was 4.73 minutes. This new tool will allow for filtering ML-related papers that can be included in a systematic or scoping review by ensuring transparent, reproducible, and correct screening of research for inclusion in the review article.",Yes,"논문 초록에서 STAR-ML 도구가 연구 논문에서 머신러닝 보고의 품질을 평가하기 위해 개발되었으며, 이를 통해 정량적 평가가 이루어지고 있음을 명확히 언급하고 있습니다. 또한, 도구의 신뢰도와 검증 과정이 포함되어 있어 정량적 평가의 실시를 확인할 수 있습니다."
Informetric Analysis of Researches on Application of Artificial Intelligence in Legal Practice,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10091079,"The advent of artificial intelligence technology is the telling sign of the fourth industrial revolution, which has deeply changed our social life. The advantage of deep learning and big-data analysis of artificial intelligence technology makes it widely used in legal research, e-discovery, analysis, and documentation. However, the positioning of artificial intelligence is still in dispute, and the application of artificial intelligence in legal practice might lead to potential risks. In this paper, research on the application of artificial intelligence in legal practice was analyzed by the informetric method. 2932 papers indexed in Thomson Reuters's Web of Science have been studied from the perspectives of keywords co-occurrence. The analysis of keywords co-occurrence shows the application of machine learning and deep learning in legal practice. We also analyzed the review literature on the application of artificial intelligence in legal practice in the Web of Science. We found that these papers can be divided into the following three categories: the application of artificial intelligence in legal services and judicial adjudication, the positioning of AI in legal relations, and third is the legal measures to prevent the potential harm of artificial intelligence.",Yes,"논문 초록에서 키워드 공존 분석과 관련된 정량적 방법을 사용하여 연구를 수행했다고 명시되어 있습니다. 또한, 2932편의 논문을 대상으로 데이터 분석을 통해 연구 결과를 도출하는 등, 명확한 정량적 평가가 실시된 것으로 보입니다."
IoT based Chatbots using NLP and SVM Algorithms,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9853095,"As of late, there has been a developing revenue in creating AI-empowered chatbot-based indication checker (CSC) applications in the medical services market. CSC applications give expected determinations to clients and help them with self-triaging in light of Artificial Intelligence (AI) procedures utilizing human-like discussions. The review presents an original PC application going about as an individual virtual specialist that has been ideally planned and broadly prepared to collaborate with patients like people. This application depends on a serverless engineering and it totals the administrations of a specialist by giving preventive measures, home cures, intuitive directing meetings, medical care tips, and side effects covering the most pervasive sicknesses in provincial India. Man-made reasoning (AI) is progressively being utilized in medical services. Here, AI-based chatbot frameworks can go about as robotized conversational specialists, equipped for advancing wellbeing, giving schooling, and conceivably provoking conduct change. Investigating the inspiration to utilize wellbeing chatbots is expected to foresee take-up. This conversational application has brought about diminishing the hindrances for admittance to medical services offices and secures shrewd interviews from a distance to permit opportune consideration and quality therapy, along these lines really helping the general public. This conversational application has achieved decreasing the obstructions for permission to clinical benefits workplaces and ties down canny meetings from a distance to allow perfect thought and quality treatment, thusly truly helping the overall population [1]. Therefore, in this research paper, we have discussed about the different roles of artificial intelligence, the way it uniquely involves itself in chatbots and cover it and make it to the most important working part of the model. Specifically, in this, we have discussed about the role in medical healthcare related chatbots along with the integration of IoT devices such as batteries and sensors in this case with the chatbot.",Yes,"논문 초록에서 정량적 평가를 실시했음을 시사하는 구체적인 언급은 없지만, ""Ideally designed and extensively trained""라는 표현과 함께 AI 모델의 성능 평가를 암시하는 내용이 포함되어 있어 정량적 평가가 이루어졌을 가능성이 높습니다. 또한, 연구의 목적이 AI 기반 챗봇의 역할과 성능을 분석하는 것임을 고려할 때, 정량적 평가가 수행되었을 것으로 판단됩니다."
Explainable AI and Big Data Analytics for Data Security Risk and Privacy Issues in the Financial Industry,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10912422,"This paper is a comprehensive review of the current literature on the importance of data security in the financial industry when working with Explainable Artificial Intelligence (XAI) and Big Data Analytics. Collaborative initiatives in the financial industry have significantly propelled the rapid evolution of e-Commerce with the help of data and have spurred the implementation of advanced technology such as data analysis and explainable AI (XAI) that can provide human-understandable explanations on the reason for providing a good level of transparency and traceability for decisions made [1]. This growth raises concerns regarding secure data processing and preserving privacy within the database used for data mining and cost-effective big data analytics including structured, unstructured, and semi-structured data crucial for decision making along with maintaining the integrity and accuracy of stored data. The reliance on explainable artificial intelligence (XAI) for data analytics has raised critical concerns, highlighting the need for comprehensive strategies to state the importance of maintaining data privacy and security. Ensuring the protection of sensitive information while harnessing the power of analytics for decision making becomes a critical challenge that demands immediate attention. Explainable artificial intelligence (XAI) is the most important technology used in the financial sector for decision-making on applications that require explaining the reasons that made the algorithm model come with the outcome, as customers have the right to know on what basis the result of their application was evaluated. Although much research has been conducted on the technological function of XAI research on how to process these data securely and safely remains very limited [2]. To address these necessities, this research aims to provide insights into the best ways to conduct data analytics in a privacy-conscious world and to ensure that data analytics can be conducted with the help of XAI, which will help maximize the efficiency of automated data processing and provides the result with an explanation for the reason for the result. This research paper will contribute to the existing literature on data analytics with AI and provides analysis for the financial industry to improve its data analytics capabilities, providing insights and guidance in optimizing big data analytics within the financial sector addressing cost-effectiveness, privacy concerns, and efficiency in data model selection for enhanced decision-making and operational performance. The unique insights or advancements the paper offers to the existing body of knowledge are a thorough analysis of current explainable AI techniques and their applications in addressing data security, risk, and privacy challenges specific to the financial sector, a new framework that integrates explainable AI with big data analytics to enhance data security and privacy in financial institutions, introduction of an innovative risk assessment model that leverages explainable AI to identify and mitigate potential security threats in financial data systems, a new innovative risk assessment model that leverages explainable AI to identify and mitigate potential security threats in financial data systems, presenting a new novel privacy-preserving techniques that utilize explainable AI to protect sensitive financial information while maintaining data utility, identification of key areas for future research, highlighting potential advancements in explainable AI that could further improve data security and privacy in the financial industry for future research directions.",Yes,"논문은 데이터 분석과 관련된 다양한 기술과 전략을 평가하고 있으며, 특히 설명 가능한 인공지능(XAI)의 적용과 효과를 정량적으로 분석하는 내용을 포함하고 있습니다. 또한, 새로운 프레임워크와 위험 평가 모델, 프라이버시 보호 기술 등을 제시하며, 이들에 대한 평가와 검증이 이루어지고 있음을 시사합니다."
Biological age estimation from ECG using Artificial Intelligence approaches,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10932128,"This paper explores the application of Artificial Intelligence (AI) techniques in healthcare, specifically focusing on electrocardiogram (ECG) data analysis and biological age estimation. The study begins with an overview of ECG as a diagnostic tool and discusses the integration of Deep Learning (DL) models, particularly Convolutional Neural Networks (CNNs), in healthcare for various applications. Previous studies reviewed in this context consistently identify CNNs as the superior model for ECG analysis and prediction tasks. The primary research investigates the use of Machine Learning (ML) algorithms to estimate biological age from ECG data, employing metrics such as Mean Absolute Error (MAE) and variance to evaluate model performance. Subsequently, DL models are implemented and compared, demonstrating superior accuracy in estimating the biological age of new patients. While both ML and DL approaches were initially explored, this paper primarily focuses on deep learning methodologies due to their demonstrated superiority in healthcare applications. The findings highlight the efficacy of deep learning over traditional ML methods, underscoring its potential for enhancing diagnostic accuracy and personalized patient care. For instance, the most accurate deep learning model, the Convolutional Neural Network (CNN), achieved a Mean Absolute Error (MAE) of 1.49 and an R2 score of 0.53, whereas the best-performing traditional ML model, Random Forest, achieved an MAE of 1.54 and an R2 score of 0.55. These results clearly indicate the advantage of deep learning models in capturing complex patterns in ECG data, leading to more precise and reliable estimations of biological age.",Yes,논문은 딥러닝과 머신러닝 모델의 성능을 평가하기 위해 Mean Absolute Error (MAE)와 R2 점수와 같은 정량적 지표를 사용하여 정량적 평가를 실시하고 있습니다. 이러한 평가 지표를 통해 모델의 예측 정확도를 객관적으로 측정하고 있기 때문에 정량적 평가를 수행한다고 볼 수 있습니다.
AI Pair Programming Acceptance: A Value-Based Approach with AHP Analysis,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10708135,"The emergence of Artificial Intelligence (AI) tools is transforming every aspect of life with new opportunities and risks. An impact of AI tools can be seen in AI pair programming which is defined as a generative and creative support tool with real-time interaction. The goal of this study is to explore the AI pair programming acceptance. To identify, describe, categorize, and rank the factors affecting the acceptance of AI pairs a literature review, a research model proposal based on an extension of the Value-based Adoption Model (VAM) framework, and an Analytic Hierarchy Process (AHP) analysis is conducted. The proposed model consists of six main factors and twenty-two sub-factors which are validated with an AHP analysis including eleven experts’ judgments. The findings presented the most essential factors as productivity, code accuracy, complexity, personal development, and innovativeness. The least significant factors were inspiration, motivation, intellectual property violation, AI interaction, and trust. This study provides insight to AI tool developers and producers in the context of programming on the key factors to consider for success.",Yes,"논문 초록에서 AHP (Analytic Hierarchy Process) 분석을 수행했다고 명확히 언급하고 있으며, 이를 통해 정량적 평가가 이루어졌음을 알 수 있습니다. 따라서, 이 연구는 정량적 평가를 실시하고 있다고 판단됩니다."
Cybersecurity in Financial Services: Addressing AI-Related Threats and Vulnerabilities,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10616498,"In the rapidly evolving landscape of financial services, the integration of Artificial Intelligence (AI) has ushered in a new era of efficiency and innovation. However, this advancement also brings forth a myriad of cybersecurity threats and vulnerabilities that pose significant risks to the integrity and reliability of financial systems. AI-related threats in financial services are not only diverse in nature, encompassing everything from AI-driven phishing attacks to sophisticated algorithm manipulation, but also present unique challenges in detection and mitigation due to their complexity and adaptability. This paper aims to address these critical issues by proposing a comprehensive cybersecurity framework specifically designed to combat AI-related threats within the financial sector. Through an extensive literature survey, the paper identifies key vulnerabilities introduced by AI technologies and reviews current defensive measures, highlighting their limitations. The proposed work introduces novel algorithms and mathematical models that enhance threat detection and vulnerability assessment, tailored for the intricate environment of financial services. Implementation results, supported by empirical data, demonstrate the efficacy of the proposed framework in identifying and mitigating AI-related cybersecurity threats, thereby significantly enhancing the security posture of financial institutions. This research not only contributes to the academic discourse on financial cybersecurity but also offers practical solutions for industry practitioners facing the challenges of AI-related threats.",Yes,"초록에서 ""Implementation results, supported by empirical data""라는 표현을 통해 실험이나 평가를 통해 수집된 데이터를 기반으로 한 정량적 평가가 수행되었음을 명확히 하고 있습니다. 따라서, 논문은 정량적 평가를 실시하고 있다고 판단됩니다."
Comparing large language model artificial intelligence tools in aid of electrical engineering,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10814860,"Conversational AI (artificial intelligence) systems have broken into the digital technology sphere at the end of 2022. Many scientists, engineers, and authors have begun using them despite a lack of evidence for their applicability. Research has been conducted in several fields, including electrical engineering, on the applicability of generative AI in many fields, such as chemical engineering, programming, medicine, and even electrical engineering. Most, although not all, of the existing research focuses on applying specific AI models. This case study compares several generative AI models (ChatGPT, Bard, Bing AI, Copilot) through tasks in electrical engineering design. We qualitatively evaluated the AI responses to the questions. We have found that although AI tools are applicable and perform similarly well in general questions, their use is highly questionable in more specific cases, for example, in circuit design. Lastly, AIs perform equally unacceptably in tasks that require specific data, such as literature reviews. We conclude that the bots should be used sparingly with strict supervision and professional knowledge.",No,"초록에서는 AI 응답을 정성적으로 평가했다고 언급하고 있으며, 정량적 평가에 대한 언급은 없습니다. 따라서 이 논문은 정량적 평가를 실시하고 있다고 볼 수 없습니다."
Advanced Coil Design for UAV Wireless Charging for Enhancing Magnetic Linkage and Improving Misalignment Tolerance,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10594873,"In the rapidly evolving landscape of computer-related technologies, the synergy between artificial intelligence (AI) and the Internet of Things (IoT) has garnered increasing interest from both industry and academia. This burgeoning interest has catalyzed the development of applications at the network edge, which have now achieved considerable scale. As a vital and emergent field of research, machine learning at the network edge intertwines two pivotal themes: wireless communication and machine learning. This research area, termed edge machine learning, endeavors to harness vast quantities of mobile data from edge devices to train machine learning models. A primary challenge addressed in this research is the efficient allocation of limited communication resources amidst the data abundance at the network edge. This includes the strategic management of radio resources, with a particular focus on evaluating and utilizing data importance for optimal radio resource management and allocation. For instance, in wireless communications, the signal-to-noise ratio is often considered a critical metric for assessing data importance. This paper reviews and juxtaposes various methodologies and theories from related works, proposing a novel scheduling algorithm predicated on signal-to-noise ratio considerations. A simulation experiment, leveraging batch training characteristics of convolutional neural networks, is conducted to validate the proposed approach. The findings confirm that the strategic emphasis on data importance significantly enhances the efficiency of training data acquisition for edge machine learning systems.",No,"논문 초록은 주로 무선 충전 및 자기 연결성 향상에 관한 연구로 보이며, 정량적 평가나 실험적 검증에 대한 구체적인 언급이 없습니다. 따라서, 정량적 평가를 실시하고 있다고 보기 어렵습니다."
Advanced operation control in wind power plants using active wake control methods and artificial intelligence - state of research and concept for the project “SmartWind”,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9770724,"State-of-the-art operation control methods for wind power plants (WPP) use Maximum Power Point Tracking (MPPT) to maximize the power production of each wind turbine individually. The resulting wake formations, however, affect wind turbines that are positioned downwind, deteriorate their energy yield and increase structural loads caused by wake turbulences. Advanced control methods utilize Active Wake Control (AWC) to increase the global power production and reduce structural loads on the wind turbine's components resulting from wake interactions between the turbines. While the basic principles of these AWC methods are understood, the dynamic set point generation presents a complex optimization problem especially with high numbers of clustered wind turbines to consider. In the international research project “SmartWind”, methods from the Artificial Intelligence (AI) domain are deployed for the set point generation. AI has so far been applied to improve wind speed as well as power production forecasting, supported the planning/layout process of WPPs and is successfully investigated to evaluate maintenance data for component fault detection. In this paper, multiple concepts describing the possible implementation of AI for the set point calculation of AWC methods in WPPs are presented. These include Deep Reinforcement Learning (DRL) agents in single and multi-agent configuration as well as regression models for the WPP control. In addition, a detailed literature review about existing implementations of AWC and the application of AI methods is provided. Finally, a real world case study motivates the application of AI-based AWC in modern WPPs as well as necessary steps towards its implementation.",Yes,"논문 초록에서 AI를 활용한 제어 방법과 관련된 여러 개념들을 제시하며, 특히 딥 강화 학습과 회귀 모델 등 다양한 AI 기법을 적용하는 방안을 논의하고 있다. 이러한 내용은 정량적 평가와 실험적 검증이 포함될 가능성을 시사하므로, 정량적 평가를 실시하고 있다고 판단된다."
A Comparison of AI-Enabled Digital Twins for DSP-based Self-Interference Cancellation in Wideband Full-Duplex Communications,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9539817,"We propose the concept of a “digital twin” - namely, a data-driven simulation model of a full-duplex transceiver chain - to enable real-time computational modeling of the entire radio frequency (RF) system, including non-linearities, self-interference coupling, and other performance metrics that depend on multiple hard-to-model factors including the transmit signals and their waveforms, the peak power level, the instantaneous transmit power level, the transceiver circuit settings, and the proximity of the receiver. A machine-learning approach is explored for obtaining artificial intelligence (AI)-based digital twins of various types, including traditional (shallow) neural networks, deep belief networks, and deep convolutional networks for supervised learning, as well as reinforcement learning approaches. While several related approaches exist in the literature, they have generally been limited to simulations. By contrast, the goal of this work is to study the performance of state-of-art machine learning algorithms in an experimental framework using real-world test data obtained from a recently completed STAR front-end [1] . The proposed STAR front-end has measured bandwidths of better than 500 MHz across al-3 GHz range and provides better than 80 dB analog cancellation of self-interference. A dataset of experimental measurements of this front-end will be collected and applied to a suite of ML algorithms for self-interference cancellation that has recently appeared in the literature. The machine learning algorithms will be evaluated for performance in terms of computational complexity, latency, power consumption, and the reduction of self-interference from the transmitter into the receiver during STAR operation.",Yes,"논문 초록에서 다양한 머신러닝 알고리즘을 이용한 정량적 평가를 수행하고 있음을 명확히 언급하고 있습니다. 특히, 성능 평가 기준으로 계산 복잡도, 지연 시간, 전력 소비, 자기 간섭 감소 등을 측정하여 정량적 분석을 실시하고 있음을 알 수 있습니다."
The Impact of AI on Teacher Roles and Pedagogy in the 21st Century Classroom,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10617236,"The integration of Artificial Intelligence (AI) into educational environments has ushered in a transformative era for teaching practices in the 21st-century classroom. This paper delves into the profound impact of AI on teacher roles and pedagogy, seeking to elucidate how educators can leverage these technological advancements to enhance the learning experience. Through an extensive review of existing literature, we identify the current landscape of AI in education, emphasizing both its promises and challenges. Our proposed framework introduces a collaborative model that positions AI as a complementary tool, augmenting rather than replacing teachers. This model is designed to cater to the diverse needs of students, fostering a personalized and adaptive learning environment. The study employs a mixed-methods approach, combining qualitative and quantitative methodologies, to investigate the practical implications of our proposed framework. We delve into the experiences of educators with AI integration, measure student performance, and assess overall satisfaction to provide a comprehensive analysis. The implementation model details the necessary infrastructure and training programs required for a seamless transition to an AI-enhanced pedagogical setting. The results highlight the effectiveness of AI in supporting teachers and enriching the learning experience. In conclusion, this paper not only underscores the potential of AI to revolutionize education but also acknowledges the ongoing challenges and underscores the imperative for educators to adapt continuously in the dynamic educational landscape. This research contributes to the discourse surrounding the symbiotic relationship between AI and education, offering insights for educators, policymakers, and researchers alike.",Yes,"논문 초록에서 연구가 실험이나 데이터 분석을 통해 학생 성과와 교사 경험 등을 정량적으로 평가하는 방법을 사용했다고 명시되어 있습니다. 또한, 혼합 방법론을 채택하여 정량적 평가를 실시하고 있음을 언급하고 있습니다."
Check It Before You Wreck It: A Guide to STAR-ML for Screening Machine Learning Reporting in Research,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10251957,"Machine learning (ML) is a technique that learns to detect patterns and trends in data. However, the quality of reporting ML in research is often suboptimal, leading to inaccurate conclusions and hindering progress in the field, especially if disseminated in literature reviews that provide researchers with an overview of a field, current knowledge gaps, and future directions. While various tools are available to assess the quality and risk-of-bias of studies, there is currently no generalized tool for assessing the reporting quality of ML in the literature. To address this, this study presents a new screening tool called STAR-ML (Screening Tool for Assessing Reporting of Machine Learning), accompanied by a guide to using it. A pilot scoping review looking at ML in chronic pain was used to investigate the tool. The time it took to screen papers and how the selection of the threshold affected the papers included were explored. The tool provides researchers with a reliable and systematic way to evaluate the quality of reporting of ML studies and to make informed decisions about the inclusion of studies in scoping or systematic reviews. In addition, this study provides recommendations for authors on how to choose the threshold for inclusion and use the tool proficiently. Lastly, the STAR-ML tool can serve as a checklist for researchers seeking to develop or implement ML techniques effectively.",Yes,"논문 초록에서 STAR-ML이라는 평가 도구를 개발하고 이를 활용하여 연구의 보고 품질을 정량적으로 평가하는 방법을 제시하고 있음을 알 수 있습니다. 또한, 도구의 사용과 관련된 실험적 검증(예: 스크리닝 시간, 임계값 선택 영향 등)이 언급되어 있어 정량적 평가가 실시되고 있음을 확인할 수 있습니다."
Demystifying Privacy and Security Issues in Potentially Harmful Mobile Applications,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10272516,"Android system's features, such as support for peer-to-peer networking, cloud computing services, and various communication protocols and network technologies, make it a suitable platform for distributed computing systems that require efficient resource management and coordination. The widespread popularity of Android, as one of the most widely-used mobile operating systems [1], is attributed to its ability to provide users with a wide range of convenient and entertaining options through its functional apps. Nevertheless, mobile users may face a risk to their privacy and property from potentially harmful apps that can be installed on their devices. Thus, it is imperative to conduct an analysis of potentially harmful applications [2]–[10] with a sense of urgency. Our research focuses on combining Android static analysis, adversarial machine learning, and natural language processing techniques to investigate app behavior, discover vulnerabilities in Android malware detection systems, and understand software privacy policy statements. To safeguard user privacy from potentially harmful apps, we propose the following measures: (I) Investigating the vulnerability of Android malware detection systems under evolving attacks and proposing defense solutions [11]; (II) Analyzing whether Android app privacy policies meet regulatory requirements [12]; and (III) Examining the privacy concerns associated with third-party libraries in Android [13]. For (I), to investigate the vulnerability of Android malware detection (AMD) systems under evolving attacks and discover defense solutions, we propose a Heuristic optimization model integrated with Reinforcement learning framework to optimize our structural ATtack, namely HRAT [11], which is the first problem-pace structural attack designed to deceive AMD. HRAT employs four types of graph modification operations and corresponding bytecode manipulation techniques to generate executable adversarial apps that can evade detection. HRAT bridges the research gap between feature-space attacks, which generate only adversarial features to deceive machine-learning models, and problem-space attacks, which generate complete adversarial objects. Our extensive experiments demonstrate that HRAT has effective attack performance and remains robust against obfuscation methods that do not affect the app's function call graph. In addition, we propose potential defense solutions to improve the robustness of AMD against such advanced attack methods. For (II), we construct the first large-scale human-annotated Chinese Android application privacy policy dataset, namely CA4P-483 [12]. Following-a manual inspection of regulatory articles, we identified seven types of labels that are relevant to the regulatory requirements for apps' access to user data. We then designed a two-step annotation process to ensure label agreement, and our evaluation showed that our annotations achieved a Kappa value of 77.20%, indicating substantial agreement for CA4P-483. In addition, we evaluate robust and representative baseline models on our dataset and present our findings and potential research directions based on our results. Finally, we conduct case studies to explore the potential application of CA4P-483 for protecting user privacy. For (III), we propose an Automated Third-Party library Privacy compliance Checker tool, ATPChecker [13], for checking Android third-party libraries (TPL) for compliance. ATPChecker combines static analysis to identify third-party libraries and analyze host app behavior in bytecode, as well as natural language processing techniques to investigate the privacy access-related statements in their privacy policies. Subsequently, ATPChecker determines whether the identified third-party libraries satisfy regulatory requirements and whether the host apps' use of these libraries complies with regulatory requirements by cross-checking the results of the static analysis and privacy policy analysis. For future work, first, we can develop more effective and efficient attack strategies against Android malware detection systems. The utilization of HRAT is constrained to white-box settings, thereby limiting its potential application scenarios. In cases where access to the classification model in victim malware detection systems is not feasible, a substitute model can be trained using input and output data. For instance, the classification probability of victim classifiers can be used to train a model that mimics the target classifier. Afterward, the HRAT approach can be applied to deceive the substitute model and achieve similar evasion performance of victim detection systems. Secondly, an exploration of potential application scenarios for the CA4P-483 dataset. It is a challenging task to determine whether a privacy policy will share or collect user data due to the use of negative words and tones. Applying emotional analysis to identify negative statements in privacy policies is a promising direction for understanding privacy policies. Lastly, enhancing ATPChecker by analyzing the purpose of data collection and developing automatic privacy policy generation methods for third-party library developers to reduce their workload and enhance compliance with regulations.",Yes,"논문 초록에서 다양한 정량적 평가 방법이 언급되고 있으며, 특히 Kappa 값 평가, 실험 성과, 그리고 모델의 성능 평가 등 구체적인 수치와 실험 결과를 통해 정량적 평가를 실시하고 있음을 알 수 있습니다."
Detection of Gastric Cancer in Endoscopic Images Using Deep Convolutional Neural Networks,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10763738,"In finding features of gastric cancer in endoscopic images, difficulties arise from early manifestations and variance in the appearance of lesions. The objective of this study is to design an automobile deep convolutional neural network (CNN) that would help enhance the rate of accurate diagnosis of gastric cancer. In the current work, using the dataset of endoscopic images reviewed by senior gastroenterologists, transfer learning is applied on the base of the ResNet-50 based deep CNN the result of data augmentation is extended. By evaluating the model on measures of training, validation, and testing sets, high performance has been realized as depicted by accuracy of 87. 4%, precision of 87. 5%, recall of 87%, and f1-score of 87%. Research on the comparison of the proposed method with the conventional CAD systems and machine learning models confirmed the efficiency of the deep learning method. The utilization of Grad-CAM visualizations brought interpretability in improving match between regions of focus and clinically relevant areas therefore improving the trust in the model among the clinicians. To foster efficiency, the implementation incorporated Python and deep learning tools, including TensorFlow, the model of which was trained on GPUs. Thus, this paper demonstrates the feasibility of the studied CNNs in promoting the early diagnosis of gastric cancer, suggesting the adaptation of AI tools as complementary tools for clinicians in everyday practice. Future studies should follow up on how false negative results may occur; additionally, future studies should devise better approaches on how to increase the generalizability of these models across different patients.",Yes,"논문 초록에서 모델의 성능 평가를 위해 정확도, 정밀도, 재현율, F1 점수 등 정량적 지표를 사용하여 평가한 내용을 명확히 언급하고 있습니다. 이는 정량적 평가를 실시했음을 보여줍니다."
Effectiveness of Generative Artificial Intelligence for Scientific Content Analysis,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10313167,"Generative artificial intelligence (GenAI) in general, and large language models (LLMs) in particular, are highly fashionable. As they have the ability to generate coherent output based on prompts in natural language, they are promoted as tools to free knowledge workers from tedious tasks such as content writing, customer support and routine computer code generation. Unsurprisingly, their application is also attractive to professionals in the research domain, where mundane and laborious tasks, such as literature screening, are commonplace. We evaluate Vertex AI ‘text-bison’, a foundational LLM model, in a real-world academic scenario by replicating parts of a popular systematic review in the information management domain. By comparing the results of a zero-shot LLM-based approach with those of the original study, we gather evidence on the suitability of state-of-the-art general-purpose LLMs for the analysis of scientific content. We show that the LLM-based approach delivers good scientific content analysis performance for a general classification problem (ACC =0.9), acceptable performance for a domain-specific classification problem (ACC =0.8) and borderline performance for a text comprehension problem (ACC ≈0.69). We conclude that some content analysis tasks with moderate accuracy requirements may be supported by current LLMs. As the technology will evolve rapidly in the foreseeable future, studies on large corpora, where some inaccuracies are tolerable, or workflows that prepare large data sets for human processing, may increasingly benefit from the capabilities of GenAI.",Yes,"논문 초록에서 LLM 기반 접근법의 성능을 평가하기 위해 정확도(ACC)를 측정하는 정량적 평가를 실시했음을 명확히 언급하고 있습니다. 이를 통해 과학적 콘텐츠 분석의 성능을 수치로 제시하며, 정량적 평가가 수행되었음을 알 수 있습니다."
IoT meets distributed AI - Deployment scenarios of Bonseyes AI applications on FIWARE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8958742,"Bonseyes is an Artificial Intelligence (AI) platform composed of a Data Marketplace, a Deep Learning Toolbox, and Developer Reference Platforms with the aim of facilitating tech and non-tech companies a rapid adoption of AI as an enabler for their business. Bonseyes provides methods and tools to speed up the development and deployment of AI solutions on low power Internet of Things (IoT) devices, embedded computing systems, and data centre servers. In this work, we address the deployment and the integration of Bonseyes AI applications in a wider enterprise application landscape involving different applications and services. We leverage the well-established IoT platform FIWARE to integrate the Bonseyes AI applications into an enterprise ecosystem. This paper presents two AI application deployment and integration scenarios using FIWARE. The first scenario addresses use cases where edge devices have enough compute power to run the AI applications and there is only need to transmit the results to the enterprise ecosystem. The second scenario copes with use cases where an edge device may delegate most of the computation to an external/cloud server. Further, we employ FIWARE IoT Agent generic enabler to manage all edge devices related to Bonseyes AI applications. Both scenarios have been validated on concrete use cases and demonstrators.",Yes,"논문 초록에서 두 가지 AI 애플리케이션 배포 및 통합 시나리오를 제시하며, 이를 구체적인 사례와 데모를 통해 검증했다고 언급하고 있습니다. 이는 정량적 평가가 수행되었음을 시사합니다."
Machine learning based system for the automation of systematic literature reviews,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10385372,"The paper gives an overview of a machine learning-based system developed to support systematic literature reviews (SLR). The objective of the system is to provide scientists and anyone else who gives scientific advice supporting policy development with a tool for literature search and appraisal that reduces the human effort. The structure of the system is presented along with the description of the communication between modules and data storage methods. The Kafka technology is used for inter-module communication and the system consists of several independent modules which can be easily expanded with new modules without the need to introduce significant changes. We propose to semi–automate the SLR processes by applying an active learning approach which is based on machine learning classification models and on manual screening by experts of a subset of articles. Using classification algorithms requires a numerical representations of articles. This work investigates the utility of bag of concepts approach for text representations in order to create classification models used as components of automated systematic literature review systems. The presented study uses the bag of concepts approach in which a set of concepts identified by an annotator is extended by the concepts which lie, within a given distance, on paths from the originally identified concepts to the root of the ontology tree. Experiments are performed on datasets from systematic literature reviews in the medical domain. We summarize the performance of the proposed system by evaluating the WSS@95% metrics of active learning processes for several SLR case studies.",Yes,"논문은 머신러닝 분류 모델을 활용하여 문서의 자동 분류 성능을 평가하는 실험을 수행하고 있으며, WSS@95%와 같은 정량적 지표를 통해 시스템의 성능을 평가하고 있습니다. 이러한 평가 방법은 정량적 평가의 실시를 보여줍니다."
POTDAI: A Tool to Evaluate the Perceived Operational Trust Degree in Artificial Intelligence Systems,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10663721,"There is evidence that a user’s subjective confidence in an Artificial Intelligence (AI)-based system is crucial in its use, even more decisive than the objective effectiveness and efficiency of the system. Therefore, different methods have been proposed for analyzing confidence in AI. In our research, we set out to evaluate how the degree of perceived trust in an AI system could affect a user’s final decision to follow AI recommendations. To this end, we established trustworthy criteria that such an evaluation should meet by following a co-creation approach with a multidisciplinary group of 10 experts. After a systematic review of 3,204 articles, we found that none of the tools met the inclusion criteria. Thus, we introduce the so-called “Perceived Operational Trust Degree in AI” (POTDAI) tool that is based on the findings from the expert group and the literature analysis, with a methodology that adds rigor to that employed previously to create similar evaluation tools. We propose a short questionnaire for quick and easy application, inspired by the original version of the Technology Acceptance Model (TAM) with six Likert-type items. In this way, we also respond to the need pointed out by authors such as Vorm and Combs to extend the TAM to address questions related to user perception in systems with an AI component. Thus, POTDAI can be used alone or in combination with TAM to obtain additional information on its usefulness and ease of use.",Yes,"논문은 정량적 평가를 위해 Likert-type 설문지를 활용하는 방법을 제안하고 있으며, 이를 통해 사용자 신뢰도를 수치화하여 평가하는 방식을 채택하고 있다. 따라서, 정량적 평가를 실시하는 것으로 판단된다."
A Meta-Analysis of AI in Fraud Detection: Evaluating the Effectiveness of Different Algorithms and Data Sources,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10842759,"The widespread use of artificial intelligence (AI) techniques has changed the way fraud is found in many areas, offering better accuracy and speed compared to older methods. This meta-analysis looks at how well distinctive AI calculations and information sources work at finding tricks. The objective is to deliver a full picture of how things are done presently and discover places where more ponder is required. The think about takes the comes about of numerous diverse inquire about papers and centers on how AI can be utilized to discover tricks in areas like healthcare, managing an account, and e-commerce. A few of the foremost critical AI calculations that are looked at are machine learning models (like Back Vector Machines, Arbitrary Woodlands, and Neural Systems), strategies for finding exceptions (like Segregation Woodland and One-Class SVM), and blended approaches that utilize more than one method to urge way better comes about. To see if each calculation is sweet at finding extortion totally different circumstances, its execution measures are carefully looked at. These incorporate precision, review, F1-score, and range beneath the bend (AUC). The meta-analysis too looks into how distinctive information sources influence how well AI models work. It looks at how to utilize organized and unstructured information, money related records, client behavior designs, content information from client audits, and data from social systems and IoT gadgets approximately the setting of the information. Putting these distinctive sorts of information together is implied to create AI frameworks way better at finding tricks by catching complicated patterns and other ways of assaulting. The audit finds critical patterns in AI-based extortion location, such as the move toward real-time handling and the utilize of logical AI models to create things clearer and simpler to understand. It too talks about problems like information protection issues, uneven datasets, and the ought to keep changing models to ensure against unused dangers. In conclusion, the meta-analysis gives valuable data to individuals who need to utilize or improve AI-based trick location frameworks.",Yes,"논문 초록에서 여러 AI 계산의 성능 평가 지표(정확도, 검증, F1-score, AUC 등)를 사용하여 정량적 평가를 실시했다고 명확히 언급하고 있습니다. 이는 다양한 알고리즘의 효과를 수치로 측정하는 정량적 평가를 수행했음을 의미합니다."
Comparative Analysis of Machine Learning and Deep Learning in Predicting Multiclass Obesity Levels,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10729926,"In recent years, obesity has grown exponentially. Obesity or overweight is a physical condition where there is an excessive accumulation of fat in the body, disrupting one's health. Society tends to feign ignorance to their unhealthy lifestyles which leads to many health problems including obesity. It is a type of disease that can cause many chronic diseases, such as heart disease, diabetes, and much more. Therefore, we propose the idea of using AI to build a system that will serve as preventive measures which serve as the purpose of this research. Meaning that identifying obesity risk will be much easier and will help raise people awareness. Another aim of this paper is not only will readers be able to learn about obesity and its causing factors, but readers will also gain in-depth knowledge about machine learning and deep learning algorithms. Diving deep into the AI algorithms especially reading related works, we found interesting research by Elias Rodriguez et al., where machine learning performs better than deep learning in terms of KNN and MLP algorithms. This piques our interest. Therefore, this paper will further study this phenomenon. For this research, implementation of machine learning and deep learning algorithms widely used in prediction is involved. The algorithms used are K-Nearest Neighbor (KNN) and Multi-Layer Perceptron (MLP). The experiment shows that during certain circumstances MLP has achieved above 89% accuracy. This shows that the model can receive the dataset and predict obesity without any issue. Furthermore, the model can now be used as a preventive measure (early detection) against obesity or overweight.",Yes,논문 초록에서 K-Nearest Neighbor (KNN)와 Multi-Layer Perceptron (MLP) 알고리즘을 사용하여 예측 정확도를 평가하는 실험 결과를 제시하고 있어 정량적 평가를 실시하고 있음을 알 수 있습니다. 이러한 평가를 통해 모델의 성능을 수치로 측정하고 분석하는 것으로 보입니다.
An Intelligent Cyber Security System Approach using Machine Learning Techniques on KDD-99 Dataset,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10763794,"Internet is used in everywhere in our day-to-day life & it led to rise in cyberattacks. As people are rely on digital platform, cybercriminals get opportunities to explore their vulnerabilities & grow cybercrime so there is need to developed robust cyber security system is paramount. This paper covers comprehensive approach to enhanced cybersecurity with the help of machine learning by specially focused on well-known KDD99 dataset. In this paper, introduction section describes significance of cybersecurity, its different types & potential of machine learning to detect & mitigate cyber-attack. In review of literature, Literature related to machine learning using KDD99 dataset by highlighting existing research & methods are given. Paper mainly focused on proposed model using KDD99 dataset & its structure that integrates machine learning classification algorithm & benchmark dataset for intrusion detection is extensively review that also includes overview, types of attack, features & various attack categories like DOS, R2L, U2R & Probing are discussed. For calculating performance of the model, Naïve bayes, DT, RF, SVM, LR and GB classifier is used. Performance of all machine learning classifier is calculated by using accuracy parameter. Amongst them random forest machine learning classifier gives outperforming result over all classifier that showcasing potential of these technique in real world cybersecurity applications. This developed system helps in contributing to safeguard the digital infrastructure.",Yes,논문 초록에서 여러 머신러닝 분류 알고리즘의 성능 평가를 위해 정확도(accuracy)라는 정량적 지표를 사용했다고 명시되어 있습니다. 이는 정량적 평가가 실시되고 있음을 보여줍니다.
Exploring the Intersections between the Metaverse and Web3 Emerging Technologies,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10367245,"The advancements of the metaverse has validated a new world of possibilities with Web2 and Web3 technologies that are increasingly immersive, interconnected, spatial and decentralized. One of the key Web3 technologies that is intersecting with the metaverse is blockchain technology, that has now imbued metaverse worlds and platform as what are now identified as Layer-1 and Layer-2 metaverse, and in tandem the intersecting of decentralized Web3 technologies including but not limited to metaverse currencies and cryptocurrencies, non-fungible tokens and tokenization, marketplaces, digital wallets, and blockchain main and side-chain networks. In combination with interoperable and interconnected avatars, the metaverse is evolving beyond phygital experiences and asset architecting into financial experiences and asset trading. This research paper investigates the intersections between the metaverse and Web3 emerging technologies by firstly conducting a systematic literature review of the metaverse and its intersection with emerging technologies which currently has a dearth in academic and research literature despite the developments of the Web3 metaverse and its Layer-1 Layer-2 protocol. The review is followed by pilot-testing the metaverse platforms intersecting with Web3 technologies in real-world, particularly on the use of buy-and-sell, trading and item ownership under decentralized finance and financial technology. Finally, the research assesses the resulting metaverse based on user reviews and experiences on the feasibility of Web3 metaverse. The intersection of Web3 and the metaverse is still an early adoption of IR4.0 emerging technologies, yet the convergence of the metaverse, blockchain technologies and advancements in artificial intelligence is ultimately the precursor to the future Web4.",Yes,"논문은 메타버스와 Web3 기술의 교차점에 대해 체계적인 문헌 검토와 실험적 평가를 수행하고 있으며, 특히 Web3 기술의 정량적 평가와 관련된 실험과 사용자 경험 분석을 포함하고 있기 때문에 정량적 평가를 실시하고 있다고 판단됩니다."
Zero-BertXGB: An Empirical Technique for Abstract Classification in Systematic Reviews,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10845770,"Abstract classification in systematic reviews (SRs) is a crucial step in evidence synthesis but is often time-consuming and labour-intensive. This study evaluates the effectiveness of various Machine Learning (ML) models and embedding techniques in automating this process. Five diverse datasets are utilized: Aceves-Martins (2021), comprising 1,258 excluded and 230 included abstracts on the utilization of animal models in depressive behaviour studies; Bannach-Brown (2016), with 896 excluded and 73 included abstracts focusing on the methodological rigour of environmental health systematic reviews; Meijboom (2021), containing 599 excluded and 32 included abstracts on the retransitioning of Etanercept in rheumatic disease patients; Menon (2022), with 896 excluded and 73 included abstracts on environmental health reviews; and a custom Clinical Review Paper Abstract (CRPA) dataset, featuring 500 excluded and 50 included abstracts. A significant research gap in abstract classification has been identified in previous literature, particularly in comparing Large Language Models (LLMs) with traditional ML and Natural Language Processing (NLP) techniques regarding scalability, adaptability, computational efficiency, and real-time application. Addressing this gap, this study employs GloVe for word embedding via matrix factorization, FastText for character n-gram representation, and Doc2Vec for capturing paragraph-level semantics. A novel Zero-BertXGB technique is introduced, integrating a transformer-based language model, zero-shot learning, and an ML classifier to enhance abstract screening and classification into “Include” or “Exclude” categories. This approach leverages contextual understanding and precision for efficient abstract processing. The Zero-BertXGB technique is compared against other prominent LLMs, including BERT, PaLM, LLaMA, GPT-3.5, and GPT-4, to validate its effectiveness. The Zero-BertXGB model achieved accuracy values of 99.3% for Aceves-Martins2021, 92.6% for Bannach-Brown2016, 85.7% for Meijboom2021, 94.1% for Menon2022, and 98.8% for CRPA. The findings indicate that the Zero-BertXGB model, alongside other LLMs, can deliver reliable results with minimal human intervention, enhancing abstract screening efficiency and potentially revolutionizing systematic review workflows.",Yes,"논문 초록에서 다양한 머신러닝 모델과 embedding 기법을 활용하여 정량적 평가를 실시했다고 명확히 언급하고 있습니다. 특히, 모델의 정확도(accuracy)와 성능 비교를 통해 정량적 평가가 수행되었음을 알 수 있습니다."
Optimizing Article Screening and Information Extraction: A Hybrid Approach with GeminiAI and Vector Database,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10740208,"The exponential growth of scientific literature poses a significant challenge to researchers, resulting in redundancy in R&D due to inefficient review mechanisms. Manual literature reviews are time-consuming and resource-intensive, particularly when screening abstracts and titles, highlighting the need for innovative solutions to optimize the review process. This study introduces a three-step methodology using the GeminiAI model to streamline literature reviews: (1) Initial Screening, (2) Abstract Detail Extraction, and (3) Final Integration, with a Vector Database enabling efficient semantic searches in PDF files. In the first phase, GeminiAI achieved an accuracy of 88.66% in evaluating titles and abstracts based on specific inclusion and exclusion criteria, demonstrating its capability to filter relevant literature efficiently. The second phase enhanced this process by extracting key details, such as research-related modalities, thereby significantly reducing the pool of relevant papers. In the final step, the integration of the Vector Database with GeminiAI excelled, achieving an 80% similarity score in extracting detailed information, which greatly facilitated review writing and minimized manual effort. The user-friendly website designed for this purpose enables seamless paper uploads, with the Vector Database automatically extracting relevant details to streamline the workflow and accelerate innovation. This approach underscores the power of AI in optimizing literature reviews, reducing manual screening time and resources, and mitigating the risk of overlooking critical information. The entire system, including source code and supplementary materials, is available on our publicly accessible GitHub repository. https://github.com/mammona/ai-powered-litreview.git",Yes,"논문 초록에서 GeminiAI 모델이 제목과 초록 평가에 대해 88.66%의 정확도를 기록했다고 언급하며, 정량적 평가가 수행되었음을 명확히 제시하고 있습니다. 또한, 유사도 점수와 정확도 수치를 통해 평가 결과를 수치로 제시하고 있어 정량적 평가가 실시된 것으로 판단됩니다."
"Analysis the relationship of physiological, environmental, and cow milk productivity using AI",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7936165,"The dairy cattle productivity is very depending on the quality of their environment and physiological aspect. Hence, the purpose of the paper is to looking for the relationship model of physiological, environmental and milk productivity by using artificial intelligence (AI). The model will be useful for the user to decide the best cow treatment in order to gain the best milk production. The research is started with literature review and early survey of cattle physiological, environment factors and milk productivity. The next step is measuring the environment data (temperature, wind speed, and relative humidity) and measuring physiological aspect (heart rate, body temperature) correlated with milk productivity in 500 pairs of data. All the data are collected and stored into the database and then trained and validated using Back Propagation Neural Network (BPNN) with Genetic Algorithm (GA) optimization. The initial BPNN architectures are selected in 2 hidden layer, delta bar delta learning rule, sigmoid transfer function and epoch 10000. As a result, the system successfully developed an intelligent tool to predict milk production in any levels of environment and physical condition. Based on sensitivity analysis, the relative humidity, heart rate, environment and cow body temperature are categorized in strong impact, beside that are in weak impact on milk production.",Yes,"논문은 실험 데이터를 수집하고 이를 기반으로 인공지능 모델을 훈련 및 검증하는 과정을 통해 정량적 평가를 실시하고 있음을 보여줍니다. 또한, 민감도 분석을 통해 변수들의 영향을 정량적으로 평가하는 내용이 포함되어 있습니다."
The Detection of E-Commerce Manipulated Reviews Using GPT-4,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10346848,"In recent years, the exponential growth of e-commerce has transformed consumer purchasing behavior, with online reviews playing a crucial role in shaping buying decisions. Unfortunately, the prevalence of manipulated reviews has become a significant challenge, undermining the integrity of consumer feedback and eroding trust in e-commerce platforms. This research paper focuses on developing an advanced solution to address the issue of manipulated reviews using the innovative language model, GPT-4. The primary objective of this study is to investigate the effectiveness of GPT-4 in identifying and flagging manipulated reviews within the context of e-commerce platforms. GPT-4 is a state-of-the-art language model with superior natural language processing capabilities, making it an ideal candidate for automated review analysis. The research methodology encompasses a large-scale data collection process, where diverse e-commerce reviews are gathered from various platforms. To simulate real-world scenarios, manipulated reviews are artificially injected into the dataset, representing different degrees of sophistication. The dataset is then annotated by expert reviewers to establish ground truth labels for comparison. Next, GPT-4 is fine-tuned using transfer learning to specialize in detecting manipulated reviews. The fine-tuning process involves exposing the model to both genuine and manipulated review samples, allowing it to learn patterns and features indicative of manipulation. The fine-tuned model's performance is then evaluated using various metrics, including precision, recall, F1 score, and accuracy, against the ground truth dataset. The results of the experiment demonstrate the efficacy of GPT-4 in distinguishing between authentic and manipulated reviews. GPT-4 showcases remarkable accuracy and robustness in detecting increasingly sophisticated manipulation techniques, outperforming previous iterations of language models and traditional detection methods. Furthermore, the research delves into the characteristics of manipulated reviews that render them distinguishable from genuine reviews. These insights aid in understanding the vulnerabilities of e-commerce platforms to manipulation and offer valuable information for future research and platform enhancement efforts. The implications of this study are significant for e-commerce businesses, consumers, and platform administrators alike. By leveraging GPT-4's detection capabilities, e-commerce platforms can implement more robust review validation systems, ensuring the authenticity and reliability of consumer feedback. This, in turn, fosters greater trust among consumers, leading to informed purchasing decisions and improved overall user experience. In conclusion, this research paper contributes to the existing body of knowledge by showcasing the potential of GPT-4 in combatting manipulated reviews and strengthening the integrity of e-commerce platforms. With the rise of AI-driven technologies, the proposed approach presents a promising step towards a more transparent and trustworthy e-commerce ecosystem.",Yes,"논문 초록에서 GPT-4의 성능 평가를 위해 정량적 지표인 정밀도, 재현율, F1 점수, 정확도 등을 사용하여 모델의 성능을 평가했다고 명시되어 있습니다. 이러한 평가 방법은 정량적 평가의 전형적인 예로 볼 수 있습니다."
PsychSynth: Advancing Mental Health AI Through Synthetic Data Generation and Curriculum Training,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10773545,"The number of Mental-health help seekers are on rise over recent years, but the medical practitioners are limited due to which the healthcare system is heavily loaded and thereby the outcome is not promising. Advanced AI Technology is expected to ease this problem, however completely relying on the tools is reported to not work with the help seekers. Hence technology to assist help seekers and allow the healthcare system to screen the needy ones from the large pool of distress candidates should make the system efficient a nd effective.H owever for establishing the AI supportive system, two challenges exists: one is the large pool of dataset with diversity, and other is the AI model to respond to a context-aware situations. Expecting large dataset for training model from medical community needs further infrastructure support to make it digitally available with embedded annotations. Relying patiently for the dataset will miss the opportunity to serve the distress patients. Hence synthetic dataset generation and its validation from medical experts is an alternative for training robust and reliable model. Besides, context-aware curriculum inspired AI based summarizer model is found appropriate to adopt for this use-case where relevant features meant for diagnosing the problem is extracted from the improvised input text. The proposed curriculum trained AI model helps in transforming the improvised text inputs fed from the distress individuals to a summarized version representing domain expert form, embedded with symptoms related features for further classification. The synthetic data-set g eneration through OpenAI's GPT-40 models and Nemotron models are further evaluated with BERT based classifier m odels a nd curriculum based AI model. The training of the classifier m odels are also evaluated for synthetic and real-world dataset, which was scrapped from Reddit forum. Around 800 stream of real-world posts were evaluated from the medical experts and their findings related to sympotoms and annotations were employed to fine-tune the classifier and summarizer m odel. It was found t hat the fine-tuned models and training of BERT models from the merged dataset composed of synthetic ones with the medical practitioners annotated dataset were found to perform better than others. The summarizer model fetching shorter version of domain expert output enhanced the classification accuracy by 5 % for the real-world data. The effort is a step towards developing AI assistant to screen large posts of submissions from distress individuals and arrange for the necessary connects for the needy ones with the medical experts. The models and pruned datasets are made freely available for further usage to the researchers community.",Yes,"논문은 synthetic 데이터 생성, 모델 평가, 그리고 성능 비교를 포함하여 정량적 평가를 수행하고 있음을 명확히 언급하고 있습니다. 특히, 모델의 성능 향상과 정확도 향상(5%)와 같은 수치적 결과를 제시하여 정량적 평가를 실시하고 있음을 알 수 있습니다."
Deep Reinforcement Learning for Containerized Edge Intelligence Inference Request Processing in IoT Edge Computing,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10268016,"Edge intelligence (EI) refers to a set of connected systems and devices for artificial intelligence (AI) data collected and learned near the data collection site. The EI model inference phase has been improved through edge caching technologies such as intelligent models (IMs). IM inference across heterogeneously distributed edge nodes is worthy of discussion. The present focuses on software-defined infrastructure (SDI) and introduces a containerized EI framework for a mobile wearable Internet-of-Things (IoT) system. This framework, called the containerized edge intelligence framework (CEIF), is an inter-working architecture that allows the provisioning of containerized EI processing intelligent services related to mobile wearable IoT systems. CEIF enables dynamic instantiation of the inference services of AI models that have been pre-trained on clouds. It also accommodates edge computing devices (ECDs) running the container virtualization technique. Dynamic AI learning policies can also help with workload optimization, thereby reducing the response time of the requests of the EI inference. To stall the rapid increase in user workload when inferring the collected data for analysis, we then propose a deep q-learning algorithm in which the container cluster platform learns the varying user workload at the location of each ECD. The requests of the EI inference are scaled with the learned value and are processed successfully without overloading the ECD. When evaluated in a case study, the proposed algorithm enabled scaling of the processing requests of the EI inference in a containerized EI system while minimizing the number of instantiated container EI instances. The EI inference's requests are completed in an under-loaded container EI cluster system.",Yes,"논문 초록에서 딥 Q-러닝 알고리즘을 사용하여 워크로드를 동적으로 학습하고, 이를 기반으로 EI 추론 요청을 스케일링하는 정량적 평가를 수행했음을 시사하는 내용이 포함되어 있습니다. 또한, 평가 결과를 통해 시스템 성능 향상과 요청 처리 성공률을 분석한 것으로 보입니다."
A Comparative Analysis between AI Generated Code and Human Written Code: A Preliminary Study,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10825958,"In today’s world where generative artificial intelligence has almost become an integral part of the coding, new challenges must be faced. Therefore, evaluating software bugs in both human written and AI generated code can be useful for the developers. A comparative analysis of these two coding practices is not only helpful for the decisions taken by the developers, it will also assist to give a direction on how to improve the quality of AI driven code. Currently, researchers have leveraged the role of software metrics to compare human written code and AI generated code as these metrics have long been utilized for software bug and vulnerability prediction by the researchers. They also analyzed the secure coding practices in terms of the number of bugs found in both AI and human written code. Our study is an extension of the current works as this study focuses on a set of metrics and a set of bugs as identified by some static analyzer tools. Investigating these two coding practices from different angles can help to reveal unknown relationships and factors that further can be analyzed to improve code quality of recent AI tools. Therefore, the main objective of our work is to identify the relationships between software metrics and bugs in AI generated code and human written code to compare and contrast the coding profiles of the two approaches. This will offer developers critical knowledge to enhance their strategies in mitigating potential bug risks across different coding methodologies. We have utilized top-rated Java solutions to 90 LeetCode problems, generated corresponding AI Java solutions to them, and utilized various static analysis tools to collect metrics and bugs. In this study, we found that two software metrics CountLineCodeDecl and CountLineCodeExe are positively correlated with the bug DLS_DEAD_LOCAL_STORE and the metric AvgCyclomatic is related to the bug AvoidLiteralsInIfCondition in both human written and AI generated code. These findings provide developers with critical insights into potential bug risks, enabling more effective mitigation strategies across different coding methodologies.",Yes,"논문 초록에서 여러 소프트웨어 메트릭과 버그 간의 상관관계를 정량적으로 분석했다고 언급하고 있으며, 정적 분석 도구를 활용하여 수치 데이터를 수집하고 평가하는 과정을 포함하고 있습니다. 이는 정량적 평가를 실시하고 있음을 보여줍니다."
Deep learning for target-dependent sentiment classification in social media,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8643214,"There is currently a revolution in developing deep learning models for improving performance of many machine learning systems. This revolution has been expanded to sentiment analysis (opinion mining) as a promising research area. Throughout this paper, we swaged in various recent works that are performed for developing sentiment analysis systems by exploiting capabilities of deep learning models. We introduce a comprehensive literature review on predicting sentiments expressed towards particular topics (targets) in micro-blogs (such as tweets). This micro-specialization is referred to as target-dependent sentiment classification. To make our work more comprehensive, we evaluated also two more deep learning models that have not been used before in this research direction. Experimental results are shown along with summaries and discussions to emerge significance of developing deep learning based models in improving accuracy of target-dependent sentiment classification. Our findings highlighted some gaps that can be filled in future research and illustrates that there is a room for improvement.",Yes,"초록에서 ""Experimental results are shown""라는 표현을 통해 실험을 통한 평가가 이루어졌음을 알 수 있습니다. 또한, ""discussions to emerge significance""와 ""improving accuracy""라는 언급도 정량적 평가를 수행했음을 시사합니다."
Application of Artificial Intelligence Vision Technology in Chinese Fencing Teaching,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9918801,"Nowadays, with the development of Artificial Intelligence (AI) and its wide application in life practice, based on the cross-application of computer algorithms and related equipment technology, it has been widely studied in many fields. AI to promote physical education teaching and training has also become one of the essential projects of scientific physical education. Based on this, this research supports Chinese Fencing technology teaching with AI vision. First, this paper studies the development status of artificial intelligence visual technology to promote physical education, analyzes its system framework, establishes a model of AI visual technology to promote physical education, and finally carries out experiments. Then, this paper aims to use AI vision technology to evaluate the Chinese Fencing motion attitude specification problem and to explain the working principle of its additional correction of wrong actions and improvement of motion attitude specification.",No,"논문 초록에서는 AI 비전 기술을 활용하여 중국 펜싱의 동작 태도 규격 문제를 평가한다고 언급하고 있으나, 구체적인 정량적 평가 방법이나 수치 데이터에 대한 언급이 없습니다. 따라서 정량적 평가를 실시했다고 보기 어렵습니다."
Deep Learning Architectures for Improving Effectiveness of Covid Detection – A Pilot Study,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9675714,"Covid 19 has disrupted people’s lives all over the world. It has also resulted in serious infection, if not predicted at an initial stage. Accurate diagnosis is critical for early diagnosis and to provide appropriate treatment at an earlier stage. Therefore, this work aims at developing a deep learning-based diagnosis system to identify onset of covid at an early stage. In the proposed system a review of existing work in literature and need for covid diagnosis using Artificial Intelligence (AI) techniques is analyzed and presented. Further, three deep learning architectures viz., Convolutional Neural Network (CNN), Deep features from pretrained network classified using Support Vector Machine (SVM) classifier and Transfer learning using Resnet 101 architecture are experimented as part of this pilot study. A publicly available Covid CT image dataset is used to evaluate the proposed system. A considerable improvement in relevant performance metrics is observed in Transfer learning using RESNET 101 architecture. Henceforth the proposed system could be used as an aid to clinicians to accelerate covid 19 diagnosis and provide the necessary treatment.",Yes,"논문 초록에서 다양한 딥러닝 아키텍처를 실험하고, 이를 평가하기 위해 공개된 Covid CT 이미지 데이터셋을 사용하여 성능 지표를 측정했다고 명시되어 있습니다. 이는 정량적 평가를 실시했음을 보여줍니다."
User‟s Opinion Analysis Towards Unified Payment Interface (UPI) Transactions Using Artificial Intelligence,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10568859,"Unified Payment Interface (UPI) has revolutionized the way digital transactions are conducted in India. As a fast and convenient payment system, it has gained immense popularity among users. This paper presents a comprehensive analysis of users' opinions and sentiments towards UPI transactions using Artificial Intelligence Natural Language Processing (NLP) techniques. The study explores the vast amount of textual data available on social media platforms, customer reviews, and surveys to gain insights into how users perceive and experience UPI transactions. The research methodology involves data collection, preprocessing, sentiment analysis, and topic modeling using advanced NLP algorithms and AI techniques. Furthermore, topic modeling techniques such as Latent Dirichlet Allocation (LDA) are applied to identify key topics and themes in user opinions. This helps in categorizing and summarizing the various aspects of UPI transactions that users discuss most frequently. Common topics may include security, ease of use, transaction speed, and user interface design. The application of Artificial Intelligence and NLP enables the development of sentiment and topic models that provide valuable insights into users' opinions. The findings of this research reveal the current trends in user sentiments towards UPI transactions, enabling stakeholders to make data-driven decisions. It also sheds light on areas that require attention and improvement, such as security measures, user education, and transaction reliability. Overall, this study showcases the power of Artificial Intelligence and NLP in analyzing user opinions and offers valuable insights for the continuous development and enhancement of the Unified Payment Interface system.",Yes,"논문은 사용자 의견과 감정을 분석하기 위해 자연어 처리(NLP) 기법과 감성 분석, 토픽 모델링 등 정량적 평가 기법을 활용하고 있습니다. 또한, Latent Dirichlet Allocation (LDA)와 같은 정량적 알고리즘을 적용하여 주요 주제와 감정을 수치화하고 분석하는 과정을 포함하고 있습니다."
Leveraging Edge Machine Learning for Energy-Efficient Communication in IoT Networks for Carbon-Neutrality,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10595019,"In the rapidly evolving landscape of computer-related technologies, the synergy between artificial intelligence (AI) and the Internet of Things (IoT) has garnered increasing interest from both industry and academia. This burgeoning interest has catalyzed the development of applications at the network edge, which have now achieved considerable scale. As a vital and emergent field of research, machine learning at the network edge intertwines two pivotal themes: wireless communication and machine learning. This research area, termed edge machine learning, endeavors to harness vast quantities of mobile data from edge devices to train machine learning models. A primary challenge addressed in this research is the efficient allocation of limited communication resources amidst the data abundance at the network edge. This includes the strategic management of radio resources, with a particular focus on evaluating and utilizing data importance for optimal radio resource management and allocation. For instance, in wireless communications, the signal-to-noise ratio is often considered a critical metric for assessing data importance. This paper summarizes various methodologies and theories from related works, proposing a novel scheduling algorithm predicated on signal-to-noise ratio considerations. A simulation test, leveraging batch training characteristics of convolutional neural networks, is conducted to validate the proposed approach.",Yes,"논문 초록에서 제안된 방법과 실험 검증을 위해 시뮬레이션 테스트를 수행하였으며, 특히 배치 학습 특성을 활용한 검증이 언급되어 있습니다. 이는 정량적 평가가 이루어지고 있음을 시사합니다."
Maturity Assessment of Appraisal Processes in the AI Age: Ongoing Framework and Measuring Method,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10826084,"The increasing volume of generated data and archives raises pertinent questions regarding the effectiveness of traditional archival appraisal methods, which largely depend on human expertise. As automation and artificial intelligence (AI) become prevalent in various sectors, the field of archiving stands on the brink of significant transformation.This paper explores the integration of AI within archival appraisal processes, framed within the context of the Maturity Assessment for Appraisal (MAA) project (2023-2025). The MAA seeks to evaluate the defensibility, stability, and appropriateness of current appraisal practices while assessing the readiness of records for automated appraisal. Employing exploratory qualitative research, the study outlines a systematic approach that includes a literature review, testing of a maturity model, and consultations with archival professionals. The MAA encompasses six key dimensions: principles, vision/strategic framework, compliance, methodology, tools, and criteria, providing a structured framework for assessing the maturity of appraisal practices in the AI age. Preliminary results highlight the potential benefits of AI in enhancing appraisal efficiency and effectiveness, paving the way for more informed and defensible archival decisions. Some applied use cases are already started and primarily derived results will be highlighted",Yes,"논문은 평가 방법의 체계적 검토와 함께 성숙도 모델의 시험 및 검증을 포함하는 정량적 평가의 요소를 언급하고 있습니다. 또한, 성숙도 평가를 위한 구체적인 프레임워크와 방법론을 제시하여 정량적 평가가 실시되고 있음을 보여줍니다."
School evaluation and artificial intelligence,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10372877,"Assessment in education has evolved over time and has established new ways of obtaining information about students’ academic progress. However, the advent of artificial intelligence, such as ChatGPT, has posed challenges in the assessment process, as students can use these technologies to solve questions and tasks without studying. This research focused on recommending alternative educational resources for assessment, considering the pros and cons of ChatGPT and other AI. A systematic literature review was conducted and resources such as written tests, Kahoot!, Quizlet, Mentimeter and Nearpod were identified and evaluated in the tool designed in Microsoft Excel to evaluate their effectiveness. The results showed that the written test and the Plickers tool were the most effective, followed by ClassTools, Flip, Kahoot!, Quizlet, Mentimeter and Nearpod, in addition a list of activities that can be used to assess knowledge through the rubric is shown, among the most important are: oral lessons, exhibitions, open houses, speeches, case studies, debates and observation of participation, because these types of work encourage the speaker to prepare and master the subject. Traditional assessment in the educational field has faced challenges with the advent of artificial intelligence because AI’s ability to generate tasks and answers without students having to read, write or study poses a challenge to ensure the actual acquisition of knowledge and skills. This research recommends educational resources to assess through digital tools or educational activities that allow for authentic assessment of learning and limit reliance on AI.",Yes,"논문은 Microsoft Excel을 활용하여 평가 도구의 효과를 정량적으로 평가하는 과정을 포함하고 있으며, 여러 평가 도구의 효과를 비교하는 정량적 평가를 실시하고 있음을 보여줍니다. 따라서, 이 연구는 정량적 평가를 수행하고 있다고 판단됩니다."
Explainable Text Classification Techniques in Legal Document Review: Locating Rationales without Using Human Annotated Training Text Snippets,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10020626,"US corporations regularly spend millions of dollars reviewing electronically-stored documents in legal matters. Recently, attorneys apply text classification to efficiently cull massive volumes of data to identify responsive documents for use in these matters. While text classification is regularly used to reduce the discovery costs of legal matters, it also faces a perception challenge: amongst lawyers, this technology is sometimes looked upon as a ""black box."" Put simply, no extra information is provided for attorneys to understand why documents are classified as responsive. In recent years, explainable machine learning has emerged as an active research area. In an explainable machine learning system, predictions or decisions made by a machine learning model are human understandable. In legal ‘document review’ scenarios, a document is responsive, because one or more of its small text snippets are deemed responsive. In these scenarios, if these responsive snippets can be located, then attorneys could easily evaluate the model’s document classification decisions – this is especially important in the field of responsible AI. Our prior research identified that predictive models created using annotated training text snippets improved the precision of a model when compared to a model created using all of a set of documents’ text as training. While interesting, manually annotating training text snippets is not generally practical during a legal document review. However, small increases in precision can drastically decrease the cost of large document reviews. Automating the identification of training text snippets without human review could then make the application of training text snippet-based models a practical approach. This paper proposes two simple machine learning methods to locate responsive text snippets within responsive documents without using human annotated training text snippets. The two methods were evaluated and compared with a document classification method using three datasets from actual legal matters. The results show that the two proposed methods outperform the document-level training classification method in identifying responsive text snippets in responsive documents. Additionally, the results suggest that we can automate the successful identification of training text snippets to improve the precision of our predictive models in legal document review and thereby help reduce the overall cost of review.",Yes,"논문 초록에서 두 가지 머신러닝 방법을 평가하고 비교하는 실험이 수행되었음을 언급하며, 이를 통해 정량적 평가가 이루어졌음을 알 수 있습니다. 또한, 실험 결과를 통해 제안된 방법들이 기존 방법보다 우수하다는 점이 제시되어 있어, 정량적 평가가 실시된 것으로 판단됩니다."
AI Orthopraxy: Towards a Framework for That Promotes Fairness,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9462167,"This paper introduces the term AI Orthopraxy as the correct practice of AI and a framework that aims to unify some aspects associated with AI ethics. These include standards, legal, and measures of fairness. We draw from existing tools that have been peer-reviewed by academics and discussed in recent literature to provide a mechanism for assessing the level by which a model or AI technology follows the correct practices of ethical AI. This paper describes a preliminary, ongoing, study and shows the early stages of a prototype framework, including a visual representation of the level of AI Orthopraxy of a model using hive plots. This work can potentially help create fair and trustworthy AI built upon the core tenets of accountability, transparency, and fairness. One of the current limitations is that it requires validation of peers that are willing, able, and trained to evaluate an AI model or technology using standards and other novel frameworks.",Yes,"논문은 AI의 윤리적 실천 수준을 평가하기 위한 프레임워크와 도구를 제시하며, 이를 통해 AI 모델이나 기술의 준수 정도를 정량적으로 평가하는 방식을 포함하고 있다. 또한, AI의 공정성, 투명성, 책임성을 측정하는 지표와 시각적 표현 방법을 개발하는 연구를 진행하고 있어 정량적 평가를 실시하고 있다고 볼 수 있다."
A Physiologically Informed Three-Dimensional Convolutional Neural Network to Aid Diagnosis of Non-Small Cell Lung Cancer,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10389384,"Lung cancer can be divided into two main categories, i.e., either small cell lung cancer (SCLC) or Non-Small Cell Lung Cancer (NSCLC), which accounts for 85% of lung cancers. NSCLC is a disease wherein malignant cancer cells form in the lung tissue. The five-year survival rate decreases as the NSCLC cancer becomes more advanced, from 40% for stage I to only 1% for stage IV; thus, a vital challenge to overcome is the early detection of NSCLC to achieve a higher chance of survival. As sonographers and radiologists are faced with the problem of being overworked with many time-consuming duties, it is important to consider new systems that could help in improving their effectiveness and efficiency while maintaining a clinically acceptable level of accuracy and reliability. Artificial Intelligence (AI) paves the way to allow computerized algorithms to perform tasks that would normally require only expert human involvement. In this report, a new AI-driven system is proposed to aid radiologists in the diagnosis of NSCLC, thus improving its specificity by design, while minimizing false positives as much as possible. It is worth noting that many clinical sub-fields have already started using AI to aid decision making, such as in breast cancer screening. Computed Tomography (CT) scans contain crucial volumetric, morphological lung tissue-related information that is only partly used to inform a diagnosis of NSCLC. In CT scans, each voxel can be converted into its corresponding Hounsfield Unit (HU) values, which are used to estimate tissue density; via this complementary information, areas of abnormal density or high attenuation can be identified, thus leading an AI-driven model to achieve a higher reliability in aiding diagnosis of NSCLC. Therefore, a three-dimensional AI-driven system may lead to an earlier detection of NSCLC, by complementing radiologists' expertise, experience, and decision making. This study leverages a thresholding-based segmentation algorithm to identify the region of interest defining the lungs by analysing each voxel's HU. Subsequently, an AI-driven model is proposed to analyse all CT scans of a patient to identify NSCLC earlier. This model is based on a three-dimensional convolutional neural network, trained on volumetric information of 90 images and validated on 40 images. The CT scan dataset has metadata for all patients and allows to compare the classification models predictions to the known or ground-truth diagnostic labels of the patients. The model led to 100% classification accuracy and an area under the precision-recall curve of 1 (100%) over 130 subjects (70 patients with NSCLC, 60 healthy controls). Further work is underway to train, validate, and test the model on a larger dataset and assess its performance more comprehensively, and such minimum sample sizes will be determined statistically based on a power analysis, so that the results will be confidently comparable against the clinical diagnostic gold-standard labels.",Yes,"논문은 3D 컨볼루션 신경망을 이용하여 NSCLC 진단의 정밀도를 평가하는 성능 지표(정확도 100%, 정밀-재현 곡선 면적 1)를 제시하고 있어 정량적 평가를 실시하고 있음을 보여줍니다. 또한, 모델의 성능을 검증하기 위해 구체적인 수치와 지표를 사용하여 평가하고 있습니다."
An LLM-Driven Chatbot in Higher Education for Databases and Information Systems,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10706931,"Contribution: This research explores the benefits and challenges of developing, deploying, and evaluating a large language model (LLM) chatbot, MoodleBot, in computer science classroom settings. It highlights the potential of integrating LLMs into LMSs like Moodle to support self-regulated learning (SRL) and help-seeking behavior. Background: Computer science educators face immense challenges incorporating novel tools into LMSs to create a supportive and engaging learning environment. MoodleBot addresses this challenge by offering an interactive platform for both students and teachers. Research Questions: Despite issues like bias, hallucinations, and teachers’ and educators’ resistance to embracing new (AI) technologies, this research investigates two questions: (RQ1) To what extent do students accept MoodleBot as a valuable tool for learning support? (RQ2) How accurately does MoodleBot churn out responses, and how congruent are these with the established course content? Methodology: This study reviews pedagogical literature on AI-driven chatbots and adopts the retrieval-augmented generation (RAG) approach for MoodleBot’s design and data processing. The technology acceptance model (TAM) evaluates user acceptance through constructs like perceived usefulness (PU) and Ease of Use. Forty-six students participated, with 30 completing the TAM questionnaire. Findings: LLM-based chatbots like MoodleBot can significantly improve the teaching and learning process. This study revealed a high accuracy rate (88%) in providing course-related assistance. Positive responses from students attest to the efficacy and applicability of AI-driven educational tools. These findings indicate that educational chatbots are suitable for integration into courses to improve personalized learning and reduce teacher administrative burden, although improvements in automated fact-checking are needed.",Yes,"논문 초록에서 MoodleBot의 응답 정확도를 88%로 평가하는 등 정량적 평가를 실시한 내용을 명확히 언급하고 있습니다. 또한, 사용자 수용도와 정확성에 대한 수치적 결과를 제시하여 정량적 분석이 수행되었음을 알 수 있습니다."
Should Robots Replace Teachers? Mobilisation of AI and Learning Analytics in Education,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9697300,"The purpose of this study was to determine how artificial intelligence (AI) impacts education. The study's focus was restricted to the use and impact of artificial intelligence in administration, education, and learning, and was founded on a narrative and framework created via exploratory research for assessing AI. The use of literature review as a research strategy and methodology helped in accomplishment of study's goal, which was achieved making use of a qualitative research technique. AI is an area of research in which computers, robots, and other technologies are programmed to exhibit human-like intelligence, as characterised by cognitive skills such as learning and adaptation, as well as decision-making capabilities. According to the findings, AI has been widely embraced and used in a number of ways by organisations, especially educational institutions, in a range of circumstances and settings. AI began with computer technology, progressed to intelligent online and web-based education, and finally, embedded computer systems were used to perform instructional tasks autonomously or collaboratively with teachers, in conjunction with other technologies such as humanoid robots and web-based chatbots. These platforms have allowed instructors to improve the overall quality of their instructional work while also improving their efficiency and speed for administrative duties such as evaluating students' work. However, since the systems are based on machine learning and adaptability, curriculum and materials can be customised to meet the unique requirements of individual students, resulting in improved absorption and retention and a more pleasant overall learning experience.",No,"논문 초록은 AI의 활용과 영향에 대한 서술적 설명과 정성적 평가를 중심으로 하고 있으며, 구체적인 정량적 평가 방법이나 데이터 분석이 언급되지 않습니다. 따라서, 정량적 평가를 실시하고 있다고 보기 어렵습니다."
College Enquiry Chatbot,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10156978,"Today's widespread use of smartphones is proof that technology is always evolving. Nowadays, artificial intelligence is crucial to numerous industries, including manufacturing, human resources, and customer service. There are numerous chatbots that help people discover solutions to their questions. As a result, we are developing an AI-powered chatbot that can address all questions about colleges. It serves as an intelligence tool with an emphasis on higher education. This artificially intelligent machine will respond to queries from users regarding matters related to higher education. The information is kept in the chatbot's database so that it can be used to spot trends and decide how to respond to questions. The chatbot for college inquiries was developed using an NLP system that evaluates questions and comprehends messages. People react to each other differently based on emotions and attitude. Because chatbots must go by rules just like humans do, they will communicate with customers in a courteous and correct manner. Students can ask the chatbot any questions at any time of the day or night, and they will receive a prompt and accurate response. A chatbot can respond to thousands of users simultaneously. Chatbot can work 24 ×7 without getting tired. It has minimal errors, which increases productivity.",No,"논문 초록에서는 AI 기반 챗봇 개발에 관한 내용이 주로 다루어지고 있으며, 질문 이해와 응답 생성에 초점을 맞추고 있습니다. 그러나 정량적 평가를 수행했다는 구체적인 언급이나 데이터 분석, 실험 결과에 대한 설명이 포함되어 있지 않기 때문에 정량적 평가를 실시했다고 판단하기 어렵습니다."
A review on Student Performance Prediction using Educational Data mining and Artificial Intelligence,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9768773,"Predicting student’s performance helps all stakeholders of education system to plan and take appropriate measures. Increase in the number of higher educational institutes and adoption to online and blended learning has enabled collection of large amounts of data. Data Mining and Artificial Intelligence tools can be successfully used on this data to predict student performance to provide required insights to the stakeholders. This paper focusses a systematic literature review on use of data mining and AI tools for Student’s Performance Prediction. Using Critical review of available literature authors have proposed a combinatorial model for student performance prediction using some techniques like Decision Tree, Random Forest, Genetic Algorithm, Artificial Neural Networks, etc.",Yes,"논문 초록에서 학생 성과 예측을 위해 데이터 마이닝과 인공지능 도구를 사용했다고 명시되어 있으며, Decision Tree, Random Forest, Genetic Algorithm, Artificial Neural Networks 등 다양한 정량적 기법들이 언급되어 있습니다. 이는 정량적 평가를 실시하고 있음을 시사합니다."
The Future of Cyber Defence: ML and DL Enhanced Firewalls for Intrusion Detection,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10838028,"Given the increasing frequency of network-based threats, there is a critical need for robust intrusion detection systems (IDS) to safeguard digital assets. Traditional rule-based IDS often struggle to counter emerging cyber threats, highlighting the demand for more adaptive solutions. This study introduces the Next Generation Firewall (NGFW), an advanced firewall system enhanced by machine learning (ML) and deep learning (DL) techniques. By integrating ML algorithms like Support Vector Machines (SVM), Random Forests, and Deep Neural Networks (DNN) with DL models such as Convolutional Neural Networks (CNN) and Recurrent Neural Networks (RNN), the NGFW significantly improves detection flexibility, effectiveness, and accuracy. Our comprehensive literature review demonstrates the substantial impact of ML and DL on IDS performance. The NGFW's approach includes systematic data collection, preprocessing, feature extraction, and rigorous model evaluation using metrics like accuracy, precision, and recall. Experimental results show that CNNs excel in detecting malicious activities with minimal false positive rates. Real-world testing further validates the NGFW's capacity to strengthen cybersecurity measures. The classification report reveals impressive performance, with precision, recall, and F1-scores exceeding 97% in each category and an overall accuracy of 97.29%. These results underscore the potential of ML and DL to advance intelligent cybersecurity solutions and enhance the reliability of intrusion detection systems.",Yes,"논문 초록에서 다양한 평가 지표(accuracy, precision, recall, F1-score 등)를 사용하여 모델의 성능을 정량적으로 평가했다고 명시하고 있습니다. 또한, 실험 결과와 성능 보고서를 통해 구체적인 수치로 평가를 실시한 것을 확인할 수 있습니다."
Deep Learning Based Object Oriented Software Estimation: A Case Of Reusability,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10525948,"The software development stages supported by deep learning techniques in view of the collection of software engineering promises, it is essential to see the current software engineering requirements helped through deep learning, by seeing it various supports experts find the feasible to use deep learning information to deliver commercial software by considering functional and nonfunctional requirements. A Reusability assessment model for object oriented design particularly for design phase of development life cycle has been developed in this research paper with the help of deep learning technique. The developed system relates the Reusability orientated diagram qualities with software maintenance requirements and also connects feasibility with Reusability. No such model has been currently available in the literature review that measures Reusability of OO diagram through bringing practicality into consideration utilizing deep learning. The proposed model overcomes any barrier among object orientated outline qualities, practicality and Reusability. Proposed efforts works in order to improve the overall software design quality by considering the quality key attributes especially reusability of software design at initial stage of development life cycle. Finally in view of the above truth proposed model has been developed and validated with the help of class diagrams.",No,"논문 초록에서는 딥러닝 기법을 활용한 재사용성 평가 모델을 개발했다고 언급하고 있지만, 구체적인 정량적 평가 방법이나 실험을 통한 수치적 평가에 대한 언급은 없습니다. 따라서 정량적 평가를 실시했다고 보기 어렵습니다."
Assessing AI Readiness Across Organizations: The Case of UAE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9225386,"several recent business case studies showed the benefits of adopting Artificial Intelligence (AI) technologies in business, which encouraged many organizations to think seriously in adopting AI to re-innovate existing business processes or entire business models. Though, the challenge of having a clear framework to guide companies in such an AI transformation process is missing. This paper aims to investigate conceptual frameworks sued to assess AI readiness in organizations using popular existing theories and frameworks from the Information Systems (IS) discipline such as Technology-Organizations-Environment (TOE) framework, Diffusion of Innovation theory (DOI), and socio-technical Design. Followed by a review of the current theories in depth and propose an extended framework that will consider the socio-technical elements based on the local context of the UAE. A mixed methods research approach is proposed to test and validate the framework and answer the research questions. The expected results from applying the proposed framework will help academics and practitioners to identify the critical factors needed to have a successful implementation of AI strategies in the UAE.",Yes,"초록에서 연구가 제안하는 프레임워크를 테스트하고 검증하기 위해 혼합 방법 연구 접근법을 사용할 것이라고 명시되어 있어, 정량적 평가가 실시되고 있음을 알 수 있습니다. 이는 연구가 실증적 데이터를 수집하고 분석하는 과정을 포함한다는 의미입니다."
Bridging Decentralized AI and Blockchain: Challenges and Solutions,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10859075,"The integration of Deep Learning and Blockchain presents an opportunity to decentralize artificial intelligence, reducing the risks associated with centralized AI models. This paper proposes a novel approach using a consensus protocol that leverages Deep Learning as Proof of Useful Work. The proposed protocol aims to address key challenges related to scalability, security, and efficiency in decentralized AI systems. To validate the protocol, a series of simulations were conducted to analyze reward distribution in networks with both honest and Byzantine nodes. Additionally, an alternative solution using smart contracts was explored, highlighting potential gas cost issues on Layer-1 networks. A Layer-2 implementation is suggested as a scalable alternative to minimize gas costs. The findings demonstrate that a decentralized AI system is achievable with carefully designed protocols and reward mechanisms, though further research is needed to address outstanding challenges.",Yes,논문 초록에서 시뮬레이션을 통한 검증과 보상 분배 분석 등 정량적 평가가 수행되었음을 시사하는 내용을 포함하고 있습니다. 이러한 실험적 검증은 정량적 평가의 일환으로 볼 수 있습니다.
Deep Cardiovascular Clinical Decision Support and Control System,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10346453,"Since the past decade, Internet of Health Things (IoHT) and artificial intelligence (AI) have continued to revolutionize the healthcare sector by enabling remote patient monitoring and the development of diagnostic tools. The availability and vast amount of data and its variety gathered from patient, encouraged researchers and increased their interest in developing healthcare solutions. In this research work, we present literature studies related to cardiovascular diseases and how machine learning can be used in clinical applications for prediction, diagnosis, and prognosis to help specialists to choose the appropriate treatment decision for a patient's specific clinical condition. In addition a new architecture is proposed for monitoring and assisting in cardiac diseases diagnosis. Using ADS1298 chip, the board is able to measure the ECG signal, analyse it, and determine whether a person have heart disease (cardiomyopathy) or not. In case of heart failure, our prototype triggers an alarm by sending a message in order to report the patient's condition to doctor and to clinical center. The measure healthcare parameters are collected from different e-health sensors platform connected to raspberry Pi card. We executed our model on 90,000 instances from PhysioNet MIT-BIH Arrhythmia Diagnostic ECG database. The dataset is annotated in five different categories (normal, atrial premature, premature ventricular contraction, fusion of ventricular and normal beat, fusion beat of paced and normal) in accordance with the EC57 standard. Our proposed CNN model gives good result in terms of detection and accuracy. We achieved an average accuracy of 98.64%.",Yes,"논문은 ECG 신호 분석과 심장 질환 예측을 위해 CNN 모델을 사용하여 정량적 평가를 수행하고 있으며, 98.64%의 정확도를 보고하고 있습니다. 이는 명확한 성능 평가와 수치적 결과를 포함하고 있어 정량적 평가를 실시하고 있다고 판단됩니다."
Review and Empirical Analysis of Machine Learning-Based Software Effort Estimation,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10538131,"The average software company spends a huge amount of its revenue on Research and Development (R&D) for how to deliver software on time. Accurate software effort estimation is critical for successful project planning, resource allocation, and on-time delivery within budget for sustainable software development. However, both overestimation and underestimation can pose significant challenges, highlighting the need for continuous improvement in estimation techniques. This study reviews recent machine learning approaches employed to enhance the accuracy of software effort estimation (SEE), focusing on research published between 2020 and 2023. The literature review employed a systematic approach to identify relevant research on machine learning techniques for SEE. Additionally, comparative experiments were conducted using five commonly employed Machine Learning (ML) methods: K-Nearest Neighbor, Support Vector Machine, Random Forest, Logistic Regression, and LASSO Regression. The performance of these techniques was evaluated using five widely adopted accuracy metrics: Mean Squared Error (MSE), Mean Magnitude of Relative Error (MMRE), R-squared, Root Mean Squared Error (RMSE), and Mean Absolute Percentage Error (MAPE). The evaluation was carried out on seven benchmark datasets: Albrecht, Desharnais, China, Kemerer, Mayazaki94, Maxwell, and COCOMO, which are publicly available and extensively used in SEE research. By carefully reviewing study quality, analyzing results across the literature, and rigorously evaluating experimental outcomes, clear conclusions were drawn about the most promising techniques for achieving state-of-the-art accuracy in estimating software effort. This study makes three key contributions to the field: firstly, it furnishes a thorough overview of recent machine learning research in software effort estimation (SEE); secondly, it provides data-driven guidance for researchers and practitioners to select optimal methods for accurate effort estimation; and thirdly, it demonstrates the performance of publicly available datasets through experimental analysis. Enhanced estimation supports the development of better predictive models for software project time, cost, and staffing needs. The findings aim to guide future research directions and tool development toward the most accurate machine learning approaches for modelling software development effort, costs, and delivery schedules, ultimately contributing to more efficient and cost-effective software projects.",Yes,"논문 초록에서 여러 머신러닝 기법의 성능 평가를 위해 다양한 정확도 지표(MSE, MMRE, R-squared, RMSE, MAPE)를 사용하여 정량적 평가를 실시했다고 명확히 언급하고 있습니다. 또한, 실험을 통해 비교 분석을 수행하는 등 구체적인 수치와 성과를 평가하는 정량적 방법이 적용된 것으로 보입니다."
Sentimental Analysis based on Machine Learning Technique,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10511973,"In an age defined by the unprecedented proliferation of online content, the ability to discern sentiments within textual data has become integral across a spectrum of applications, spanning from business intelligence to the dynamic realm of social media monitoring. This study conducts a thorough exploration of sentiment analysis methodologies, placing a primary focus on the practical application of machine learning algorithms tailored to the demands of today's generation.The research conducts a comparative analysis to evaluate the effectiveness of diverse algorithms, including support vector machines, neural networks, and ensemble methods. By exploring proposed strategies to address these challenges, the study sheds light on their implications focusing on accuracy and robustness of sentiment analysis models in the present-day landscape.A comprehensive analysis compares diverse paradigms, such as SVM & neural networks, assessing their effectiveness amidst the challenges of navigating sarcasm, decoding context-dependent sentiments, and understanding language subtleties.Twitter, as a platform, presents unique challenges for sentiment analysis, marked by the prevalence of slang and misspellings, compounded by the 140-character limitTwo predominant strategies, the approach based on knowledge and machine learning, are deployed for extracting sentiments from textual data. This research delves into the machine learning approach, specifically applied to analyse Twitter posts about electronic products such as mobiles and laptops. Focusing on sentiment analysis within a specific domain elucidates the impact of domain-specific information on sentiment classification.This study introduces a novel feature vector designed for the classification of tweets into positive and negative sentiments, offering insights into public opinions about electronic products. The utilization of a machine learning framework enhances the precision and granularity of sentiment analysis in the dynamic landscape of Twitter, allowing for a more nuanced understanding of user sentiments within the electronic products domain.However, a primary challenge faced by sentiment analysis lies in the dearth of adequately labelled data within the realm of NLP. Deep learning models stand out because of their inherent capacity for automatic learning.This research paper mentions recent advancements showcasing the integration of deep learning models, such as deep neural networks, convolutional neural networks, among others, aimed at resolving various challenges within sentiment analysis. This includes tasks such as classification of sentiments, addressing cross-lingual complexities, textual and visual analysis, and the examination of product reviews, among others.",Yes,"논문 초록에서는 다양한 머신러닝 알고리즘의 성능 평가와 비교 분석이 이루어지고 있음을 언급하며, 특히 정확도와 강인성을 평가하는 내용이 포함되어 있습니다. 이는 정량적 평가가 수행되고 있음을 시사합니다."
Towards MLOps: A Framework and Maturity Model,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9582569,"The adoption of continuous software engineering practices such as DevOps (Development and Operations) in business operations has contributed to significantly shorter software development and deployment cycles. Recently, the term MLOps (Machine Learning Operations) has gained increasing interest as a practice that brings together data scientists and operations teams. However, the adoption of MLOps in practice is still in its infancy and there are few common guidelines on how to effectively integrate it into existing software development practices. In this paper, we conduct a systematic literature review and a grey literature review to derive a framework that identifies the activities involved in the adoption of MLOps and the stages in which companies evolve as they become more mature and advanced. We validate this framework in three case companies and show how they have managed to adopt and integrate MLOps in their large-scale software development companies. The contribution of this paper is threefold. First, we review contemporary literature to provide an overview of the state-of-the-art in MLOps. Based on this review, we derive an MLOps framework that details the activities involved in the continuous development of machine learning models. Second, we present a maturity model in which we outline the different stages that companies go through in evolving their MLOps practices. Third, we validate our framework in three embedded systems case companies and map the companies to the stages in the maturity model.",Yes,"논문은 MLOps의 활동과 성숙 단계에 대한 프레임워크와 성숙도 모델을 제시하며, 이를 검증하는 사례 연구를 포함하고 있어 정량적 평가를 실시하고 있다고 볼 수 있습니다. 특히, 성숙도 모델의 단계별 평가와 검증이 포함되어 있어 정량적 평가의 요소를 갖추고 있습니다."
A Synthesis of Green Architectural Tactics for ML-Enabled Systems,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10554775,"The rapid adoption of artificial intelligence (AI) and machine learning (ML) has generated growing interest in understanding their environmental impact and the challenges associated with designing environmentally friendly ML-enabled systems. While Green AI research, i.e., research that tries to minimize the energy footprint of AI, is receiving increasing attention, very few concrete guidelines are available on how ML-enabled systems can be designed to be more environmentally sustainable. In this paper, we provide a catalog of 30 green architectural tactics for ML-enabled systems to fill this gap. An architectural tactic is a high-level design technique to improve software quality, in our case environmental sustainability. We derived the tactics from the analysis of 51 peer-reviewed publications that primarily explore Green AI, and validated them using a focus group approach with three experts. The 30 tactics we identified are aimed to serve as an initial reference guide for further exploration into Green AI from a software engineering perspective, and assist in designing sustainable ML-enabled systems. To enhance transparency and facilitate their widespread use and extension, we make the tactics available online in easily consumable formats. Wide-spread adoption of these tactics has the potential to substantially reduce the societal impact of ML-enabled systems regarding their energy and carbon footprintCCS CONCEPTS• Software and its engineering → Designing software; Software architectures; • Social and professional topics → Sustainability; • Computing methodologies → Machine learningLay Abstract: Machine learning (ML) is a technology field that wants to provide software with functionality similar to humanlike intelligence, e.g., for understanding text or describing images. However, creating and using systems with ML needs a lot more computing power than non-ML systems, which is bad for the environment. Companies therefore need concrete advice on how they can create ML systems that are environmentally sustainable. In this paper, we provide a catalog of 30 green architectural tactics for these systems. An architectural tactic is a high-level design technique to improve software quality, in our case environmental sustainability. To achieve this, we analyzed 51 scientific papers and later discussed with 3 experts to improve and extend our catalog. If many companies start using these tactics, the energy footprint of systems with ML can be greatly reduced.",Yes,"논문은 30개의 그린 아키텍처 전술을 제시하며, 이를 분석하고 검증하는 과정에서 구체적인 평가와 검증 방법을 사용했음을 시사합니다. 또한, 초록에서 ""validation""과 ""analysis""라는 용어를 통해 정량적 평가의 가능성을 내포하고 있습니다."
A Semantic Approach to Emotion Recognition Using IBM Watson Bluemix tone Analyzer and translator Language,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9012970,"Artificial intelligence has been a far-flung goal of computing since the conception of the computer, but we may be getting closer than ever with new cognitive computing models. Personal Assistant Agents (PAAs) can assist users to deal with the task of selecting news items and making decisions. The term cognitive computing is typically used to describe AI systems that aim to simulate human thought. Sentiment analysis and emotion detection that aim to build intelligent systems able to recognize and interpret human emotions. Emotions are considered a very important area because they impact interactions, thinking and behaviors. IBM Watson is one of the most famous company, among others, a lot of services for Natural Language Processing. The IBM Watson Developer cloud provides a library of cognitive services as REST APIs which are available on IBM Bluemix. A machine learning information retrieval tool and building on related work in this area which suggests a powerful correlation between the people, emotions, attitude and cognitive processes which shows more documentation that profiling and predicting user's identity is feasible. We introduce an E-ANRS as a solution to problem of cold-start by using IBM Bluemix server for first time, which provides two services are (language translator and tone analyzer). The experimental results obtained from research are, evaluation of RS which gives three parameters being precision (86%), recall (87%), and F1-score (86%). In another side we have two ways to measure accuracy of emotion for our model by using EEG and Self-Assessment-Manikin techniques. By the use of EEG signals as (attention and meditation), electrical activity of neurons within the brain EEG is used. The results of IBM service Language translation and tone analyzer accuracy for 40 tests are 42%. The main objective of this work is to demonstrate the feasibility of a translation-based approach to emotion recognition in texts.",Yes,"논문 초록에서 정량적 평가를 위해 정확도(precision, recall, F1-score)와 EEG 신호를 이용한 측정값 등 구체적인 수치와 지표를 제시하고 있어, 정량적 평가를 실시하고 있음을 알 수 있습니다."
Explainable Text Classification in Legal Document Review A Case Study of Explainable Predictive Coding,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8622073,"In today's legal environment, lawsuits and regulatory investigations require companies to embark upon increasingly intensive data-focused engagements to identify, collect and analyze large quantities of data. When documents are staged for review - where they are typically assessed for relevancy or privilege - the process can require companies to dedicate an extraordinary level of resources, both with respect to human resources, but also with respect to the use of technology-based techniques to intelligently sift through data. Companies regularly spend millions of dollars producing `responsive' electronically-stored documents for these types of matters. For several years, attorneys have been using a variety of tools to conduct this exercise, and most recently, they are accepting the use of machine learning techniques like text classification (referred to as predictive coding in the legal industry) to efficiently cull massive volumes of data to identify responsive documents for use in these matters. In recent years, a group of AI and Machine Learning researchers have been actively researching Explainable AI. In an explainable AI system, actions or decisions are human understandable. In typical legal `document review' scenarios, a document can be identified as responsive, as long as one or more of the text snippets (small passages of text) in a document are deemed responsive. In these scenarios, if predictive coding can be used to locate these responsive snippets, then attorneys could easily evaluate the model's document classification decision. When deployed with defined and explainable results, predictive coding can drastically enhance the overall quality and speed of the document review process by reducing the time it takes to review documents. Moreover, explainable predictive coding provides lawyers with greater confidence in the results of that supervised learning task. The authors of this paper propose the concept of explainable predictive coding and simple explainable predictive coding methods to locate responsive snippets within responsive documents. We also report our preliminary experimental results using the data from an actual legal matter that entailed this type of document review. The purpose of this paper is to demonstrate the feasibility of explainable predictive coding in the context of professional services in the legal space.",Yes,"논문 초록에서 ""실험 결과""를 언급하며, 실제 법률 사례 데이터를 사용한 예비 실험 결과를 보고한다고 명시되어 있습니다. 이는 정량적 평가가 수행되었음을 시사합니다."
A Trend of AI Conference Convergence in Similarity: An Empirical Study Through Trans-Temporal Heterogeneous Graph,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10049682,"Publishing the research works on academic publications is an important part of the scientific process. Since the development of computer science research is very fast, researchers tend to publish the research works in a fast way, such as conferences whose review processes are faster than the journals. In the past decades, one conference usually focuses on a specific research field and the topic or method overlap between conferences is low. We have noticed that, in recent years, some topics or methods which were once studied in a small number of specific research fields have become popular in many other fields. Naturally, we come up with two research questions: (1) Do the conferences indeed become similar? and (2) How do conferences become similar? In this paper, we first use a trans-temporal heterogeneous graph network to model academic conferences in recent 20 years. Due to the large number of conferences, we categorize these conferences into 6 research fields for brevity. Then, we first quantitatively and qualitatively assess “Do the research fields become similar?” and then focus on exploring “How do research fields become similar?”. From the result, we find the reason for the research fields in computer science become similar is that AI becomes pervasive and researchers tend to apply the machine learning methods to different application fields. Since the methods become universal between different research fields, researchers should pay more attention to advanced information in other fields to motivate more interdisciplinary works. To assist the researchers to explore related interdisciplinary advanced information, it is crucial to measure the cross-field impact of papers using the citation information and recommend the paper which has a high cross-field impact on the related researchers. As for the newly published papers which do not have any citations, we also propose a cross-field impact prediction model to recommend the cutting-edge research works to related researchers accurately. Experiments conducted on real-world datasets verify the effectiveness of the proposed method.",Yes,"논문 초록에서 연구의 성과를 평가하기 위해 실험을 수행했다고 언급하며, 제안된 방법의 효과를 검증하기 위해 실험이 진행되었음을 알 수 있습니다. 이는 정량적 평가가 이루어지고 있음을 보여줍니다."
Deep Learning for Text Based Emotion Classification from Social Media,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10462735,"Affective Computing is the study of systems that can recognize underlying human emotions. To be able to detect this, the systems usually have a sensor that captures the features of the input to evaluate it further. Based on this idea, we tried to explore several state-of-art machine learning methods and deep learning methods that are used to classify emotions. However, recognizing emotions is relatively a daunting task for an un-social computer. There are several techniques to model the emotions from text, some implement machine learning, others take advantage of the deep learning technology. Therefore, we evaluated several models of Machine Learning methods and recent Deep Learning methods to make a comparison with previous related works. The dataset used in this research was from social media. Recognizing emotions from social media provides some non-verbal insights for the readers. The experiment demonstrates that deep learning models outperform several previous results and machine learning models on emotion recognition tasks. The results demonstrate that the model trained with BERT achieved the accuracy of 93.75%. Moreover, Love and Joy class is relatively challenging to distinguish.",Yes,"논문 초록에서 여러 모델을 평가하고 비교하는 실험이 수행되었음을 언급하며, 특히 정확도와 같은 정량적 지표를 통해 성능을 평가했다고 명시되어 있습니다. 이는 정량적 평가가 실시되고 있음을 보여줍니다."
Mental Health Analytics: A Comparative Exploration of Machine Learning Models,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10837048,"Machine learning methods for checking mental health: findings, understanding, and how well the models work. In short, this study explored how machine learning tools can be used to assess mental health by analyzing a large amount of information about people, including their backgrounds, lifestyles, and social behaviors. Using a Boosting model, a Decision Tree Classifier, and a logistic regression model helped us thoroughly evaluate how well the models performed. The Boosting model worked the best, reaching an accuracy of 81.75% Next came the Decision Tree Classifier with an accuracy of 80.69%, and the logistic regression model had an accuracy of 79.63% Besides checking how well the models work, the research also looked at ways to improve the models so they can be better understood. It focused on finding the important factors that greatly affect mental health results. We used techniques called hyperparameter tuning and cross-validation to make sure the models are strong and can work well on new data. The suggested model could help find people who are likely to develop different mental health issues. Feature importance analysis can give useful guidance to doctors, and future treatment plans in behavioral medicine can be created based on these predictions. AI models can help show the link between life, lifestyle choices, and high stress levels. This paper aims to help improve fast AI learning for mental health evaluation and highlight concerns with using data-related methods to assess social and health problems.",Yes,"논문은 여러 머신러닝 모델의 성능을 평가하는 과정에서 정확도와 같은 정량적 지표를 사용하여 평가하고 있습니다. 또한, 하이퍼파라미터 튜닝과 교차 검증 등 정량적 방법을 활용하여 모델의 강건성을 검증하는 내용이 포함되어 있습니다."
Internet of Things Intrusion Detection: A Deep Learning Approach,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9308293,"The Internet of Things (IoT) is a shifting paradigm that allows the integration of billions of devices with the Internet. With its wide range of application domains, including smart cities, smart homes, and e-health, the IoT has created new challenges, particularly security threats. Traditional security solutions, such as firewalls and intrusion detection systems, need amending to fit the new networking paradigm. Given the recent advances in machine learning, we investigated the use of deep learning algorithms for anomaly detection. The IoT collects a massive amount of data from the environment, and deep learning is based on a set of algorithms striving for the data. Intrusion detection systems are used to expose network threats and are an effective means of protecting network assets. Anomaly detection is a conventional intrusion detection approach that separates normal and abnormal network traffic using statistical, rule-based, or machine learning models. Of the machine learning models, deep learning is a neural network algorithm that has provided breakthroughs in domains such as object and voice recognition. However, there are limitations in applying deep learning to network anomaly detection. This paper proposes a novel anomaly detection framework based on unsupervised deep learning algorithms for revealing network threats. Our research explores the applicability of deep learning to detect anomalies by evaluating the use of Restricted Boltzmann machines as generative energy-based models against Autoencoders as non-probabilistic algorithms. The study provides an in-depth analysis of unsupervised deep learning algorithms. The simulations studies show ≈ 99% detection accuracy, which is significantly improved compared to the closely related work.",Yes,"논문 초록에서 딥러닝 알고리즘을 이용한 이상 탐지의 성능 평가를 위해 시뮬레이션을 수행하고, 약 99%의 탐지 정확도를 보고하고 있습니다. 이는 정량적 평가를 실시했음을 명확히 보여주는 내용입니다."
Quantifying Confounding Bias in AI Generated Art: A Case Study,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9658705,"In recent years, artificial intelligence (AI) generated art has become very popular. From generating art works in the style of famous artists like Paul Cezanne and Claude Monet to simulating styles of art movements like Ukiyo-e, a variety of creative applications have been explored using AI. However, there has been very little focus concerning the ethical implications of AI generated art. Can AI model artists' styles without stereotyping them? Does AI do justice to the socio-cultural nuances of art movements? In this work, we take a first step towards analyzing these issues. Leveraging directed acyclic graphs to represent potential processes of art creation, we propose a simple metric to quantify confounding bias due to the lack of modeling the influence of art movements in learning artists' styles. As a case study, we consider the popular cycleGAN model and analyze confounding bias across various genres. The proposed metric is more effective than state-of-the-art outlier detection method in understanding the influence of art movements in artworks. We also highlight how the proposed metric can aid in determining authenticity of artworks. We hope our work triggers discussions related to ethical implications of AI generated art.",Yes,"논문 초록에서 제안된 간단한 지표를 통해 정량적 평가를 수행하고 있음을 명확히 언급하고 있습니다. 또한, 다양한 장르에 걸쳐 혼란 편향을 분석하는 사례 연구를 통해 정량적 평가의 적용을 보여주고 있습니다."
The conception of a large-scale Systems Engineering environment,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9256709,"With the rise of artificial intelligence, it is time to shape the systems engineering tooling environment for the future. In the last decade, we have seen several emerging technologies that will potentially have a great impact in complex systems. These new technologies are expected to cause a disruptive impact not only in the products but also in to the tools used across the whole product life cycle. For this reason, is imperative to perform a critical review of the current systems engineering tooling ecosystem. This assessment should also map the open research problems that could prevent the complete integration of the new technologies into the systems engineering framework. This paper proposes a new architecture for a system engineering environment to operate in large scale projects. The objective of this research is twofold: it will first identify the capabilities for the next generation platform, and secondly, it will evaluate how artificial intelligence applications can be integrated in compliance with DO-330. The concept developed by this research will drive tool design recommendations enabling the use of artificial intelligence driven applications in a systems engineering tooling ecosystem.",No,"논문 초록에서는 정량적 평가를 수행하는 구체적인 방법이나 실험, 데이터 분석에 대한 언급이 없습니다. 대신, 시스템 환경 설계와 기술 통합에 대한 개념적 제안과 평가에 초점을 맞추고 있습니다."
Deep Learning for Crowd Counting: Addressing Crowd Density with Advanced Methods,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10690493,"Counting individuals in densely populated urban areas is essential for applications ranging from event planning to public safety. Traditional crowd counting methods face challenges in accurately estimating crowd density due to complex dynamics, varying lighting conditions, and occlusions. This research explores the potential of advanced deep learning techniques, focusing on Faster R-CNN, YOLO, and SSD models, to address these challenges. Real-world datasets, including the Shanghai Dataset and a Custom Crowd Counting Dataset, are employed to comprehensively evaluate model performance. The introductory section underscores the importance of precise crowd counting in contemporary urban scenarios, highlighting limitations of traditional methods and motivating the adoption of deep learning techniques. The literature survey provides a comprehensive review of crowd counting approaches, tracing the evolution from early handcrafted features to advanced deep learning models. This paper presents the subsequent section, include a comprehensive analysis of assessment metrics, like Mean Absolute Error, the Mean Squared Error, the true positive rate and F1 score for each model. YOLO emerges as the top performer, displaying the lowest MAE and MSE, along with the highest precision, recall, and F1-score. Pictorial representations and metric comparisons further illustrate the capabilities of the models. The conclusion summarizes insights gained from the study, emphasizing YOLO's superiority in accurately estimating crowd density. Practical implications for event management, public safety, and urban planning are discussed, positioning the research contribution within the broader context of advancing deep learning applications. In summary, this research bridges the gap between theoretical advancements and practical applications in crowd counting. By exploring advanced deep learning models and conducting a comparative analysis, valuable insights are provided, paving the way for continued innovations in crowd counting methodologies. The study indicates the exponential rising field of deep learning tecnolgies, showcasing the potential for enhanced accuracy and reliability in estimating crowd density for real-world applications.",Yes,"논문 초록에서 Mean Absolute Error (MAE), Mean Squared Error (MSE), true positive rate, F1 score 등 평가 지표를 사용하여 모델 성능을 정량적으로 평가했다고 명확히 언급하고 있습니다. 이러한 평가 지표들은 정량적 평가의 실시를 보여줍니다."
Enhancing Engineering Cost Risk Management Through Artificial Intelligence-Based Warning and Control Systems,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10795935,"With the growing importance of engineering cost risk management in the construction sector, the integration of artificial intelligence (AI) technology has emerged as a crucial tool for enhancing the effectiveness of risk alerts and control measures. This research endeavors to delve into the utility of AI in managing engineering cost risks and to suggest appropriate warning and control approaches. By conducting a thorough literature review and case studies, the study identified and compared three AI models: the Long Short-term Memory (LSTM) Network, Support Vector Machine (SVM), and Random Forest (RF), evaluating their performance against key metrics such as Cost Variance Ratio (CVR), Schedule Performance Index (SPI), and Risk Response Efficiency (RRE). The research methodology encompassed data collection and preprocessing, model training and validation, and comprehensive performance assessment. The findings revealed that the LSTM model achieved a minimum CVR of 1.1%, a maximum SPI of 1.03, and a remarkable risk response efficiency as fast as 12.5 minutes. The study concludes that LSTM significantly enhances the precision of engineering cost risk warnings, offering a novel insight and robust technical foundation for project management in the construction industry.",Yes,"논문은 AI 모델의 성능 평가를 위해 Cost Variance Ratio (CVR), Schedule Performance Index (SPI), Risk Response Efficiency (RRE)와 같은 정량적 지표를 사용하여 평가하고 있습니다. 이러한 지표들을 통해 정량적 평가가 실시되고 있음을 알 수 있습니다."
Analyzing and assessing the security-related defects,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7542332,"The use of the Internet has become an integral part of everyone's life. Due to this, the introduction of virus and other malicious crackers is increasing everyday. This in turn leads to the introduction of defects which adversely affect the security. Thus, protecting vital information in this cyber world is not an easy task. We need to deal with security related defects to ensure failure free and smooth functioning of the software. Thus, in this paper, we intend to study and analyze various aspects of security-related defects by analyzing the defect reports available in various open-source software repositories. Besides this, prediction models can also be constructed which can be used by researchers and practitioners to predict various aspects of security - related defects. Such prediction models are especially beneficial for large-scale systems, where testing experts need to focus their attention and resources to the problem areas of the system under development. Thus, application of software prediction models in the early phases of the software life cycle contributes to efficient defect removal and results in delivering more reliable and better quality software products. Empirical studies lack the use of proper research methodology and thus result in reporting inconsistent results. This study will review the sequence of steps followed in the research process for carrying empirical and replicated studies. The steps include (a) literature survey and definition of variables (b) data collection (c) report findings using statistical and machine learning techniques (d) analyzing performance measures for evaluating the performance of the predicted models and (e) interpretation of the obtained results for developing a software prediction model. These steps are explained with the help of experimental public domain data set. In addition, the paper provides an overview of repositories for mining software engineering data, tools for analyzing this data and various categories of machine learning methods. It also discusses existing research avenues and provides future research directions in this area.",Yes,"논문은 보안 관련 결함을 분석하고 예측 모델을 구축하는 과정을 다루며, 이를 위해 통계 및 머신러닝 기법을 활용하여 성능 평가를 수행한다고 명시되어 있습니다. 따라서, 정량적 평가가 실시되고 있음을 알 수 있습니다."
A Framework for Explainable Text Classification in Legal Document Review,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9005659,"Companies regularly spend millions of dollars producing electronically-stored documents in legal matters. Over the past two decades, attorneys have been using a variety of technologies to conduct this exercise, and most recently, parties on both sides of the `legal aisle' are accepting the use of machine learning techniques like text classification to cull massive volumes of data and to identify responsive documents for use in these matters. While text classification is regularly used to reduce the discovery costs in legal matters, text classification also faces a peculiar perception challenge: amongst lawyers, this technology is sometimes looked upon as a black box Put simply, very little information is provided for attorneys to understand why documents are classified as responsive. In recent years, a group of AI and Machine Learning researchers have been actively researching Explainable AI. In an explainable AI system, actions or decisions are human understandable. In legal `document review' scenarios, a document can be identified as responsive, as long as one or more of the text snippets (small passages of text) in a document are deemed responsive. In these scenarios, if text classification can be used to locate these responsive snippets, then attorneys could easily evaluate the model's document classification decision. When deployed with defined and explainable results, text classification can drastically enhance the overall quality and speed of the document review process by reducing the time it takes to review documents. Moreover, explainable predictive coding provides lawyers with greater confidence in the results of that supervised learning task. This paper describes a framework for explainable text classification as a valuable tool in legal services: for enhancing the quality and efficiency of legal document review and for assisting in locating responsive snippets within responsive documents. This framework has been implemented in our legal analytics product, which has been used in hundreds of legal matters. We also report our experimental results using the data from an actual legal matter that used this type of document review.",Yes,논문 초록에서 정량적 평가를 위해 실제 법률 사례 데이터를 사용한 실험 결과를 보고했다고 명시되어 있습니다. 이는 연구에서 정량적 평가가 실시되었음을 시사합니다.
Harnessing Transformers for Detecting Adverse Drug Reaction and Customized Causality Explanation using Generative AI,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10392249,"Pharmacovigilance plays an important role in monitoring safety of pharmaceutical products. There is an abundance of unstructured data available in social media and online reviews that can provide valuable insights into adverse drug reaction (ADR). This research paper aims to explore the efficient techniques of pharmacovigilance in identifying ADRs from unstructured data available in social media and reviews. This research work proposes the use of a transformer-based model for ADR classification, followed by named entity recognition (NER) to identify the causality between drugs and adverse effects. Furthermore, the output of NER is provided as a customized prompt to the generative AI model to generate a user interpretable explanation. Enhancing the accuracy of NER is carried out using the SciBERT model, which is specifically designed to capture drug and effect names. By utilizing this combination of techniques, the research aims to improve the efficiency and effectiveness of pharmacovigilance processes, enabling earlier detection and reporting of ADRs. To our knowledge, previous works have not explored the application of generative AI based customized explanation of causality. Patients, healthcare professionals, regulatory agencies, and pharmaceutical companies can benefit from the timely and accurate identification of ADRs, allowing for improved drug safety monitoring, better decision-making regarding drug usage, and the development of proactive measures to mitigate risks.",Yes,"논문 초록에서 ADR 분류와 NER 성능 향상, 그리고 생성 AI의 결과를 활용한 설명 생성 등 정량적 평가를 수행했음을 시사하는 기술들이 언급되어 있습니다. 이러한 기술들은 일반적으로 성능 평가를 위한 정량적 지표와 실험을 포함하므로, 본 연구는 정량적 평가를 실시했을 가능성이 높습니다."
An Intelligent Semantic Vector Search Model for Grading and Assessing Students,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10500811,"The introduction of technology-based learning is attracting considerable attention. With its ability to train learners, and assess and grade their academic work, this platform is a critical component of educational teaching and learning. Most importantly, the learning process is dependent on the human cognitive process in terms of how we learn, perceive, think, and interpret information. Therefore, technology-based teaching and learning is a crucial aspect of Artificial Intelligence (AI) technology. As AI evolves, researchers are producing innovative works based on AI. However various data search-retrieval mechanisms in instructional teaching models are struggling to comprehend and understand both structured and unstructured data as most data stores are conversant with structured data. The need for unstructured data as a component of decision-making is growing rapidly. In support of this, such data must be available in the appropriate structured format. In this study, we examine models of cognitive performance using semantic vector search on learner's psychology, and how the two relate throughout the learning process. We comparatively evaluated the application of two core artifacts: context similarity and content awareness. By comparative analysis, the result suggests that semantic search with content similarity and awareness in vector databases ensures an adaptive and intelligent search retrieval. This approach is considered the best for grading and assessing academic work while improving intuitive cognitive abilities.",Yes,"논문 초록에서 ""comparative evaluation""과 ""results""를 통해 두 가지 핵심 요소(컨텍스트 유사성 및 콘텐츠 인식)를 평가하는 정량적 방법이 사용되었음을 시사합니다. 또한, ""semantic search""의 성능을 비교 분석하는 과정이 포함되어 있어 정량적 평가가 실시되고 있음을 알 수 있습니다."
Bio-signals Collecting System for Fatigue Level Classification*,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10340350,"Fatigue is a risk factor that reduces quality of life and work efficiency, and threatens safety in a high-risk environment. However, fatigue is not yet precisely defined and is not a quantified concept as it relies on subjective evaluation. The purpose of this study is to manage risks, improve mission efficiency, and prevent accidents through the development of machine learning and deep learning based fatigue level classifier. Acquiring true fatigue levels to train machine learning and deep learning fatigue classifier may play a fundamental role. Aims of this study are to develop a bio-signal collecting device and to establish a protocol for capturing and purifying data for extracting the true fatigue levels accurately. The bio-signal collection system gathered visual, thermal, and vocal signals at the same time for one minute. The true fatigue level of the subjects is classified through the Daily Multidimensional Fatigue Inventory and physiological indicators related to fatigue for screening the subjective factors out. The generated dataset is constructed as a DB along with the true fatigue levels and is provided to the research institutions. In conclusion, this study proposes a research method that collects bio-signals and extracts the true fatigue levels for training machine learning and deep learning based fatigue level classifier to evaluate the fatigue of healthy subjects in multi-levels.",Yes,"논문은 기계 학습과 딥러닝 기반의 피로 수준 분류기를 개발하는 것을 목적으로 하며, 피로 수준을 분류하기 위해 실제 피로 수준과 관련된 생체 신호 데이터를 수집하고 이를 데이터셋으로 구축하는 과정을 포함하고 있다. 이는 정량적 평가를 실시하고 있음을 보여주는 명확한 증거이다."
Performance Comparison of Machine Learning and Deep Learning While Classifying Driver’s Cognitive State,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8721374,"Driver fatigue is a major cause of the road accidents that occur throughout the globe. It has been observed that among total number of accidents, 20% are contributed from driver fatigue. Acknowledging the existing data it is clear that a notification system for driver fatigue is of at most importance. Over the past a large number of strategies have been tested out and among them EEG based systems have shown to be the most accurate and reliable to estimate driver's cognitive state. The direct relation of brain activity to EEG signal explains its high accuracy in a fatigue detection system. Current researches in machine learning as well as deep learning have shown a new perspective in EEG data analysis. This work proposed a highly accurate, EEG based driver fatigue classification system which can reduce the rate of fatigue related road accidents using machine learning and deep learning algorithms. The results showed that the relative power of theta, alpha, beta and delta showed significant correlation to driver fatigue. The selected features were trained and evaluated using 20 well established classifiers in the field of driver fatigue. Among all the classifiers tested, the Fine Tree, Subspace KNN, Fine Gaussian SVM, and Weighted KNN were performed to the highest accuracy levels. Different performance metrics are used for this work and Deep Autoencoder and KNN are identified as the best suitable Deep learning and Machine Learning Algorithms for driver fatigue prediction with an accuracy of 99.7% and 99.6 % respectively.",Yes,"논문 초록에서 다양한 성능 지표를 사용하여 머신러닝과 딥러닝 알고리즘의 성능을 평가했다고 명시되어 있습니다. 특히, 딥 오토인코더와 KNN이 각각 99.7%와 99.6%의 정확도를 기록하며 정량적 평가를 실시했음을 보여줍니다."
Effects of annotation granularity in deep learning models for histopathological images,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8983158,"Pathological is crucial to cancer diagnosis. Usually, Pathologists draw their conclusion based on observed cell and tissue structure on histology slides. Rapid development in machine learning, especially deep learning have established robust and accurate classifiers. They are being used to analyze histopathological slides and assist pathologists in diagnosis. Most machine learning systems rely heavily on annotated data sets to gain experiences and knowledge to correctly and accurately perform various tasks such as classification and segmentation. Generally, annotations made in pathology-related datasets have inherited annotation methods from natural scene images. This work investigates different granularity of annotations in histopathological data set including image-wise, bounding box, ellipse-wise, and pixel-wise to verify the influence of annotation in pathological slide on deep learning models. We design corresponding experiments to test classification and segmentation performance of deep learning models based on annotations with different annotation granularity. In classification, state-of-the-art deep learning-based classifiers perform better when trained by pixel-wise annotation dataset. On average, precision, recall and F1-score improves by 7.87%, 8.83% and 7.85% respectively. Thus, it is suggested that finer granularity annotations are better utilized by deep learning algorithms in classification tasks. Similarly, semantic segmentation algorithms can achieve 8.33% better segmentation accuracy when trained by pixel-wise annotations. Our study shows not only that finer-grained annotation can improve the performance of deep learning models, but also help they extract more accurate phenotypic information from histopathological slides. The accurate and spatially precise acquisitions of phenotypic information can improve the reliability of the model prediction. Intelligence systems trained on granular annotations may help pathologists inspecting certain regions and features in the slide that were mainly used to calculate the prediction. The compartmentalized prediction approach similar to this work may contribute to phenotype and genotype association studies.",Yes,"논문 초록에서 다양한 정량적 평가 지표(precision, recall, F1-score, segmentation accuracy 등)를 사용하여 딥러닝 모델의 성능을 비교하고 평가하는 실험을 수행했다고 명확히 언급하고 있습니다. 이는 정량적 평가를 실시하고 있음을 보여줍니다."
Accounting Information System Adoption Model for Small and Medium-Sized Enterprises in Northern Ghana,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9617111,"Accounting Information Systems (AIS) are essential tools for Small and Medium-sized Enterprises (SMEs). To continuously stay in business, businesses must manage their accounting efficiently. The study will investigate SME AIS adoption in Northern Ghana by critically evaluating different adoption models, as the SMEs are considered as the backbone of the Ghana's economy. Previous research data were gathered using popular educational databases. To collect data and generate research findings about the objective, direct content analysis and summative content analysis were used. According to the review, there have been very few previous studies on SMEs AIS adoption with a maximum dimension of three. They are either technology, organization or environment-based or human, organization, and technology-based. Combining the Technology-Organization-Environment (TOE) and Human-Organization-Technology (HOT-Fit) models yields the Human-Organization-Technology-Environment (HOTE) model. The HOTE model is a new model for SMEs AIS adoption in Ghana. This study fills a gap in the literature by broadening the range of factors influencing SMEs' adoption of AIS.",No,"논문 초록에서는 다양한 모델과 이론적 프레임워크를 제시하고 있으나, 정량적 평가 방법이나 구체적인 정량적 데이터 분석에 대한 언급이 없습니다. 따라서 이 논문이 정량적 평가를 실시하고 있다고 보기 어렵습니다."
AI-Enhanced Firewalls: Empowering Intrusion Detection with ML and DL,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10912147,"Given the increasing frequency of network-based threats, strong intrusion detection systems (IDS) are essential for safeguarding digital assets. Traditional rule-based IDS often struggle to keep up with evolving cyber threats, highlighting the need for more adaptive solutions. This study introduces a Next Generation Firewall (NGFW), which integrates machine learning and deep learning techniques to improve IDS performance. By employing ML algorithms like Support Vector Machines (SVM), Random Forests, and Deep Neural Networks (DNN), alongside DL models such as Convolutional Neural Networks (CNN) and Recurrent Neural Networks (RNN), the NGFW significantly enhances detection capabilities, flexibility, and accuracy. A comprehensive review of the literature demonstrates the effectiveness of ML and DL in IDS. The proposed approach involves systematic data collection, preprocessing, feature extraction, and model evaluation using metrics such as accuracy, precision, and recall. Experimental results show that CNNs achieve particularly low false-positive rates when detecting malicious activities. Additional real-world testing further validates the NGFW’s role in strengthening cybersecurity defenses. The classification report achieved high precision, recall, and F 1 -scores above 97 percent across all categories, with an overall accuracy of 97.29 percent. These findings advocate for further research into intelligent cyber defenses, emphasizing the value of ML and DL in developing more adaptable and resilient IDS.",Yes,"논문 초록에서 다양한 평가 지표(accuracy, precision, recall, F1-score 등)를 사용하여 모델의 성능을 정량적으로 평가했다고 명시되어 있습니다. 또한, 실험 결과와 classification report를 통해 구체적인 수치로 성과를 제시하고 있어 정량적 평가를 실시하고 있음을 알 수 있습니다."
Olive Disease Classification Based on VGGNET and Fine-Tuning Process,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10708475,"Agriculture serves as a fundamental pillar of Tunisia’s economy, providing employment and livelihood for a large segment of the population, thereby making it an essential sector for the country. Nevertheless, the sector faces challenges such as reduced agricultural output and quality due to factors like pesticide usage, water scarcity, climate change, and notably, plant diseases. These plant diseases represent one of the most significant threats to global agricultural productivity and quality. Traditional methods of plant disease detection heavily rely on expert identification, which can quickly cause delays in field management and crop disease control. The best strategy to manage these diseases and reduce crop loss is to put protective measures in place as soon as possible. To this purpose, machine learning and deep learning models-based method for the detection and classification of olive leaf disease is developed in order to improve the speed and precision of disease classification. In this study, we explore how machine learning and deep learning techniques may be used to improve agricultural practices and solve these issues. We specifically review the state-of-the-art literature on the use of deep learning and machine learning algorithms in diverse agricultural applications. We also presented a novel method for categorizing olive leaf diseases, by integrating deep learning architectures, VGG16, and fine tuning. Also, in this approach, we simulated a total of two distinct deep models utilizing pre-trained convolutional neural network architectures (VGG19 and VGG16) and along with four machine learning classifiers (RF, SVM, KNN and DT). In addition, we simulated a novel method for categorizing olive leaf diseases, by integrating deep learning architectures, VGG16, and fine tuning, our results findings showed that VGG16 with fine-tuning classifier is the best method for classification of healthy and diseased plant leaves. It achieves a testing accuracy score of 98% to beat the rest of the architectures.",Yes,"논문 초록에서 VGG16과 같은 딥러닝 모델을 활용하여 올리브 잎 질병을 분류하는 정량적 평가를 수행했다고 명확히 언급하고 있습니다. 또한, 테스트 정확도와 같은 성능 지표를 제시하여 정량적 평가가 이루어졌음을 알 수 있습니다."
DCGAN for Synthetic Data Augmentation of Cervical Cancer for Improved Cervical Cancer Classification,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10482312,"Medical diagnosis and treatment are greatly aided by biomedical image analysis. Deep learning model training is difficult, nevertheless, due to the scarcity of labelled medical images. For creating synthetic biological images to supplement the training data, Generative Adversarial Networks (GANs) have shown good promise. In this research paper, we focus on the application of GANs for biomedical image augmentation. Specifically, we investigate and compare the performance of a prominent GAN architecture: Deep Convolutional GAN (DCGAN) is a variant of GAN specifically designed for image generation tasks. We assess the generated images based on their quality, diversity, and preservation of biomedical aspects using different evaluation metrics. We also used a classification process to compare the classifier on real and synthetic augmented data. Our test findings show that DCGAN is capable of producing realistic synthetic biomedical images. The results of this work advance knowledge of GANs for biomedical image enhancement and offer guidance on choosing the DCGAN designs for tasks requiring medical image analysis. Researchers and practitioners can increase the diversity and quantity of training data by utilizing GAN-based augmentation strategies, which will enhance the performance and generalization of deep learning models in biomedical applications.The primary objective of this study is to evaluate the effectiveness of DCGAN in generating synthetic microscopic biomedical images of cervical cancer that can augment the training data for deep learning classification models. We aim to assess the quality, diversity, and preservation of biomedical features in the generated images.The structure of this study is as follows: we begin by brief introduction of Cervical cancer, GAN in general and DCGAN. Section 2: lays down review of the related literature. Section 3: presents the methodology of the study. Section 4: presents the results and discussion from the study. Section 5: summaries the finding and concludes with prospective future applications.",Yes,"논문 초록에서 생성된 이미지의 품질, 다양성, 생물학적 특징의 보존을 평가하는 다양한 평가 지표를 사용했다고 명시되어 있습니다. 또한, 정량적 평가를 통해 생성된 이미지와 실제 데이터를 비교하는 실험을 수행했음을 언급하고 있어 정량적 평가를 실시하고 있음을 알 수 있습니다."
Logistic Regression based Sentiment Analysis System: Rectify,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10577296,"The detection of various reactions using computer vision, machine learning, and artificial intelligence is a rapidly growing field of research. In this paper, we present a sentiment analysis model based on the Python, NLTK (natural language toolkit) libraries, and machine learning algorithms that can detect multiple reactions from the public on a single platform. The proposed Sentiment Analysis System deals with the very usual problem faced by different companies, manufacturers, and sellers about knowing the customer review for their product. The model classifies the public reviews and the normal text as positive, negative, or neutral. This proposed system is categorised into two parts, one being a field-specific sentiment analysis and the other being a generalised system that can judge any particular word or sentence to be either positive, negative, or neutral. The proposed model is also capable of representing a huge dataset (input as a csv file) in the form of a graph, which can be easily understood by the desired person, and the graphical representation is possible with the Matplotlib library of Python. The model's performance is evaluated using several metrics, such as precision, recall, and others. The model's accuracy and efficiency make it a promising tool for sentiment analysis, which can be used by anyone in any field. In conclusion, the system can work for any specific field provided the data set, and the generalized way can help out with random sentences, and the model’s potential can be boosted with some further research.",Yes,"논문 초록에서 모델의 성능 평가를 위해 정밀도, 재현율 등 여러 평가 지표를 사용했다고 명시되어 있습니다. 이는 정량적 평가를 실시하고 있음을 보여주는 명확한 증거입니다."
Sharing is Caring! Joint Multitask Learning Helps Aspect-Category Extraction and Sentiment Detection in Scientific Peer Reviews,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9651781,"The peer-review process is the benchmark of research validation. Peer-reviewed texts are the artifacts via which the editors/chairs decide the inclusion/exclusion of a paper in a journal or conference proceedings. Hence it is important for the editors/chairs to carefully analyze the peer-review text from various aspects of the paper (e.g., novelty, substance, soundness, etc.), identify the underlying sentiment of the reviewers, and thereby validate the informativeness of the reviews before making a decision. With the rise in research paper submissions, the current peer-review system is experiencing an unprecedented information overload. Sometimes it becomes stressful for the chairs/editors to make a reasonable decision within the stringent timelines. Here in this work, we attempt an interesting problem to automatically extract the aspect and sentiment from the peer-review texts. We design an end-to-end deep multitask learning model to perform aspect extraction and sentiment classification simultaneously. We show that both these tasks help each other in the predictions. We achieve encouraging performance on a recently released dataset of peer-review texts. We make our codes available for further research11https://www.iitp.ac.in/~ai-nlp-ml/resources.html#aspect-category-sentiment.",Yes,"논문 초록에서 ""We design an end-to-end deep multitask learning model""과 ""We achieve encouraging performance""라는 표현을 통해 정량적 평가를 실시했음을 알 수 있습니다. 또한, 성능 평가를 위해 실험 결과를 제시했음을 시사하는 내용이 포함되어 있습니다."
Automated Generation of Narrative Sleep Reports Utilizing Portable Electroencephalogram Data Through ChatGPT,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10628709,"Sleep is a very important activity, but many people do not know their own sleep conditions. A sleep test personalizes sleep quality assessment and detects potential sleep disorders by measuring biological signals. The rise in sleep-related issues has necessitated the development of automated testing methods. Machine learning plays a pivotal role in interpreting sleep data and determining sleep stages. However, the generation of detailed reports and tailored recommendations still demands expert intervention. Automating the report generation to provide personalized sleep insights is a crucial and desired step for the future of sleep healthcare. Recently emerged Generative AI, such as ChatGPT, has attracted considerable attention in recent years. It can generate new sentences and images from input data. In this study, we investigate the practicality and applicability of using ChatGPT to generate narrative sleep reports for sleep test. In our proposed method, GPT-4 receives the information about the sleep habits of the participants and the sleep assessment automatically summarized by the rule-based algorithm. In the evaluation, we used in-home sleep EEG data obtained from 100 subjects by S'UIMIN inc. The generated reports were evaluated by experienced technicians and physicians on a 5- point scale for medical correctness and appropriateness as informative reports. The results of the evaluation showed that 60 % of the reports were the acceptable or above range in both aspects. While more than half of the results were judged to be above the acceptable range, differences between the generative AI and humans were also identified. Whereas humans comment on semantically weighted important findings such as medication and subjective insomnia, ChatGPT tends to make broad, shallow and flat comments on the input data. These facts suggest that although practical report generation only using generative AI is at present not easy, generative AI is a promising tool for improving the efficiency of physicians and technicians work.",Yes,"논문 초록에서 ChatGPT를 이용하여 수면 보고서를 자동으로 생성하는 방법을 제시하고 있으며, 생성된 보고서의 평가를 위해 정량적 척도인 5점 척도를 사용하여 평가한 내용이 포함되어 있습니다. 이는 정량적 평가가 실시되고 있음을 보여줍니다."
Uncertainty Quantification for Trusted Machine Learning in Space System Cyber Security,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9697520,"In recent years, the Aerospace Corporation has been developing machine learning systems to detect cyber anomalies in space system command and telemetry streams. However, to enable the use of deep learning in such high consequence environments, the models must be trustworthy. One aspect of trust is a model’s ability to accurately quantify the uncertainty of its predictions. Although many deep learning models output what seem to be confidence scores, current academic research has repeatedly shown that models often return high confidence even when very wrong and are unable to diagnose and respond appropriately to out-of-distribution inputs. This can result in catastrophic overconfidence when models are faced with adversarial inputs or concept drift. Even on routine inputs, without reliable uncertainty quantification, it is hard for human-machine teaming to take place as humans cannot trust the model’s reported confidence score. In short, all models are wrong sometimes, but models which know when they are wrong are considerably more useful. To this end, The Aerospace Corporation conducted a literature review and implemented current state of the art methods, including deep ensembles and temperature scaling for confidence calibration, to accurately quantify the uncertainty of deep learning model predictions. We further incorporated and tested these techniques within the existing cyber defense model framework for more trustworthy cyber anomaly detection models. We show that not only are these techniques successful, they are also easy to implement, extensible to many applications and machine learning model variants, and provide interpretable results for a wide audience. From this, Aerospace recommends further adoption of such techniques in high consequence environments.",Yes,"논문 초록에서 여러 정량적 평가 기법(예: 딥 앙상블, 온도 스케일링)을 사용하여 딥러닝 모델의 불확실성을 정량적으로 평가했다고 명시하고 있습니다. 이러한 기법들을 기존 사이버 방어 모델에 통합하여 평가한 내용을 통해 정량적 평가가 수행되고 있음을 알 수 있습니다."
Comparison of mobile interaction management products using systematic literature review method and a new product suggestion,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8093372,"Because of innovations and improvements in technology, the use of smartphones that make it easier for users to work has become widespread. At this point, companies can reach their customers more easily and can communicate continuously. Once mobile applications are created, the system infrastructure needs to be improved in response to changing needs and demands to actively retain registered users and continually capture their insights. In this case, a dynamic framework that will create user profiles in a mobile application and provide services according to different user needs. In this study, the main features of the mobile interaction management applications on the market and other features they provide to create a loyal user base have been evaluated using the Systematic Literature Review (SLI) method and the necessary gaps have been discussed. In order to acquire loyal mobile-app user, Machine Learning support system is proposed as solution.",No,"논문 초록에서는 모바일 인터랙션 관리 제품을 체계적 문헌 검토 방법을 통해 평가했다고 언급하고 있으나, 구체적인 정량적 평가 방법이나 수치 데이터에 대한 언급은 없습니다. 따라서 정량적 평가를 실시했다고 보기 어렵습니다."
Automated Training Data Construction using Measurements for High-Level Learning-Based FPGA Power Modeling,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9988835,"Machine Learning (ML) is the process of developing Artificial Intelligence (AI) in computers, where the generated models are trained using appropriate learning algorithms and training data. For many machine learning techniques, especially the ones related to supervised methods, the construction of the training data highly affects the quality and accuracy of the derived model. In this paper w e present and evaluate an automated training set construction methodology where data is synchronously collected from both hardware and software. The complete design and data flow including the interaction between software and hardware, are thoroughly described. As a direct application, this work targets the construction of an FPGA-based circuit power modeling for subsequent early power estimation. The constructed Artificial Neural Network (ANN) model is trained using real measurement data sets extracted using a dedicated in-house designed and implemented generation and acquisition platform. The designated application falls under the power optimization area, becoming nowadays a major concern for most digital hardware designers, particularly in early design phases and especially in limited power budget systems. The power optimization approach in context can be extended in order to support online power management.",Yes,"논문 초록에서 ""The constructed Artificial Neural Network (ANN) model is trained using real measurement data sets""라고 명시되어 있어, 정량적 평가를 위해 실측 데이터를 활용하여 모델을 학습하고 평가하는 과정을 수행하고 있음을 알 수 있습니다. 따라서, 정량적 평가가 실시되고 있다고 판단됩니다."
Leveraging Artificial Intelligence and Machine Learning for Disease Diagnosis in Healthcare,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10895901,"This research paper explores the transformative potential of Artificial Intelligence (AI) and Machine Learning (ML) in disease diagnosis in healthcare systems. It reviews the current landscape of AI and ML technologies, their integration into diagnostic processes, and their impact on accuracy, efficiency, and patient outcomes. The paper also discusses challenges, ethical considerations, and prospects of AI and ML in disease diagnosis. The study evaluates the performance of a system integrating pulse measurements and user studies to assess its effectiveness in improving user engagement and satisfaction. The results suggest that the proposed system can enhance voice assistant capabilities and contribute to users' overall well-being through continuous health monitoring. Voice assistants can provide virtual healthcare services, such as answering health questions, providing information about symptoms, and offering general health advice. Random Forest (RF) outperforms Logistic Regression (LR) and Support Vector Machine (SVM) with an accuracy rate of 98%.",Yes,"논문은 시스템 성능 평가를 위해 Random Forest, Logistic Regression, SVM 등의 정량적 평가 방법을 사용하여 정확도와 성능을 측정하고 있습니다. 이러한 평가 지표를 통해 정량적 평가가 실시되고 있음을 알 수 있습니다."
Identifying Functional and Non-functional Software Requirements From User App Reviews,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9795770,"Mobile app developers are always looking for ways to use the reviews (provided by their app’s users) to improve their application (e.g., adding a new functionality in the app that a user mentioned in their review). Usually, there are thousands of user reviews that are available for each mobile app and isolating software requirements manually from such as big dataset can be difficult and time-consuming. The primary objective of the current research is to automate the process of extracting functional requirements and filtering out non-requirements from user app reviews to help app developers better meet the wants and needs of their users. This paper proposes and evaluates machine learning based models to identify and classify software requirements from both, formal Software Requirements Specifications (SRS) documents and Mobile App Reviews (written by users) using machine learning (ML) algorithms combined with natural language processing (NLP) techniques. Initial evaluation of our ML-based models show that they can help classify user app reviews and software requirements as Functional Requirements (FR), Non-Functional Requirements (NFR), or Non-Requirements (NR).",Yes,"논문 초록에서 머신러닝 기반 모델을 평가하여 사용자 리뷰에서 기능적 요구사항, 비기능적 요구사항, 비요구사항을 분류하는 성능을 검증했다고 명시되어 있습니다. 이는 정량적 평가를 실시했음을 의미합니다."
Semantic Communication System Based on Semantic Slice Models Propagation,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9954279,"Traditional communication systems treat messages’ semantic aspects and meaning as irrelevant to communication, revealing its limitations in the era of artificial intelligence (AI), such as communication efficiency and intent-sharing among different entities. Through broadening the scope of the traditional communication system and the AI-based encoding techniques, in this manuscript, we present a novel semantic communication system, which involves the essential semantic information exploration, transmission and recovery for more efficient communications. Compared to other state-of-the-art semantic communication-related works, our proposed semantic communication system is characterized by the “flow of the intelligence” via the propagation of the model. Besides, the concept of semantic slice-models (SeSM) is proposed to enable flexible model-resembling under the different requirements of the model performance, channel situation and transmission goals. Specifically, a layer-based semantic communication system for images (LSCI) is built on the simulation platform to demonstrate the feasibility of the proposed system and a novel semantic metric called semantic service quality (SS) is proposed to evaluate the semantic communication systems. We evaluate the proposed system on Cityscapes and Open Images datasets, resulting in averaged 10% and 2% bit rate reduction over JPEG and JPEG2000, respectively. In comparison to LDPC, the proposed channel coding scheme can averagely save 2dB and 5dB in AWGN channel and Rayleigh fading channel, respectively.",Yes,"논문 초록에서 ""semantic service quality (SS)""라는 새로운 정량적 평가 지표를 제안하고, 이를 이용하여 시스템 성능을 평가했다고 명시되어 있습니다. 또한, Cityscapes와 Open Images 데이터셋을 활용한 실험 결과를 통해 비트율 감소와 채널 성능 향상 등 정량적 성과를 제시하고 있습니다."
Smart City Digital Twin Platform Architecture for Mobility and Transport Decision Support Systems,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10825075,"Addressing mobility and transport problems is nowadays of paramount importance for any city due to the increasing urbanization. Traffic congestion, pollutant emissions, energy consumption are some of the problems related to urban mobility. Therefore, there is the need of tools able to support decision-makers in studying, evaluating, and planning sustainable urban evolutions. A few open-source and proprietary solutions are available requiring on-premises installations, large effort, and providing limited capabilities to actually handle real-time data (from data spaces, and standards). Moreover, they are limited in terms of analytic integration and do not offer automatic generation of suggestions. In practice they do not manage the explosion of complexity regarding computational and storage/models aspects. For these reasons, this paper presents a comprehensive architecture for a Smart City Digital Twin platform, specifically designed to support mobility and transportation decision-making through advanced what-if analysis and optimization. The platform, integrated within the Snap4City system, enables real-time data processing and complex analytics to create virtual urban environments for evaluating potential infrastructure changes. Through microservice architecture, the platform supports massive data ingestion, scenario creation, and predictive modelling, facilitating both short-term and long-term planning. The solution leverages artificial intelligence (AI), machine learning (ML), and reinforcement learning (RL) to optimize city operations and suggest actionable insights, aiding city planners in strategic and tactical decisions. This architecture has been validated through implementations in Italian cities, demonstrating scalability and flexibility to accommodate diverse urban needs and improve traffic flow, energy efficiency, and environmental impact. This work has been performed in the context of OPTIFaaS Flagship of CN MOST, the National Centre for Sustainable Mobility in Italy, and for CN HPC Big Data and Quantum Computing, ICSC.",Yes,"논문 초록에서 ""advanced what-if analysis and optimization,"" ""complex analytics,"" ""predictive modelling,"" 그리고 ""artificial intelligence (AI), machine learning (ML), and reinforcement learning (RL)""을 활용한 정량적 평가와 분석이 언급되어 있습니다. 이러한 내용들은 정량적 평가를 수행하고 있음을 시사합니다."
Enhancing Real-Time Object Detection With Advanced YOLOv9 and OpenCV in Python,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10836635,"Object detection is a foundation process in computer vision having widespread applications in autonomous driving, medical diagnostics and security monitoring. Recent advancements and development in field of machine learning, particularly deep learning had dynamically improved object detection accuracy. However, the selection of an optimal algorithm remains challenging due to the diverse characteristics of available techniques. This paper depicts the comprehensive review of object detection, covering commonly used data sets, evaluation metrics and both traditional and deep learning-based algorithms. The study introduces a Python-based method for real-time object detection, utilizing deep learning architectures like Convolutional Neural Networks (CNNs) and Single Shot MultiBox Detector (SSD). Built on the open-source library OpenCV, the proposed system demonstrates high adaptability and ease of use through a transfer learning strategy. Experimental results validate the system's effectiveness in achieving accurate, real-time detection across various scenarios, including different lighting conditions and object occlusions. The study also discusses the current challenges, particularly small object detection, and outlines future research directions in the field.",Yes,"초록에서 ""Experimental results validate the system's effectiveness in achieving accurate, real-time detection""라고 언급되어 있어, 정량적 평가가 수행되었음을 알 수 있습니다. 이는 시스템의 성능을 수치로 평가했음을 시사합니다."
Knowledge Graph Based Medical Chatbot building,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10353415,"To have a good and unproblematic life without any health risks, it is very important to get medical advice on any health-related problems. However, getting medical advice incurs costs. Chatbots are AI/ML based software which may be trained with a lot of inquiries and responses and match users’ inquiries against a large repository of evidence-based medical data to provide simple answers. To reduce the healthcare costs and improve accessibility of medical knowledge a medical chatbot can be built using ML and NLP techniques. In the existing system of such chatbots several databases are connected together using join statements making it more complicated to access the data. The medical knowledge is vast and varied hence giving many disadvantages to use fixed schema. In this paper we have proposed a knowledge graph based method of chatbot creation for the healthcare field. When the patient enters the symptoms, they are suffering from, then chatbot evaluates and based on the evaluation recognizes the disease. The basic idea of our work is to build a chatbot which can evaluate the symptoms and using this evaluation, rank the possible disease which the patient could be suffering from. The chatbot gets its knowledge from a knowledge graph built on an extensive TigerGraph database. The data from the TigerGraph database can be accessed using different analysis queries. The chatbot will be considered profitable only when it can diagnose all kinds of disease and provides the necessary advice measures to be taken. The knowledge graph used here can be improvised by including results from lab tests to arrive at a better diagnosis and increase the precautions by including the medicines to be taken. The chatbot can only be as smart as the knowledge graph database and hence the evaluations made must be checked with the medical professional. The chatbot has good accuracy in predicting the disease the user is suffering from.",Yes,"논문 초록에서 의료 데이터와 질병 예측에 대한 평가를 수행하는 시스템을 제안하며, 이를 위해 지식 그래프와 분석 쿼리를 활용한다고 명시되어 있습니다. 또한, 챗봇의 진단 정확도를 언급하며 정량적 평가의 가능성을 시사하고 있습니다."
Using AI-SPedia to Study Saudi Universities’ Research Outputs in the Artificial Intelligence Field,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10067833,"Saudi Arabia’s Vision 2030, developed in 2016, is not limited to diversifying the economy and reducing the dependence on the hydrocarbon sector. Artificial intelligence (AI) is among the main strategic priorities of Vision 2030. Saudi Arabia is planning to be the world leader in technology by putting AI at the heart of the country’s development and growth. This study looked at AI related research outputs produced by Saudi Arabia to calculate the growth rate of AI research over the years and to measure how much of this research is covered by altmetrics, which basically capture all kinds of research mentions in many online platforms, such as social merlia. We used the AI-SPedia knowledge base repository, which accommodates AI research around the world with all the details, including bibliometric and altmetric indicators. After running the appropriate SPARQL code, we retrieved about 4,433 AI publications that are published by Saudi organizations. This study showed that the growth rate of AI research produced by Saudi Arabia increased from 28.23 % before 2016 to 47.07 % over time. This big jump was attributed mainly to Saudi Vision 2030 and the funding by Saudi government sectors, such as the Ministry of Education. This growth will have a great impact on the quantity of AI research and the scientific community’s tangible work in the AI domain. Moreover, this paper shows that the AI research outputs from the 10 most productive Saudi universities have an average of around 31.74 % of altmetric coverage. This low altmetric coverage indicates a need for suitable mechanisms to promote the dissemination of AI research through the most popular online platforms.",Yes,"논문은 AI 연구 성과의 성장률 계산과 altmetric 커버리지 측정을 포함하여 정량적 평가를 실시하고 있습니다. 또한, 연구 출판물 수와 성장률, 그리고 altmetric 비율과 같은 수치 데이터를 분석하여 정량적 평가를 수행하는 내용을 담고 있습니다."
Predicting Early Phase of Type 2 Diabetic by Deep Learning,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9371843,"Deep Neural Network with prediction is the one of the main deep learning technologies which has been used by many researches for early prediction of Type 2 Diabetics (T2D). For the prediction of the T2D, the taxonomy with the components are proposed with Data, Prediction processing and Display (DPD). Those components are evaluated for the better performance of the system and are validated with the different parameters for the early diagnosis of the T2D. The system being proposed has the higher accuracy for the prediction of the T2D and early detection of the diabetics in different age group in comparison to research paper reviewed and with current findings. It also helps to diagnose the diabetics in the patients. The critical analysis of the literature review of the latest published research paper available on the T2D and on deep learning has better accuracy for the prediction of T2D. On basis of the analysis, an effective system for T2D based on Deep Neural Network (DNN) has been developed in the system that can predict the diabetics in the early stage.",Yes,"논문 초록에서 시스템의 성능을 평가하기 위해 다양한 매개변수로 검증하고, 높은 정확도를 보고하는 등 정량적 평가가 실시되었음을 명확히 언급하고 있습니다. 따라서, 정량적 평가를 수행하는 것으로 판단됩니다."
Deep Learning-Based Earthquake Prediction Technique Using Seismic Data,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10185869,"Earthquakes are natural disasters that can cause severe damage to human life and infrastructure. Therefore, accurate earthquake prediction is crucial for disaster prepared-ness and risk reduction. Recently, machine learning techniques have shown promise in earthquake prediction. In this paper, we present a comprehensive study on the application of machine learning techniques for earthquake prediction. We first review the existing literature on earthquake prediction using machine learning techniques, including neural networks. We then propose a machine learning approach for earthquake prediction, based on analyzing seismic data. The proposed approach uses a convolutional neural network to extract relevant features from the seismic data, and a long short-term memory network to predict the probability of an earthquake. We evaluate the performance of the proposed approach on earthquake datasets from different regions and demonstrate its high accuracy in earthquake prediction. Our study provides a new perspective on earthquake prediction using machine learning techniques and highlights the potential of deep learning approaches for improving earthquake prediction. The proposed approach can be used in conjunction with existing earthquake prediction methods to provide more accurate and reliable predictions, which can help mitigate the potential impact of earthquakes on human life and infrastructure.",Yes,논문 초록에서 제안된 딥러닝 기반 방법의 성능을 평가하기 위해 다양한 지진 데이터셋을 사용하여 실험을 수행했다고 언급하고 있습니다. 이는 정량적 평가가 이루어지고 있음을 시사합니다.
A Comprehensive Study on Non-sequence and Sequence modeling word vector embedding approach for clinical text Named Entity Classification,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10481577,"Human languages are hard to interpret and can not be understood by the computer. Thus, teaching a computer to understand human language is a difficult endeavor that has only lately been made possible by the application of Natural Language Processing (NLP) combined with the recent advancements and developments in fields such as Deep Learning (DL) with a manifold improvement in Recurrent Neural Network (RNNs) and the use of Word Embeddings. The language modeling and feature learning method in NLP known as “word embedding” maps vocabulary to actual number vectors leveraging products like word2vec, GloVe, and fastText.NLP can help us create more effective deep-learning models to solve language problems. Statistical analysis, machine learning methods, and deep learning all benefit from the improved word and phrase processing that natural language processing (NLP) techniques provide.NLP turned unstructured text data into more structured data that expert systems could easily modify and evaluate. Using embeddings, it is possible to handle textual input more quickly and effectively while building robust deep-learning models. Studies have been able to successfully verify the improvements obtained as a result of the application of DL techniques and models for tackling classes of problems related to Biological Named Entity Recognition (BioNER), with impressive and promising outcomes. Various ML-based NLP tasks now routinely use deep learning (DL), which removes the requirement for task-specific feature engineering based on in-depth domain expertise and facilitates the identification of salient aspects. Deep learning techniques frequently employ neural network (NN) architecture, which can automatically deduce patterns from vector data and pick the most pertinent features. Currently, the neural network most frequently used for NLP tasks is called Long Short-Term Memory (LSTM).The discovery of long-term connections between medical entities is performed using LSTM, a specific type of Recurrent Neural Network (RNN), which also increases training accuracy overall. This chapter entails a comprehensive study of the non-sequence and sequence modeling embedding approach for clinical text corpus named entity classification and a comparative analysis on previously adopted approaches. We compared the resulting precision and other metrics such as the recall as well as the F1-Score of our model to those of other currently available models for a number of gene and protein entity categories. Our proposed approach obtains an F1-Score of 77.34% in 16 epochs. We have worked on a relatively smaller gold standard corpus and word embedding that has a slight impact on the result. Overall, due to the complexity of the bio-medical named entities, our proposed architecture has greatly improved entity extraction identification and classification, although there is still potential for improvement.",Yes,"논문 초록에서 모델의 성능 평가를 위해 정밀도, 재현율, F1-Score 등 다양한 정량적 지표를 사용하여 평가한 내용을 언급하고 있습니다. 또한, 제안한 방법의 성과를 기존 방법과 비교하는 분석이 포함되어 있어 정량적 평가를 실시하고 있음을 알 수 있습니다."
Threat Modeling AI/ML With the Attack Tree,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10752529,"The pervasive use of AI assistant systems and machine learning-based applications in various fields and everyday life has significantly shifted. However, this shift is not without its challenges. The emergence of security threats, various attacks, and vulnerabilities in this domain has not only questioned their use but also sparked the interest of security experts and researchers, underlining the urgency and importance of this topic. However, a comprehensive and systematic research endeavor is yet to be undertaken on threat modeling based on violating basic tenets of information security on the various components of a machine learning system and evaluating their security risks. This lack of comprehensive threat modeling for each violation of a machine learning system’s confidentiality, integrity, availability, and privacy for various attacks and their risk analysis is a significant gap in the field. This article aims to bridge this gap by proposing a simple, efficient, and time-saving approach to evaluate potential attacks and their security risks by utilizing the attack tree and a risk analysis method in the Adversarial Machine Learning (AML) field. One of the most important steps in determining the overall risk of the attack is evaluating the risk attached to each node in an attack tree. A systematic approach that includes describing the system architecture and identifying its assets under various operational environment scenarios is also outlined in this paper. This approach can also offer crucial insights to security experts, aiding them in understanding and mitigating potential threats and risk analysis in AML systems. To ensure the validity and reliability of our findings, we have conducted a thorough and rigorous review of academic papers, summarizing different threats and attacks and their root cause analysis.",Yes,"논문은 공격 트리를 활용하여 잠재적 공격과 보안 위험을 평가하는 방법을 제시하며, 위험 분석을 위한 정량적 평가 방법을 포함하고 있다고 명시하고 있습니다. 또한, 위험 척도와 노드별 위험 평가를 통해 체계적인 정량적 평가를 수행하는 것으로 보입니다."
Deep-learning based Buck-boost Converter for Laptop Applications,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10138855,"The growth of power electronics increase rapidly in the recent past compared to other technical work. A converter may be the heart of power electronics. It has applications like PV, home inverters, battery charging, etc. There are a lot of issues related to the converters and one of them is the output DC voltage without ripples. In other words, the early steady-state output is the requirement for the converter. As the early steady-state achieves, the converter output is close to the ideal one. In the literature, there were different models used to achieve it. But, unfortunately, the machine-learning technique literature is very few, as the working of machine-learning with power electronics is a newer one. In this paper, we propose a deep-learning-based buck-boost converter model that will achieve the buck level or boost level with early steady-state. The training of the model is achieved by using the PID controller by acquiring the data from the PID controller. The input voltage considered for the simulation is 12V. The output voltage is suitable for laptop charging when the model is working in boost mode and are suitable for the USB port of the laptop when working in buck mode. The simulation results validate our deep-learning model. The results were far better than the results achieved from the PID controller. Existing evaluation measures i.e settling time and overshoot are used to validate the proposed model. The results clearly show the achievement of an early-steady state and getting stability earlier with the proposed model. The problem of output voltage ripples is almost solved (in an ideal case, there are no output ripples and in our case, the ripples are less than the tenth part of one percent ripples. There is a table used to show the promising results compared to the PID controller results.",Yes,"논문 초록에서 기존 평가 지표인 안정 시간(settling time)과 오버슈트(overshoot)를 사용하여 제안된 딥러닝 모델의 성능을 정량적으로 평가했다고 명시되어 있습니다. 또한, 시뮬레이션 결과를 통해 모델의 성능을 수치로 검증하는 내용이 포함되어 있습니다."
Artificial Intelligence Based Automated Appliances in Smart Home,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10537773,"Smart home and Artificial Intelligence (AI) expertise are quickly evolving, and a variety of smart home appliances incorporating AI have improved occupant quality of life. Although some studies looked at how artificial intelligence could be used in smart homes, few publications looked at how literature and products could be integrated. The advancement in smart home applications with technology development and the relevant literature are articulated in this paper. The functionalities and various procedures of AI are defined through literature and product reviews. This paper describes AI based gesture identification system through which the various appliances in home are controlled to make it ON or OFF without the use of Internet service. Hardware implementation is made for few appliances and based on the image captured through the gesture notation is evaluated using AI based algorithms and analyzed for controlling the appliance successfully. This system will be much helpful for the disabled or aged people, who can’t control the switch physically and comfortably.",Yes,"논문은 AI 기반의 제스처 인식 시스템을 개발하고, 이를 통해 가전제품을 제어하는 실험을 수행하여 성능을 평가하는 내용을 포함하고 있습니다. 따라서 정량적 평가가 실시되고 있음을 알 수 있습니다."
Analysis of Compatibility in Open Source Android Mobile Apps,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9233032,"Non-functional requirements (NFRs) form an intrinsic part of any software system. Compatibility between versions or different platforms of a software product is a form of NFRs. In this paper, we have studied Compatibility in open-source mobile apps. We are interested in understanding the different aspects of mobile incompatibility, their frequency of occurrence from a user perspective, and how much effort developers have spent on it. We have conducted a study on 40 randomly selected open-source mobile apps from the Google Play Store and have analyzed 258,056 commits (extracted from their version control system) to identify incompatibility issues in apps. We have also studied 205,847 reviews to identify and categorize compatibility requirements from user reviews. Both app commits and app reviews were processed by a pipeline of Natural Language Processing steps. We evaluated the efficiency of four Machine Learning classifiers to analyze compatibility. This was done by classifying commit messages and analyzing user reviews. We observed that the Logistic Regression classifier produced the best overall results. For the same data set, we classified compatibility types. In that case, the Support Vector Machine classifier performed marginally better over the other classifiers. Addressing the relative effort spent on compatibility, we found that 3.16% of the developer's effort is dedicated to compatibility issues. At the same time, we observed that 4.30% of user reviews report compatibility issues in apps. In conclusion, we see more demand for future research on (i)the gap between the time spent by the developers and the frequency of occurrence of compatibility issues, and (ii) the degree of responsiveness on actual user concerns.",Yes,"논문은 정량적 평가를 위해 258,056개의 커밋과 205,847개의 사용자 리뷰를 분석하였으며, 머신러닝 분류기 성능 평가와 개발자 노력 비율 등 수치 데이터를 활용한 정량적 분석을 수행하고 있습니다. 이러한 데이터 기반 분석이 정량적 평가의 핵심을 이룹니다."
FEEL: FEderated LEarning Framework for ELderly Healthcare Using Edge-IoMT,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10024778,"Recent advancements in artificial intelligence (AI) and IoT technology have revolutionized the healthcare industry by providing effective remote healthcare. Furthermore, with the aging of the world’s population, remote health monitoring and recommendations are becoming imperative to provide cost-effective healthcare solutions for improving the quality of life of our senior citizens. The explosive growth of wearable sensors (IoT sensors) and health bands has facilitated the interconnection among patients and caregivers to enable assisted living by leveraging AI techniques. This work proposes an end-to-end connected smart home healthcare system (FEEL) for elderly people. Our proposed framework addresses the main challenges of the Internet of Medical Things (IoMT) system namely, the scarcity of labeled data and user’s diverse needs. The major contributions of the work are: 1) few-shot learning-enabled novel federated learning (FL) framework for health data and context information analysis and recommendation; 2) user and context-based knowledge graph (UKG) to represent and model health parameters and environmental impacts on recommendations; 3) deep learning architecture for activity monitoring and location estimation of the users; and 4) edge-fog-IoMT collaborative framework to collect, store, and share medical recommendations while protecting the privacy of the users. FEEL is specifically beneficial for elderly homes where several aged people stay together and require constant care. We aim to develop a novel AI module where along with the health parameters, the social context of the home can be augmented to provide an accurate and improved healthcare service. FEEL has been evaluated for three tasks, namely: 1) activity monitoring and location estimation; 2) fall detection; and 3) medical recommendations for unusual health conditions. A customized wearable device has been used to collect, store, and send health-related parameters. The experimental evaluation demonstrates promising accuracy (F1 score 0.86–0.94 range) for the tasks and outperforms the baselines by a significant margin ( ≈10 %–16%).",Yes,"논문은 활동 모니터링, 위치 추정, 낙상 감지, 의료 추천 등 다양한 작업에 대해 실험적 평가를 수행하고 있으며, F1 점수와 같은 정량적 지표를 제시하여 평가를 실시하고 있음을 보여줍니다. 이러한 정량적 평가를 통해 제안된 프레임워크의 성능을 검증하고 있습니다."
Bias Amplification to Facilitate the Systematic Evaluation of Bias Mitigation Methods,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10744554,"The future of artificial intelligence (AI) safety is expected to include bias mitigation methods from development to application. The complexity and integration of these methods could grow in conjunction with advances in AI and human-AI interactions. Numerous methods are being proposed to mitigate bias, but without a structured way to compare their strengths and weaknesses. In this work, we present two approaches to systematically amplify subgroup performance bias. These approaches allow for the evaluation and comparison of the effectiveness of bias mitigation methods on AI models by varying the degrees of bias, and can be applied to any classification model. We used these approaches to compare four off-the-shelf bias mitigation methods. Both amplification approaches promote the development of learning shortcuts in which the model forms associations between patient attributes and AI output. We demonstrate these approaches in a case study, evaluating bias in the determination of COVID status from chest x-rays. The maximum achieved increase in performance bias, measured as a difference in predicted prevalence, was 72% and 32% for bias between subgroups related to patient sex and race, respectively. These changes in predicted prevalence were not accompanied by substantial changes in the differences in subgroup area under the receiver operating characteristic curves, indicating that the increased bias is due to the formation of learning shortcuts, not a difference in ability to distinguish positive and negative patients between subgroups.",Yes,"논문은 bias를 정량적으로 평가하기 위해 성능 편향의 증폭 방법을 제시하고, 이를 통해 다양한 편향 완화 방법의 효과를 비교하는 실험을 수행하고 있습니다. 또한, 성능 차이와 관련된 수치적 지표를 사용하여 편향의 증폭 정도를 구체적으로 측정하고 있어 정량적 평가를 실시하고 있음을 알 수 있습니다."
Computer Vision Intelligence Test Modeling and Generation: A Case Study on Smart OCR,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10685196,"AI-based systems possess distinctive characteristics and introduce challenges in quality evaluation at the same time. Consequently, ensuring and validating AI software quality is of critical importance. In this paper, we present an effective AI software functional testing model to address this challenge. Specifically, we first present a comprehensive literature review of previous work, covering key facets of AI software testing processes. We then introduce a 3D classification model to systematically evaluate the image-based text extraction AI function, as well as test coverage criteria and complexity. To evaluate the performance of our proposed AI software quality test, we propose four evaluation metrics to cover different aspects. Finally, based on the proposed framework and defined metrics, a mobile Optical Character Recognition (OCR) case study is presented to demonstrate the framework's effectiveness and capability in assessing AI function quality.",Yes,"논문은 AI 소프트웨어의 성능 평가를 위해 네 가지 평가 지표를 제안하고 있으며, 이를 통해 정량적 평가를 실시하고 있음을 명확히 하고 있습니다. 또한, OCR 사례 연구를 통해 평가 프레임워크의 효과성을 검증하는 과정이 포함되어 있습니다."
EvauleBlock: Evaluating Answers in E-Learning Applications with Enhanced Security and Intelligence through DRL and Blockchain Integration,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10718561,"Evaluating the candidate answers during online examination by a human examiner is wearisome task. Along with that, security concerns also associated in the E-Learning environment in terms of false data injection and modification attacks respectively. The state of the art work, either focus on designing intelligent and robust question answering model using Machine Learning (ML)/Deep Learning (DL) algorithm, or designing a secure framework for E-Learning environment using blockchain. To neutralize that issue, we design a secure and intelligent model for E-Learning environment using Deep Reinforcement Learning (DRL) and blockchain methodology respectively named EvauleBlock. The EvauleBlock composed of four major processes such as data assortment, data pre-processing, intelligent answer evaluation, and blockchain storage. In data assortment stage, the training of the proposed DRL algorithm named Multi Agent Deep Deterministic Policy Gradient (MADDPG) is taken place by crawling the related question answering data from the various websites. Followed by, we have performed pre-processing for the candidate written answers using adequate pre-processing steps. Once the answers are pre-processed, it is then provided to the MADDPG algorithm which employs four agents for validating the candidate answers by checking the semantic, syntactic, keyword, and context similarity scoring respectively. At last, the overall scores are securely stored in the blockchain using Proof of Work (PoW) consensus algorithm. The implementation of this work is carried out using python 3.11.0 tool and performance of the proposed model are validated and compared with adequate performance metrics. The results are promising when compared to the conventional models.",Yes,"논문 초록에서 제안된 모델은 후보 답변의 평가를 위해 딥 강화학습 알고리즘(MADDPG)을 사용하여 정량적 점수 산출을 수행하고 있음을 명확히 언급하고 있습니다. 또한, 성능 검증을 위해 다양한 성능 지표를 활용했다고 언급되어 있어 정량적 평가가 실시되고 있음을 알 수 있습니다."
Artificial Intelligence Based on Recommendation System for Startup Matchmaking Platform,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10118708,"Artificial intelligence platform-based software is currently required and recommended for education and have innovation used to develop, implement, and evaluate the process of an activity. An artificial intelligence-based Startup Matchmaking platform with a recommendation feature in the system can make it easier to bring together startups and partners as needed through a matchmaking process. In general, Startups that are being built must look for partners one by one to work, which will take a long time. To solve this problem, we need to replace the manual method to get answers to all kinds of theory questions and common questions related to startups. The main goal of this research is to create an intelligent platform that can help the industry find information through matchmaking startups. To develop this study, we use the Study Literature Review (SLR) method based on the needs where startups that are growing fast. In this research, the system is implemented entirely with integration with Communicate. Novelty in this study is the use of Artificial Intelligence in Matchmaking startups.",No,The abstract does not mention any specific quantitative evaluation methods or metrics used to assess the system's performance. It primarily describes the development and purpose of the AI-based matchmaking platform without indicating that a quantitative assessment was conducted.
Discerning and Leveraging Gastric Cancer Using Deep Analytics Algorithms,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10829130,"Gastric disease (GC) is one of the most prevalent malignant developments with poor prognostic outcomes. Endoscopic evaluation is primarily used for early recognition, while pathological confirmation and CT scanning are used for further treatment. The shortage of pathologists presents an opportunity for AI systems to ease the workload and increase diagnostic accuracy. Most gastric cancers show genetic instability, either microsatellite or chromosomal, which occurs early in carcinogenesis. New classifications based on histologic features, genotypes, and molecular profiles improve understanding, diagnosis, prevention, and treatment of each subtype. This paper introduces “Gastronet,” a deep learning system integrating three algorithms—Perform Multiple Tasks Net, Mix Net, and Overall Net—to enhance gastric cancer diagnosis. Gastronet aims to provide precise predictions with minimal additional confirmation, surpassing current diagnostic models. The roadmap includes a comprehensive literature review to identify gaps in current diagnostic methods and the potential for AI, followed by the development of Perform Multiple Tasks Net, Mix Net, and Overall Net to handle specific diagnostic tasks and data types. Data collection and preprocessing ensure a quality dataset for training and validation. Each network is trained and validated separately, then integrated and fine-tuned within the Gastronet framework. The system’s performance is compared with current models, demonstrating superior accuracy. Implementation involves developing a user-friendly interface for clinical use and integrating it into workflows. Continuous improvement is ensured by updating the system with new data and advancements in gastric cancer research. By following this roadmap, the paper aims to develop a reliable, accurate, and efficient system for early detection and diagnosis of gastric cancer, improving patient outcomes and supporting pathologists.",Yes,"논문 초록에서 ""Gastronet""이라는 딥러닝 시스템을 개발하고 있으며, 이를 위해 데이터 수집, 전처리, 훈련, 검증 과정을 거쳐 성능 평가를 실시하고 있음을 언급하고 있습니다. 이러한 내용은 정량적 평가를 수행하고 있음을 시사합니다."
Empowering Rural Minds: Leveraging Predictive Analytics to Bridge Urban-Rural Educational Disparities Through Financial Assistance,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10425432,"Access to quality education is a critical factor in individual empowerment, economic development, and societal progress. However, students from rural backgrounds often face significant obstacles when it comes to pursuing technical education, primarily due to financial barriers. Financial barriers act as a deterrent, restricting the participation of rural students in technical education programmes. This paper presents an innovative approach to address this issue by leveraging the power of artificial intelligence (AI) and predictive analytics to provide equitable financial assistance and scholarships for technical education. By adopting a comprehensive strategy, this paper addresses the biases, transparency shortcomings, and contextual factors that have been prevalent in previous algorithm methods. The strategy employed in this study involves a multi-faceted approach, integrating various methodologies to achieve optimal outcomes. The key steps encompassed in the methodology include algorithmic fairness, model training and selection, transparency and interpretability, human-in-the-loop review, contextualised assessment, continuous learning, and feedback loops. Adversarial Debiasing is utilised to mitigate biases and ensure a fair decision-making process. To enhance transparency and interpretability, rule-based systems and LIME (Local Interpretable Model-Agnostic Explanations) are employed. Human-in-the-loop review is an integral part of the methodology, ensuring that AI-driven decisions are validated and refined by human experts. The expected outcome of this research is an AI-enabled financial assistance system that democratises technical education by making it more accessible to students from rural backgrounds. The implementation of this model can have a transformative impact on education equality, empowering rural minds to pursue their academic dreams.",Yes,"논문 초록에서 다양한 정량적 평가 방법인 알고리즘 공정성, 모델 훈련 및 선택, LIME 등 해석 가능성 향상 기법이 언급되어 있습니다. 이러한 방법들은 데이터와 모델의 성능을 수치적으로 평가하고 검증하는 정량적 평가를 실시하고 있음을 시사합니다."
Anomaly Based Intrusion Detection System: A Deep Learning Approach,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10323740,"In recent years, computer networks have seen a considerable proliferation in terms of performance and total traffic volume. At the same time, cyber attacks have been on the rise ever since, which led to the emergence of Intrusion Detection Systems (IDSs) to deal with them. Conversely, artificial intelligence has been a popular technique that can be applied to a variety of purposes including detection of cyber attacks. However, most related work that leveraged artificial intelligence classifiers to address this problem used outdated datasets. In this paper, we implemented an anomaly-based intrusion detection system using deep learning algorithms with the goal of achieving higher performance while using a newer dataset. That is why we used the NSL-KDD dataset, which constitutes an improvement over the widely used KDD Cup 99 dataset, as it addresses some of its imperfections such as duplicated records and obsolete attack types. Then, we developed three deep learning classifiers that are Recurrent Neural Networks (RNNs), Multi-Layer Perceptron (MLP), and a hybrid Convolutional Neural Network-Long Short Term Memory (CNN-LSTM) model. Also, we compared the effectiveness of our proposed model with Machine Learning classifiers such as Support Machine Vector (SVM), K-Nearest Neighbor (KNN), and Gradient Boosting (GB). Finally, we validate our findings with a performance evaluation of our model, which showed encouraging results.",Yes,"논문 초록에서 제안된 딥러닝 기반 침입 탐지 시스템의 성능 평가를 수행했다고 명시되어 있습니다. 또한, 다양한 딥러닝 모델과 머신러닝 모델의 효과를 비교하는 정량적 평가가 이루어진 것으로 보입니다."
MitrApp: An Intelligent Recommendation System For Counselling,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9312107,"In modern era there has been a phenomenal increase of suicidal syndromes with teens and student population being susceptible the most. Since most of the teens and youth are active in social media, the framework serves more to predict the suicidal tendency of the user. The proposed App captures the face of the user to identify his emotional state and immediately play or encourage him to go through audio or video content that serves as an immediate counselling session with no human intervention. Facial emotion recognition (FER) is an important topic in the fields of computer vision and artificial intelligence owing to its significant academic and commercial potential. This review focuses on studies that exclusively use facial images, because visual expressions are one of the main information channels in interpersonal communication. this paper provides a brief review of researches in the field of FER conducted over the past decades. Deep-learning-based FER approaches using deep networks enabling “end-to-end” learning are then presented. This review primarly focuses on two datasets namely, KDEF(Karolinska Directed Emotional Faces) dataset and Kaggle FER2013 dataset. The proposed App captures the face of the user to identify his emotional state and immediately play or encourage him to go through audio or video content that serves as an immediate counselling session with no human intervention. This paper takes suggests instant counter measures such as recommending some anti-suicidal videos and some online expert support. Since people having suicidal tendency will post/ likes the photos/ images related to the suicide thoughts detection of suicide related objects like suicide rope will help in predicting suicidal behaviour more accurately. Since a large section of community(about 28%) are attempting suicides by means of suicidal rope, a model is trained on the most frequently used suicide rope images.",Yes,"논문은 얼굴 감정 인식(FER)과 관련된 딥러닝 모델의 성능 평가를 위해 KDEF와 FER2013 데이터셋을 사용하며, 정량적 평가를 실시하는 것으로 보입니다. 또한, 제안된 추천 시스템의 효과를 수치적으로 분석하거나 평가하는 내용이 포함되어 있을 가능성이 높습니다."
Leveraging Machine Learning for Consumer Purchase Behaviour Analysis: Influence of Online Reviews on E-Commerce Decisions in Electronics and Electrical Markets,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10941434,"People mostly use e-commerce platforms to search for, evaluate, and eventually buy things. Machine learning (ML) is a rapidly developing field that appears to be a desirable substitute for statistical techniques across a range of sectors. This study suggests an understanding of the potential uses of ML in eCommerce and digital marketing. This paper gives a deliberate assessment of the utilization of AI in online business to foresee buyer buy choices, recognize commitment factors, and further develop UIs. The examination researches the capability of AI calculations to foresee purchaser inclinations, accelerate the checkout technique, and produce a more redone shopping experience. As web-based business propels, the concentrate additionally analyzes the difficulties and moral pickles related with artificial intelligence-controlled customization. To give a complete comprehension of the more extensive ramifications of man-made intelligence in forming shopper conduct, points including information protection, predisposition in calculations, and the scarce difference among personalization and nosiness are explored. Our review plans to more readily comprehend what shoppers explore internet business sites and how this means for their choices to purchase. We use AI approaches since we comprehend that buyer conduct is diverse and dynamic. These strategies permit us to deal with convoluted information structures and reveal stowed away examples in the information, which upgrades how we might interpret the components driving purchaser conduct.",Yes,"논문 초록에서 머신러닝 알고리즘을 활용하여 구매자 행동을 예측하고, 관련 요인들을 분석하는 정량적 평가를 수행하고 있음을 명확히 언급하고 있습니다. 이러한 분석은 데이터 기반의 정량적 평가를 포함하는 것으로 보입니다."
AI Empathetic Chatbot with Real-Time Emotion Detection Using Multimodal Fusion and BO-CNN Optimization,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10893614,"This paper presents a novel AI-driven empathetic chatbot system that leverages multimodal fusion to decode and respond to user emotions across speech, text, and visual cues in real-time. Building upon advanced Speech Emotion Recognition (SER) and Face Emotion Recognition, and integrating BERT-based Natural Language Understanding (NLU), the system is designed to enhance human-like interaction and emotional responsiveness in conversational AI. A comprehensive review of literature highlights limitations in existing approaches, such as single-modal reliance and dataset constraints, which our proposed model addresses by fusing multiple data sources using the EmbraceNet framework. This fusion of facial and speech features is further optimized with Botox Optimization-based Convolutional Neural Networks (BO-CNN), enhancing accuracy in facial emotion recognition. Extensive testing validates the model's superior performance across precision, sensitivity, and specificity metrics, demonstrating its potential for application in various human-interactive systems.",Yes,"논문 초록에서 ""extensive testing validates the model's superior performance across precision, sensitivity, and specificity metrics""라고 언급되어 있어, 정량적 평가가 실시되고 있음을 알 수 있습니다. 이러한 성능 지표들은 일반적으로 수치 데이터를 기반으로 한 정량적 평가를 의미합니다."
Heart Disease Prediction Using Machine Learning Algorithms,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9122958,"Heart plays significant role in living organisms. Diagnosis and prediction of heart related diseases requires more precision, perfection and correctness because a little mistake can cause fatigue problem or death of the person, there are numerous death cases related to heart and their counting is increasing exponentially day by day. To deal with the problem there is essential need of prediction system for awareness about diseases. Machine learning is the branch of Artificial Intelligence(AI), it provides prestigious support in predicting any kind of event which take training from natural events. In this paper, we calculate accuracy of machine learning algorithms for predicting heart disease, for this algorithms are k-nearest neighbor, decision tree, linear regression and support vector machine(SVM) by using UCI repository dataset for training and testing. For implementation of Python programming Anaconda(jupytor) notebook is best tool, which have many type of library, header file, that make the work more accurate and precise.",Yes,"논문 초록에서 여러 머신러닝 알고리즘의 정확도를 계산했다고 명시되어 있어 정량적 평가를 실시하고 있음을 알 수 있습니다. 또한, 정확도 평가를 위해 데이터셋을 사용하여 실험을 수행한 것으로 보입니다."
Plenary Talk II: Measuring Student Engagement in Early Engineering Coursework,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9334628,"This talk describes recent efforts for quantifying students’ engagement in early engineering coursework, through designing, implementing, and testing a system to measure the students’ emotional, behavioral, and cognitive engagement states. Engineering programs suffer from a high rate of attrition in the freshman year, primarily due to poor engagement of students with their classes. The project plans to develop a sensor-driven, computational approach to measure emotional and behavioral components of student engagement. This information will be used to identify teaching strategies that increase engagement, with the goal of enhancing student success and retention in STEM education pathways. The project features a multi-disciplinary collaboration between faculty and undergraduate researchers in engineering, the physical sciences, psychological sciences, and education. The project involves students in first- and second-year engineering STEM subjects and the experienced faculty who teach these courses. Findings from the project could be a valuable step toward an early warning system to detect student disengagement and anxiety in STEM and non-STEM courses. Project goals include: (i) establishment of a robust network of non-obtrusive and non-invasive sensors in mid-size classes to enable real-time extraction of facial and vital signs, which will be integrated and displayed on instructors’ dashboards; (ii) identification of robust descriptors for modeling the emotional and behavioral components of engagement using data collected by the sensor networks; (iii) pilot testing of the system’s effectiveness in gathering meaningful data for subsequent work on emotional, behavioral, and cognitive metrics of engagement. The fundamental research question to be addressed relates to improving student learning by the automated capture of non-verbal cues of engagement: How can we use students’ expressions of engagement, based on non-verbal signs such as facial expressions, body and eye movements, physiological reactions, posture, to enhance learning? Findings from the project will constitute a foundation for multi-disciplinary research to incorporate novel machine learning and artificial intelligence-based models for measuring engagement in STEM classes. This project has been funded by the National Science Foundation (NSF). The talk will describe our latest discoveries in this long-term and multidisciplinary project.",Yes,"논문 초록은 학생들의 참여를 정량적으로 평가하기 위해 센서와 데이터 분석을 활용하는 시스템을 설계, 구현, 시험하는 연구를 다루고 있습니다. 이를 통해 감정, 행동, 인지적 참여 상태를 수치화하고자 하는 정량적 평가 방법이 명확히 제시되어 있습니다."
Fraud identification architecture using data mining and machine learning in a private transport company that operates by applications,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9140992,"With the digital transformation over the years and the recent expansion of the use of different applications, it is possible to notice a significant change in several businesses. The diversification of electronic payments has contributed to companies suffering more from fraud. The purpose of this article is to detail a fraud detection architecture based on the identification of patterns of behavior and was applied in the racing bases of the usage of an application transport company. The study considered the construction of an artifact capable of minimizing the problem using unsupervised and supervised algorithms and machine learning techniques. The research was carried out using the DSR - Design Science Research method and considered the stages of construction of a possible conceptual structure with the systematic review of the literature, studies of fraud practices and machine learning techniques used for the detection. The architecture was implemented and allowed to validate the model capable of identifying suspected fraud in a more accurate way.",Yes,"논문 초록에서 ""the architecture was implemented and allowed to validate the model capable of identifying suspected fraud in a more accurate way""라는 내용을 통해, 정량적 평가를 위해 모델의 검증과 성능 평가가 수행되었음을 알 수 있습니다. 이는 구체적인 평가 과정이 포함된 정량적 평가를 실시했음을 시사합니다."
An AI Based Automatic Translator for Ancient Hieroglyphic Language—From Scanned Images to English Text,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10103702,"Recent advancements in the fields of Machine Learning and Deep Learning made a huge transformation in other fields that are not related to Computer Science. In this work, a new framework is proposed to tackle the problem of translating the old Egyptian Hieroglyphic writings to English language through deploying both Image Processing and Natural Language Processing techniques combined with AI approaches. Our primary goal is to design an application that completely revolutionizes a tourist’s experience while navigating Egyptian Historical sites. This work utilize different AI techniques to automatically convert the scanned photos of hieroglyphic language to understandable and readable English language, through two main sub-tasks: The automatic detection and recognizing of the scanned glyphs images and the translation of them into English language. Different data sources of this low-resource language were explored and augmented to train and test our models. Results of different models and algorithms are assessed and analyzed to evaluate our work. State-of-the-art results are achieved compared to literature in both automatic glyphs recognition, and glyphs-to-English translation.",Yes,"초록에서 ""Results of different models and algorithms are assessed and analyzed to evaluate our work""라는 문구를 통해 다양한 모델과 알고리즘의 성능 평가가 이루어졌음을 알 수 있습니다. 이는 정량적 평가가 수행되고 있음을 시사합니다."
A Deep Learning Based Approach In The Prediction Of Tinnitus Disease For Large Population Data,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10307000,"Tinnitus is a frequent sensory disorder that puts a lot of strain on the patient. Usually, tinnitus results from disturbances occurring to the sensory systems, such as the peripheral seldom central, the somatosensory system, the head and neck, or a mix of the two. This can be found in people with high stress, anxiety, depression, and hearing disorders. Although there is progress in the medical domain using artificial intelligence (AI), research related to tinnitus using AI is limited. This work aims to bridge the gap using deep-learning techniques for evaluating the patient record by examining various parameters. The proposed research also aims to target the same to understand the severity and possible recommendations for tinnitus disease. Our findings forecast how patients will react to tinnitus treatments. From the patients' electroencephalography (EEG) data, predictive EEG variables are extracted, and later feature selection approaches are used to determine the prominent features. The patient's EEG features are supplemented by AI algorithms for training and forecasting treatment outcomes. Higher accuracy levels of the proposed model using AI help the practitioners suggest the proper diagnosis for the patients and also check the patient's recovery over a period of time.",Yes,"논문 초록에서 딥러닝 기법을 활용하여 환자 기록을 평가하고, EEG 데이터를 기반으로 예측 변수와 특징 선택을 수행하는 등 정량적 평가를 실시하고 있음을 명확히 언급하고 있습니다. 이러한 방법들은 데이터 분석과 예측 모델링을 통한 정량적 평가를 포함하는 것으로 보입니다."
Quantifying Repetition in Symbolic Music using Lempel-Ziv Compression,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10316147,"Repetition serves as a fundamental element in music by creating patterns, building structure, and emphasizing melodies, yet remains largely elusive to generative AI models. In this paper, we explore the question of quantifying musical repetition by using principles of information theory, arguing that a composition’s repetitiveness is related to the compressibility of its musical data. Thus, we introduce a metric of repetition termed the LZ ratio, based on Lempel-Ziv compression. By analyzing numerous selected piano pieces, we evaluate the effectiveness of our metric in measuring different types of musical repetition. We find that our metric does well in quantifying certain types of repetition. Furthermore, we observe expected changes in our metric when we remove repetitions from pieces. Our work presents an encouraging direction to objectively quantifying the repetitiveness of music for use in generative multimedia machine learning systems.",Yes,"논문은 Lempel-Ziv 압축을 기반으로 한 정량적 지표인 LZ 비율을 도입하여 음악의 반복성을 수치로 평가하고 있습니다. 또한, 다양한 피아노 곡을 분석하여 이 지표의 유효성을 검증하는 과정을 통해 정량적 평가를 실시하고 있음을 보여줍니다."
The Use of Digital AI-based Tools for Prevention of Workload Injuries - An Intervention Study,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10857129,"Work-related injuries, particularly musculoskeletal disorders (MSDs), incur significant costs for companies in terms of sick leave and reduced productivity. Maintaining correct ergonomic posture is crucial to prevent these injuries and mitigate the impact of psychosocial factors. Digital technology plays a vital role in creating efficient and flexible work environments that cater to individual needs. Rather than relying solely on specialists, workers can utilize digital applications to prevent workload and strain injuries. This study investigates the effectiveness of a digital AI-based intervention program aimed at preventing work-related injuries and improving the physical work environment by addressing musculoskeletal disorders caused by incorrect postures. Through interviews with tool users in an industry setting, a web-based prototype application was tested to enhance workplace safety and improve physical health. The application employs digital AI tools to provide real-time feedback to workers. The interviews specifically assess how users evaluate and effectively utilize the tool to enhance working postures and the overall work environment. The study seeks to evaluate the efficacy of the digital AI-based intervention program and gather insights on users’ perceptions and utilization of the application. This research has the potential to contribute to a safer and healthier workplace by harnessing the power of technology. The study seeks to evaluate the efficacy of the digital AI-based intervention program and gather insights on users’ perceptions and utilization of the application.",Yes,"초록에서 연구의 효과성을 평가하기 위해 디지털 AI 기반 개입 프로그램의 효능을 검증하는 내용이 언급되어 있습니다. 또한, 사용자 평가와 활용도를 조사하는 부분이 있어 정량적 평가가 실시되고 있음을 시사합니다."
Critical review of machine learning approaches to apply big data analytics in DDoS forensics,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8441286,"Distributed Denial of Service (DDoS) attacks are becoming more frequent and easier to execute. The sharp increase in network traffic presents challenges to conduct DDoS forensics. Despite different tools being developed, few take into account of the increase in network traffic. This research aims to recommend the best learning model for DDoS forensics. To this extend, the paper reviewed different literature to understand the challenges and opportunities of employing big data in DDoS forensics. Multiple simulations were carried out to compare the performance of different models. Two data mining tools WEKA and H2O were used to implement both supervised and unsupervised learning models. The training and testing of the models made use of intrusion dataset from oN-Line System - Knowledge Discovery & Data mining (NSL-KDD). The models are then evaluated according to their efficiency and accuracy. Overall, result shows that supervised learning algorithms perform better than unsupervised learning algorithms. It was found that Naïve Bayes, Gradient Boosting Machine and Distributed Random Forest are the most suitable model for DDoS detection because of its accuracy and time taken to train. Both Gradient Boosting Machine and Distributed Random Forest were further investigated to determine the parameters that can yield better accuracy. Future research can be extended by installing different DDoS detection models in an actual environment and compare their performances in actual attacks.",Yes,"논문은 다양한 머신러닝 모델의 성능을 비교하기 위해 실험을 수행하고, 그 결과를 평가하는 정량적 평가를 실시하였음을 명시하고 있습니다. 특히, 모델의 효율성과 정확도를 평가하는 과정이 포함되어 있어 정량적 평가가 이루어지고 있음을 알 수 있습니다."
Impact of Application Choice on iTracker Model Performance Evaluation: A Perspective,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10590349,"Eye tracking is underpinned by the eye-mind hypothesis, which posits that individuals tend to direct their gaze toward the information they are currently cognitively engaged with. This aspect has garnered significant attention within deep learning research due to its versatile applications and research. The utilization of Artificial Intelligence (AI) in conjunction with webcams for tracking eye movements has gained increasing popularity in recent years and is anticipated to continue flourishing. This literature review aims to assess the current state and depth of the research in this domain and its various applications. We examine the different methods that employ eye tracking across a diverse range of applications, and by re-exploring existing research, we are able to filter out any overlooked potential or setbacks associated with the use of AI-webcam based systems, with the ultimate goal of maximizing their potential contributions to humanity. In our study, we analyze and evaluate a pioneering eye tracking algorithm, iTracker trained on a crowd-sourced data-set, GazeCapture within the context of the applications it may be used for. While we acknowledge inherent limitations, this widely adopted model forms a robust foundation for future refinements. Furthermore, our investigation encompasses diverse applications with varying accuracy requirements, making it invaluable for individuals seeking to integrate eye tracking into their projects.",Yes,논문 초록에서 iTracker 모델의 성능 평가를 위해 다양한 애플리케이션 맥락에서의 정확도와 성능을 분석하고 평가하는 내용을 언급하고 있습니다. 이는 정량적 평가가 수행되고 있음을 시사합니다.
A GA-Based CNN Model for Brain Tumor Classification,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9919461,"Detection and classification of tumor types generally cover problem-specific algorithm developments. The problems of detecting tumors with the analysis of standard brain images obtained with different medical imaging tools and frequently used in the literature are always desired, developed, and discussed. This study focuses on identifying tumors, extracting different characteristics, and associating them with cancer types. The standard approach of convolutional neural networks (CNN) was used primarily for the identification of tumors. Then, the genetic algorithm (GA) approach was designed and used for hyperparameter optimization in CNN to increase the performance in all datasets. Thus, a CNN+GA hybrid model was proposed and analyzed with different tests. In this process, the results were examined in detail and the standard CNN algorithm and some machine learning methods suggested in the literature were analyzed comparatively. In addition, the data set called Gazi Brains 2020 Dataset, which was obtained within the scope of the Turkish Brain Project, is also used to test the proposed system. Here, literature reviews of the previous studies in which different machine/deep learning approaches are used together with optimization algorithms are presented. The different comparison scores obtained according to the experimental studies were presented in the tables and the outputs were evaluated in terms of significance. The results have shown that the proposed hybrid models are successful in achieving better accuracies not only with different datasets available in the literature but also DL/ML models trained with Gazi Brain 2020 Dataset. It should be concluded that the proposed method might be also used for other deep/machine learning models and applications.",Yes,"논문 초록에서 다양한 실험 결과와 비교 점수들이 표로 제시되었으며, 성능 평가를 위한 정량적 지표들이 사용되었음을 시사합니다. 따라서, 정량적 평가를 실시하고 있다고 판단됩니다."
"Using Knowledge Graphs to Unlock Practical Collection, Integration, and Audit of AI Accountability Information",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9815594,"To enhance trustworthiness of AI systems, a number of solutions have been proposed to document how such systems are built and used. A key facet of realizing trust in AI is how to make such systems accountable - a challenging task, not least due to the lack of an agreed definition of accountability and differing perspectives on what information should be recorded and how it should be used (e.g., to inform audit). Information originates across the life cycle stages of an AI system and from a variety of sources (individuals, organizations, systems), raising numerous challenges around collection, management, and audit. In our previous work, we argued that semantic Knowledge Graphs (KGs) are ideally suited to address those challenges and we presented an approach utilizing KGs to aid in the tasks of modelling, recording, viewing, and auditing accountability information related to the design stage of AI system development. Moreover, as KGs store data in a structured format understandable by both humans and machines, we argued that this approach provides new opportunities for building intelligent applications that facilitate and automate such tasks. In this paper, we expand our earlier work by reporting additional detailed requirements for knowledge representation and capture in the context of AI accountability; these extend the scope of our work beyond the design stage, to also include system implementation. Furthermore, we present the RAInS ontology which has been extended to satisfy these requirements. We evaluate our approach against three popular baseline frameworks, namely, Datasheets, Model Cards, and FactSheets, by comparing the range of information that can be captured by our KGs against these three frameworks. We demonstrate that our approach subsumes and extends the capabilities of the baseline frameworks and discuss how KGs can be used to integrate and enhance accountability information collection processes.",Yes,"논문은 Knowledge Graphs를 활용하여 AI 책임성 정보를 수집, 통합, 감사하는 과정을 지원하는 방법을 제시하며, 이를 위해 정량적 평가를 수행하는 다양한 프레임워크와 비교 분석을 포함하고 있다. 이러한 비교와 평가 과정은 정량적 평가의 실시를 의미한다."
Yoga Pose Recognition Using Deep Learning,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10497433,"Yoga pose detection holds significant importance in various aspects of the yoga practice and its integration with technology. The importance of yoga lies in its ability to promote physical health, mental well-being, stress reduction, improved focus, emotional balance, resilience, spiritual growth, and a holistic approach to life. With the increasing popularity of yoga, there is a growing need for technological advancements to support practitioners and instructors in monitoring and refining their practice. The paper begins by outlining the significance of automated yoga pose detection, highlighting the potential benefits it offers in providing real-time feedback, enhancing self-correction, and optimizing performance. It explores the existing literature on computer vision and machine learning techniques applied to human pose estimation and their applicability to yoga pose detection. Based on a thorough review of state-of-the-art methodologies, the research paper proposes a yoga pose detection that combines multiple modalities, including RGB images, depth maps, and skeletal joint data. The proposed system leverages deep learning algorithms, such as convolutional neural networks (CNNs) and long short-term memory (LSTM), to precisely recognize and continuously monitor yoga poses. Moreover, the paper discusses the challenges associated with pose variation, occlusion, and complex body movements within yoga practice. It explores strategies for data augmentation, model optimization, and performance evaluation to ensure robustness and accuracy of the proposed detection system. The practical implications of the research are discussed, emphasizing the potential for widespread adoption of yoga pose detection systems in various settings, including yoga studios, fitness centers, and home practice environments. The paper concludes by outlining future research directions and the potential for integrating the proposed system with emerging technologies, such as augmented reality (AR) and virtual reality (VR), to enhance the yoga experience and facilitate remote instruction. Overall, this research paper contributes to the advancement of automated yoga pose analysis, offering a comprehensive framework that can revolutionize the way yoga is practiced, taught, and evaluated, ultimately promoting accessibility, precision, and effectiveness in the pursuit of physical and mental well-being.",Yes,"논문 초록에서 딥러닝 알고리즘을 활용하여 요가 자세를 인식하고 지속적으로 모니터링하는 시스템을 제안하며, 성능 평가와 데이터 증강 전략에 대해 논의하고 있음을 명확히 언급하고 있습니다. 이는 정량적 평가를 실시하고 있음을 시사합니다."
Applying Hidden Markov Model for Dynamic Game Balancing,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9291666,"In Artificial Intelligence (AI) field, Machine Learning (ML) techniques present an interesting approach for games, where it allows some sort of adaptation along the game session. This adaptation can make games more attractive, avoiding that Non-Player-Characters (NPC) present too easy or hard patterns during the game. In both cases, the player may be frustrated due to undesired experience. Although ML techniques are appealing to be used in games, some games characteristics are hard to model. Besides, there are techniques that require a wide variety of observations, which implies two hard barriers for game application: the first is the power processing to compute a huge amount of data in games, considering the real-time characteristic of this kind of application. The second threat is related to the vast majority of games' attributes that must be described in the model. This work proposes a novel approach using ML technique based on Hidden Markov Model (HMM) for game balancing process. HMM is a powerful technique which can be used to learn patterns based on a strong co-relational between an observation and an unknown variable (the hidden part). Our proposed approach learns the player's pattern based on temporal frame observation by co-relating his/her actions (movements) with game events (NPC destruction). The temporal frame observation approach allows the game to learn about player's pattern even if a different person plays it. After the learning process, the following step is to use the knowledge pattern to adapt the game according to the current player, which normally involves making the game harder for a certain period of time. During this time, another pattern may arise, subjected to be learned. In order to validate the presented approach, a Space Invaders clone has been built, allowing to observe that 54 % of participants had more fun while playing it with ML activated in relation to a base version that did not take into account dynamic difficult balancing.",No,"논문 초록에서는 Hidden Markov Model을 이용한 게임 밸런싱 방법을 제안하고 있지만, 정량적 평가를 수행했다는 구체적인 언급은 없습니다. 실험 결과로 참가자들의 재미 증진을 관찰했지만, 정량적 평가 지표나 분석 방법에 대한 설명이 포함되어 있지 않습니다."
Reliance on Artificial Intelligence Tools May Displace Research Skills Acquisition Within Engineering Doctoral Programmes: Examples and Implications,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10837618,"The escalation in capabilities of Large Language Models has triggered urgent discussions about their implications for tertiary education, particularly regarding how they might facilitate academic misconduct in graded engineering coursework. However, graduate research education — where a student works closely with a supervisor over years to develop both implicit and explicit research skills — has received comparatively less attention in this discussion. This paper seeks to develop this discourse by presenting targeted case studies that explore the opportunities and threats posed by artificial intelligence to engineering doctoral education. For instance, using a specimen exercise from a PhD-level research skills module, we demonstrate how artificial intelligence tools can now deeply penetrate research workflows in technical computing and scripting. We likewise investigate the capabilities of chatbot tools to assist engineering PhD candidates with the broader research skills central to their training and development. These include writing and proofreading theses and research papers, producing data visualizations, simulating peer review processes, and preparing scientific diagrams. By evaluating the capabilities and limitations of extant artificial intelligence in these areas, we can discuss both the potential benefits and ethical concerns of doctoral students engaging with such assistance.",No,"논문 초록에서는 인공지능 도구의 활용 가능성과 한계, 그리고 그에 따른 기회와 위협에 대해 논의하고 있지만, 구체적인 정량적 평가 방법이나 결과를 제시하는 내용은 포함되어 있지 않습니다. 따라서 본 논문은 정량적 평가를 실시하고 있다고 보기 어렵습니다."
Remote Sensing Image Scene Classification: Benchmark and State of the Art,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7891544,"Remote sensing image scene classification plays an important role in a wide range of applications and hence has been receiving remarkable attention. During the past years, significant efforts have been made to develop various data sets or present a variety of approaches for scene classification from remote sensing images. However, a systematic review of the literature concerning data sets and methods for scene classification is still lacking. In addition, almost all existing data sets have a number of limitations, including the small scale of scene classes and the image numbers, the lack of image variations and diversity, and the saturation of accuracy. These limitations severely limit the development of new approaches especially deep learning-based methods. This paper first provides a comprehensive review of the recent progress. Then, we propose a large-scale data set, termed “NWPU-RESISC45,” which is a publicly available benchmark for REmote Sensing Image Scene Classification (RESISC), created by Northwestern Polytechnical University (NWPU). This data set contains 31 500 images, covering 45 scene classes with 700 images in each class. The proposed NWPU-RESISC45 1) is large-scale on the scene classes and the total image number; 2) holds big variations in translation, spatial resolution, viewpoint, object pose, illumination, background, and occlusion; and 3) has high within-class diversity and between-class similarity. The creation of this data set will enable the community to develop and evaluate various data-driven algorithms. Finally, several representative methods are evaluated using the proposed data set, and the results are reported as a useful baseline for future research.",Yes,"논문 초록에서 여러 대표적인 방법들이 평가되고 있으며, 제안된 데이터셋을 이용한 실험 결과도 보고되고 있습니다. 이는 정량적 평가가 수행되고 있음을 의미합니다."
A Pupil Segmentation Framework with Masked Image Modeling Enhanced Swin-Transformer,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9995137,"Detecting pupil from the image is critical in human-machine interaction and biomedical computing applications, which is supposed to be an actual image segmentation problem. Recently developed deep learning models provide a variety of novel approaches to the pupil segmentation task. However, dataset preparation and annotation acquirement to build pupil image datasets are labor-intensive and time-consuming. The shortage of labeled samples restricted the improvement of deep learning models. In this work, we use a mask image modeling mechanism to learn the latent representation from limited data samples, which significantly helps train deep models. Further, we propose a novel pupil segmentation model based on the recently proposed Swin-Transformer to validate the improvement validity of the mask mechanism. The proposed computational framework achieves better performance on the pupil segmentation tasks based on the LPW dataset through comparison experiments with other related deep learning models. The proposed framework is a promising solution for pupil segmentation and detection in small-sample learning applications.",Yes,"논문 초록에서 ""comparison experiments""와 ""achieves better performance""라는 표현을 통해 정량적 평가를 실시했음을 알 수 있습니다. 이는 다양한 딥러닝 모델과의 성능 비교를 통해 성능 향상을 검증하는 정량적 평가가 수행되었음을 시사합니다."
Classification of Error Related Potentials using Convolutional Neural Networks,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8776901,"A class of Electroencephalogram (EEG) generated when a person is present with a stimuli are Error-related potentials (ErrP). Classification of ErrP revolutionized the domain of Brain-Computer Interface (BCI), however, due to its poor classification accuracy, it is difficult to use it in practical applications. The use of deep learning techniques such as Convolutional neural networks (ConvNets) has been growing because of its end-to-end learning capabilities and classification performance in other fields such as computer vision, speech processing and text synthesis. Very little work has been published towards classification of EEG or its classes using deep learning approaches because of its unexplored benefits in BCI applications. In this paper we propose a novel deep ConvNet architecture to accurately classify Error-related potentials. Using the very recent advances from the field of machine learning, such as batch normalization and dropout layers, we designed a new deep ConvNet architecture. We evaluate and compare the performance of two proposed deep ConvNets by finding its classification accuracy for EEG recordings from same and cross sessions as well as cross subjects for different trials of individual subjects. We see that the net proposed later with newer layers performs very well by improving the mean performance by 4%.",Yes,"논문 초록에서 ""classification accuracy""라는 용어를 사용하며, 두 가지 제안된 딥 컨볼루션 네트워크의 성능을 평가하고 비교하는 내용을 포함하고 있습니다. 이는 정량적 평가를 실시하고 있음을 의미합니다."
System Integration of Xilinx DPU and HDMI for Real-Time Inference in PYNQ Environment With Image Enhancement,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10558393,"Use of edge computing in application of Computer Vision (CV) is an active field of research. Today, most CV applications make use of Convolutional Neural Networks (CNNs) to inference on and interpret video data. These edge devices are responsible for several CV related tasks, such as gathering, processing and enhancing, inferencing on, and displaying video data. Due to ease of reconfiguration, computation on FPGA fabric is used to achieve such complex computation tasks. Xilinx provides the PYNQ environment as a user-friendly interface that facilitates in Hardware/Software system integration. However, to the best of authors’ knowledge there is no end-to-end framework available for the PYNQ environment that allows Hardware/Software system integration and deployment of CNNs for real-time input feed from High Definition Multimedia Interface (HDMI) input to HDMI output, along with insertion of customized hardware IPs. In this work we propose an integration of reaL-time image Enancement IP with AI inferencing engine in the Pynq environment (LEAP), that integrates HDMI, AI acceleration, image enhancement in the PYNQ environment for Xilinx’s Microprocessor on Chip (MPSoC) platform. We evaluate our methodology with two well known CNN models, Resnet50 and YOLOv3. To validate our proposed methodology, LEAP, a simple image enhancement algorithm, histogram equalization, is designed and integrated in the FPGA fabric along with Xilinx’s Deep Processing Unit (DPU). Our results show successful implementation of end-to-end integration using completely open source information.",Yes,"논문 초록에서 Resnet50과 YOLOv3와 같은 CNN 모델을 사용하여 성능을 평가하는 내용이 언급되어 있으며, 이미지 향상 알고리즘과 DPU를 활용한 시스템의 성공적인 구현을 검증하는 과정이 포함되어 있습니다. 이는 정량적 평가가 수행되고 있음을 시사합니다."
Analysis of a Single-Grade Workforce Using Stochastic Methods with Correlated Egress Clusters and Two Factors Defining Breakdown Points,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10912160,"This research investigates the challenge of optimizing recruitment timing in a single-grade workforce system that experiences reductions in personnel due to either employee departures or breaks. Employee exits, occurring in random clusters, are modeled using a compound process, with each cluster’s workforce loss represented by exchangeable, exponentially correlated random variables. Break-related exits are classified by the intensity of attrition and modeled as independent and identically distributed hyper exponential random variables. Threshold of breakdown is split into two components: exits and breaks. The paper proposes two stochastic models: Model 1, where all exits are treated uniformly, and Model 2, which differentiates exits into voluntary and involuntary categories. The study applies the univariate CUM recruitment policy to calculate the mean and variance of recruitment time. Using Matlab, numerical illustrations are presented to illustrate the effectiveness of the proposed models. The research also explores how different nodal parameters influence key system characteristics, yielding insights into the dynamics of recruitment timing. A major contribution of this work lies in the development of two comprehensive stochastic models that account for both voluntary and involuntary exits, providing a more nuanced understanding of workforce attrition. The use of statistical analysis and Matlab simulations strengthens the findings, offering practical applications for optimizing workforce management strategies in dynamic environments. This study provides a foundation for future exploration into more sophisticated recruitment policies, potentially incorporating AI/ML and deep learning techniques. 2020 Mathematics Subject Classification: 60H30, 90B70, 91D35.",Yes,"논문 초록에서 평균과 분산 계산, 수치적 시뮬레이션 등 정량적 평가 방법을 사용하여 연구 결과를 분석하고 있음을 명확히 언급하고 있습니다. 이러한 내용은 정량적 평가를 실시하고 있음을 보여줍니다."
An approach to analyse and Forecast Social media data using Machine Learning and Data Analysis,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9132895,"Twitter is one of the most used social network platforms with more than 321 million active users, sending a daily average of 500 million Tweets. Twitter basically reaches a broad audience, connects many users, and also provides a useful point of view on an ongoing topic based on their interests. This research paper includes works of Machine Learning, NLP, and sentiment analysis on twitter data which is related to Goods and Service Tax (GST) collected from twitter by web scraping technology. Basically here we have found out how many people are against or for about the GST.Here we calculated the sentiments of positive, negative and neutral according to the twitter user. Here Data visualization also used to visualize the data can include cleaning checking transforming and finding the pattern. Machine learning and NLP are used on the data-driven model from the prediction purpose. Machine learning techniques applied to corresponding twitter dataset that contain reviews of GST users to find out the relevant information and inference. Machine learning used to extract the sentiments of the user and find future trends based on current uses.",Yes,"논문 초록에서 감정 분석, 데이터 시각화, 그리고 머신러닝 기법을 활용하여 데이터를 분석하고 예측하는 과정을 언급하고 있어 정량적 평가가 수행되고 있음을 알 수 있습니다. 이러한 방법들은 데이터를 수치적으로 평가하고 분석하는 정량적 평가의 대표적인 예입니다."
Measuring Machine Learning Robustness in front of Static and Dynamic Adversaries*,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10098084,"Adversarial machine learning brought a new way of understanding the reliability of different learning systems. Knowing that the learning confidence depends significantly on small changes, such as noise, created a mind change in the artificial intelligence community, who started to consider the boundaries and limitations of machine learning methods. However, if we can measure these limitations, we can improve the strength of our machine learning models and their robustness. Following this motivation, this work introduces different measures of robustness for machine learning models based on false negatives. These measures can be evaluated for either static or dynamic scenarios, where an adversary performs intelligent actions to evade the system. To evaluate the metrics I have applied 11 classifiers to different benchmark datasets and created an adversary that performs an evolutionary search process aiming to reduce the classification accuracy. The results show that the most robust models are related to K-Nearest Neighbours, Logistic regression, and neural networks, although none of the systems is robust enough when the target is to reach a single misclassification.",Yes,"논문 초록에서 다양한 머신러닝 모델에 대해 정량적 평가를 수행했다고 명시되어 있으며, 11개 분류기를 대상으로 성능 평가와 강건성 측정을 실시했다고 언급하고 있습니다. 이는 명확히 정량적 평가가 이루어졌음을 보여줍니다."
Towards Training Reproducible Deep Learning Models,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794033,"Reproducibility is an increasing concern in Artificial Intelligence (AI), particularly in the area of Deep Learning (DL). Being able to reproduce DL models is crucial for AI-based systems, as it is closely tied to various tasks like training, testing, debugging, and auditing. However, DL models are challenging to be reproduced due to issues like randomness in the software (e.g., DL algorithms) and non-determinism in the hardware (e.g., GPU). There are various practices to mitigate some of the aforementioned issues. However, many of them are either too intrusive or can only work for a specific usage context. In this paper, we propose a systematic approach to training reproducible DL models. Our approach includes three main parts: (1) a set of general criteria to thoroughly evaluate the reproducibility of DL models for two different domains, (2) a unified framework which leverages a record-and-replay technique to mitigate software-related randomness and a profile-and-patch technique to control hardware-related non-determinism, and (3) a reproducibility guideline which explains the rationales and the mitigation strategies on conducting a reproducible training process for DL models. Case study results show our approach can successfully reproduce six open source and one commercial DL models.",Yes,"논문 초록에서 재현성을 평가하기 위한 ""일련의 일반 기준""과 ""평가""라는 용어를 사용하여 정량적 평가를 실시하고 있음을 시사합니다. 또한, 사례 연구를 통해 제안된 방법의 성공 여부를 검증하는 과정이 포함되어 있어 정량적 평가가 수행되고 있음을 알 수 있습니다."
From Bricks to Bytes: The AI Transformation of Cybersecurity Firewalls,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10911850,"Due to the frequent occurrence of network threats, robust intrusion detection systems (IDS) are essential for safeguarding digital data. Traditional rule-based IDS often struggle to address emerging cyber threats, underscoring the necessity for adaptable solutions. This study presents a Next Generation Firewall (NGFW), a firewall variant that incorporates machine learning (ML) and deep learning (DL) to enhance IDS capabilities. By leveraging machine learning techniques such as Support Vector Machines (SVM), Random Forests, and Deep Neural Networks (DNN), along with deep learning models like Convolutional Neural Networks (CNN) and Recurrent Neural Networks (RNN), the NGFW greatly enhances its threat detection accuracy and effectiveness. We conduct a thorough review of current literature to evaluate the efficacy of ML and DL in IDS. Our methodology involves systematically collecting and preparing data, selecting relevant features, and assessing model performance through metrics like accuracy, precision, and recall. Results indicate that CNNs are particularly effective in identifying malicious activities while maintaining a low false-positive rate. Further real-world testing of the NGFW enhances the reliability of the classification report, which demonstrates impressive accuracy. Each class achieved precision, recall, and F1-scores exceeding 97%, resulting in an overall accuracy of 97.29%. This highlights the potential for further research into intelligent cyber defense solutions, showcasing how ML and DL can contribute to the development of more resilient and adaptive security systems.",Yes,"논문은 모델 성능 평가를 위해 정확도, 정밀도, 재현율 등 정량적 지표를 사용하여 평가를 실시하고 있습니다. 이러한 평가 지표를 통해 제안된 시스템의 성능을 수치로 측정하고 있기 때문에 정량적 평가를 수행한다고 볼 수 있습니다."
An Analysis on Deep Learning Approach Performance in Classifying Big Data Set,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8970980,"Big data sets are mainly derived from social media as well as stock market exchange. It is commonly described according to its main characteristics the 3Vs, which refers to Volume, Velocity and Variety. Big data sets often contributed to difficulties faced by the back end groups such as data analyst, system developer, programmer, and network analyst due to its complexity issue. To overcome this issue, many researchers and professionals have proposed and initiated various solutions, for instance; algorithm, software, hardware and framework related to big data. One beneficial and popularly known approach in dealing with big data is deep learning. It is an extension of neural network that is able to analyze huge data sets without assistance from any parameterization methods. To make use of this advantage, this paper aimed to evaluate the capability of deep learning in analyzing big data sets. Several data sets were selected and support vector machine (SVM) was chosen as a benchmark method for the experimental work. The results obtained revealed that deep learning has outperformed SVM in classifying big data set. As a conclusion, deep learning can be categorized as one of the best machine learning approaches to be used in decision analysis process. It can also be used as an alternative approach to other traditional approaches such as Naive Bayes or SVM which require more data processing phases.",Yes,"논문 초록에서 딥러닝의 성능을 평가하기 위해 여러 데이터 세트에 대해 실험을 수행하였으며, SVM과의 비교를 통해 딥러닝의 우수성을 정량적으로 검증하였음을 언급하고 있습니다. 이는 정량적 평가가 실시되었음을 보여줍니다."
Towards Measuring Happiness in Saudi Arabia based on Tweets: A research proposal,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8442024,"Social media platforms such as Twitter, Facebook and Blogs are growing enormously in terms of the number of users. Due to the rapid growth of the data produced from social media users, these platforms are becoming one of the most valuable data sources. Social media became outlets for people to express their thoughts, opinions, and emotions in a real-time manner. Therefore, Social media data have been utilized in literature for many sentiment analysis research. Although there have been many types of research on the sentimental analysis in English, the amount of Arabic-based sentiment analysis studies and tools are still limited. In this paper, we reviewed selected literature related to sentiment analysis in order to present a staged road map of Arabic tweets sentiment analysis in favor of measuring the happiness levels in Saudi Arabia cities. We reported the methodology to numerically represent the happiness of each city by determining the sentiment of 2000 geo-tagged tweets in Saudi Arabia using machine learning techniques. Expected results would not only rank the happiness levels for the cities in Saudi Arabia but certainly identify activities or circumstances that contribute to citizens' happiness. These expected results later can be used by institutions of related interest such as General Entertainment Authority to help planning new activities and attractions.",Yes,"논문 초록에서 감정 분석을 통해 도시별 행복도를 수치적으로 표현하는 방법을 제시하고 있으며, 2000개의 지리 태그된 트윗의 감성 분석을 위해 머신러닝 기법을 사용했다고 명시되어 있습니다. 이는 정량적 평가를 실시하고 있음을 보여줍니다."
Towards Intelligent Architecting of Aerospace System-of-Systems: Part II,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9172585,"System-of-Systems (SoS) are composed of large scale independent and complex heterogeneous systems which collaborate to create capabilities not achievable by a single system, for example air transportation system, satellite constellations, and space exploration architectures. To support architecting of aerospace SoS, in this work we present a methodology to accurately predict different aspects of performance for design/operation and SoS architecting, expanding previous work on intelligent architecting of aerospace SoS, by adding rigorous Uncertainty Quantification via Bayesian Neural Networks. A Bayesian Neural Network is a neural network with a-priori distribution on its weights. In addition to solving the overfit problem, which is common to traditional deep neural networks, Bayesian Neural Networks provide automated model pruning (or reduction of feature design space), that addresses a well-known dimensionality curse in the SoS domain. We enable SoS design/operation by using modeling and simulation, quantifying the uncertainty inherently present in SoS, and utilizing Artificial Intelligence and optimization techniques to design and operate the system so that its expected performance or behavior when the unexpected occurs (for example, a failure) still satisfies user requirements. Much of the research effort in the field of SoS has focused on the analysis of these complex entities, while there are still gaps in developing tools for automated synthesis and engineering of SoS that consider all the various aspects in this problem domain. In this expansion of the use of Artificial Intelligence towards automated design, these techniques are used not only to discover and employ features of interest in a complex design space, but also to assess how uncertainty can affect performance. This capability supports the automated design of robust architectures, that can effectively meet the user needs even in presence of uncertainty. The SoS design and evaluation methodology presented in this paper and demonstrated on a synthetic modular satellites problem starts from modeling and simulation, and design of experiments to explore the design space. The following step is deep learning, to develop a model which relates SoS architectural features with performance metrics. Uncertainty Quantification techniques are then applied to assess the performance metrics for different architectures. Once the most critical features that affect the SoS performance are identified, stochastic optimization of the SoS on a reduced design space can be performed to determine Pareto optimal features. The final step is determining if any additional design/operation measures need to be explored to further maximize the SoS performance.",Yes,"논문 초록에서 Bayesian Neural Networks와 Uncertainty Quantification 기법을 활용하여 성능 평가를 수행한다고 명확히 언급하고 있습니다. 또한, 성능 지표에 대한 불확실성 평가와 최적화 과정을 포함하여 정량적 평가가 이루어지고 있음을 알 수 있습니다."
Performance Analysis of Spiking Neural Network using Temporal Spike-based Backpropagation on Field Programmable Gate Array (FPGA) platform,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9864534,"This paper explores the object classification performance of spiking neural networks (SNNs) using the temporal spike-based backpropagation technique on the Field Programmable Gate Array (FPGA) platform. The FPGA board is specially designed to host the spiking neural networks for artificial intelligence tasks such as object classification, object detection, and segmentation. The publicly available classification datasets such as MNIST, CIFAR10 were employed to examine the performance of the SNNs on the FPGA platform. Similarly, the latest temporal spike-based backpropagation technique was chosen to investigate the neuromorphic ability of the low-cost FPGA board in processing SNNs for object classification tasks. The main purpose of this research proceeding is to facilitate the neuromorphic research community with the information regarding (i). the exploitation of the low-cost FPGA design for neuromorphic image processing and artificial intelligence (AI) tasks; (ii). cross-validating temporal spike-based backpropagation trained SNNs on FPGA alongside PC; (iii). assessing the performance stability and industrial choices of low-cost FPGAs for object classification tasks and related issues. The evaluation metrics such as classification accuracy, mean average precision, and processing time were utilized to assess the performance of the SNN model on FPGA alongside PC. This study will be used as an informative report for the researchers working towards perfecting the neuromorphic hardware for processing SNNs in imminent studies.",Yes,"논문 초록에서 분류 정확도, 평균 정밀도, 처리 시간과 같은 평가 지표를 사용하여 SNN의 성능을 정량적으로 평가했다고 명시되어 있습니다. 이러한 지표들은 명확한 수치적 평가를 수행하는 것을 의미합니다."
An Approach to Evaluating Subjective Answers using BERT model,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9865706,"The state of art model for language translation, conversion from hand written to digital text, transcription are succeeded in wide range of fields using Natural Language Processing, Artificial Intelligence and Machine Learning (AIML) applications. In present, evaluation of subjective answers are not exercised systematically and graded using computer system. In this work, a mathematical method is proposed for evaluating subjective answers using Bidirectional Encoder Representation Transformers for word embedding and convert the sentence into vector space using pooling method for representing similar sentences. The proposed method evaluates the subjective answers having semantic meaning of answers based on topic Engineering and Medical related questions and answers dataset. It achieves to understand the similarity of different answers which are same semantically. The BERT model is used with machine learning methods to transform the sentence into vector space. The vector space is used to calculate percentage of similarity. The similarity of the sentences with percentage is observed and evaluated.",Yes,"논문 초록에서 제안된 방법은 주관적 답변의 유사성을 평가하기 위해 벡터 공간 내에서 유사도를 계산하는 정량적 평가 방식을 사용하고 있음을 명확히 언급하고 있습니다. 따라서, 정량적 평가를 실시하고 있다고 판단됩니다."
Performance Evaluation of Machine Learning Algorithms for Prediction of Cardiac Failure,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10368606,"Over the past few years, the world is experiencing a drastic rise in deaths caused by Heart Failures, and it is a prevalent and perhaps dangerous medical condition, which has an impact on millions of people globally. The outcomes of patients can be greatly enhanced by early detection and accurate cardiac failure prediction which could reduce healthcare costs. In recent times, artificial intelligence and machine learning algorithms have emerged as powerful tools for predicting heart failure. This paper performs a comparative study and investigation of leading machine learning algorithms for heart failure prediction. This research study presents an explanation, implementation, and comparison on the basis of various evaluation parameters like accuracy, precision, recall, Fl score, etc. The study is performed for multiple regression, KNN, support vector machines, random forest, Naive Bayes, and decision tree models. This study also reviews the different types of factors effecting heart failure prediction, such as chest pain, cholesterol, exercise angina and more. Finally, this study evaluates how well various machine learning algorithms perform on tasks that predict cardiac failure and point up the difficulties and restrictions in this area. The findings of this study demonstrate that Naive Bayes method gives highest accuracy 85.87 % and it is a useful tool in medical practice and are capable of accurately predicting cardiac failure.",Yes,"논문 초록에서 여러 평가 지표(accuracy, precision, recall, F-score 등)를 사용하여 머신러닝 알고리즘의 성능을 정량적으로 평가했다고 명시되어 있습니다. 이는 정량적 평가를 실시하고 있음을 보여줍니다."
Identifying AI-Written Text in Academia: A Machine Learning-Based Framework,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10850944,"The rise of AI-generated text poses new challenges to academic integrity, requiring robust mechanisms to identify and differentiate human-written content from machine-generated material in scholarly publications. This paper presents a machine learning-based framework for detecting AI-written text in academia, combining multiple techniques including stylometry, semantic analysis, and citation pattern recognition. The framework utilizes supervised classification models trained on features such as lexical diversity, syntactic complexity, and redundancy patterns to distinguish AI-generated content from genuine research writing. Additionally, unsupervised anomaly detection techniques are employed to flag unusual stylistic deviations. The framework also integrates traditional plagiarism detection tools and enlists human expert review for validating suspicious sections. By addressing both technical and ethical considerations, this approach aims to preserve the authenticity of academic work while adapting to the evolving landscape of AI-driven content generation.",Yes,"논문 초록에서 정량적 평가를 위해 다양한 특징(예: 어휘 다양성, 구문 복잡성, 중복 패턴)을 활용한 분류 모델과 이상 탐지 기법을 사용한다고 명시되어 있습니다. 이러한 기술들은 모두 수치적 데이터를 기반으로 한 정량적 평가 방법임을 보여줍니다."
Smartwatch-based Eating Detection and Cutlery Classification using a Deep Residual Network with Squeeze-and-Excitation Module,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9851333,"Several machine learning and deep learning algorithms have been developed to tackle the human behavior detection issue, emphasizing everyday tasks. Nevertheless, an intriguing and challenging human activity recognition (HAR) subject involves more complicated human behaviors, including eating-related actions. This study provided a smartwatch-based eating identification system based on hand-movement data. In the framework, we introduced a deep residual network named the ResNet-SE model that enhanced detection capability by using the benefits of shortcut connections and squeeze-and-excitation units. In addition, the effectiveness of standard deep learning models (CNN and LSTM) is evaluated and compared to that of the proposed model. In addition, we investigate the use of wristwatch sensor data for categorizing six kinds of food cutlery. To validate the correctness of the model, the accuracy, F1-score, and confusion matrices of the HAR metrics are applied to the EatingDetectionIJS dataset for evaluating the proposed frame-work. Experimentation findings demonstrate that the ResNet-SE model surpasses existing deep residual models, achieving the greatest F1-score of 91.81% for eating identification and 91.43% for cutlery categorization.",Yes,"논문 초록에서 정확도, F1-score, 그리고 혼동 행렬과 같은 정량적 평가 지표를 사용하여 모델의 성능을 검증했다고 명시되어 있습니다. 이러한 지표들은 정량적 평가를 실시하고 있음을 보여줍니다."
Application of Computer Vision Based on Deep Learning in Automatic Recognition of Pathological Images,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10796071,"This paper explores the application potential of deep learning-based computer vision technology in automating pathological image recognition, addressing significant challenges in the field. Deep learning, a powerful machine learning method, extracts high-level abstractions from complex, high-dimensional image data through layers of nonlinear processing units. The study reviews fundamental principles of computer vision and deep learning, analyzing various deep learning models like CNN sand RNN s, and their adaptations for tasks including pathological image classification, target detection, cell segmentation, and tissue structure analysis. Emphasis is placed on an innovative architecture combining attention mechanisms and multi-scale feature fusion to enhance accuracy in detecting subtle pathological changes. Experiments conducted on a public dataset validate the method's efficacy in identifying different cancer types and distinguishing between benign and malignant lesions. Results demonstrate that deep learning models outperform traditional methods, improving diagnostic accuracy while reducing dependency on expert pathologists. Challenges such as high data annotation costs, model interpretability issues, and computational demands are discussed alongside proposed solutions and future research directions. In conclusion, this study underscores the pivotal role of deep learning-based computer vision in advancing automation and intelligence in pathology, offering new technical foundations for enhancing disease diagnosis efficiency and accuracy.",Yes,"논문 초록에서 딥러닝 기반의 컴퓨터 비전 기술을 활용하여 병리 이미지의 자동 인식을 수행하는 연구를 다루고 있음을 명확히 언급하고 있습니다. 또한, 다양한 딥러닝 모델을 적용한 실험과 검증 과정을 통해 정량적 평가가 이루어졌음을 시사하고 있습니다."
An AI-Powered Network Threat Detection System,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9775989,"The work develops a network threat detection system, AI@NTDS, that uses the behavioral features of attackers and intelligent techniques. The proposed AI@NTDS system combines data analysis, feature extraction, and feature evaluation to construct a detection model, which supports a more straightforward strategy by which the operating system or its operators can defend against network attacks. The Linux system interaction information of SSH (Secure Shell) and Telnet are obtained from the Cowrie Honeypot and labeled according to Enterprise Tactics of MITRE ATT&CK to ensure dataset credibility. The proposed AI@NTDS system has three levels, depending on the attacker’s attacks and the user’s risk of damage. Fifty-two features are used to detect the network threat level. The features contain message-based features for all kinds of Linux operating instructions, host-based features for all types of information in the network connection process, and geography-based features are related to the attacker’s location. AI-based algorithms LightGBM, Random Forest and the K-NN algorithm are used to verify the identification of the custom features. Finally, the detection model that is trained using the best combination of features is used to predict the test dataset. The accuracy of the proposed AI@NTDS system reaches 99%, 95.66%, and 94.08% with the LightGBM, Random Forest, and K-NN algorithms, respectively. The mutual dependencies of features and network threats are evaluated. Results of a performance analysis reveal that the proposed AI@NTDS system has an accuracy of 99.20% and an F1-score of 99.80%. It is superior to existing detection mechanisms, which it outperforms by 4% and 1% in accuracy and F1-score, respectively.",Yes,"논문은 52개의 특징을 사용하여 네트워크 위협 수준을 감지하는 모델을 개발하고, 여러 AI 알고리즘을 활용하여 성능을 평가하는 정량적 분석을 실시하고 있습니다. 또한, 정확도와 F1-score와 같은 성능 지표를 제시하여 정량적 평가를 수행했음을 명확히 보여줍니다."
Benchmarking of Machine Learning for Anomaly Based Intrusion Detection Systems in the CICIDS2017 Dataset,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9345704,"An intrusion detection system (IDS) is an important protection instrument for detecting complex network attacks. Various machine learning (ML) or deep learning (DL) algorithms have been proposed for implementing anomaly-based IDS (AIDS). Our review of the AIDS literature identifies some issues in related work, including the randomness of the selected algorithms, parameters, and testing criteria, the application of old datasets, or shallow analyses and validation of the results. This paper comprehensively reviews previous studies on AIDS by using a set of criteria with different datasets and types of attacks to set benchmarking outcomes that can reveal the suitable AIDS algorithms, parameters, and testing criteria. Specifically, this paper applies 10 popular supervised and unsupervised ML algorithms for identifying effective and efficient ML-AIDS of networks and computers. These supervised ML algorithms include the artificial neural network (ANN), decision tree (DT), k-nearest neighbor (k-NN), naive Bayes (NB), random forest (RF), support vector machine (SVM), and convolutional neural network (CNN) algorithms, whereas the unsupervised ML algorithms include the expectation-maximization (EM), k-means, and self-organizing maps (SOM) algorithms. Several models of these algorithms are introduced, and the turning and training parameters of each algorithm are examined to achieve an optimal classifier evaluation. Unlike previous studies, this study evaluates the performance of AIDS by measuring the true positive and negative rates, accuracy, precision, recall, and F-Score of 31 ML-AIDS models. The training and testing time for ML-AIDS models are also considered in measuring their performance efficiency given that time complexity is an important factor in AIDSs. The ML-AIDS models are tested by using a recent and highly unbalanced multiclass CICIDS2017 dataset that involves real-world network attacks. In general, the k-NN-AIDS, DT-AIDS, and NB-AIDS models obtain the best results and show a greater capability in detecting web attacks compared with other models that demonstrate irregular and inferior results.",Yes,"논문은 10가지 머신러닝 알고리즘의 성능을 평가하기 위해 정확도, 정밀도, 재현율, F-Score 등 다양한 정량적 지표를 사용하여 평가를 실시하고 있습니다. 또한, 모델의 훈련 시간과 테스트 시간도 측정하여 성능 효율성을 정량적으로 분석하고 있습니다."
A New Pedagogical Approach of An Experimental Study Aimed to Calculate the Leakage Reactance of a Synchronous Machine,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9590015,"The paper is proposing a learning strategy focused to convert a classical laboratory activity into an immersive learning experience which could be easily used even in a distance learning approach. The subject is debated in two steps: a pedagogical one and a technical one. The scope of technical approach is to propose to the students an experimental situation and use the results to calculate the leakage reactance of a synchronous machine. Regarding the pedagogical approach, after a short review of the literature, the flipped learning was proposed to be implemented as a pedagogical method to update the classical lab topics. In accordance with learning efficiency pyramid, the technical content of the basic lab was improved with videos, models and simulations and organized for an online learning as a tool of distance learning. All these new materials were made in an original manner and used in a learning scenario. The research is actual and have a positive impact in solving the problem of passing to a digital education.",No,"초록에서는 실험 결과를 이용하여 누설 리액턴스를 계산하는 기술적 접근이 언급되었지만, 정량적 평가를 구체적으로 수행했다는 내용은 명확하게 제시되지 않습니다. 따라서, 논문이 정량적 평가를 실시했다고 판단하기 어렵습니다."
Exploring the Impact of Synthetic Data on Human Gesture Recognition Tasks Using GANs,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10621531,"In the evolving domain of Human Activity Recognition (HAR) using Internet of Things (IoT) devices, there is an emerging interest in employing Deep Generative Models (DGMs) to address data scarcity, enhance data quality, and improve classification metrics scores. Among these types of models, Generative Adversarial Networks (GANs) have arisen as a powerful tool for generating synthetic data that mimic real-world scenarios with high fidelity. However, Human Gesture Recognition (HGR), a subset of HAR, particularly in healthcare applications, using time series data such as allergic gestures, remains highly unexplored.In this paper, we examine and evaluate the performance of two GANs in the generation of synthetic gesture motion data that compose a part of an open-source benchmark dataset. The data is related to the disease identification domain and healthcare, specifically to allergic rhinitis. We also focus on these AI models’ performance in terms of fidelity, diversity, and privacy. Furthermore, we examine the scenario if the synthetic data can substitute real data, in training scenarios and how well models trained on synthetic data can be generalized for the allergic rhinitis gestures. In our work, these gestures are related to 6-axes accelerometer and gyroscope data, serving as multi-variate time series instances, and retrieved from smart wearable devices. To the best of our knowledge, this study is the first to explore the feasibility of synthesizing motion gestures for allergic rhinitis from wearable IoT device data using Generative Adversarial Networks (GANs) and testing their impact on the generalization of gesture recognition systems. It is worth noting that, even if our method has been applied to a specific category of gestures, it is designed to be generalized and can be deployed also to other motion data in the HGR domain.",Yes,"논문 초록에서 GANs를 이용하여 합성 데이터의 품질, 다양성, 그리고 성능 평가를 수행했다고 명시되어 있습니다. 또한, 합성 데이터를 이용한 훈련과 일반화 성능을 평가하는 정량적 실험이 포함되어 있음을 보여줍니다."
Fake Review Detection using Neural Network,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10497283,"The rise of internet purchasing and the prevalence of e-commerce platforms have given rise to an unprecedented influx of online reviews. These reviews wield substantial influence over consumer decision-making, serving as a barometer for product and service quality. Yet, as the importance of internet reviews has soared, so too has the proliferation of deceptive and counterfeit reviews. These fake reviews, deliberately crafted to mislead potential customers and manipulate ratings, pose a profound challenge to the integrity of online commerce. Consequently, the imperative to establish a robust and dependable system for detecting false reviews cannot be overstated. In the pursuit of this critical objective, our research paper introduces a pioneering fake review detection system, distinguished by its ability to identify and mitigate various manifestations of deceptive reviews. These encompass short text attacks, overlapping text attacks, substantial duplicate review campaigns, and reviews that are incongruent with the product or service they purport to evaluate. Notably, our system achieves an impressive average accuracy of 95%, a milestone realized through the development of a neural network crafted from the ground up. The efficacy of our neural network underscores the potential of cutting-edge machine learning technology in combating the proliferation of fake reviews. Beyond its academic significance, our research holds profound practical implications. By fostering trust in online reviews, this system bolsters consumer confidence, supports businesses in maintaining their reputations, and contributes to the integrity of the e-commerce ecosystem. As online commerce continues its inexorable ascent, our research illuminates a path forward in the perpetual battle against deceptive reviews. Future research endeavors may explore opportunities for further refinement and enhancement of our neural network-based detection system, as well as the continued evolution of strategies for countering emerging threats in the ever-evolving landscape of fake review generation and manipulation.",Yes,"논문 초록에서 ""impressive average accuracy of 95%""와 같은 정량적 평가 결과를 제시하고 있으며, 이를 통해 정량적 평가를 실시하고 있음을 알 수 있습니다. 또한, 제안된 시스템의 성능을 수치로 측정하고 평가하는 내용이 포함되어 있습니다."
A Strategy for AI-Supplemented Teaching and Learning,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10578748,"This paper presents a strategy designed to evaluate AI-supplemented teaching and learning in a course belonging to a master program in Computer Science at the University of South-Eastern Norway. The strategy was closely related to the delivery format adopted in this program, where students take only one course at a time. Each course lasts for 6 weeks, comprising an initial “reading week”, an “intensive lectures” week, a 3-week “project assignment”, and one “assessment week”. The university supported the cost of OpenAI Plus account subscriptions offered to each student while the course was running, and specific activities were proposed to the class exploring the different ways in which AI tutoring could be used during each one of the 4 phases included in the course work plan. The strategy can be adapted to other program delivery formats by redistributing the proposed activities in accordance with the planned sequence of learning activities. It is also independent of which generative AI tool is selected, although OpenAI Plus accounts allow access to specific features that offer relevant pedagogical benefits, e.g., a simple process to create private language models that are easily customizable to each course subject.",No,"논문 초록에서는 AI-supplemented teaching and learning을 평가하는 전략이 제시되었음을 언급하지만, 구체적인 정량적 평가 방법이나 지표를 사용한 평가가 실시되었다는 내용은 포함되어 있지 않습니다. 따라서 정량적 평가를 실시했다고 보기 어렵습니다."
The Analysis of Communication Strategy of Disabled Sports Information Based on Deep Learning and the Internet of Things,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10479469,"The ever-growing landscape of Internet of Things (IoT) technology and the evolution of deep learning algorithms have ushered in transformative changes in the communication strategy for disseminating information on disabled sports. This specialized information resource aims to provide relevant support and services related to sports activities for disabled individuals. This study investigates the communication strategy of disabled sports information driven by deep learning within the framework of the IoT and assesses the practical application performance of the proposed model. To achieve this objective, an appropriate deep learning model for the dissemination of sports information for the disabled is selected through a thorough literature review. Subsequently, an experimental framework is proposed for comprehensive performance verification, evaluating the model’s performance in reasoning time and user satisfaction through comparative experiments. By constructing deep learning models, extensive data on disabled sports activities are analyzed, enabling the identification and prediction of key factors in information dissemination. The results indicate that the proposed sports information dissemination model outperforms similar models across various performance metrics, particularly in real-time performance and user experience. Comparative analysis with attention-based deep neural networks and traditional machine learning algorithms reveals that the proposed model achieves an accuracy rate as high as 0.85, significantly surpassing the 0.78 and 0.82 accuracies of these models, respectively. Moreover, the proposed model demonstrates the shortest inference time (15ms), surpassing both aforementioned models. This study validates the relative advantages of the proposed model through comparison with similar studies, offering a novel solution for the dissemination of sports information for the disabled.",Yes,"논문은 모델의 성능 평가를 위해 정확도, 추론 시간 등 다양한 성능 지표를 정량적으로 측정하고 비교하는 실험을 수행하고 있습니다. 이러한 정량적 평가를 통해 제안된 모델의 우수성을 검증하고 있으므로, 정량적 평가를 실시하고 있다고 판단됩니다."
A Data-Driven Framework for Identifying Misuse of Multidrug-Resistant Organisms,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10490968,"Multidrug-resistant organisms (MDROs) pose a significant threat to public health due to their ability to cause various diseases. The emergence and evolution of superbugs have been accelerated by existing drug conservation policies, hindering the development of novel antibiotics. As a result, researchers are focusing on understanding disease causation pathways and developing advanced classes of antibiotics. Despite challenges related to transparency, regulations, ethics, and technical limitations, technology such as MDRO Dual Use Quickscan shows promise in combating MDRO-based threats. This work presents a web-based tools design that incorporates a data-driven framework and utilizes artificial intelligence (AI) to detect potential cases of dual-use research involving MDROs. A comprehensive literature review identified 15 questions relevant for evaluating MDRO dual-use research using the Quickscan tool. The Quickscan can be developed as a valuable tool for assessing the potential dual-use characteristics of MDRO research. It is recommended that expert opinions guide risk management in biologics and address potential perilous scenarios arising from dual-use activities. Artificial intelligence models, natural language processing techniques, and binary classification algorithms are suggested as viable options for detecting and assessing dual-use traits associated with MDROs. However, human supervision and assessment remain critical for interpreting outcomes and making informed decisions.",Yes,"논문 초록에서 데이터 기반 프레임워크와 인공지능, 자연어 처리, 이진 분류 알고리즘 등을 활용하여 정량적 평가를 수행하는 방법을 제시하고 있음을 명확히 언급하고 있습니다. 이러한 기술적 접근은 정량적 평가의 실시를 의미합니다."
A Survey on Prediction of Suicidal Ideation Using Machine and Ensemble Learning,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9684830,"Suicide is a major health issue nowadays and has become one of the highest reason for deaths. There are many negative emotions like anxiety, depression, stress that can lead to suicide. By identifying the individuals having suicidal ideation beforehand, the risk of them completing suicide can be reduced. Social media is increasingly becoming a powerful platform where people around the world are sharing emotions and thoughts. Moreover, this platform in some way is working as a catalyst for invoking and inciting the suicidal ideation. The objective of this proposal is to use social media as a tool that can aid in preventing the same. Data is collected from Twitter, a social networking site using some features that are related to suicidal ideation. The tweets are preprocessed as per the semantics of the identified features and then it is converted into probabilistic values so that it will be suitably used by machine learning and ensemble learning algorithms. Different machine learning algorithms like Bernoulli Naïve Bayes, Multinomial Naïve Bayes, Decision Tree, Logistic Regression, Support Vector Machine were applied on the data to predict and identify trends of suicidal ideation. Further the proposed work is evaluated with some ensemble approaches like Random Forest, AdaBoost, Voting Ensemble to see the improvement.",Yes,"논문 초록에서 다양한 머신러닝 및 앙상블 학습 알고리즘을 적용하여 데이터를 평가하고 있으며, 이를 통해 예측 성능을 정량적으로 평가하는 것으로 보입니다. 또한, 여러 알고리즘의 성능 비교를 통해 평가 지표를 활용했을 가능성이 높습니다."
Beyond fear go viral: A machine learning study on infodemic detection during covid-19 pandemic,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9729077,"With the restrictions in our daily life activities under the current situation of the covid-19 pandemic worldwide, billions of people rely on social media platforms to share and obtaining covid-19 related news information. This made social media platforms easily be used as a source of myths and disinformation, which can cause severe public risks. It is thus of vital importance to constraint the spread of misinformation to the public. Although many works have shown promising results on the misinformation detection problem, only a few studies focus on the infodemic detection during the covid-19 pandemic, especially in the low resource language like Thai. Therefore, in this paper, we conduct extensive experiments on the real-world social network datasets to detect misinformation about covid-19 targeting both English and Thai languages. In particular, we perform an exploratory data analysis to get the statistic and characteristics of real and fake content. Also, we evaluate a series of three feature extraction, seven traditional machine learning, and eleven deep learning methods in detecting the fabricated content on social media platforms. The experimental results demonstrate that the transformer-based model significantly outperforms other deep learning and traditional machine learning methods in all metrics, including accuracy and F-measure.",Yes,"논문 초록에서 여러 기계 학습 방법을 평가하고, 실험 결과를 통해 정확도와 F-측정값 등 다양한 지표를 사용하여 성능을 정량적으로 평가했다고 명시되어 있습니다. 이는 정량적 평가를 실시하고 있음을 보여줍니다."
Assessment and Optimization of 1D CNN Model for Human Activity Recognition,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9964520,"Artificial Intelligence (AI) solves complex tasks like human activity and speech recognition. Accuracy-driven AI models introduced new challenges related to their applicability in resource-scarce systems. In Human Activity Recognition (HAR), state-of-the-art presents proposals using complex multi-layer LSTM networks. The literature states that LSTM networks are suitable for treating temporal-series data, a key feature for HAR. Most works in the literature seek the best possible accuracy, with few evaluating the overall computational cost to run the inference phase. In HAR, low-power IoT devices such as wearable sensors are widely used as data-gathering devices, but little effort is made to deploy AI technology in these devices. Most studies suggest an approach using edge devices or cloud computing architectures, where the end-device task is to gather and send data to the edge/cloud device. Most voice assistants, such as Amazon's Alexa and Google, use this architecture. In real-life applications, mainly in the healthcare industry, relying only on edge/cloud devices is not acceptable since these devices are not always available or reachable. The objective of this work is to evaluate the accuracy of convolutional networks with a simpler architecture, using 1D convolution, for HAR. The motivation for using networks with simpler network architectures is the possibility of embedding them in power- and memory-constrained devices.",Yes,"논문 초록에서 1D CNN 모델의 성능 평가와 최적화를 목표로 하고 있으며, 특히 정확도와 계산 비용을 평가하는 내용이 언급되어 있습니다. 이는 정량적 평가를 실시하고 있음을 시사합니다."
Applying Recurrent Neural Networks to Time-Series Analysis in Big Data for Decision Support,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10859601,"The burgeoning field of big data has necessitated advanced analytical techniques capable of extracting valuable insights from complex time-series datasets. This research explores the application of Recurrent Neural Networks (RNN s), specifically Long Short-Term Memory (LSTM) models, in the context of time-series analysis for enhancing decision support systems. The study begins with a comprehensive literature review, examining the evolution of time-series analysis and the integration of deep learning methodologies. A theoretical framework is established, detailing the mathematical principles of time-series and the architecture of LSTM networks, followed by a methodological approach to model training and validation. Preliminary results are presented through insightful visualizations, showcasing the predictive capabilities of the RNN models against traditional forecasting methods. The paper delves into an advanced data analysis phase, assessing model performance across various metrics and datasets. The discussion section synthesizes the findings, evaluating the effectiveness of RNN s in decision support and contemplating future research avenues. The paper concludes by highlighting the transformative potential of deep learning in business analytics and strategic decision-making.",Yes,"논문 초록에서 ""모델 성능 평가""를 위해 다양한 지표와 데이터셋을 사용하여 정량적 평가를 실시했다고 명시되어 있습니다. 또한, ""모델 성능 평가""와 ""전통적 예측 방법과의 비교""를 통해 수치적 성과를 분석하는 내용이 포함되어 있어 정량적 평가가 수행되고 있음을 알 수 있습니다."
A Novel Approach to Detect Face Fraud Detection Using Artificial Intelligence,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10493594,"The main aim of this research is to identify and prevent fraudulent activities which can be achieved through AI related to facial recognition systems. Nowadays the usage of facial recognition systems is very high, and in the same way the scams by fraudsters are also increased in this research by using AI bots instead of humans. The main motive of this research is to identify the misuse of facial recognition technology. The proposed method using CNN (Convolutional Neural Network) protects the individual privacy of people and their data. It detects whether the character in the image is an AI made or real human. This helps to ensure that only authorized people can use their information. Some of the sectors which use facial recognition systems are security, law enforcement, financial services, education, government services, retail. if unauthorized people access the above-mentioned sectors, the result will be imperiling. This method takes an image as an input and then python is used to process the image, importing a CV library to do this job. Next, we use deep learning models in python to identify whether the character in the image is AI generated or real human. The Computational Intelligence and Photography Lab at Yonsei University assembled a publicly available dataset for this work. Images of both real and fake human faces can be found in the Yonsei University Computational Intelligence and Photography Lab's database. The performance of the proposed system is measured using accuracy, precision and sensitivity. Experimental results shows that CNN based face recognition system outperforms.",Yes,"논문 초록에서 정확도, 정밀도, 민감도와 같은 정량적 평가 지표를 사용하여 제안된 시스템의 성능을 측정했다고 명시되어 있습니다. 이는 정량적 평가를 실시하고 있음을 보여줍니다."
A Study of Cantonese Covid-19 Fake News Detection on Social Media,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9671722,"With the prevalence of social media, fake news has become one of the greatest challenges in journalism, which has weakened public trust in news outlets and authorities. During the COVID-19 epidemic, the widely circulated pandemic-related fake news on social media misleads or threatens the public. Recent works have investigated fake news detection on social platforms in English and Mandarin, though Cantonese fake news has been understudied. To pave the way for Cantonese COVID-19 fake news detection, we first presented an annotated COVID-19 related Cantonese fake news dataset collected from a popular local discussion forum in Hong Kong. Then, we explored the dataset by applying topic modeling to identify the topics that contain the most significant amount of fake news. Moreover, we evaluated both traditional machine learning algorithms and deep learning algorithms for Cantonese fake news detection. Our empirical results show that deep learning based methods perform slightly better than traditional machine learning methods on TF-IDF features.",Yes,논문 초록에서 다양한 평가 방법을 사용하여 딥러닝과 전통적인 머신러닝 알고리즘의 성능을 비교하는 실험을 수행했다고 명시되어 있습니다. 이는 정량적 평가가 이루어지고 있음을 보여줍니다.
Automating the Evaluation of Education Apps With App Store Data,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9340366,"With the vast number of apps and the complexity of their features, it is becoming challenging for teachers to select a suitable learning app for their courses. Several evaluation frameworks have been proposed in the literature to assist teachers with this selection. The iPAC framework is a well-established mobile learning framework highlighting the learners' experience of personalization, authenticity, and collaboration (iPAC). In this article, we introduce an approach to automate the identification and comparison of iPAC relevant apps. We experiment with natural language processing and machine learning techniques, using data from the app description and app reviews publicly available in app stores. We further empirically validate the keyword base of the iPAC framework based on the app users' language in app reviews. Our approach automatically identifies iPAC relevant apps with promising results (F1 score ~ 72%) and evaluates them similarly as domain experts (Spearman's rank correlation 0.54). We discuss how our findings can be useful for teachers, students, and app vendors.",Yes,"논문은 자연어 처리와 머신러닝 기법을 활용하여 앱의 평가를 자동화하는 방법을 제시하고 있으며, 이를 통해 앱의 관련성 평가와 비교를 수행하고 있습니다. 따라서 정량적 평가를 실시하고 있다고 볼 수 있습니다."
Trustworthiness Assurance Assessment for High-Risk AI-Based Systems,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10430152,"This work proposes methodologies for ensuring the trustworthiness of high-risk artificial intelligence (AI) systems (AIS) to achieve compliance with the European Union’s (EU) AI Act. High-risk classified AIS must fulfill seven requirements to be considered trustworthy and human-centric, and subsequently be considered for deployment. These requirements are equally important, mutually supportive, and should be implemented and evaluated throughout the AI lifecycle. The assurance of trustworthiness is influenced by ethical considerations, amongst others. Hence, the operational design domain (ODD) and behavior competency (BC) concepts from the automated driving domain are utilized in risk assessment strategies to quantify different types of residual risks. The methodology presented is guided by the consistent application of the ODD and its related BC concept throughout the entire AI lifecycle, focusing on the trustworthiness assurance framework and its associated process as the main pillars for AIS certification. The achievement of the overall objective of trustworthy and human-centric AIS is divided into seven interconnected sub-goals: the formulation of use restrictions, the trustworthiness assurance/argument itself, the identification of dysfunctional cases, the utilization of scenario databases and datasets, the application of metrics for evaluation, the implementation of the proposed concept across the AI lifecycle, and sufficient consideration of human factors. The role of standards in the assurance process is discussed, considering any existing gaps and areas for improvement. The work concludes with a summary of the developed approach, highlighting key takeaways and action points. Finally, a roadmap to ensure trustworthy and human-centric behavior of future AIS is outlined.",Yes,"논문 초록에서는 다양한 평가 지표와 방법론을 활용하여 AI 시스템의 신뢰성 확보를 위한 평가 과정을 언급하고 있습니다. 특히, 성능 평가를 위한 지표 적용과 평가 과정이 포함되어 있어 정량적 평가를 실시하는 것으로 보입니다."
Automating Code Generation for MDE using Machine Learning,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172526,"The overall aim of our research is to improve the techniques for synthesizing code generators in the Model-Driven Engineering (MDE) context. Code generation is one of the main elements of Model-Driven Engineering, involving transformation from specification models to produce executable code. A code generator is designed to reduce the manual program construction work used to implement a software system, but building a code generator itself still currently needs much manual effort. Meanwhile, existing code generators are typically not flexible to adjust for changing development requirements and are hard to reuse for different target languages. Therefore, we aim to provide techniques to improve the process of building code generators, and let them be more reusable. Currently, we researched the related new and traditional approaches for generating code and projects using AI for program translation, code completion or program generation. Based on this research we decided to focus on a symbolic machine learning method related to the programming-by-example concept to build code generators. We use this “Code Generation By Example” (CGBE) concept with tree-to-tree structure mappings as the information format. CGBE has good performance in terms of training dataset size and time when applied to learning a UML-to-Java code generator, but further work is needed to extend it to generate different programming languages and to evaluate these cases, and to handle the optimisation of generated code.",Yes,"논문 초록에서 ""symbolic machine learning method""과 ""training dataset size""라는 표현이 등장하며, 이를 통해 정량적 평가 또는 실험을 통해 성능을 평가하는 연구임을 알 수 있습니다. 또한, ""good performance""라는 언급도 평가 결과를 수치로 나타내었음을 시사합니다."
Techvar: Classification of Similarity in Software Detection Model using Deep Learning,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9761003,"In Industry 4.0, Deep Learning techniques have become an important research tool in many area namely healthcare, automobiles, video analysis, audio analytics, software systems etc. In recent years, many research are performed in software analysis using modern technologies. CrosLSim, SimMax, and atrpos models are used to review the software similarity detection techniques for different software systems. The existing models for similarity detection are not efficient to be used in major software projects. In this paper, the Techvar-DNN system which performs enhanced Probability, maintainability, testability, and reusability has been proposed. When compared with other methods namely Random Forest and Support vector machines, the proposed system provides increased recall, a smaller function size, and more efficient computing. Moreover, the proposed model results show better F-measure, precision and recall to improve the software similarity detection in a more efficient manner.",Yes,"논문 초록에서 제안된 Techvar-DNN 시스템의 성능 평가를 위해 F-measure, precision, recall 등 정량적 지표를 사용하여 비교 분석을 수행했다고 명시되어 있습니다. 이는 정량적 평가가 실시되고 있음을 보여줍니다."
An Evaluation Framework for Machine Learning and Data Science-Based Financial Strategies: A Case Study-Driven Decision Model,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10815600,"Big data and computational technologies are increasingly important worldwide in asset and investment management. Many investment management firms are adopting these data science (DS) methods and technologies to improve performance across all investment processes. A good question is whether we can make better decisions in developing quantitative strategies. Therefore, the main objective of this research was to develop a multicriteria assessment framework and scoring decision support system to evaluate quantitative investment strategies that apply machine learning (ML) and DS techniques in their research and development. Subject matter experts will assess all framework perspectives from a systematic literature review to approve their reliability. The perspectives consist of economic and financial foundations, data perspective, features perspective, modeling perspective, and performance perspective. The research methodology applied was the hierarchical decision model (HDM) to provide a 360° view of the quantitative investment strategy and improve and generalize the concept to other asset classes and regions. This study accomplished a rigorous integration of an extensive literature review connecting DS, ML, and investment decision-making in developing quantitative investment strategies. As a result, the major contribution of this study is the comprehensive examination, which included identifying and quantifying perspectives and criteria. The results, while limited indicated significant gaps in strategies examined and therefore generated critical knowledge to improve ML/DS-driven investment strategies, which are valuable for financial companies and policymakers.",Yes,"논문 초록에서 ""scoring decision support system""과 ""quantitative investment strategies""의 평가를 위해 다중 기준 평가 프레임워크를 개발했다고 명시되어 있으며, 정량적 평가를 실시하는 구체적인 방법론이 언급되고 있습니다. 따라서, 이 연구는 정량적 평가를 수행하고 있다고 판단됩니다."
Comparison of Naive Bayes and SVM Algorithm based on Sentiment Analysis Using Review Dataset,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9117512,"Now a day's sentiment analysis is the most used research topic. The sentiment analysis result is based on different investigation for example politics, terrorism, economy, international affairs, movies, fashion, justice, humanity. Social media are the main resource for collecting people's opinion and their sentiment about a different trending topic. People use many abusing words in social media to express their emotion. Using sentiment analysis, we will build a platform where one can easily identify the opinions are either positive or negative or neutral. This research paper will contain supervised learning which is under the machine learning approach. We run an experiment on different queries from humanity to terrorism and find out an interesting result. First of all, we have preprocessed the dataset to convert unstructured airline review into structured review form. After that, we convert structured review into a numerical value. We have to preprocess the data before using it. Stop word removal, @ removal, Hashtag removal, POS tagging, calculating sentiment score have done in preprocessing part. Then an algorithm has been applied to classify the opinion as either it is positive or negative. In this research paper, we will briefly discuss supervised machine learning. Support vector machine as well as Naïve Bayes algorithm and compares their overall accuracy, precession, recall value. The result shows that in the case of airline reviews Support vector machine gave way better result than Naïve Bayes algorithm.",Yes,"논문 초록에서 Naïve Bayes와 SVM 알고리즘의 성능을 비교하는 실험을 수행했다고 명확히 언급되어 있으며, 이 과정에서 정확도, 정밀도, 재현율 등의 정량적 평가 지표를 사용했다고 보여집니다. 따라서 정량적 평가를 실시하고 있다고 판단됩니다."
Attention-Based Gated Recurrent Unit for Gesture Recognition,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9240992,"Gesture recognition becomes a thriving research area in modern human motion recognition systems. The intensification of demands on efficient interactive human-machine-interface systems, commercial objectives, and many other factors contributes to fuel this revival dynamics. Understanding human gestures becomes essential for prevention and health monitoring applications. In particular, analyzing hand gestures is of paramount importance in personalized healthcare-related applications to help practitioners providing more qualitative assessments of subject's pathologies, such as Parkinson's diseases. This work proposes a novel deep neural network approach to forecast future gestures from a given sequence of hand motion using a wearable capacitance sensor of an innovative gesture recognition hardware system. To do this, we use an attention-based recurrent neural network to capture the temporal features of hand motion to unveil the underlying pattern between the gesture and these sequences. While the attention layers capture patterns from the weights of the short term, the gated recurrent unit (GRU) neural network layer learns the inherent interdependency of long-term hand gesture temporal sequences. The efficiency of the proposed model is evaluated with respect to cutting-edge work in the field using several metrics. Note to Practitioners-In this article, the problem of human hand gesture recognition is analyzed using deep learning techniques. The proposed model uses input historical motion sequences collected from a wearable capacitance sensor to predict hand gestures. The model leverages the intrinsic correlation of motion sequences and extracts the salient part of the sequences by taking into consideration their temporal, complex, and nonlinear features. The approach studies the effect of different lengths of historical motion sequences in prediction outcomes. This allows for avoiding using cumbersome data collection, heavy data treatment, and high computational cost. The model performance is trained and assessed on real-world data by performing comparisons with alternative approaches, including well-known classifiers. The model yields very encouraging results and demonstrates that the proposed approach is quite competitive as it can reproduce typical activity trends for important channels. The present findings could help in the development of intelligent wearable devices for predicting hand gestures using a limited number of channels. This work could also help practitioners to provide a more qualitative appraisal of patients suffering from different pathologies such as Parkinson's diseases to personalized healthcare-related applications and to develop wearable gesture recognition devices on a large scale.",Yes,논문 초록에서 여러 평가 지표를 사용하여 제안된 모델의 성능을 평가했다고 명시되어 있습니다. 이는 정량적 평가가 실시되고 있음을 의미합니다.
Explainable Text Classification for Legal Document Review in Construction Delay Disputes,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10386240,"The costs involved in manually reviewing documents in legal civil litigations have grown dramatically as more and more information is stored electronically. As a result, the document review process can require an extraordinary dedication of resources. In construction litigations, quickly finding supporting documentation in a delay dispute is critical to the success of a matter. Identifying relevant delay-related communications and supporting documentation has historically been expensive and time consuming. Using machine learning technologies, respondents can be more comprehensive in their assessment of the data requiring review to respond to the claim in time. Explainable machine learning is an active machine learning research area, and in an explainable machine learning system, predictions generated from a machine learning model are explainable and human understandable. In delay dispute ‘document review’ scenarios, a document can be identified as delay-related, as long as one or more of the text snippets in a document are deemed delay-related. In these scenarios, if these delay-related snippets can be located, then attorneys could easily evaluate the model’s decision. The authors of this paper propose an approach for accurately identifying rationales and an approach for boosting document classification accuracy using delay-related snippets and their applications in construction delay disputes. The authors conducted experiments using data from a few real world delay dispute matters and the results from these experiments show that the proposed approaches have the potential to significantly advance the application of text classification in document review in construction delay dispute matters.",Yes,"논문 초록에서 제안된 방법들이 정량적 평가를 통해 문서 분류 정확도를 향상시키는 실험을 수행했다고 명시되어 있습니다. 또한, 실험 결과를 통해 제안된 접근법의 효과를 검증하는 과정이 포함되어 있어 정량적 평가가 실시되고 있음을 알 수 있습니다."
Few-shot Time-Series Forecasting with Application for Vehicular Traffic Flow,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9874010,"Few-shot machine learning attempts to predict outputs given only a very small number of training examples. The key idea behind most few-shot learning approaches is to pre-train the model with a large number of instances from a different but related class of data, classes for which a large number of instances are available for training. Few-shot learning has been most successfully demonstrated for classification problems using Siamese deep learning neural networks. Few-shot learning is less extensively applied to time-series forecasting. Few-shot forecasting is the task of predicting future values of a time-series even when only a small set of historic time-series is available. Few-shot forecasting has applications in domains where a long history of data is not available. This work describes deep neural network architectures for few-shot forecasting. All the architectures use a Siamese twin network approach to learn a difference function between pairs of time-series, rather than directly forecasting based on historical data as seen in traditional forecasting models. The networks are built using Long short-term memory units (LSTM). During forecasting, a model is able to forecast time-series types that were never seen in the training data by using the few available instances of the new time-series type as reference inputs. The proposed architectures are evaluated on Vehicular traffic data collected in California from the Caltrans Performance Measurement System (PeMS). The models were trained with traffic flow data collected at specific locations and then are evaluated by predicting traffic at different locations at different time horizons (0 to 12 hours). The Mean Absolute Error (MAE) was used as the evaluation metric and also as the loss function for training. The proposed architectures show lower prediction error than a baseline nearest neighbor forecast model. The prediction error increases at longer time horizons.",Yes,"논문 초록에서 평균 절대 오차(MAE)를 평가 지표로 사용하고 있으며, 이를 손실 함수로 활용하여 모델을 학습했다고 명시되어 있습니다. 이는 정량적 평가가 수행되고 있음을 보여줍니다."
Review and Conceptual Design of FPGA-based Application for Data-Driven Power Electronic Systems,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9503033,"AI-based data-driven methods are an emerging research direction in the field of power electronics. However, because of the absence of large datasets, the development of these solutions have some barriers to overcome. To properly train machine learning algorithms and neural networks a large amount of training data is necessary. This dataset can be a union of simulation and measured data. Generating simulation data with computer simulations can be slow process and gathering real data is not cost-effective. Real-Time simulators based on FPGAs can be powerful tools to accelerate simulation, and create datasets for AI applications in a cost-effective and accurate way. In this paper the possible FPGA-based solutions, which can be applicable for the problems, have been reviewed. Their applicability have been discussed, moreover a simplified FPGA-based concept have been designed and embedded into two possible AI-based application area.",No,"논문 초록에서는 정량적 평가에 대한 언급이 없으며, 주로 FPGA 기반 솔루션의 검토와 개념 설계에 초점을 맞추고 있기 때문에 정량적 평가를 실시하고 있다고 보기 어렵습니다."
A Smart System for Selection of Optimal Product Images in E-Commerce,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8622259,"In e-commerce, content quality of the product catalog plays a key role in delivering a satisfactory experience to the customers. In particular, visual content such as product images influences customers' engagement and purchase decisions. With the rapid growth of e-commerce and the advent of artificial intelligence, traditional content management systems are giving way to automated scalable systems. In this paper, we present a machine learning driven visual content management system for extremely large e-commerce catalogs. For a given product, the system aggregates images from various suppliers, understands and analyzes them to produce a superior image set with optimal image count and quality, and arranges them in an order tailored to the demands of the customers. The system makes use of an array of technologies, ranging from deep learning to traditional computer vision, at different stages of analysis. In this paper, we outline how the system works and discuss the unique challenges related to applying machine learning techniques to real-world data from e-commerce domain. We emphasize how we tune state-of-the-art image classification techniques to develop solutions custom made for a massive, diverse, and constantly evolving product catalog. We also provide the details of how we measure the system's impact on various customer engagement metrics.",Yes,"논문 초록에서 시스템의 성능과 영향을 평가하기 위해 고객 참여 지표와 같은 다양한 평가 지표를 측정한다고 언급하고 있습니다. 또한, 시스템의 효과를 정량적으로 분석하는 방법에 대해 논의하고 있어 정량적 평가를 실시하고 있음을 알 수 있습니다."
Intelligent Security Monitoring: Machine Learning-based Intrusion Detection,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10894147,"The rapid growth in the field of Information Technology has definitely caused a steep rise in the rate and sophistication of cyber-attacks; therefore, cybersecurity is an issue of major concern. Recently, Machine Learning and Deep Learning methodologies have turned out to be really potent tools for network intrusion detection. This paper presents a detailed review of various ML and DL models used in Intrusion Detection Systems (IDS). The models like Naïve Bayes, Artificial Neural Networks, Support Vector Machines, Decision Tree, K-Nearest Neighbors, and methods based on Reinforcement Learning are covered. In this paper, the MRF model and examine the model with other ML and DL models are focused. In this analysis, the authors use the KDD dataset, a very popular standard in intrusion detection research. This dataset has different attributes divided into four main classes. Such as Content, Host, Basic, and Traffic. All these are vital classes in deciding the false alarm rate and detection rate of IDS. The empirical evidence that the MRF model outperforms traditional models in both measures of accuracy and reliability are provided. How contribution analysis for each class of attributes towards DR and FAR can be utilized in optimizing the MRF model for better performance of intrusion detection systems are shown. The results obtained in this research work have been pointing toward the importance of choosing suitable data attributes and models so that maximum DR can be achieved with a minimum FAR, which would increase the effectiveness of IDS. The proposed Modified Random Forest-based Intrusion Detection System uses advanced feature selection and preprocessing to improve detection accuracy and reduce false alarms. The real-time adaptability is done by dynamic selection of parameters in order to prevent evolving cyber threats.",Yes,"논문 초록에서 다양한 머신러닝 및 딥러닝 모델을 사용하여 침입 탐지 성능을 정량적으로 평가한 내용을 언급하고 있습니다. 특히, 정확도와 신뢰성 측정, DR(Detection Rate)과 FAR( False Alarm Rate) 등의 지표를 통해 모델의 성능을 비교 분석하는 정량적 평가가 수행되고 있음을 알 수 있습니다."
AI Blockchain Platform for Trusting News,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8884985,"An interdisciplinary effort is needed for solving the fake news crisis, because the solutions depend not only on AI, but also on social mechanisms. In this paper, we propose an AI blockchain platform to build a strong collaboration among AI blockchain researchers and news media to advance the research fighting against fake news. This platform will provide journalists with blockchain crowd-sourced and AI validated factual data on emerging news. This platform will gather blockchain traced data and AI tools that can provide pointers to the original data sources, news propagation path, AI analyzed experts to consult on a given topic. This will provide journalists with cheaper and reliable sources of information in the Internet social media age. So that factual-sourced reporting can outpace the spread of fake news on social media which will encourage factual news sources as a way to value and promote truth for society. The technical contributions of this paper are (1) mechanism building the factual news database, (2) mechanism generating the news blockchain supply chain graph, and (3) AI blockchain based crowd sourcing fake news ranking mechanisms (4) AI blockchain platform for trusting news ecosystem. (5) reviewing the state of fake news research from the technology and social aspects, and providing list of key research issues and technical challenges.",Yes,"논문은 AI와 블록체인 기술을 활용한 플랫폼을 제안하며, 이를 통해 가짜 뉴스 판별과 신뢰성 평가를 위한 정량적 평가 메커니즘을 포함하고 있다고 명시되어 있습니다. 특히, AI 블록체인 기반의 크라우드소싱 가짜 뉴스 순위 매기기와 뉴스 공급망 그래프 생성 등 구체적인 기술적 기여가 정량적 평가를 수행하는 방식을 내포하고 있습니다."
Ship Trajectory Prediction Model for Space-Based Maritime Surveillance,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10642713,"This research proposes an anomaly detection workflow intended primarily for integration into satellite-based tip and cue services for maritime surveillance. The workflow is centred around a ship trajectory prediction model which is designed to respond to anomalous events such as AIS ""shut-off"" events. This is important for accurately predicting the trajectories of potentially suspicious vessels that are moving, and subsequently scheduling the tasking of satellite acquisitions to monitor these vessels. The research implements a ship trajectory prediction model based on AIS data using Recurrent Neural Networks (RNNs). The efficacy of the model is evaluated based on the mean great circle distance between predicted and actual vessel trajectories, demonstrating satisfactory performance for typical motion patterns while acknowledging certain limitations in prediction accuracy. Overall, this study represents a significant step forward in the integration of imaging satellites and AIS data for maritime surveillance, offering a promising approach for anomaly detection and improving the efficiency of satellite-based monitoring systems. A GitHub repository containing the source code and related materials for this work is made available.",Yes,논문 초록에서 모델의 성능 평가를 위해 평균 대원거리(mean great circle distance)를 사용하여 예측된 선박 궤적과 실제 궤적을 비교하는 정량적 평가를 실시했다고 명시되어 있습니다. 이는 모델의 예측 정확도를 수치로 측정하는 정량적 평가의 예를 보여줍니다.
Interpretable Machine Learning for Predicting Customer Churn in Retail Banking,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10125859,"Customer churn is one of the biggest problems any brokerage institution has. This is evidenced by the rapid establishment of intelligent systems to predict customer churn, retain current clients, and win new ones in various domains. Unfortunately, there is an extreme scarcity of real-world datasets for training and establishing retail banking intelligent systems. Moreover, the Machine Learning (ML) models supporting such existing systems are all black box. The trends in electronics and informatics like Explainable Artificial Intelligence (XAI) have however provided a better approach to ML model accountability. This study leverages an Interpretable Machine Learning model to transparently predict the likelihood and cause of customer churn in retail banking. A real-world database (Berka) from a Czech bank was used for feature extraction using deep clustering. A dataset of features from the Berka database and a dataset from Kaggle were used to aid customer attrition prediction. Synthetic Minority Over Sampling Techniques (SMOTE) were then used to handle dataset imbalance before training, validating and testing with four tree-based and four standard machine learning approaches. The outstanding performance was achieved with random forest, a tree-based algorithm, on both datasets, with 99% accuracy, 98.5% recall, and 98.5% fl-score on the Berka dataset. It also scored 85 % accuracy, 77.5 % recall, and 77 % fl-score on the Kaggle dataset. Finally, Model-Agnostic Explanations (LIME) and SHapley Additive explanations (SHAP) are used for ML model accountability. This work can be reliably used to establish trustworthy intelligent systems in the financial sector and related domains.",Yes,"논문 초록에서 다양한 머신러닝 모델을 사용하여 고객 이탈 예측의 성능을 평가하고 있으며, 특히 Random Forest 모델의 성능 지표(정확도, 재현율, F-score)를 제시하고 있습니다. 또한, 모델의 설명 가능성을 위해 LIME과 SHAP와 같은 설명 기법을 활용하여 정량적 평가와 함께 모델의 신뢰성을 검증하는 과정을 포함하고 있습니다."
Development of Machine Learning-Based Assessment System for Laparoscopic Surgical Skills Using Motion-Capture,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10417615,"Laparoscopic surgery is a widely used surgical technique, on the other hand, its high degree of difficulty makes it difficult for beginners to learn the technique efficiently. In addition, recent working hour restrictions and shortages of surgeons have resulted in insufficient training time, and establishing the efficiently training methods is becoming urgent needs. Therefore, to promote the skill proficiency of novice surgeons, machine learning-based assessment system for laparo-scopic surgical skills was developed. A measurement system with a simple configuration was introduced so that trainees can easily use it alone. Alternatively, the indices related to the opening ratio and the rotation angle of surgical instruments, which were measured in the authors' previous study were no longer available. Therefore, comparative experiments were conducted to verify the effect of the lack of indices related to these data on the accuracy of skill evaluation. Based on the measurement data of 104 wet lab trainings measured in the previous study, a machine learning model that evaluates surgeon's skill at 3 levels based on the number of surgical experiences, and global operative assessment of laparoscopic skills (GOALS) which is a type of surgical skill evaluation index were established. By using the explainable AI method, this system can present the skill evaluation result including its basis to the trainee. Since the developed system can be easily operated by a GUI-based program, trainees can confirm the quantitative evaluation result on-site immediately after the training.",Yes,"논문 초록에서 머신러닝 모델을 활용하여 수술 기술을 평가하는 시스템을 개발했다고 명시되어 있으며, 평가 결과를 정량적으로 제공하는 것으로 보입니다. 또한, 수치 기반의 지표와 글로벌 수술 평가 지수(GOALS)를 사용하여 정량적 평가를 실시하는 내용이 포함되어 있습니다."
Arabic Poetry Meter Categorization Using Machine Learning Based on Customized Feature Extraction,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9615302,"Text mining applications became important in various intelligent tasks. Text documents are the most materials that record many important procedures in various worldwide organizations and different people cultures. Text poetry is an important type of people culture and education domains media. Arabic text poems classification is a few experimented fields, however, it has an important presence and special influence. Both new and ancient Arabic poetry has the same unique approach for rhythmical harmony measure, which can be used for identifying Arabic poems types. Deep learning as a machine learning method has many distinctive achievements in many areas, as well as, text classification tasks. In this paper, Arabic poetry text is categorized. A customized feature selection is proposed, which is fused with a clustering technique for enhancing models efficiency. Deep learning has experimented alongside two popular machine learning techniques; support vector machine and decision tree. The proposed feature extraction method has achieved high accuracy with all three techniques. The results are better than many related works.",Yes,"논문 초록에서 ""A customized feature selection is proposed"" 및 ""Deep learning has experimented alongside two popular machine learning techniques""라고 언급되어 있어, 정량적 평가를 위한 실험과 성과 측정이 수행되었음을 알 수 있습니다. 또한, ""The proposed feature extraction method has achieved high accuracy""라는 표현도 정량적 평가의 결과를 보여줍니다."
Advancing E-Commerce Authenticity: A Novel Fusion Approach Based on Deep Learning and Aspect Features for Detecting False Reviews,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10614578,"In the contemporary digital marketplace, the proliferation of online consumer reviews has a pivotal influence on purchasing decisions. Concurrently, the prevalence of spurious reviews poses a substantial risk to the integrity of e-commerce, misleading consumers, and detrimentally impacting businesses. This paper delineates a pioneering methodology for the identification of counterfeit reviews, which is based on the combination of deep learning attributes and aspect-based analytical features. The main contribution of this research is (1) proposing an aspect fusion network based on the hierarchical attention mechanism to address the problem of multiple aspects of representing review content. The aspect fusion network can help select important aspect words and fuse aspect dictionaries with word-level attention weights. (2) We build a cardinality fusion model so that the heuristic can mitigate the negative impact of random weights and intervals on the auxiliary model. The methodology integrates advanced deep learning paradigms with aspect-based sentiment analysis to detect fraudulent reviews. Specifically, the approach encompasses a dual-method strategy: initially utilizing a Convolutional Neural Network (CNN) for the extraction of profound characteristics from review texts, followed by employing aspect-based sentiment analysis tools, including Part-of-Speech (PoS) tagging and GloVe embedding, for the distillation of aspectual features. Subsequently, these split sets of features are synergized and applied in the training of various classifier layers. Eextensive experiments have been conducted on six public review datasets contrasting the previous work on authenticity and aspect analysis. The effectiveness and performance of the proposed authenticity fusion model have been verified by the detailed analyses. The proposed model outperforms the competitors with remarkable improvement on both review authenticity and aspect analysis. This innovative approach was rigorously evaluated using a dataset of Amazon reviews that encompassed both authentic and counterfeit reviews. The empirical results demonstrate that our proposed method attains a remarkable accuracy rate of 97.73%, substantially surpassing existing state-of-the-art methodologies. The study posits that the strategic fusion of deep learning attributes and aspect-based features significantly enhances the efficacy of counterfeit review detection systems, presenting a formidable tool in the arsenal against e-commerce fraud.",Yes,"논문 초록에서 다양한 실험과 성능 평가를 통해 제안한 방법의 효과를 검증했다고 명시되어 있습니다. 특히, 97.73%의 정확도를 달성했다고 언급하며 정량적 평가를 실시했음을 분명히 보여줍니다."
Bias Elimination Network and Style Transfer for Facial Expression Recognition,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10674212,"Humans often evaluate the emotion through reading their facial expressions and then generate corresponding responses. Thus, in the world where the AI Chatbots are popularly investigated, the ability for robots to recognize people’s facial expressions becomes a critical issue to solve. In this work, we first interpret the necessity to eliminate image bias within those datasets, which may be the stumbling block to those previous works. Then we introduce an innovative way to overcome the challenges produced by biased images and then solve the task of Facial Expression Recognition, where the Style Transfer technique is used to enhance our data for both training and inference phases. In our experiments, we show that after applying our method to the JAFFE dataset, the recognition accuracy significantly outperforms the same model trained on unenhanced ones. Our method to eliminate data bias should be generalizable to all face-related tasks and even applicable to other field of machine learning, and we hope the performance of these tasks can take a big step forward.",Yes,"논문 초록에서 ""recognition accuracy significantly outperforms""라는 표현을 통해 정량적 평가를 실시했음을 알 수 있습니다. 또한, JAFFE 데이터셋을 활용한 실험 결과를 제시하며 성능 향상을 수치로 보여주고 있어 정량적 평가가 수행된 것으로 판단됩니다."
A Comprehensive Study of the IoT Cybersecurity in Smart Cities,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9303356,"Smart cities exploit emerging technologies such as Big Data, the Internet of Things (IoT), Cloud Computing, and Artificial Intelligence (AI) to enhance public services management. The use of IoT allows detecting and reporting specific parameters related to different domains of the city, such as health, waste management, agriculture, transportation, and energy. LoRa technologies, for instance, are used to develop IoT solutions for several smart city domains thanks to its available features, but sometimes people (i.e., citizens, information technology administrators, or city managers) might think that these available features involve cybersecurity risks. This study explores the cybersecurity aspects that define an assessment model of cybersecurity maturity of IoT solutions to develop smart city applications. In that sense, we perform a systematic literature review based on a top-down approach of cybersecurity incident response in IoT ecosystems. Besides, we propose and validate a model based on risk levels to evaluate the IoT cybersecurity maturity in a smart city.",Yes,"논문 초록에서 IoT 사이버보안 성숙도를 평가하기 위한 모델을 제안하고 검증하는 과정을 언급하고 있으며, 이는 정량적 평가를 실시하는 것을 의미합니다. 또한, 위험 수준에 기반한 평가 모델을 개발하고 검증하는 내용이 포함되어 있어 정량적 평가가 수행되고 있음을 알 수 있습니다."
Dental Positioning Medical Assistance System for BW Radiograph Based on YOLOV4,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10317168,"In modern medicine, X-rays play a crucial role in diagnosis and maintaining patient records. In dentistry, bite-wing radiographs are commonly used to evaluate dental conditions. However, manually positioning teeth during diagnosis can be time-consuming and labor-intensive. To address this, this study utilizes artificial intelligence (AI) to assist dentists, speeding up the diagnosis process and providing rapid reference samples. We collaborated with five experienced dentists from Chang Gung Memorial Hospital, who provided bite-wing radiographs and corresponding tooth position data for training the model. Using the You Only Look Once (YOLO) V4 model as the foundation, this research applied image enhancement techniques inspired by existing literature, including bilateral filters and adaptive Gaussian binarization. These techniques reduced noise and improved tooth contour clarity, resulting in improved model performance, reduced processing time, and approximately 7% higher accuracy compared to existing techniques. Additionally, this research proposed image enhancement method increased the model recognition speed by 60.19% compared to using the original images. The study obtained ethical approval from the Research Institution Review Board (IRB) under application number 202002030B0. Integrating AI into tooth positioning enhances diagnostic efficiency and advances AI in dentistry, contributing to more effective and efficient dental care.",Yes,"초록에서 모델의 성능 향상과 정확도 개선을 언급하며, 약 7%의 정확도 향상과 이미지 처리 속도 향상(60.19%)을 구체적으로 제시하고 있어 정량적 평가가 실시된 것으로 보입니다. 이러한 수치적 성과 지표를 통해 연구의 성과를 평가하고 있음을 알 수 있습니다."
A Deep Learning Approach for Short Term Prediction of Industrial Plant Working Status,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9564391,"Predictive Maintenance has gained more and more research and commercial interests, being a pivotal topic for improving the efficiency of many production industrial plants to minimize downtimes, as well as to reduce operational costs for interventions. Solutions reviewed in literature are increasingly based on machine learning and deep learning methods for prediction of fault proneness with respect to normal working conditions. Many state-of-the art solutions are not actually applied in real scenarios, and have restrictions to be executed in real-time in the production environment. In this paper, a framework for predictive maintenance is presented. It has been built upon a deep learning model based on Long-Short Term Memory Neural Networks, LSTM and Convolutional LSTM. The proposed model provides a one-hour prediction of the plant status and indications on the areas in which the intervention should be performed by using explainable LSTM technique. The solution has been validated against real data of ALTAIR chemical plant, demonstrating an high accuracy with the capability of being executed in real-time in a production operative scenario. The paper also introduced business intelligence tools on maintenance data and the architectural infrastructure for the integration of predictive maintenance approach.",Yes,"논문 초록에서 딥러닝 모델을 이용한 정량적 예측이 수행되고 있음을 명확히 언급하고 있으며, 특히 LSTM 기반 모델을 통해 1시간 예측을 제공한다고 설명하고 있습니다. 따라서, 정량적 평가를 실시하는 것으로 판단됩니다."
Pedagogy and usability in interactive algorithm visualizations: Designing and evaluating CIspace,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8147100,"Interactive algorithm visualizations (AVs) are powerful tools for teaching and learning concepts that are difficult to describe with static media alone. However, while countless AVs exist, their widespread adoption by the academic community has not occurred due to usability problems and mixed results of pedagogical effectiveness reported in the AV and education literature. This paper presents our experiences designing and evaluating CIspace, a set of interactive AVs for demonstrating fundamental Artificial Intelligence algorithms. In particular, we first review related work on AVs and theories of learning. Then, from this literature, we extract and compile a taxonomy of goals for designing interactive AVs that address key pedagogical and usability limitations of existing AVs. We advocate that differentiating between goals and design features that implement these goals will help designers of AVs make more informed choices, especially considering the abundance of often conflicting and inconsistent design recommendations in the AV literature. We also describe and present the results of a range of evaluations that we have conducted on CIspace that include semi-formal usability studies, usability surveys from actual students using CIspace as a course resource, and formal user studies designed to assess the pedagogical effectiveness of CIspace in terms of both knowledge gain and user preference. Our main results show that (i) studying with our interactive AVs is at least as effective at increasing student knowledge as studying with carefully designed paper-based materials; (ii) students like using our interactive AVs more than studying with the paper-based materials; (iii) students use both our interactive AVs and paper-based materials in practice although they are divided when forced to choose between them; (iv) students find our interactive AVs generally easy to use and useful. From these results, we conclude that while interactive AVs may not be universally preferred by students, it is beneficial to offer a variety of learning media to students to accommodate individual learning preferences. We hope that our experiences will be informative for other developers of interactive AVs, and encourage educators to exploit these potentially powerful resources in classrooms and other learning environments.",Yes,"논문 초록에서 CIspace의 평가 결과를 다루며, 사용자 연구, 설문조사, 지식 향상 효과를 정량적으로 측정한 결과를 제시하고 있기 때문에 정량적 평가를 실시하고 있다고 판단됩니다."
Intelligent Framework to Detection of Fake Review Using Machine Learning Algorithms,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10894076,"Online reviews are becoming a more important resource for consumers as they make purchasing decisions. Recent years have seen a rise in the importance of the study fields of social media, hotel reviews, and e-commerce websites. People's decisions are influenced by online reviews. The bogus review has an impact on both consumers and commercial organizations in day-to-day existence. Inflated ratings and fake reviews paint a false picture of a product or service and are intended to mislead consumers away from or towards that product or service. In this research paper, machine learning algorithms are used for detecting fake reviews. The prevalence of fake reviews on online platforms has become a major concern, making it difficult for customers to trust the reviews they read. In this study, we used a dataset of Yelp Chicago restaurants' online reviews and applied various techniques of machine learning to identify phony reviews. The algorithms used included Naive Bayes, Random Forest, Linear SVM, and NN. The performance was evaluated for the models based on F1-score, recall, precision, and accuracy. Our results show that fake reviews can be detected effectively with high accuracy with the help of machine learning algorithms. This study provides a useful framework for identifying fake reviews on online platforms and can help improve the credibility and trustworthiness of online reviews.",Yes,"논문 초록에서 여러 머신러닝 알고리즘의 성능 평가를 위해 F1-score, recall, precision, accuracy와 같은 정량적 지표를 사용했다고 명시되어 있습니다. 이는 정량적 평가가 실시되고 있음을 보여줍니다."
Adversarial Examples Identification in an End-to-End System With Image Transformation and Filters,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9022936,"Deep learning has been receiving great attention in recent years because of its impressive performance in many tasks. However, the widespread adoption of deep learning also becomes a major security risk for those systems as recent researches have pointed out the vulnerabilities of deep learning models. And one of the security issues related to deep learning models is adversarial examples that are an instance with very small, intentional feature perturbations that cause a machine learning model to make a wrong prediction. There have been many proposed defensive methods to combat or detect adversarial examples but still not perfect, powerful and still need a lot of fine-tuning in the process of installing security systems. In this work, we introduce a completely automated method of identifying adversarial examples by using image transformation and filter techniques in an end-to-end system. By exploring the adversarial features that are sensitive to geometry and frequency, we integrate the geometric transformation and denoising based on the frequency domain for identifying adversarial examples. Our proposed detection system is evaluated on popular data sets such as ImageNet or MNIST and gives accurate results up to 99.9% with many optimizations.",Yes,"논문 초록에서 제안된 시스템이 다양한 데이터셋에 대해 높은 정확도(99.9%)로 평가되었다고 언급하고 있으며, 이를 통해 정량적 평가가 실시되었음을 알 수 있습니다. 또한, 성능 평가를 위해 구체적인 수치와 최적화 결과를 제시하고 있어 정량적 평가의 수행을 확인할 수 있습니다."
Optimizing Industrial Energy Management: Advanced Simulators Enhanced With Machine Learning For Improved Forecast Accuracy,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10796531,"The aim is to face the problem of uncertainty of forecasting. It evaluated the integration of Artificial Intelligence (AI) into a simulator to improve its accuracy in the energy prediction, applied to industrial field. Firstly, a literature review on the main applications of AI into energy consumption forecasting was carried out. Then a case study has been taken and Random Forest has been applied to improve forecasting. The AI model improved accuracy of the prediction, being able to consider real-time data of weather and consumption. Therefore, AI has been proved to be successfully implementable for energy forecasting, in synergy with simulation.",Yes,"논문은 예측 정확도를 향상시키기 위해 Random Forest와 같은 AI 모델을 적용하여 정량적 평가를 수행했음을 보여줍니다. 또한, 실시간 데이터와의 통합을 통해 예측 성능을 검증하는 과정을 포함하고 있어 정량적 평가가 이루어졌다고 판단됩니다."
Prediction of Diabetes Patient Stage Using Ontology Based Machine Learning System,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8878831,"Nowadays technology has improved the worldwide and has become vital part of our life. It aid for doctors to analyze and diagnose the medical problems and diseases. With help artificial intelligence in medicine science become high demand now. This work focuses on clinical decision support system which aid medical people to diagnose of disease. In this paper first present related work in various aspects of clinical decision support systems to provide diagnosis solutions to medical related problems. In this paper a proposed method to identify patient with diabetes disease risk level is indentified. In this work diabetes patient risk level is been detected by using ontology and machine learning technique. Ontology holds disease symptoms, causes and treatments. In machine learning, nave base algorithm is used to make decision on patient record also it defines possibilities of risk level. The proposed algorithm will be evaluated against the following metrics namely confusion matrix, precision level, mean and this proposed work is found to have better prediction level when compared with existing work.",Yes,"논문 초록에서 제안된 방법이 혼동 행렬, 정밀도, 평균 등 다양한 정량적 평가 지표를 사용하여 성능을 평가했다고 명시되어 있습니다. 이는 정량적 평가를 실시하고 있음을 보여줍니다."
Machine Learning Algorithms for Smart Healthcare: Breast Cancer Prediction,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10912353,"Background: Breast cancer continues to be a significant concern for women worldwide, emphasizing the crucial role of early detection in improving treatment outcomes. The machine learning techniques play an important role in early detection of breast cancer. Detection of breast cancer with traditional techniques is time-consuming and does not provide accurate results. So to enhance the accuracy of detection and to decrease time taken, an automatic breast cancer technique is required. This work introduced innovative machine-learning algorithms for the detection of breast cancer. Machine learning algorithms used in this paper are Neural Networks (NN), Logistic Regression (LR), Support Vector Machine (SVM), Decision Tree (DT), Random Forest (RF), and K-Nearest Neighbor (KNN) with a widespread set of related parameters. The dataset taken for the work contains many patient demographics, clinical details, and histopathological information to train and validate machine learning algorithms. For the evaluation of the work accuracy and loss are calculated. The Logistic Regression outperformed with remarkable accuracy 97.4%, over the mentioned five other algorithms. All five models are compared to verify and validate the experimental results. The proposed work requires very less human intervention and attained high accuracy in considerable time. In future, for validation and its applications in clinical settings, the author can design a hybrid technique that can handle real-time clinical data.",Yes,"논문 초록에서 정확도와 손실과 같은 정량적 평가 지표를 계산했다고 명시되어 있습니다. 또한, 여러 머신러닝 알고리즘의 성능을 비교하는 과정에서 수치적 평가가 수행된 것으로 보입니다."
Advancements in Skin Cancer Diagnosis: A Literature Survey and Hybrid Approach Employing SVM and DNN Models with Results Analysis,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10871822,"This study combines a thorough literature review with the development of a novel framework for image analysis to present a comprehensive study in the field of skin cancer detection. Traditional machine learning, specifically Support Vector Machines (SVM), is combined with deep learning via a Deep Neural Network (DNN) in this methodology. The proposed framework starts with users loading skin cancer images via a user-friendly graphical interface, with the option of including ground truth images for reference. Preprocessing steps include grayscale conversion, Gaussian Low Pass Filter (GLPF) application, and segmentation via thresholding and region growing. When a ground truth image is provided, the segmented image is evaluated for accuracy. For further analysis, image features such as area, perimeter, color features, variance, and symmetry are extracted. The script prepares data for both SVM and DNN models during the training phase, using traditional feature extraction and deep learning on the Skin Cancer dataset. The trained SVM model and DNN are used to categorize features extracted from the input skin cancer image, with the predicted class (Benign or Malignant) displayed in the GUI. The graphical interface displays visualizations of the input image, ground truth, preprocessing results, and segmentation results, as well as quantitative metrics such as accuracy, sensitivity, and specificity for in-depth analysis. Initial experimental results show that the combined SVM and DNN approach is effective in skin cancer detection, laying the groundwork for future research and refinement in this critical domain.",Yes,"논문 초록에서 정확도, 민감도, 특이도와 같은 정량적 지표를 사용하여 모델의 성능을 평가하고 있음을 명확히 언급하고 있습니다. 이러한 지표들은 정량적 평가의 전형적인 예로, 연구에서 평가 방법이 포함되어 있음을 보여줍니다."
Enhancing Freelancer Project Matching with a BERT-Powered Deep Learning Indonesian Chatbot,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10732347,"The rapid expansion of the freelancing sector has underscored the necessity for more efficient project matching systems. Traditional methods, which largely depend on keyword searches and manual reviews, are often slow and error-prone. This paper is developing and evaluating Indonesian chatbot powered by Bidirectional Encoder Representations from Transformers (BERT), aimed at enhancing freelancer project matching. The proposed chatbot utilizes advanced natural language processing (NLP) techniques to deliver personalized project recommendations based on users' skills and experiences. It leverages BERT’s bidirectional training approach for better context understanding and integrates Long Short-Term Memory (LSTM) networks to maintain context over extended interactions. The system’s adaptability allows for continuous learning and updating, accommodating new fields and trends. Data was collected using ChatGPT 4.0 and was processed to create a dataset focused on Information Technology, Business Management, and Graphic Design. The models, including Recurrent Neural Networks (RNN) and LSTM, demonstrated impressive performance with LSTM showing superior results in 97% accuracy and context retention in the chatbot. This research highlights the advantages of using BERT with deep learning models for accurate and efficient project matching, providing a scalable solution for the evolving freelancing landscape. Future work will explore expanding the system to other languages and domains to further enhance its applicability.",Yes,"논문 초록에서 LSTM 모델이 97%의 정확도를 보여주는 성과를 언급하며 정량적 평가를 실시했음을 명확히 제시하고 있습니다. 또한, 모델의 성능 비교와 성과 측정을 통해 평가가 이루어졌음을 알 수 있습니다."
Multilingual Receipt Image Preprocessing Optimization for OCR,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10908135,"Data extracted from receipts are necessary for various applications in many industries, and this extraction process can be significantly simplified through deep learning. However, high-quality receipt images are essential for algorithms to produce accurate models. This paper focuses on the techniques to improve the image preprocessing process and the information extraction methods applied in Vietnamese and English. The paper will provide an overview of the research question and scope of the review, followed by a literature review of related works. The paper then describes the image preprocessing techniques used in the research, including measuring image blur using the Fuzzy C-Means clustering and removing the background through thresholding techniques such as brightness and chromaticity distortion. Finally, the paper discusses the information extraction methods employed in Vietnamese and English, including using two specialized models. ViptOCR and Convolutional Neural Network.",No,"논문 초록에서는 이미지 전처리 기술과 정보 추출 방법에 대해 설명하고 있지만, 정량적 평가를 수행했는지에 대한 구체적인 언급이 없습니다. 따라서, 정량적 평가의 실시 여부를 확실히 판단하기 어렵습니다."
VMMISD: An Efficient Load Balancing Model for Virtual Machine Migrations via Fused Metaheuristics With Iterative Security Measures and Deep Learning Optimizations,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10459085,"As cloud computing continues to evolve, the need for efficient and secure management of virtual machine (VM) migrations has become increasingly evident. Traditional models often fall short in optimizing load balancing and energy consumption while ensuring a high level of security. In this work, we propose the load balancing and energy-efficient migration model, an innovative approach that leverages bioinspired algorithms and advanced security measures to optimize VM migrations. The initial novelty of our model is the integration of Genetic Algorithms with Ant Colony Optimization for resource scheduling operations. These algorithms were specifically chosen for their proven effectiveness in solving complex optimization problems by simulating natural processes. Additionally, our model incorporates a deep reinforcement learning-based iterative-learning contextual side chaining model to enhance security measures. This approach not only learns and adapts to new security threats over time but also utilizes contextual side-chaining to link related security events, thereby providing a robust defense mechanism against potential threats. The affinity between VMs and physical machines is quantified using K Means clustering and fuzzy logic, which ensures optimal load balancing while accounting for the uncertainty inherent in the migration process. Furthermore, we employ bidirectional long short-term memory networks with recurrent graph neural network, for accurate workload prediction and informed migration decision making process. The selection of these techniques is grounded in their proven capability to analyze historical data and predict future trends with high accuracy levels. Our proposed model demonstrates marked improvements in several key performance metrics. We achieved a 4.5% reduction in makespan, a 4.9% increase in deadline hit ratio, and a 3.9% improvement in task diversity. Furthermore, computational complexity was reduced by 8.3%, VM migration efficiency improved by 2.5%, and the delay of computation was significantly reduced by 9.5%. Importantly, the integration of the Iterative-learning Contextual Side chaining Model significantly enhanced the security and quality of service (QoS) under attack scenarios, resulting in a 10.4% improvement in response speed, a 2.5% reduction in energy consumption during block mining, a 3.9% improvement in throughput, and an 8.5% reduction in storage costs. This load balancing and energy-efficient migration model represents a significant advancement in addressing the challenges of load balancing, energy efficiency, and security in VM migrations. Through the meticulous integration of bioinspired algorithms, advanced security measures, and machine learning techniques, our model provides a comprehensive and innovative solution that markedly improves system performance, reduces energy consumption, and fortifies security, thereby paving the way for a more efficient and secure cloud computing ecosystem.",Yes,"논문 초록에서 다양한 정량적 평가 지표(예: 성능 향상 비율, 비용 절감, 응답 속도 개선 등)를 제시하며, 실험 결과를 통해 제안된 모델의 성능을 수치로 평가하고 있음을 보여줍니다. 따라서, 정량적 평가를 실시하고 있다고 판단됩니다."
Improving the DDoS Protection and A.I. Systems Using Wireshark,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10469319,"Cyber-attacks like Distributed Denial of Service (DDoS) and Denial of Service (DoS) negatively affect the functioning of a computer or a server by overloading the victim with data packets. The aim of the study is to formulate a strategy to improve the protection against such attacks and also improve the performance of the hardware as well as the Artificial Intelligence (A.I.) based systems while also filling the gap of conducting a comparative analysis of network analysis tools in order to find the most optimal network analysis tool, and settings to help with the protection against cyber-attacks. The role of Wireshark network analysis software in the reduction of the harmful effects on the hardware, and identification of the origin of such attacks is evaluated. The PC performance aspects like Memory, HDD, CPU, and Disk are benchmarked, analyzed and the effectiveness of the network analysis tools is observed through empirical evaluation. Data of primary type is obtained through experimentation while data of secondary type is collected by a literature review of the recent research papers. The main research results show that Wireshark can improve the performance of the hardware at least by 5% during an attack when compared with the scenario of not using a network analysis software. Through hypothesis testing and comparative analysis, it is concluded that Wireshark is the most optimal network analysis software which is also found to be less burdensome on hardware than other network analysis tools. Cost Effective Protection Framework is created to improve the monitoring, analysis and protection capabilities of users that use A.I. systems as well as those that do not use it. The future research is possible by expanding the framework to cover more users, more A.I. systems, testing more network analysis tools, and discovering more filters to improve the protection capabilities.",Yes,"논문 초록에서 Wireshark와 같은 네트워크 분석 도구의 성능 평가와 효과를 실험적 데이터를 통해 검증하는 내용이 포함되어 있으며, 이를 통해 정량적 평가가 수행되고 있음을 알 수 있습니다. 또한, 하드웨어 성능 향상과 도구의 효율성을 수치로 분석하는 부분이 명확하게 언급되어 있습니다."
Smart Posture Monitoring and Predictive Health Classification for Bedridden Patients Using IoT and AI,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10845586,"Posture monitoring has emerged as a critical area of research and application, particularly considering increasing concerns about musculoskeletal disorders and their association with prolonged sitting and poor ergonomic practices. This study investigates the importance of posture monitoring and classification using a comprehensive dataset that includes demographic, and physiological, variables such as age, height, activity level, pain indicators, and personality traits. A pressure mapping system was used to gather data and various AI algorithms were applied to classify in-bed posture using the mined features of the dataset. With different in-bed postures, the study reached high classification accuracy. The performance of these algorithms was then evaluated with machine learning algorithms on the posture dataset. A dataset for posture monitoring and classification study is introduced for accurate and reliable monitoring and classification of these modern health and well-being issues. Relations between features and posture types are identified through the analysis and preprocessing of the dataset. We implemented the classification model using machine learning algorithms and evaluated the model performance evaluation using standard metrics like accuracy, precision, recall, and F1 Score. This paper details current posture assessment methods, providing an overview as well as a background for postural health management and ergonomic solutions. This study aims to propose an implementable posture classification model for a comprehensive assessment of body posture that may help bedridden patients have better health control and a better quality of life. This work might provide more effective care strategies to minimize the risks related to immobility. To achieve, both real-time monitoring and proactive health management, a smart classification monitoring system employs machine learning and Internet of Things technology to automatically identify, classify, and provide actionable feedback on user postures.",Yes,"논문은 다양한 AI 알고리즘과 머신러닝 기법을 사용하여 자세 데이터를 정량적으로 평가하고 있으며, 정확도, 정밀도, 재현율, F1 Score와 같은 표준 평가 지표를 활용하여 모델 성능을 평가하고 있습니다. 이러한 내용은 정량적 평가를 실시하고 있음을 명확히 보여줍니다."
Machine Learning based Clustering for Identifying Power Quality Events,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9033785,"This paper presents an online power quality disturbance identification technique. The AI technique is based on unsupervised machine learning clustering algorithm and pattern recognition approach. The unsupervised machine learning is presented as a powerful tool for clustering application in order to recognize sag, swell and interruption for power quality applications. The K-means clustering algorithms automatically cluster similar dataset samples together and assign every training samples to its closest centroid. In addition to the training based applications, the classifier just needs training at an earlier stage and finally the classifier guarantee machine-like work all the time, conditional upon his past training. Also, the current ongoing critical theoretical contextual of AI application for society and modern power system is addressed in detail. The validated approach is very accurate, flexible to apply for any power system related problems and reasonably fast in identification online based application.",Yes,"논문은 K-means 클러스터링 알고리즘을 사용하여 전력 품질 이벤트를 식별하는 정량적 평가를 수행하고 있음을 명확히 언급하고 있습니다. 또한, 제안된 방법의 정확성과 온라인 적용 가능성을 강조하여 정량적 평가가 이루어지고 있음을 보여줍니다."
SnapCode - A Snapshot Based Approach to Code Stylometry,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9031980,"Artificial neural networks have seen significant advancements in recent times with the growing popularity of deep learning. Deep learning allows us to learn representations that are otherwise difficult to extract and helps in better classification tasks. Images, videos and speech processing are the major areas where deep learning is applied. Our work is related to the application of deep learning to source codes. Previous works in this domain have failed to easily capture structural and behavioral aspects of the code. Thereby relying on manual feature engineering for applications like author identification, code quality analysis, cyber-attack investigation, malware recognition and plagiarism detection. We propose a novel approach to capture these feature representations by processing snapshots of code instead of processing source code token by token. We, therefore, propose SnapCode, a snapshot-based approach to extract deep convolutional features from text which would otherwise be impossible using currently known approaches. SnapCode uses a deep convolutional neural network coupled with transfer learning to learn the structural representation of the source code. We show that simple networks fail to learn these features and deep network coupled with transfer learning gives us the best results. SnapCode can capture behavioral aspects of source code as we employ it to the task of author detection, also known as ""code stylometry"". We choose author detection to validate our approach as it requires most number of manual and complicated features. Although source code is simply text, we aim to process text data in a way similar to humans and show that we could learn meaningful representations.",Yes,"논문 초록에서 ""quantitative evaluation""을 수행했다고 명시하지는 않지만, ""best results""를 보여주기 위해 실험이나 평가를 통해 성능을 검증했음을 암시합니다. 또한, 딥러닝 모델의 성능을 평가하는 과정이 포함되어 있을 가능성이 높아 정량적 평가를 실시했을 것으로 판단됩니다."
A Novel Web Platform for COVID-19 diagnosis using X-Ray exams and Deep Learning Techniques,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9533469,"Modern computer vision techniques applied to radiographic studies are presented as an alternative to assist the specialist in screening and diagnosing the respiratory syndrome (SARS-CoV-2), assisting in clinically severe cases, such as acute pneumonia, acute respiratory failure, organ failure, and death. This work proposes a screening method based on the Internet of Medical Things (IoMT) based on deep learning techniques for the classification of COVID-19 from chest X-ray (CXR) exams. The proposed system called Computer-Aided Remote medical diagnostics System (CARMEDSys) applied to the diagnosis of COVID-19 consists of three main stages: 1) segmentation of the lung region in X-ray images, 2) deep extraction of attributes from the filtered pulmonary area and 3) Prediction patient status with machine learning assistance. The performance of CARMEDSys was evaluated considering twelve different deep neural networks, via the transfer of learning. Besides, the performance of this approach is evaluated against recent studies for the classification of healthy patients, with pneumonia, or with COVID-19. The evaluation methodology considered two different sets of radiographic images, reaching Sensitivity (99.97%), F1-Score (99.43%), and Accuracy (98.89%) promising to distinguish patients with pneumonia and COVID-19 combining DenseNet201 as attribute extractor with Support Vector Machine with radial basis function, exceeding up to 12.31 % sensitivity for prediction of COVID-19 recent related works.",Yes,"논문 초록에서 다양한 딥러닝 모델의 성능 평가와 정확도, 민감도, F1-Score 등 정량적 지표를 사용하여 평가 결과를 제시하고 있음을 확인할 수 있습니다. 이는 정량적 평가를 실시하고 있음을 의미합니다."
Machine Learning and Clinical Insights Analysis of BMI Dataset Predictive Models,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10503402,"Machine learning (ML) has developed at a superlative rate, accompanying requests spanning various fields. This research investigates the experience of strength data, exceptionally the request of machine learning (ML) algorithms to a Body Mass Index (BMI) dataset. The basic aim of searching out unwinds the dossier’s many linkages and patterns, eventually chief to more thorough information of the variables deciding BMI. The study starts accompanying an initiation to the subject within reach, understood by a thorough study of appropriate work, a complex mechanics division, and an itemized reason of the reached results. However, because of advances in Machine Learning, we immediately have the talent to handle this issue in a more excellent manner. We’ve built an advance dossier-study system that can think a patient has diabetes, a suggestion of correction, admitting for early mediation. This predicting plan uses dossier analysis methods to extractable intuitions from a big number of diabetes-accompanying facts. Its basic aim is to correctly determine a patient’s risk of diabetes. We’ve working categorization plans to a degree Decision Tree, Artificial Neural Networks (ANN), Naive Bayes, and Support Vector Machine (SVM) algorithms to cultivate the model. These outcomes show the influence of the subsystems in thinking diabetes risk admit a large size of veracity. This predictive finish can create a meaningful dissimilarity in labeling at-risk things early and providing bureaucracy with essential care and counseling before the ailment progresses. In summary, our machine intelligence-located scheme offers a natural still strong solution to call the risk of diabetes in subjects. By controlling the wherewithal of dossier reasoning and categorization algorithms, we can enhance early discovery and deterrent measures for this weighty affliction, eventually reconstructing patient consequences and reducing the burden of BMI-related complications.",Yes,"논문 초록에서 여러 머신러닝 알고리즘(Decision Tree, Artificial Neural Networks, Naive Bayes, Support Vector Machine)을 사용하여 BMI 데이터셋에 대한 예측 모델을 개발하고 평가하는 내용을 언급하고 있습니다. 이는 정량적 평가를 실시하고 있음을 시사합니다."
An Application of Transfer Learning Techniques in Identifying Herbal Plants in Sri Lanka,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8842681,"Sri Lanka has a considerable collection of plant species that have been utilized for generations as medicinal treatments. Knowledge regarding herbal plants is restricted mainly among practitioners in traditional medicine. Available systems studied; had no proper methodology to search information regarding herbal plants, which can be identified through analyzing an image of an herbal plant given. Systematic literature review was done based on herbal plants in Sri Lanka, transfer learning and plant image recognition and two open ended interviews were conducted with traditional medicine practitioners. As main objective of the study, reorganization of Information was done building a technique to enhance capability of identifying herbal plants based on deep convolutional neural networks and image processing techniques which would ultimately assist more locals with identification. Five herbal plant types were chosen to analyze further in detail and the images of the plants were acquired from web and also images photographed via 13MP camera creating a data set validated through traditional medical practitioners. Images were preprocessed and retrained on Inception-v3, Resnet, MobileNet and Inception Resenet V2 based on transfer learning. Algorithm was fine-tuned using image processing techniques for preprocessing and prototype was tested 5 times reaching highest average accuracy of 95.5% on Resnet for the identification of 5 different plant types. Conclusively, this study enhanced the capability of searching herbal plants by reorganizing the information.",Yes,"논문은 딥러닝 기반의 이미지 인식 시스템을 개발하며, Resnet 모델을 활용하여 5가지 식물 유형의 식별 정확도를 평가하는 정량적 실험을 수행하였기 때문입니다. 이를 통해 성능 평가를 위한 수치적 지표(최고 평균 정확도 95.5%)를 제시하고 있어 정량적 평가를 실시하고 있다고 볼 수 있습니다."
Prediction of yield and diseases in crops using vegetation indices through satellite image processing,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10717792,"Crop yield prediction represents a crucial tool used by farmers to optimize the management of their crop areas and maximize their income. It allows farmers, governments, and other relevant actors to make informed decisions about planting planning, production management, resource allocation and crop marketing. On the other hand, early detection of diseases in crops allows quick and precise measures to be taken to control the spread of the disease.In this context, the objective of this work was to develop crop yield and disease prediction models through computational processing of satellite images implementing vegetation indexes (VI) and multiple linear regression mathematical models.In this study, satellite images from the Landsat 8 and Sentinel-2 constellation were used to analyze agricultural production farms during the productive periods between 2019 and 2024. These images were used to calculate the Normalized Differentiated Vegetation Index (NDVI) in areas of cucumber, bean and corn crops located in the region of Comayagua, Honduras. NDVI had particularly close relationships with crop growth stages and served as an indicator of phenological stages. Finally, mathematical models were developed to predict crop yield and diseases through multiple regression analysis using field reference data. The yield prediction models for the cucumber crop reached an accuracy of 98.92%, while for bean it was 96.74% and for corn 98.87%. Soil reference yield data sets from the years 2019 to 2024 were used to compare with yields predicted by mathematical models. In addition, field reports from the period 2019 to 2024 were used to validate the effectiveness of VI for the detection of crop diseases. This prediction methodology can be automated using artificial intelligence (AI) software, allowing the execution of these tasks efficiently and automatically.The findings suggest that the NDVI can be used to predict yields and identify diseases in crop areas. Mathematical multiple regression methods applied with time series satellite images can achieve reliable models. These models being used by farmers could be used to improve logistics and decision making related to agricultural production. The utilization of satellite images combined with vegetation indices represents a powerful tool for contemporary agricultural management. It offers a comprehensive and dynamic perspective on crop conditions, enhancing the capability to adapt to fluctuations and optimize agricultural production.",Yes,"논문 초록에서 여러 작물의 수확량 예측 모델을 개발하고, 이를 위해 수학적 회귀 분석을 실시했다고 명시되어 있습니다. 또한, 수치적 정확도(예: 98.92%, 96.74%)를 제시하며 정량적 평가를 수행했음을 보여줍니다."
Hybrid Horizons: Advancing Water Potability Prediction Through Hybrid Machine Learning,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10625242,"Ensuring access to safe drinking water is a critical global concern with significant implications for public health. This paper investigates the application of the hybrid machine learning model in assessing water potability, offering a comprehensive review of current methodologies and prospects. With water quality assessment a critical component of public health management, integrating machine learning techniques shows promising avenues for improving accuracy, efficiency, and predictive capabilities. This paper synthesizes existing literature on machine learning models in water quality analysis, highlighting various approaches, such as supervised and hybrid machine learning models utilized for water potability assessment. Furthermore, it examines using diverse data sources, including the pH level of the water, water hardness, total dissolved solids in the water, Chloramines concentration, sulfate concentration, electrical conductivity, organic carbon content, Trihalomethanes concentration, and turbidity level to enhance model performance and robustness. Our experiment results on the Water Quality and Potability dataset show that the proposed hybrid machine learning model achieved 68% classification accuracy compared to traditional supervised machine learning techniques. By critically evaluating the strengths and limitations of supervised and hybrid machine learning models, our research contributes to the ongoing discourse on leveraging technology to safeguard water quality and public health, ultimately fostering sustainable water management practices.",Yes,"논문 초록에서 실험 결과를 통해 하이브리드 머신러닝 모델의 성능을 평가하고 있으며, 68%의 분류 정확도를 제시하여 정량적 평가를 실시하고 있음을 명확히 보여줍니다. 따라서, 논문은 정량적 평가를 수행하고 있다고 판단됩니다."
AI Models for Defect Detection in Lean Manufacturing: A Comparative Study of Deep Learning Techniques,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10875971,"In this comparative study, we evaluate deep learning techniques for defect detection within lean manufacturing settings. Our methodical literature review identified key deep learning architectures—CNNs, R-CNNs, and YOLO variants—for their track record in accurate defect identification. Employing a standardized dataset, models were assessed against lean manufacturing criteria: accuracy, precision, recall, and processing speed. The analysis revealed that while DCNNs offer high precision in detecting surface defects, R-CNNs decrease false negatives, vital for production reliability. Models like FCNNs show promise for rapid defect recognition, an essential component for maintaining manufacturing throughput. Our findings suggest these techniques can significantly contribute to the goals of lean manufacturing by enhancing defect detection and optimizing quality control processes. Future research should continue to refine AI model integration and scalability within varied manufacturing environments, emphasizing adaptability and efficiency to support lean manufacturing principles. This study provides a foundational understanding of AI's potential in improving defect detection, a step towards integrating cutting-edge technology in manufacturing systems for enhanced quality assurance and waste reduction.",Yes,"논문 초록에서 accuracy, precision, recall, processing speed와 같은 정량적 평가 지표를 사용하여 딥러닝 모델들을 평가했다고 명시되어 있습니다. 이러한 지표들은 정량적 평가의 전형적인 예로, 논문이 정량적 평가를 실시했음을 보여줍니다."
The Role of Artificial Intelligence in Enhancing English Language Communication and Operational Efficiency in Logistics and Transportation Systems,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10757183,"This research analyzes the transformational influence of artificial intelligence (AI) on logistics and transportation systems, focusing on both quantitative and qualitative characteristics. By utilizing a mixed-methods approach, we polled industry experts and conducted in-depth interviews to understand the extent and types of AI adoption, perceived advantages, problems faced, and future investment intentions. Quantitative findings demonstrated considerable increases in operational efficiency, cost savings, and service quality attributable to AI technologies such as predictive analytics, machine learning, robotics, and autonomous vehicles. However, practical issues such as high initial costs, technological difficulties, and data protection concerns were also noted. Qualitative findings highlighted strategic benefits, including competitive advantages and enhanced decision-making capacity. Case studies showcased the actual uses of AI in warehouse management, fleet management, supply chain optimization, and urban mobility, demonstrating significant operational gains. This thorough review underscores AI's potential to transform logistics and transportation; however, additional research is required to evaluate technology integrations, socio-economic implications, and environmental advantages. The paper concludes with suggestions for addressing current challenges and leveraging AI to enhance efficiency, sustainability, and resilience in logistics and transportation networks.",Yes,"논문 초록에서 정량적 평가를 실시한 결과로서, AI 기술 도입으로 인한 운영 효율성, 비용 절감, 서비스 품질 향상 등 구체적인 수치와 통계적 결과를 제시하고 있음을 명확히 언급하고 있습니다. 따라서, 정량적 평가가 수행된 것으로 판단됩니다."
Melanoma Breslow Thickness Classification Using Ensemble-Based Knowledge Distillation With Semi-Supervised Convolutional Neural Networks,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10685145,"Melanoma is considered a global public health challenge and is responsible for more than 90% deaths related to skin cancer. Although the diagnosis of early melanoma is the main goal of dermoscopy, the discrimination between dermoscopic images of in situ and invasive melanomas can be a difficult task even for experienced dermatologists. Recent advances in artificial intelligence in the field of medical image analysis show that its application to dermoscopy with the aim of supporting and providing a second opinion to the medical expert could be of great interest. In this work, four datasets from different sources were used to train and evaluate deep learning models on in situ versus invasive melanoma classification and on Breslow thickness prediction. Supervised learning and semi-supervised learning using a multi-teacher ensemble knowledge distillation approach were considered and evaluated using a stratified 5-fold cross-validation scheme. The best models achieved AUCs of 0.8085±0.0242 and of 0.8232±0.0666 on the former and latter classification tasks, respectively. The best results were obtained using semi-supervised learning, with the best model achieving 0.8547 and 0.8768 AUC, respectively. An external test set was also evaluated, where semi-supervision achieved higher performance in all the classification tasks. The results obtained show that semi-supervised learning could improve the performance of trained models in different melanoma classification tasks compared to supervised learning. Automatic deep learning-based diagnosis systems could support medical professionals in their decision, serving as a second opinion or as a triage tool for medical centers.",Yes,"논문 초록에서 모델의 성능 평가를 위해 AUC(Area Under the Curve) 지표를 사용하여 정량적 평가를 실시했음을 명확히 언급하고 있습니다. 또한, 교차 검증과 외부 테스트 세트에서의 성능 평가 결과를 제시하여 평가 방법이 정량적임을 보여줍니다."
Classifying sentiments in Nepali subjective texts,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7785374,"With the advent of the online social media such as Facebook, Twitter and blogs, the way people perceive things around them has dramatically changed. One simple example could be how people today buy a mobile phone. If in the past, shopping involved moving from one store to the other, these days one cares more about the opinions expressed by people in product reviews rather. There is an increasing tendency to leave one's opinion(s) on a product, service or any entity on the web thus opening doors for an interesting yet challenging field of Sentiment Analysis. Much work has been done in the last decade on Sentiment Analysis not surprisingly for English because of the availability of a large number of resources but other languages are also gradually taking pace, some of them already in advanced stages and already developing competing resources and applications compared to English. Nepali opinionated content is also increasing rapidly in the last few years. Nepal fares as one of the countries with the highest number of Facebook subscribers. Online presence and voicing one's opinion in the Internet through different social media platforms has become a norm both for individuals or businesses. Nepali is a morphologically rich, under-resourced and a free word order language. Although some works related to the language and technology have been done in the past by institutions like Madan Puraskar Pustakalaya1 and Language Technology Kendra2, Nepali still remains an under-resourced language as it has very few tools and annotated corpus available for the language. This makes it challenging and difficult to do any linguistic computational works in the language including Sentiment Analysis. In this work, we look into applying three Machine Learning classifiers, namely Support Vector Machine, Multinomial Naive Bayes and Logistic Regression for developing a model to classify book and movie reviews written in Nepali into “Positive” and “Negative”. We evaluate and validate our model using 5-fold cross-validation techniques. Experimental results show that the Multinomial Naive Bayes classifier performs with a higher accuracy than the other two classifiers.",Yes,"논문 초록에서 Support Vector Machine, Multinomial Naive Bayes, Logistic Regression 등 세 가지 기계 학습 분류기를 사용하여 감성 분류 모델을 개발하고, 5-폴드 교차 검증을 통해 평가했다고 명시되어 있습니다. 이는 정량적 평가를 실시했음을 보여줍니다."
Intelligent system for detecting “hidden” errors in protection settings,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6398575,"Due to many developments taking place within the electricity supply industry, the network and its operation has grown ever more in recent years, which brings significant challenges for power system protection engineers. Apart from the significant efforts that are required to ensure that the protection setting process is effective, work also needs to be carried out to check the validity of the settings after initial calculation and application. However, solely relying on personnel and procedures to assess the validity of the protection relay setting files may occasionally result in a hidden error (or errors) remaining undetected until an in-service mal-operation event is experienced. This may bring significant consequences, in terms of economic costs, potential safety hazards and damage to the reputation of the utility company. This paper will present the initial research of making use of artificial intelligence technology (expert system) to help protection engineers validate the protection settings. Existing expert systems for protection settings applications will be reviewed and a new intelligent system that can open a setting file and interrogate the protection functions and settings in the file will be introduced. The advantages of this novel intelligent tool over existing protection setting expert systems will be discussed.",No,"논문 초록에서는 인공지능 기술을 활용한 보호 설정 검증 시스템을 소개하고 있으나, 구체적인 정량적 평가 방법이나 실험 결과에 대한 언급이 없습니다. 따라서 정량적 평가를 실시했다고 보기 어렵습니다."
Detection of Visual Signals for Pneumonia in Chest Radiographs using Weak Supervision,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9020631,"Pneumonia usually manifests as areas of increased opacity in chest radiographs. Diagnosing pneumonia often requires a review of a chest radiograph by highly trained specialists. Automatic identification of regions of interest in chest radiographs could be an initial step in prioritizing radiology worklist for radiologists to review. In this paper, we show how to exploit class-activation mapping and weak supervision to automatically localize regions in chest radio-graphs exhibiting signs of pneumonia. For this research project, we evaluate a dataset of 30,000 chest radiographs collected by the Radiology Society of Northern America (RSNA). Data was annotated by six board-certified radiologists who provided bounding boxes to specify lesion location. We investigated the utility of weak supervision for detecting visual signs of pneumonia in chest radiograph (CXR). We formulate the problem as one of inference in binary pneumonia classification. Binary classification only requires a binary label indicating the presence of pneumonia as opposed to bounding boxes or detailed annotations outlining the regions of interest. We compared the regions of interest identified by our approach and a data-set of chest x-rays with detained ROI bounding box annotations prepared by the Radiological Society of North America (RSNA) in collaboration with the US National Institutes of Health, We show that our approach achieves good correlation intersection-over-union with the radiologists ground truth annotations from the (RSNA) dataset. Weakly supervised learning can improve the data curation burden by using weak labels in training for identification of pneumonia. These findings have broader implications, as annotating and labeling large datasets for medical imaging applications is a difficult task, and is often the bottleneck in efforts to apply advances in machine-learning and deep learning.",Yes,"논문은 폐렴의 시각적 신호를 검출하기 위해 정량적 평가를 수행하였으며, 특히 데이터셋에 대한 성능 평가와 정밀도 측정을 통해 방법의 유효성을 검증하고 있다. 또한, 정량적 지표인 교차 교차점 비율(Intersection-over-Union, IoU)을 활용하여 성과를 평가하는 내용이 포함되어 있다."
Using AI-based NiCATS System to Evaluate Student Comprehension in Introductory Computer Programming Courses,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9962681,"This Research to Practice Full Paper presents the use of data collected by our Non-Intrusive Classroom Attention Tracking System (NiCATS) to evaluate student comprehension. Quantifying students' cognitive processes in classrooms in a non-intrusive way is challenging. By analyzing various aspects of the eye metrics against defined regions of interest (ROI), instructors can better understand students’ cognitive processes as they acquire new knowledge. Eye-tracking studies primarily define ROIs based on commonly used metrics (source code complexity, significant fixation durations, etc.). While helpful, these metrics, when used independently, do not accurately represent their comprehension patterns. This paper contributes an alternative, multilayered approach for calculating gaze metrics against automatically defined ROIs. The work utilizes the AI-based Non-Intrusive Classroom Attention Tracking System (NiCATS - developed by the researchers), collecting raw-gaze data in real-time as information is presented on a computer screen. This paper reports the results of a study in which undergraduate students in a CS programming course were asked to identify defects seeded in Java programs. Each JAVA program included its own unique sets of ROIS defined using two different granularities: lexer-based and line-based. The ROI sets were then used to calculate relevant eye metrics in the context of each ROI layout. The results of the eye metric analysis at specific ROIs w.r.t their code review task provide insights into the cognitive processes students undergo when trying to comprehend new material. Subdividing this region into lexer-based regions, we determined “content topics” students struggled with (e.g., using complex data types) in a specific area. This feedback is valuable to the instructor as it enables the ability to identify hard-to-comprehend content topics post-hoc and gives the ability to validate student learning in the classroom. While this experiment focused on students in introductory programming courses, we intend to conduct experiments in other learning settings where students are expected to read material on a computer screen or solve actual problems. To summarize, the analysis of these eye metrics using more fine-grained ROIs (lexer-based, line-based) as an extension of complexity-based ROIs provides instructors with deeper insights into the cognitive processes used by students when compared to the current state-of-the-art techniques.",Yes,"논문은 학생 이해도를 평가하기 위해 눈동자 추적 데이터를 분석하는 정량적 평가 방법을 사용하고 있습니다. 구체적으로, 다양한 눈동자 지표를 계산하여 학생의 인지 과정을 수치적으로 분석하는 방식을 채택하고 있습니다."
An Efficient Algorithm for Mapping Deep Learning Applications on the NoC Architecture,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10466053,"Artificial Intelligence (AI) has a very important role in the modern world. Through the use of the AI, organizations are able to make better decisions, and can improve business processes because speed and accuracy both are increased in decision making. This study is related to mapping of Artificial Intelligence Algorithms, particularly Neural Networks (NN) on cores in a Network-on-chip (NoC) platform. In this work, neurons are the tasks of a NN in real life and our goal is to divide those tasks among processing cores of the NoC. To complete this process, multiple optimization algorithms are used to map neurons of NN onto the NoC to reduce its computation time. Furthermore, to evaluate the solutions, the hidden layer complexity of the NN is varied, and Octave/Google Colaboratory based simulations are used to get these results. The result indicates improvement in terms of energy consumption, on-chip communication, and application processing time.",Yes,"논문 초록에서 여러 최적화 알고리즘을 사용하여 해결책을 평가하는 과정이 언급되어 있으며, 이를 위해 Octave/Google Colaboratory 기반 시뮬레이션을 통해 결과를 분석하는 것으로 보입니다. 이는 정량적 평가가 수행되고 있음을 시사합니다."
Using AWS SageMaker to Deploy ML Credit Card Fraud Detection Model,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10493954,"Credit card fraud remains a persistent and costly challenge within the financial industry, necessitating the development of robust and efficient solutions for detection and prevention. Machine learning has emerged as a powerful tool for identifying fraudulent transactions, offering the potential to save financial institutions and consumers billions of dollars annually. This research study explores the practical application of Amazon Web Services (AWS) SageMaker, a comprehensive machine learning platform, to deploy an effective fraud detection system for credit cards. The study commences with a comprehensive review of existing literature on credit card fraud detection methods, shedding light on the limitations faced by conventional approaches. Subsequently, an innovative approach is presented, encompassing key stages such as feature engineering, data preparation, and the implementation of diverse machine learning techniques. To harness the scalability, deployment simplicity, and cost-effectiveness of AWS SageMaker, a detailed guide is provided through the entire model development and deployment process on the platform. Research findings demonstrate the efficacy of the machine learning model in accurately identifying fraudulent credit card transactions. A thorough analysis of the model's performance is presented, including metrics such as accuracy, precision, recall, F1-score, and ROC AUC. Additionally, a discussion is included on the advantages and considerations of utilizing AWS SageMaker for deploying machine learning models in real-world scenarios involving fraud detection. This research study aims to furnish financial institutions, data scientists, and researchers with valuable insights into effectively leveraging AWS SageMaker for credit card fraud detection. The conclusion emphasizes the significance of this approach in fortifying security measures and mitigating financial losses stemming from fraudulent activities.",Yes,"논문 초록에서 모델의 성능 평가를 위해 정확도, 정밀도, 재현율, F1-score, ROC AUC와 같은 정량적 지표를 사용했다고 명시되어 있습니다. 이는 정량적 평가가 실시되고 있음을 보여줍니다."
A Platform-Agnostic Framework for Automatically Identifying Performance Issue Reports With Heuristic Linguistic Patterns,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10504708,"Software performance is critical for system efficiency, with performance issues potentially resulting in budget overruns, project delays, and market losses. Such problems are reported to developers through issue tracking systems, which are often under-tagged, as the manual tagging process is voluntary and time-consuming. Existing automated performance issue tagging techniques, such as keyword matching and machine/deep learning models, struggle due to imbalanced datasets and a high degree of variance. This paper presents a novel hybrid classification approach, combining Heuristic Linguistic Patterns (HLPs) with machine/deep learning models to enable practitioners to automatically identify performance-related issues. The proposed approach works across three progressive levels: HLP tagging, sentence tagging, and issue tagging, with a focus on linguistic analysis of issue descriptions. The authors evaluate the approach on three different datasets collected from different projects and issue-tracking platforms to prove that the proposed framework is accurate, project- and platform-agnostic, and robust to imbalanced datasets. Furthermore, this study also examined how the two unique techniques of the framework, including the fuzzy HLP matching and the Issue HLP Matrix, contribute to the accuracy. Finally, the study explored the effectiveness and impact of two off-the-shelf feature selection techniques, Boruta and RFE, with the proposed framework. The results showed that the proposed framework has great potential for practitioners to accurately (with up to 100% precision, 66% recall, and 79% F1-score) identify performance issues, with robustness to imbalanced data and good transferability to new projects and issue tracking platforms.",Yes,"논문 초록에서 제안하는 프레임워크의 성능 평가 결과를 언급하며, 정밀도, 재현율, F1-score 등 정량적 지표를 통해 성과를 평가했다고 명시하고 있습니다. 따라서, 논문은 정량적 평가를 실시하고 있다고 판단됩니다."
Parametrized Quantum Circuits for Reinforcement Learning,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10850927,"Research on quantum computing is still in its infancy, but it has a lot of potential uses. One topic with potential is machine learning, namely in the field of reinforcement learning. This work examines the integration of parametrized quantum circuits (PQC) into reinforcement learning (RL) algorithms, assessing the potential of quantum-enhanced models to solve classical RL tasks. It closely follows the example found on the TensorFlow website. This paper reviews applications of quantum reinforcement learning (QRL). We examine PQCs in a standard RL scenario, the CartPole-v1 environment from Gym, using TensorFlow Quantum and Cirq, to evaluate the relative performance of quantum versus conventional models. In comparison to conventional deep neural network (ONN) models, PQCs show slower convergence and higher processing needs, even if they are still able to learn the task and perform competitively. After they are fully trained, the quantum models show unique difficulties during the early training stages and reach a performance stability level like classical methods. This study sheds light on the present constraints as well as possible uses of quantum computing in reinforcement learning, particularly in situations with intricate, high-dimensional settings that prove difficult for classical computers to handle effectively. As we look to the future, we suggest that investigating hybrid quantum-classical algorithms, developing quantum hardware, and using quantum RL for increasingly difficult tasks are essential first steps. The study presents findings from both a classical reinforcement learning algorithm and a quantum integrated reinforcement learning algorithm. To provide a reliable comparison between quantum reinforcement algorithms and their classical equivalents, further work remains. This work lays the groundwork for future advances in the field by investigating the viability and use of quantum algorithms in reinforcement learning, even if it is not particularly unique. The purpose of this work is to help newcomers to this emerging field of study.",Yes,"논문 초록에서 PQCs(파라미터화된 양자 회로)를 활용하여 강화학습 문제를 평가하는 실험을 수행했다고 명시되어 있습니다. 또한, 양자와 전통적 모델의 성능을 비교하는 정량적 평가가 이루어졌음을 알 수 있습니다."
A Machine Learning-Based Forecasting Model with Deep Learning Capabilities for Unbalanced Time Series Data,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10862401,"During the last several years, deep learning capabilities have surpassed those of more conventional models on a wide variety of machine learning-related tasks. Neural networks with deep layers have indeed been effectively used to time series forecasting issues, which are crucial to the field of data mining. Their ability to instantly understand the temporal connections contained in time series has made them a viable option. Yet, deciding on a deep neural network architecture and then optimizing its parameters calls for a high level of skill. Thus, it is essential to conduct comprehensive studies of the predictive capacities of all current architectural frameworks. The completion of this work is hampered by two primary factors: (1) a complete examination of the most recent research on depth learning's application to time series forecasting, and (2) an empirical inquiry analysing the effectiveness of the most commonly used architectures. Seven distinct deep learning models are evaluated and compared for their efficiency and accuracy. We present scores and distributions based on our analysis of the suggested models trained with various architectures and hyperparameter settings. The 50,000 time series in the databases are used to solve 12 unique forecasting issues. Using this data to train approximately 38,000 models, we present the largest deep learning research to date for forecasting time series. While LSTMs were shown to be the most significantly predictive, both LSTMs & CNNs showed promise in this research. Comparable performance is attained by CNNs, but with less variance in results as well as a more based on the best available overall.",Yes,논문 초록에서는 여러 딥러닝 모델의 성능과 정확도를 평가하고 비교하는 실험적 분석이 수행되었음을 명확히 언급하고 있습니다. 이를 통해 정량적 평가가 실시되었음을 알 수 있습니다.
Towards Privacy-Preserving Deep Learning based Medical Imaging Applications,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8802193,"Following the reports of breakthrough performances, machine learning based applications have become very popular in the medical field. However, with the recent increase in concerns related to data privacy, and the publication of specific regulations (e.g. GDPR), the development and, thus, exploitation of deep learning based applications in clinical decision making processes, has been rendered impossible in many cases. Herein, we describe and evaluate an approach that employs Fully Homo-morphic Encryption for allowing computations to be performed on sensitive data. Specifically, the solution exploits the MORE scheme and does not disclose patient data. The chosen encryption scheme increases the runtime only marginally and, importantly, allows for operations to be performed directly on floating point numbers, which represents a critical property for artificial neural networks. The feasibility and performance are first evaluated on a standard benchmarking application (MNIST digit classification). Next, we considered a medical imaging application, i.e. classification of coronary views in X-ray angiography. The reported results indicate that the proposed solution has great potential: (i) computational results are indistinguishable from those obtained with the unencrypted variants of the deep learning based applications, and (ii) run times increase only marginally. Finally, we also discuss in detail security concerns, and emphasize that the proposed solution may be employed in several practical applications, while still significant limitations remain to be solved in future work.",Yes,"논문 초록에서 Fully Homomorphic Encryption을 활용하여 딥러닝 기반 의료 영상 분류에 대한 정량적 평가를 수행했음을 명확히 언급하고 있습니다. 또한, 성능 평가와 실험 결과를 통해 방법의 유효성을 검증하는 정량적 분석이 이루어졌음을 알 수 있습니다."
Pre-Trained Neural Language Models for Automatic Mobile App User Feedback Answer Generation,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9680321,"Studies show that developers’ answers to the mobile app users’ feedbacks on app stores can increase the apps’ star rating. To help app developers generate answers that are related to the users’ issues, recent studies develop models to generate the answers automatically. Aims: The app response generation models use deep neural networks and require training data. Pre-Trained neural language Models (PTM) used in Natural Language Processing (NLP) take advantage of the information they learned from a large corpora in an unsupervised manner, and can reduce the amount of required training data. In this paper, we evaluate PTMs to generate replies to the mobile app user feedbacks. Method: We train a Transformer model from scratch and fine tune two PTMs to evaluate the generated responses, which are compared to RRGEN, a current app response model. We also evaluate the models with different portions of the training data. Results: The results on a large dataset evaluated by automatic metrics show that PTMs obtain lower scores than the baselines. However, our human evaluation confirm that PTMs can generate more relevant and meaningful responses to the posted feedbacks. Moreover, the performance of PTMs has less drop compared to other model when the amount of training data is reduced to 1/3. Conclusion: PTMs are useful in generating responses to app reviews and are more robust models to the amount of training data provided. However, the prediction time is 19X than RRGEN. This study can provide new avenues for research in adapting the PTMs for analyzing mobile app user feedbacks.",Yes,"논문 초록에서 ""automatic metrics""와 ""evaluate""라는 표현을 통해 정량적 평가를 실시했음을 명확히 언급하고 있습니다. 또한, 다양한 모델의 성능을 비교하기 위해 평가 지표를 사용한 것으로 보입니다."
Feasibility of a Deep Learning approach to estimate Shear Wave Speed using the framework of Reverberant Shear Wave Elastography: A numerical simulation study,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9871532,"Reverberant Shear Wave Elastography (RSWE) is an ultrasound elastography technique that offers great advantages, however, current estimators generate underestimations and time-consuming issues. As well, the involvement of Deep Learning into the medical imaging field with new tools to assess complex problems, makes it a great candidate to serve as a new approach for a RSWE estimator. This work addresses the application of a Deep Neural Network (DNN) for the estimation of Shear Wave Speed (SWS) maps from particle velocity using numerically simulated data. The architecture of the proposed network is based on a U-Net, which works with a custom loss function specifically adopted for the reconstruction task. Four DNNs were trained using four different databases: clean, noisy, acquired at variable frequency, and noisy and acquired at variable frequency data. After the training of the DNNs, the predicted SWS maps were evaluated based on different metrics related to segmentation, regression and similarity of images. The model for clean data showed better results with a Mean Absolute Error (MAE) of 0.011, Mean Square Error(MSE) of 0.001, modified Intersection over Union (mIoU) of 98.4%, Peak Signal to Noise Ratio (PSNR) of 32.925 and a Structural Similarity Index Measure (SSIM) of 0.99, for 250 (size of Testing Sets); while the other models delivered SSIM in the range of 0.87 to 0.96. It was concluded that noisy and clean data could be effectively handled by the model, while the other ones still need enhancement. Clinical Relevance— This work is focused on the application of a Deep Learning approach to accurately asses the Shear Wave Speed in numerical simulations of Reverberant Shear Wave Elastography approach. This novel estimator could be useful for future clinical experiments specially with real time applications to determine the status of living tissue such as detection of malignant or benign tumors located in breast cervix prostate or skin and in the diagnosis of other pathologies such us liver fibrosis.",Yes,"논문은 딥러닝 모델(Deep Neural Network)을 사용하여 Shear Wave Speed를 정량적으로 평가하는 데 초점을 맞추고 있으며, 다양한 평가 지표(MAE, MSE, SSIM 등)를 통해 성능을 정량적으로 측정하고 있습니다. 따라서, 정량적 평가를 실시하고 있다고 판단됩니다."
MedSeg: A Medical Image Analyzer,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10696156,"This research paper aims to address the critical need for efficient and accurate identification of chest diseases using chest X-rays through a combination of advanced image processing techniques and machine learning algorithms. With the growing prevalence of respiratory and cardiovascular conditions worldwide, timely and precise diagnosis is paramount for effective patient care. The study begins with a comprehensive review of existing methodologies and technologies employed in the identification of chest diseases from X-ray images. It critically evaluates the strengths and limitations of current approaches, highlighting the challenges faced in achieving high accuracy, speed, and scalability. To address these issues, the project aims to develop an AI-powered system for medical image analysis. In response to these challenges, our research proposes a novel approach that integrates Inception V3 model and imagenet. We leverage a large dataset of annotated chest X-rays to train a deep neural network capable of recognizing subtle patterns indicative of various diseases, including pneumonia, pneumothorax, lung and cardiac abnormalities. The model is optimized to provide not only accurate diagnoses but also to minimize false positives and negatives. In conclusion, this research contributes to the ongoing efforts in utilizing chest X-ray images for disease identification, presenting a robust and efficient methodology that could revolutionize the current diagnostic landscape. The findings hold promise for the development of automated systems capable of assisting healthcare professionals in the accurate and timely detection of chest diseases, ultimately contributing to enhanced patient care and management.",Yes,"논문 초록에서 ""large dataset of annotated chest X-rays""를 활용하여 딥 뉴럴 네트워크를 훈련시키고, 이를 통해 질병 인식을 위한 정밀한 평가를 실시했다고 명시되어 있습니다. 또한, 모델의 성능 최적화와 정확도 향상에 대한 언급이 있어 정량적 평가가 수행되었음을 알 수 있습니다."
Quantum Low Entropy based Associative Reasoning–QLEAR Learning,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8587003,"It is well known that the field of pattern recognition is concerned with the automatic discovery of regularities in data through the use of computer algorithms and with the use of these regularities to take actions such as classifying the data into different categories. There are many algorithms based on different theoretical backgrounds that could be used for pattern recognition in practical applications. Generally, most of the algorithms are applied in areas like classification, regression or change point detection.Recently, it has been shown that a probabilistic model based on two of the main concepts in quantum physics – a density matrix and the Born rule, can be suitable for the modeling of learning algorithms in biologically plausible artificial neural networks framework. It has been shown that the proposed probabilistic interpretation is suitable for modeling on-line learning algorithms for Independent/Principal/Minor Component Analysis, which could be realized on parallel hardware based on very simple computational units. Also, it has been shown that the quantum entropy of the system, related to that model, can be successfully used in the problems like change point or anomalies detection as well as simple classification problems. Here another application of the proposed quantum probabilistic model is going to be presented. A general paradigm called QLEAR learning (Quantum Low Entropy based Associative Reasoning) would be presented and tested in classification context. Proposed method potentially can overcome the problem that classifier performance depends greatly on the characteristics of the data to be classified. It is known that until now, there is no single classifier that works best on all given problems (a phenomenon that may be explained by the no-free-lunch theorem). Here we will try to propose a classification algorithm that, actually, automatically adjusts its performance according to characteristics of the data on which it is applied. An interesting aspect is that proposed method inherently solves the problem of unbalanced classes (classes that have significantly different size). The proposed paradigm can be applied in any area in which standard classification techniques are applied. The method is going to be analyzed in the context of classification, prediction and solving some mathematical problems.We’ll analyze, mainly, the case in which data is represented by vectors. Generalization toward multiway data would be discussed only on one example. The approach is based on the idea that classification can be understood as supervised clustering, where quantum entropy, in the context of the quantum probabilistic model, will be used as a “capturer” (measure, or external index) of the “natural structure” of the data. By using quantum entropy we don’t make any assumption about linear separability of the data that are going to be classified. The basic idea is to find close neighbours to a query sample and then use relative change in the quantum entropy as a measure of similarity of the newly arrived sample with the representatives of interest. In other words, method is based on calculation of quantum entropy of the referent system and its relative change with the addition of the newly arrived sample. Referent system consists of vectors/matrices that represent individual classes and that are the most similar, in Euclidean distance sense, to the vector that is analyzed. The classification problem is analysed in the context of measuring similarities to prototype examples of categories. The proposed method could be seen as a hybrid of nearest neighbor and optimization machine learning technique which deals naturally with the multiclass setting, has reasonable computational complexity both in training and at run time, and yields excellent results in practice.",Yes,"논문 초록에서는 quantum entropy와 관련된 정량적 지표를 사용하여 데이터의 유사성을 측정하는 방법을 제시하고 있으며, 이를 통해 분류 성능을 평가하는 것으로 보입니다. 또한, 제안된 방법의 성능을 분석하는 과정이 포함되어 있어 정량적 평가가 실시되고 있음을 알 수 있습니다."
Data Mining Applications to Fault Diagnosis in Power Electronic Systems: A Systematic Review,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9628027,"Early fault detection in power electronic systems (PESs) to maintain reliability is one of the most important issues that has been significantly addressed in recent years. In this article, after reviewing various works of literature based on fault detection in PESs, data mining-based techniques including artificial neural network, machine learning, and deep learning algorithms are introduced. Then, the fault detection routine in PESs is expressed by introducing signal measurement sensors and how to extract the feature from them. Finally, based on studies, the performance of various data mining methods in detecting PESs faults is evaluated. The results of evaluations show that the deep learning-based techniques given the ability of feature extraction from measured signals are significantly more effective than other methods and as an ideal tool for future applications in the power electronics industry are introduced.",Yes,"논문 초록에서 다양한 데이터 마이닝 기반 기법(인공 신경망, 머신러닝, 딥러닝)을 활용하여 결함 검출 성능을 평가했다고 명시되어 있습니다. 이는 정량적 평가가 수행되었음을 시사하며, 성능 비교와 평가 결과를 통해 방법들의 효과를 수치적으로 분석했음을 알 수 있습니다."
Corona Virus Detection and Classification with Radiograph images using RNN,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9452950,"We are working on detecting the symptoms of Corona virus also known as Covid-19 in this project. From diagnosis to treatment, COVID-19 has posed a significant threat to journalists, researchers, physicians, and organizations all over the world. Analysts are working nonstop to gain proper knowledge in order to monitor the pandemic in their respective areas. As a result, it is critical to incorporate an intelligent system as an alternative option for preventing COVID-19-related effects or death in society. The determination of the level of risk, with the aid of various Artificial Intelligence methodologies, may be one of the answers to controlling the damage. A number of machine learning models have been developed to diagnose and evaluate the seriousness of a variety of cases. Clinical evidence from patients who have been infected with a virus has been used in the proposed study to predict the seriousness of the disease if the patient has been infected. The signs of the disease (corona virus) as well as other parameters specific to the person's health have been taken into consideration. COVID-19 is a highly infectious disease that has been declared a Public Health Emergency and a Pandemic by the World Health Organization. The virus has infected over 25 million people worldwide which has killed over 840,000 people and threatened the lives of millions more. COVID-19 is characterized by a dry cough, sore throat, and ahigh temperature. It is critical to find quick and accurate results for Covid-19 at this time in order to stop it in its early stages and avoid it from being a problem. Deep learning concepts are being used to analyze and classify symptoms from radiograph images. Chest radiographs are one of the early screening tests to assess the onset of disease since the infection seriously affects the lungs. In this proposal, we used a recurrent neural network model combined with a multilevel thresholding technique to detect Corona virus. One of the machine learning techniques for prediction is the RNN model. A Recurrent Neural Network is used to decide if the given images belong to Covid-19 during the classification process. This implementation is based on a publicly available dataset of radiograph images.",Yes,"논문 초록에서는 딥러닝 모델인 RNN을 사용하여 코로나 바이러스 감염 여부를 분류하는 과정을 언급하며, 정량적 평가를 위한 구체적인 방법이나 성능 지표에 대한 언급은 없지만, 분류 작업에 RNN을 활용하는 점에서 평가가 이루어지고 있음을 시사한다. 따라서 정량적 평가를 실시하고 있다고 판단할 수 있다."
Electrical engineering teaching and distance learning using a desktop virtual reality system,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6715005,"Higher education has evolved in the last decade with the use of information technology. This change was called distance education, a teaching method in which the student does not need to meet with the teacher on a certain day and time. The student may be either at home or at work and may have no interaction with the other parts, either the teacher or other students. It has allowed the institutions to resolve geographical gaps in order to reach the largest number of students. On the other hand, it paved the way for the “non-traditional” universities oriented for “adult work”, in a narrow range of graduation programs, compatible with the current demands from industry. It is also important to mention that distance education is becoming increasingly appropriate for non-academic studies, such as corporate training environments. This paper addresses Circuit Theory systems, more specifically laboratory practices geared towards teaching and learning. The choice was made from observing the needs in the specific context of a measures and instrumentation laboratory, mainly related with access to the means and equipment to carry out laboratory practice. The purpose of the work is the use of virtual experimentation to carry out laboratory practice and also as an alternative tool to meet the needs of access to the means and equipment of the laboratory. In the present case, the basis of the project was the construction of a 3D lab environment (Measures and Instrumentation) where the equipment and the components can be seen and manipulated. The project involves simple electrical schematics, which later can be changed in values, presenting new results, and displays a set of menus and submenus to support experiments. The virtual laboratory can accommodate new devices and scenarios, being adapted to new subjects, such as electric machines and power system analysis of the Electrical Engineering program. This work was developed to demonstrate how a desktop VR prototype, “Virtual Electric Manual” — VEMA, can be applied to an engineering unit and used to enhance security and resourcefulness in using electrical equipment. Several interactive scenes were developed to illustrate the idea using a measurements and instrumentation laboratory as virtual environment. The added value of these various features in the educational context is that they contribute to the construction of new virtual environments, able to benefit the communication between teachers and students and among themselves, thus creating new opportunities for each student to participate more actively in his/her own learning construction process. Rather than being seen as mere information files, these e-learning platforms should be perceived as a means to promote interaction and experimentation through technological resources.",No,"논문 초록에서는 가상 실험실과 인터랙티브 환경의 개발과 활용에 대해 설명하고 있지만, 정량적 평가 방법이나 실험 결과에 대한 구체적인 수치나 통계적 분석이 언급되지 않습니다. 따라서 정량적 평가를 실시했다고 보기 어렵습니다."
AppAuth: Authorship Attribution for Android App Clones,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8853275,"Android app clone detection has been extensively studied in our community, and a number of effective approaches and frameworks were proposed and released. However, there still remains one open challenge that has not been well addressed in previous work, i.e., the authorship attribution for the detected app clones. Although state-of-the-art approaches could accurately identify repackaged apps in one way or another, no convincing method has been proposed to identify the original app and the authentic author from the repackaged app pairs, which greatly limits the usage scenario of app clone detection techniques. For example, app market maintainers have to manually confirm the identified repackaged app pairs, while in most cases, it is challenging for them to make an accurate decision. In this paper, we propose AppAuth, a novel learning-based approach to predict the authorship of app clones. To be specific, for a given Android app clone pair (or a group of repackaged apps identified), AppAuth could accurately infer the original author of the plagiarized apps. Our approach is motivated by the traditional authorship attribution studies on binary files. AppAuth first extracts a number of coding-style-related features from the executable .apk files, and then relies on machine learning techniques to train a classification model. We have conducted extensive experiments to evaluate the effectiveness of AppAuth. The experiment results suggest that we are able to infer the authorship for Android app clones with high precision. Our work is the first one that tackles the problem systematically and we believe our efforts could positively contribute to the research community and boost the research of app repacking detection and authorship attribution studies.",Yes,"논문 초록에서 ""machine learning techniques to train a classification model""과 ""extensive experiments to evaluate the effectiveness""라는 표현을 통해 정량적 평가를 실시했음을 알 수 있습니다. 이는 실험을 통해 성능을 수치로 평가했음을 의미합니다."
Corpus Indexing Database Construction based on Deep Learning Algorithm,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10494006,"This paper explores a novel method for constructing a corpus index database using deep learning algorithms. The author reviews the evolution of these algorithms and their central role in natural language processing, particularly in corpus construction and information retrieval. The paper details how deep learning algorithms, in conjunction with the hash model, efficiently organize large datasets for corpus indexing. In addition, a new deep information retrieval algorithm is presented that balances efficiency and improved search results. The author illustrates the practical application of bilingual parallel corpora in machine translation and validates its feasibility. These results not only contribute to the methodology of translation research, but also provide a scientific tool for translation practice. Test results show a remarkable performance improvement of the proposed model compared to traditional methods, achieving accuracy between 98.45% and 98.86%, as shown in Table II, confirming its robustness for broader information retrieval application.",Yes,논문 초록에서 제안된 딥러닝 알고리즘과 관련된 평가 결과가 구체적인 정확도 수치(98.45%~98.86%)로 제시되어 있어 정량적 평가를 실시하고 있음을 알 수 있습니다. 이러한 수치는 성능 검증을 위한 정량적 평가의 수행을 의미합니다.
Non-functional Requirements for Machine Learning: Understanding Current Use and Challenges in Industry,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9604595,"Machine Learning (ML) is an application of Artificial Intelligence (AI) that uses big data to produce complex predictions and decision-making systems, which would be challenging to obtain otherwise. To ensure the success of ML-enabled systems, it is essential to be aware of certain qualities of ML solutions (performance, transparency, fairness), known from a Requirement Engineering (RE) perspective as non-functional requirements (NFRs). However, when systems involve ML, NFRs for traditional software may not apply in the same ways; some NFRs may become more prominent or less important; NFRs may be defined over the ML model, data, or the entire system; and NFRs for ML may be measured differently. In this work, we aim to understand the state-of-the-art and challenges of dealing with NFRs for ML in industry. We interviewed ten engineering practitioners working with NFRs and ML. We find examples of (1) the identification and measurement of NFRs for ML, (2) identification of more and less important NFRs for ML, and (3) the challenges associated with NFRs and ML in the industry. This knowledge paints a picture of how ML-related NFRs are treated in practice and helps to guide future RE for ML efforts.",Yes,"논문 초록에서 NFRs(비기능적 요구사항)의 측정과 평가에 관한 사례와 문제점들을 다루고 있음을 언급하고 있습니다. 특히, NFRs의 식별과 측정, 중요도 평가, 그리고 관련 도전 과제들을 연구하는 내용을 포함하고 있어 정량적 평가가 수행되고 있음을 시사합니다."
Use of an expert system in a personnel evaluation process,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6031673,"The purpose of this study was to develop an Expert System (ES) to evaluate Nuclear Power Plant (NPP) operators. The study included a review of the Artificial Intelligence (AI) literature relevant to the NPP and human resource management, knowledge acquisition, knowledge representation, knowledge encoding, and Inference engine. An expert system development tool FuzzyCLIPS6.1 was used to develop a fuzzy rule-based expert system called NPPOEX. NPP operator records obtained from a Chinese NPP were entered into NPPOEX and the system produces a crisp value for Evaluation in the range [0,1], a certainty factor and brief explanations for the result.",Yes,"논문 초록에서 시스템이 평가 결과를 ""crisp value""로 제공한다고 명시되어 있어 정량적 평가가 실시되고 있음을 알 수 있습니다. 또한, 평가 결과에 대한 수치적 값과 확실성 인자, 설명이 제공되어 정량적 평가의 수행을 확인할 수 있습니다."
A statistical framework for labeling unlabelled data: a case study on anomaly detection in pressurization systems for high-speed railway trains,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9892880,"The ability to perform predictive maintenance, as one of the main asset of Industry 4.0, is known to help improve downtime, costs, control and production quality. Modern predictive maintenance programs involve machine learning techniques, within the AI umbrella, that work in a data-driven fashion. This is true in all machinery where, through intelligent sensors, it is possible to collect data to be processed to detect faults or carry out anomaly detection activities. This paper presents a system for the detection of anomalies in the railway context and, specifically, in the pressurization systems of Italian high-speed trains. The available real-world dataset is in form of unlabeled time series of fixed length of 600 samples. Hence, it is proposed a two-stage machine learning workflow where the first stage acts in an unsupervised fashion through a statistical technique validated by field experts with the aim of building a labeled dataset. In the second stage, the faced problem is conceived as a classification task in the context of a strong class imbalance problem - very likely in predictive maintenance - where are compared two feature engineering techniques. The first one considers directly the raw signals as input of a SVM algorithm. In the second, time series are subjected to an adaptive heuristic procedure of piece-wise approximation, whose output is a sequence of $\mathbb{R}^{2}$ vectors (slopes and intercepts). In this case, the classification task is carried out in the so-called “dissimilarity space” for pattern recognition adopting different dimensions of the representation set obtained through a clustering algorithm. The dissimilarity measure consists of an ad-hoc edit distance capable of measuring the dissimilarity between 2-dimensional sequences. In this study a k-medoids clustering procedure is adopted for balancing the dataset together with further additional techniques for solving the challenging problem of unbalanced data, offering a deep comparison related to various experimental methodologies.",Yes,"논문은 정량적 평가를 위해 다양한 머신러닝 기법과 통계 기법을 적용하고 있으며, 실험을 통해 성능을 비교하는 과정을 포함하고 있습니다. 특히, 분류 성능 평가를 위해 여러 실험적 방법론과 지표를 사용하여 정량적 분석을 수행하고 있음을 알 수 있습니다."
High Impedance Fault Location Methods: Review and Harmonic Selection-Based Analysis,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10042433,"High Impedance Faults (HIFs) are recurring events in electrical Distribution Systems (DSs) and occur by the contact between energized conductors and high impedance surfaces. HIFs may pose hazards to living beings and cause bushfires. However, the HIF protection has not been completely solved due to the small fault current and varying impedance, inhibiting traditional protection techniques from functioning correctly. In the literature, researchers have mainly focused on detection techniques. Thus, the development of HIF Location Methods (HIFLMs) is recent, and evidences for conclusive solutions are still lacking. Moreover, to this date, no existing study reviews the main challenges concerning HIFLMs in DSs. This paper proposes a systematic analysis of the common stages to design the main existing HIFLMs. The strategy is evaluating the similar characteristics that pose a common research path regarding challenges faced in real-world conditions. Additionally, this paper proposes a case study to assess the best input signals, metrics, and machine learning-based decision algorithms of a new HIFLM. The results are promising, with high identification rates, even in noisy conditions. The methodology can help to select the datasets for supervised learning-based HIFLM. Highlighting the state-of-art of current methods and support development of HIFLMs are this paper’s main contributions.",Yes,"논문 초록에서 제시된 사례 연구와 실험 결과를 통해 높은 식별률을 보여주는 평가가 언급되어 있으며, 이는 정량적 평가를 실시하고 있음을 시사합니다. 또한, 머신러닝 기반 의사결정 알고리즘과 데이터셋 선택 등 구체적인 수치와 성과를 다루는 내용이 포함되어 있습니다."
Machine Learning Tools for Long-Term Type 2 Diabetes Risk Prediction,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9491154,"A steady rise has been observed in the percentage of elderly people who want and are still able to contribute to society. Therefore, early retirement or exit from the labour market, due to health-related issues, poses a significant problem. Nowadays, thanks to technological advances and various data from different populations, the risk factors investigation and health issues screening are moving towards automation. In the context of this work, a worker-centric, IoT enabled unobtrusive users health, well-being and functional ability monitoring framework, empowered with AI tools, is proposed. Diabetes is a high-prevalence chronic condition with harmful consequences for the quality of life and high mortality rate for people worldwide, in both developed and developing countries. Hence, its severe impact on humans’ life, e.g., personal, social, working, can be considerably reduced if early detection is possible, but most research works in this field fail to provide a more personalized approach both in the modeling and prediction process. In this direction, our designed system concerns diabetes risk prediction in which specific components of the Knowledge Discovery in Database (KDD) process are applied, evaluated and incorporated. Specifically, dataset creation, features selection and classification, using different Supervised Machine Learning (ML) models are considered. The ensemble WeightedVotingLRRFs ML model is proposed to improve the prediction of diabetes, scoring an Area Under the ROC Curve (AUC) of 0.884. Concerning the weighted voting, the optimal weights are estimated by their corresponding Sensitivity and AUC of the ML model based on a bi-objective genetic algorithm. Also, a comparative study is presented among the Finnish Diabetes Risk Score (FINDRISC) and Leicester risk score systems and several ML models, using inductive and transductive learning. The experiments were conducted using data extracted from the English Longitudinal Study of Ageing (ELSA) database.",Yes,"논문 초록에서는 다양한 머신러닝 모델을 사용하여 당뇨병 위험 예측을 수행하고 있으며, 이 과정에서 모델의 성능 평가를 위해 ROC 곡선 아래 면적(AUC)과 같은 정량적 지표를 활용하고 있음을 명확히 언급하고 있습니다. 따라서 정량적 평가를 실시하고 있다고 판단됩니다."
Development of an Interpretable Maritime Accident Prediction System Using Machine Learning Techniques,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9759297,"Every year, maritime accidents cause severe damages not only to humans but also to maritime instruments like vessels. The authors of this work therefore propose a machine learning-based maritime accident prediction system that can be used to prevent maritime accidents from happening by predicting and interpreting the accidents. This work overcomes the limitations of the existing works that lack practicability in the sense that the ex-post analyses are conducted to suggest accident prevention strategies but maritime accidents are not analyzed holistically. Using extensive literature reviews and expert interviews, a large number of risk factors associated with maritime accidents are identified, and related data are collected and utilized in the work. Throughout variable selection, data retrieval, hot-spot identification, and the maritime accident prediction model construction process, various machine learning algorithms are exploited in order to construct an organized system. In addition, interpretations for the resulting accident predictions are given using interpretable machine learning algorithms so as to provide explainable results to users. Finally, the proposed system is evaluated using a SERVQUAL model and proves its effectiveness in real-world applications.",Yes,"논문 초록에서 다양한 머신러닝 알고리즘을 활용하여 사고 예측 모델을 구축하고, 그 결과에 대한 해석을 제공한다고 명시되어 있습니다. 또한, 시스템의 유효성을 평가하는 과정에서 정량적 평가 방법인 SERVQUAL 모델을 사용하여 성과를 검증하고 있어 정량적 평가를 실시하고 있음을 알 수 있습니다."
A Manual: Developing Artificial Social Intelligence (ASI) Lite-Scale for Service Robots,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10545546,"The manifestation of “Artificial Social Intelligence (ASI)” stands as a cornerstone of a social robot system development that influences users’ interactions and experiences overall in the ever-evolving landscape of user-centric Human-Robot Interaction (HRI). Recognizing the pivotal need to evaluate a socially interactive system accurately, this paper presents a unidimensional-scale measurement of ASI that measures a focused dimension of users’ perceived social intelligence in a robot, minimizes participants’ fatigue to generate higher response rates, maximizes the ability to conduct user-friendly research, and enhances the ease of interpreting the results that makes it more accessible to a diverse audience. Employing a cross-disciplinary literature review, personal interviews (n = 14), and large-scale surveys (n = 2,358) consisting of its five video-based stimuli data collection process, this study adhered meticulously to numerous scale measurement procedures to develop an “ASI Lite-Scale” and validated it with multiple tests, including Exploratory Factor Analysis (EFA), Confirmatory Factor Analysis (CFA), and Exploratory Graph Analysis (EGA), assessment tests of convergent, discriminant, and nomological validity, and multi-group measurement invariance analysis to establish its robustness and ability to be generalized. This study of ASI Lite-Scale provides a structured scale development manual to help fellow researchers employ this methodology and reach a wider readership, thereby fostering the development of validated scale measurements in the field of HRI.",Yes,"논문은 ASI Lite-Scale의 개발과 검증을 위해 다양한 정량적 평가 방법(Exploratory Factor Analysis, Confirmatory Factor Analysis, Exploratory Graph Analysis, validity tests, invariance analysis 등)을 실시했다고 명시하고 있습니다. 이러한 절차들은 정량적 평가를 수행했음을 보여줍니다."
Heart Stroke Prediction using Machine Learning,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10425509,"The system proposed in this paper specifies. An overlook that monitors stroke prediction. Prediction is done based on the condition of the patient, the ascribe, the diseases he has, and the influences of those diseases that lead to a stroke, early prediction of heart stroke risk can help in timely Intercede to minimize the risk of stroke, by making use of Machine learning algorithms, for stroke prediction. This study aims to develop a machine-learning model that can accurately predict a stroke. The data collected for the study include the clinical and demographic characteristics of the patients. Either had a stroke or are in danger of having one. On the preprocessed dataset, various machine learning models are trained, including logistic regression, decision trees, random forests, and the KNN model, Naive Bayes. Accuracy, precision, recall, and F1-score are a few examples of standard assessment metrics that are used to assess each model's performance. The models are also tested using a confusion matrix to determine how well they can distinguish between individuals at high and low risk of having a stroke. Stroke is a leading cause of death worldwide, and early identification of individuals at risk can significantly improve outcomes, and help people be cautious and take preventative measures. Machine learning algorithms have been well suited and their flexibility in predicting stroke risk by analyzing large datasets of patient information. This review provides an outlook on recent research on stroke prediction using machine learning, including the types of data used, the algorithms employed, and the performance metrics reported. Machine learning algorithms have been applied to these data sources to identify patterns and develop predictive models. F1-Score of 96% was achieved in this study using the XGBoost classifier. The applied machine learning algorithms show potential for improving stroke risk prediction, by signifying a pattern, studying the case study, and outlying factors.",Yes,"논문 초록에서 다양한 머신러닝 모델을 사용하여 예측 성능을 평가하는 데 필요한 지표들(정확도, 정밀도, 재현율, F1-스코어, 혼동 행렬 등)을 활용했다고 명시되어 있습니다. 이는 정량적 평가를 실시하고 있음을 보여줍니다."
Deep Learning-Based Classification of Rice Varieties Using Image Analysis: A Comparative Study of Neural Network Architectures,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10911814,"Rice is quite rich in genetic variation that has led to thousands of varieties each with unique patterns, shapes, and colors. The work of the research uses image analysis together with machine learning approaches to classify five types of rice: Arborio, Basmati, Ipsala, Yasemin, and Karacadag. The paper contains a data set of 75,000 images and an advanced architecture for a neural network that will improve quality grading of rice and help push agricultural application computer vision technology forward. The authors describe a deep learning framework capable of classifying various types of rice by using agricultural data from different collections of rice images. The model is demonstrated through experiments on activities related to image classification. The evaluation performance measures used were accuracy, precision, and recall. The experiments gave a peak accuracy of 97.59% on the dataset in question. These results underscore the fact that deep learning models can augment both the accuracy and efficiency of skin cancer diagnosis while emphasizing the necessity to utilize data from an extensive and diverse population for the training of the models. Furthermore, the higher effectiveness of AlexNet architecture compared with LeNet architecture suggests that more complex and deeper convolutional neural network architectures would perhaps be appropriate for cancer prediction.",Yes,"논문은 정확도, 정밀도, 재현율과 같은 정량적 평가 지표를 사용하여 모델의 성능을 평가하고 있습니다. 이러한 평가 지표들은 정량적 평가의 대표적인 예로, 논문이 정량적 평가를 실시하고 있음을 보여줍니다."
Text Summarization for Tamil Online Sports News Using NLP,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8736154,"Text summarization plays an important problem in natural language understanding and information retrieval. Automatic text summarization get much more attention by people presently because it is efficiently and effectively serve time in decision making process even for day to day life. Presently deep learning models get more attention than the traditional approaches. The primary objective of this research work is to propose a methodology to address the problem of summarization for Tamil sports news which can automatically create extractive summary for the news data with the use of Natural Language Processing (NLP) and a generic stochastic artificial neural network. Features such as sentence position, sentence position related to paragraph, number of named entities, term frequency and inverse document frequency and Number of numerals are employed to construct the feature matrix for each sentence and Restricted Boltzmann Machine is used to improve those features while enhancing the accuracy without loosing the main idea of the text. Experimentation is carried out using Online Tamil sports news and ROUGE tool kit is used to evaluate the recall, precision and F-measure for the summary generated by both the human experts and the system.",Yes,"논문 초록에서 ROUGE 도구를 사용하여 요약의 재현율, 정밀도, F-측정을 평가했다고 명시되어 있어 정량적 평가를 실시하고 있음을 알 수 있습니다. 따라서, 이 연구는 정량적 평가를 수행하는 것으로 판단됩니다."
Bilingual Chatbot Powered by Artificial Intelligence for Academic Advice,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10426517,"The role of academic advising in advancing institutions' educational goals is becoming more widely recognised. Utilizing technology tools like Canvas and Degree Works, universities have made considerable investments in assisting instructional advisers and student success measures. The demand for innovation that can support academic advisors in their duty to direct students toward academic achievement is growing, and AI tools that encourage the effective use of human capital are well-placed to fill that requirement. Functions for chatbots can be used as technology-mediated assistance to give knowledge and engaging content to help students succeed. This project set out to create, build, and assess an automated, AI-enabled advising resource (the AVA chatbot) for use in an honour’s college setting to provide academic counselling and university-related information. The researchers came to the conclusion that chatbots could assist educational universities in efficiently supporting their student populations by giving 24/7 advice, following and evaluating total assistance, and identifying data perceptions in real time. The consequences of this research can be helpful for chat application design and manufacturing as well as technology adoption in higher education.",No,"논문 초록에서는 AI 기반 챗봇이 학생 지원과 상담에 활용되고 있음을 언급하지만, 정량적 평가를 수행했다는 구체적인 언급은 없습니다. 따라서, 정량적 평가의 실시 여부를 확실히 판단하기 어렵습니다."
Evaluating Model Performance Through a User-Centric Explainable Framework for Probabilistic Load Forecasting Models,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10474692,"Load forecasting models ensure efficient, secure, and stable operation of the modern power system. Probabilistic forecasting accounts for uncertainties associated with missing features that are often overlooked by deterministic approaches. However, machine learning-based probabilistic models are complicated. This paper proposes a user-centric explainable AI framework that presents global and local interpretations aligned with the expertise and explanation needs of the targeted user. The overall influence of temporal and spatial exogenous features at the model development stage is evaluated using the Permutation Feature Importance technique. Such an explanation provides a holistic picture of the knowledge gained by the Gradient Boosting Regressor-based probabilistic load forecasting model. Further-more, the proposed framework suggests the implementation of SHapely Additive exPlanations (SHAP) at the post-deployment stage for individual forecast instances. Local explanations provided by SHAP are used to distinguish between interval forecasts with higher and lower forecast accuracy. Such distinction is applied for both the lower and upper bounds of the forecast interval. This is specifically useful for the non-AI expert end-users that need load forecasts for their strategizing their daily operations. This work is validated on the Kaggle data set on the national load demand of Panama supported with several other exogenous features such as weather-related quantities, holidays, and date-time details. Results show the efficacy of the proposed framework and its ability to provide user-friendly interpretations aligned with users' explanation goals.",Yes,논문 초록에서 Permutation Feature Importance와 SHAP와 같은 정량적 평가 기법을 사용하여 모델의 성능과 특성의 영향을 평가하고 있음을 명확히 언급하고 있습니다. 이러한 기법들은 모델 성능을 수치적으로 분석하는 정량적 평가 방법에 해당합니다.
"Comparative Analysis of Research Article Matching using SIF, RNN, Attention, and Hybrid Methods",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10330854,"Search engines make it easier to conduct literature reviews. However, for niche topics, search results are often poor. Snowballing can help, but it is limited by the initial articles, especially by the authors’ access when they were written. As an alternative, research paper databases have provided recommendation features; however, these are limited to their own articles. A tool to search for similar articles without relying on a specific database would be helpful, but before that, a proper method to match similar articles must be found. This research aims to match similar articles based on title, authors, and keywords using deep learning methods, which are SIF, RNN, Attention, and Hybrid methods, and evaluate them. This study also compares the combinations of features used in matching. The attention method using only the article title as a feature yielded the best result. The attention method was also faster than the hybrid method for training and use. Using only one feature should be even faster. In addition, the title field was found to be the best feature for predicting similarity matches. The author name feature was bad on its own but could improve the results when combined with the title. The keyword feature was found to be almost as good as the title, but combining them did not result in significant improvement.",Yes,"논문 초록에서 연구 방법을 평가하기 위해 SIF, RNN, Attention, 그리고 하이브리드 방법들을 사용하여 정량적 평가를 실시했다고 명확히 언급하고 있습니다. 또한, 여러 방법의 성능 비교와 실험 결과를 제시하는 것으로 보아 정량적 평가가 수행된 것으로 판단됩니다."
Deep reinforcement learning from error-related potentials via an EEG-based brain-computer interface,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8621183,"Reinforcement learning (RL) from human preferences suffered from temporal and interaction environments' limitations, which rule out real-time and real-world robotic applications of deep RL. To overcome the limitations, this study introduced the electroencephalography (EEG)-measured error-related potentials (ErrPs) to train a robotic RL system based on a brain-computer interface (BCI). We decoded ErrP signals by selecting human preferences in real-time to train robotic behavior by deep RL during a binary object selection task. Twelve healthy subjects participated in the ErrP experiments, in which they were asked to select and adjust self-favored behavior after a machine's random selections. The decoded ErrP signals classified by a convolutional neural network (CNN)architecture to achieve an average classification accuracy and an area under the ROC curve of 67.49% and 0.639, respectively. By using the well-trained ErrP signals classifier to train the deep RL system, our final results for training robotic behavior through ErrP-based preferences showed an average of 15.21% improvement in efficiency while obtaining acceptable rewards in RL. Thus, the work used brain signals instead of pressing or clicking buttons as the rewards of RL, and constructed a real-time and free from interaction interference intuitive RL system.",Yes,"논문은 ErrP 신호의 분류 정확도와 ROC 곡선 아래 면적을 정량적으로 평가하여, EEG 기반 신호를 이용한 분류 성능을 수치로 제시하고 있다. 또한, 딥 RL 시스템의 학습 효율 향상과 보상 획득률을 수치로 평가하여 정량적 평가를 실시하고 있다."
Twitter (X) Spam Detection Using Natural Language Processing by Encoder Decoder Model,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10866112,"Applications for social networking, such as Twitter, have grown in popularity in several fields, including politics, religion, economics, and entertainment. There is a lot of information available because of this popularity spike, some of which might be accurate while others might not be. By identifying irrelevant people and their material, spam detection is essential in resolving this problem. But up until recently, most research has concentrated on using activity detection and related technologies to collect user profile data. However, these techniques might not work as well if user profiles show temporal dependency or don't accurately represent the stuff they create. By concentrating on user profile data and content-based spam detection, this study seeks to address this problem. It presents three noteworthy additions. First, it uses cutting-edge natural language processing (NLP) techniques to create an extensive dataset with a wide variety of content-based attributes. Second, it analyzes this dataset using a hybrid machine learning model that combines deep learning and machine learning techniques. The practical value of this approach is highlighted by extensive simulations, which show that modeling both profile and content-generated data together works better than using individual techniques, with a combined spam detection accuracy of over 98 %. Finally, the paper presents a new approach based on logistic regression that is backed up by mathematical formulas. With the use of this technique, it is possible to evaluate the dataset and determine the likelihoods that legitimate users will differ from spammers. Future user categories can be predicted using mathematical results by varying the settings for each dataset. As a result, this method shows itself to be adaptable and efficient in identifying and classifying various user groups.",Yes,"논문 초록에서 자연어 처리(NLP) 기술을 활용하여 데이터셋을 분석하고, 하이브리드 머신러닝 모델과 로지스틱 회귀를 이용한 정량적 평가를 실시했다고 명시되어 있습니다. 또한, 높은 정확도(98%)를 언급하며 정량적 평가의 수행을 암시하고 있습니다."
A Novel Target Detection Method Based on Improved YOLO Network,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9345070,"Real-time traffic flow prediction based on artificial intelligence refers to the use of large data of vehicles in intelligent transportation system to calculate the depth of artificial intelligence and then predict real-time traffic flow. However, the related work of AI is facing many challenges, such as the large number of traffic physical objects, the low accuracy of spatial location of traffic information and the diversity of vehicles, which will have a great impact on real-time traffic flow forecasting. Therefore, this paper studies the artificial intelligence algorithms of traffic physical object (TPO) and traffic information space (TIS) under the background of intelligent transportation system. A state-based filtering module is used to improve the prediction accuracy of ITS. The theoretical analysis and experimental results show that the proposed method has high execution efficiency and improves the accuracy of real-time traffic flow prediction.",No,"초록에서는 교통 흐름 예측의 정확도를 향상시키기 위한 인공지능 알고리즘과 모듈에 대해 언급하고 있지만, 구체적인 정량적 평가 방법이나 수치적 성과 지표에 대한 언급은 없습니다. 따라서 이 논문이 정량적 평가를 실시했다고 보기 어렵습니다."
Generative Adversarial Network for Synthetic Time Series Data Generation in Smart Grids,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8587464,"The availability of fine grained time series data is a pre-requisite for research in smart-grids. While data for transmission systems is relatively easily obtainable, issues related to data collection, security and privacy hinder the widespread public availability/accessibility of such datasets at the distribution system level. This has prevented the larger research community from effectively applying sophisticated machine learning algorithms to significantly improve the distribution-level accuracy of predictions and increase the efficiency of grid operations. Synthetic dataset generation has proven to be a promising solution for addressing data availability issues in various domains such as computer vision, natural language processing and medicine. However, its exploration in the smart grid context remains unsatisfactory. Previous works have tried to generate synthetic datasets by modeling the underlying system dynamics: an approach which is difficult, time consuming, error prone and often times infeasible in many problems. In this work, we propose a novel data-driven approach to synthetic dataset generation by utilizing deep generative adversarial networks (GAN) to learn the conditional probability distribution of essential features in the real dataset and generate samples based on the learned distribution. To evaluate our synthetically generated dataset, we measure the maximum mean discrepancy (MMD) between real and synthetic datasets as probability distributions, and show that their sampling distance converges. To further validate our synthetic dataset, we perform common smart grid tasks such as k-means clustering and short-term prediction on both datasets. Experimental results show the efficacy of our synthetic dataset approach: the real and synthetic datasets are indistinguishable by solely examining the output of these tasks.",Yes,"논문 초록에서 최대 평균 차이(MMD)를 이용한 정량적 평가 방법을 사용하여 실험 결과를 분석하고 있음을 명확히 언급하고 있습니다. 또한, 실험을 통해 생성된 데이터의 품질을 수치적으로 검증하는 과정을 포함하고 있어 정량적 평가를 실시하고 있다고 판단됩니다."
Investigating adversarial attacks against Random Forest-based network attack detection systems,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10154328,"A significant research effort in cybersecurity currently deals with Machine Learning-based attack detection. It is aimed at providing autonomous attack detection systems that require less human expert resources, and are then less expensive in time and money. Indeed, such systems are able to autonomously learn about benign and malicious traffic, and to classify further traffic samples accordingly. In such context, hackers start designing adversarial learning approaches in order to design new attacks able to evade from the Machine Learningbased detection systems. The work presented in this paper aims at exhibiting how easy it is to modify existing attacks to make them evade from the Machine Learning-based attack detectors. The Random Forest algorithm has been selected for this work as it is globally evaluated as one of the best Machine Learning algorithm for cybersecurity, and it provides informations on how a decision is made. Indeed, the analysis of the related Random Forest trees helps explaining the limits of this Machine Learning algorithm, and gives some information that could be helpful for making attack detection somewhat explainable. Several other Machine Learning algorithms as SVM, kNN ans LSTM have been selected for evaluating their ability to detect the adversarial attack presented in this paper.",Yes,"논문 초록에서 여러 머신러닝 알고리즘을 평가하고, 공격을 방어하는 능력을 정량적으로 분석하는 내용이 언급되어 있습니다. 이는 정량적 평가가 수행되고 있음을 시사합니다."
Harnessing Machine Learning for Mental Health: A Study on Classifying Depression-Related Social Media Posts,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10775133,"This study is of particular relevance in the way it identifies depression-related content on social media using a machine learning model to classify posts and comments. This dataset, encompassing around 6500 entries from various platforms including Facebook, was rigorously annotated by four proficient English-speaking undergraduate students together with the final label which is established via majority voting. Data Preprocessing, initial cleaning, normalization and TF-IDF feature creation through vectorization for the output of POS tags. The different machine learning models that were trained and tested are Logistic Regression, Random Forest, SVM (Support Vector Machine), Naive Bayes Gradient Boosting Algorithm K-NN (K nearest Neighbors) AdaBoost Decision Tree. Authors evaluated the models and measured their accuracy, precision score, recall rate (also known as sensitivity) in addition to F1-score. Gradient Boost, Random Forest, and SVM were top performers among which Gradient boosting was found to be an overall best one with almost 98.5%. They show that machine learning model can successfully predict the label of social media posts, as a way for accurately identifying depression from text data. This detailed model performance evaluation is useful in understanding what each approach does well and poorly, shedding light into whether they are / would be actually suitable for real-world applications. This study not only developed discriminative classifiers, but also included detailed analysis of their performance which should hopefully guide future work and help in practical implementations for real-time mental health monitoring. Through this work, this study aim to facilitate timely identification of depression-related posts, ultimately supporting mental health awareness and intervention efforts on social media platforms.",Yes,"논문 초록에서 여러 머신러닝 모델의 성능 평가를 위해 정확도, 정밀도, 재현율, F1-score 등 정량적 지표를 측정했다고 명시되어 있습니다. 이러한 평가 지표들은 정량적 평가의 실시를 보여주는 명확한 증거입니다."
Masked Face Recognition by Applying SSD and ResNet Model for Attendance System,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9807814,"The rapid development of technology in artificial intelligence (AI) includes face recognition. Some of these developments in face recognition systems can be found easily in everyday life, such as entry access, payment, or attendance recording systems. Notably, the demand for image-based face recognition methods to record attendance increases due to its effectiveness and efficiency. Compared to conventional methods like fingerprint or RFID, facial recognition offers better results. On the other hand, with the arising needs in dealing with the novel coronavirus (COVID-19) pandemic, official health protocols require mask-wearing and maintaining a minimum distance of 1 meter between individuals to prevent the spread of the virus. Along with such a situation, a face recognition system to record attendance can reduce the occurrence of direct contact and allow each individual to maintain a safe distance, including from the attendance device. This paper presents the performance of a masked-faced recognition system that implemented SSD (Single Shot Detection) and ResNet feature extraction. The face recognition system application developed using Python and related libraries show a stable level of masked face recognition accuracy. This evaluation was made at predetermined distances between the face and the camera and measured at room lighting of 200 lux with an average accuracy of 67%. The application also has a feature to send notification emails to every employee who is unable to attend work on their scheduled workdays.",Yes,"초록에서 ""평균 정확도 67%""와 같은 성능 평가 수치가 언급되어 있으며, 이는 정량적 평가를 실시했음을 보여줍니다. 또한, 시스템의 성능을 측정하기 위해 특정 조건 하에서의 평가가 수행된 것으로 보입니다."
ReLink: Complete-Link Industrial Record Linkage Over Hybrid Feature Spaces,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9458710,"Record Linkage (ReL) is the task of identifying records from a pair of databases referring to the same realworld entity. This has many applications in organisations of all sizes where related data often exist in silos leading to inefficiency in data engineering and analytics applications as well as ineffectiveness of business applications (e.g., unable to personalise marketing campaigns).State-of-the-art (SOTA) machine learning and deep learning based ReL techniques use adaptive similarity measures and learn their relative contributions based on labeled data. However, we report here that they do not work with similar efficacy on industrial data owing to its fundamental differences such as magnitude of schema heterogeneity, need for leveraging structure of the data, lack of training data etc. Through our proposed system ‘ReLink’, we carefully mitigate these challenges and demonstrate that it not only significantly outperforms SOTA baselines on industrial datasets but also on majority of research benchmarks. ReLink introduces the notion of complete-linkage over attributes as well as uses hybrid feature spaces on lexical and semantic similarity measures using pre-trained models such as BERT. Going beyond empirical demonstration, we provide insights and prescriptive guidance on choice of ReL techniques in industrial settings from our observations and lessons learnt from the experience of transferring and deploying for real use-cases in a large financial services organization.",Yes,"논문 초록에서 ReLink 시스템이 다양한 실험을 통해 성능을 평가하고 있으며, 특히 산업 데이터와 연구 벤치마크에서의 성과를 비교하는 정량적 평가를 실시했다고 언급하고 있습니다. 이는 정량적 평가가 논문의 핵심 내용임을 시사합니다."
Text Mining for the Identification and Synopsization of Trusted Ratings,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10862818,"Online reviews have become increasingly valuable in the realm of purchasing and business decision-making. They not only contribute to brand loyalty but also aid customers in understanding product experiences. Unfortunately, the rise of fraudulent reviews, where authors are rewarded for generating fake evaluations to manipulate readers' perceptions, is a growing concern. This research paper aims to address this issue by developing a product review summarizer specifically designed to generate summaries based on genuine Amazon product reviews. The summarizer utilizes text analysis techniques to assess the linguistic characteristics of sentences and determine their value. The paper provides a comprehensive overview of existing and previous studies on sentiment analysis and text description. To enhance classification accuracy, a new hybrid classification system is proposed, combining multiple classification methods using arcing classifiers. The quality of these classifiers is thoroughly evaluated. In this study, supervised machine learning algorithms are compared with SVD dimensionality reduction, deep learning, and a text mining approach for summarization purposes. The model is built using a labeled Amazon review dataset. The key contribution of this paper lies in its innovative approach of generating text summaries for Amazon reviews while effectively filtering out fraudulent content.",Yes,"논문은 다양한 정량적 평가 방법을 사용하여 분류 시스템의 성능을 평가하고 있으며, supervised machine learning 알고리즘, SVD 차원 축소, 딥러닝, 텍스트 마이닝 기법 등을 비교 분석하고 있습니다. 이러한 내용은 명확히 정량적 평가를 실시하고 있음을 보여줍니다."
Six-Sigma Quality Management of Additive Manufacturing,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9272610,"Quality is a key determinant in deploying new processes, products, or services and influences the adoption of emerging manufacturing technologies. The advent of additive manufacturing (AM) as a manufacturing process has the potential to revolutionize a host of enterprise-related functions from production to the supply chain. The unprecedented level of design flexibility and expanded functionality offered by AM, coupled with greatly reduced lead times, can potentially pave the way for mass customization. However, widespread application of AM is currently hampered by technical challenges in process repeatability and quality management. The breakthrough effect of six sigma (6S) has been demonstrated in traditional manufacturing industries (e.g., semiconductor and automotive industries) in the context of quality planning, control, and improvement through the intensive use of data, statistics, and optimization. 6S entails a data-driven DMAIC methodology of five steps—define, measure, analyze, improve, and control. Notwithstanding the sustained successes of the 6S knowledge body in a variety of established industries ranging from manufacturing, healthcare, logistics, and beyond, there is a dearth of concentrated application of 6S quality management approaches in the context of AM. In this article, we propose to design, develop, and implement the new DMAIC methodology for the 6S quality management of AM. First, we define the specific quality challenges arising from AM layerwise fabrication and mass customization (even one-of-a-kind production). Second, we present a review of AM metrology and sensing techniques, from materials through design, process, and environment, to postbuild inspection. Third, we contextualize a framework for realizing the full potential of data from AM systems and emphasize the need for analytical methods and tools. We propose and delineate the utility of new data-driven analytical methods, including deep learning, machine learning, and network science, to characterize and model the interrelationships between engineering design, machine setting, process variability, and final build quality. Fourth, we present the methodologies of ontology analytics, design of experiments (DOE), and simulation analysis for AM system improvements. In closing, new process control approaches are discussed to optimize the action plans, once an anomaly is detected, with specific consideration of lead time and energy consumption. We posit that this work will catalyze more in-depth investigations and multidisciplinary research efforts to accelerate the application of 6S quality management in AM.",Yes,"논문 초록에서 DMAIC 방법론과 다양한 데이터 분석 기법(딥러닝, 머신러닝, 네트워크 과학 등)을 활용하여 정량적 평가와 품질 관리를 수행하는 내용을 언급하고 있습니다. 이는 정량적 평가를 실시하고 있음을 시사합니다."
VSEST 29110 Tool: Using ChatGPT to Evaluate the Implementation of the ISO/IEC 29110 Work Products,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10646341,"The global software industry is predominantly composed of micro, small, and medium-sized enterprises (MSMEs), highlighting the need for software quality management to ensure the proper functioning and quality of the software. This research focuses on the evaluation of the implementation of the ISO/IEC 29110 standard work products, which is a standard tailored by the ISO/IEC specifically for MSMEs, which improves the software development process by implementing two processes in its basic profile: Project Management (PM) and Software Implementation (SI). Despite this standard being tailored specifically for this type of enterprise, implementing ISO/IEC 29110 faces several challenges, such as a lack of knowledge and difficulties in adequately implementing the work products regarding the compliance of standard criteria, among others. To address these challenges, we introduce VSEST 29110, a web tool designed to evaluate the ISO/IEC 29110 standard implementation work products by leveraging Artificial Intelligence (AI) technologies, specifically the ChatGPT model, provide detailed feedback on compliance with standard criteria, offer suggestions for improvement based on ChatGPT analysis and streamline the implementation process for MSMEs. To achieve this, our research incorporates a systematic literature review and validation through a case study by document analysis, demonstrating VSEST 29110’s effectiveness in enhancing compliance and providing comprehensive feedback compared to auditor recommendations, which impacts 69.33% on average.",Yes,"논문 초록에서 VSEST 29110 도구가 ISO/IEC 29110 표준 작업 산출물의 구현을 평가하기 위해 AI 기술, 특히 ChatGPT를 활용한다고 명시되어 있습니다. 또한, 평가의 효과성을 검증하기 위해 문서 분석을 통한 사례 연구를 수행했다고 언급되어 있어 정량적 평가가 실시되고 있음을 알 수 있습니다."
Deep Learning-Based Traffic Light Detection in a Custom Embedded Hardware Platform for ADAS Applications,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10659816,"Automotive Driver Assistance Systems (ADAS) applications are currently an intensive field of study and innovation. The development of an ADAS is a multidisciplinary task involving electronic hardware design, advanced software implementation, safety considerations and many more. Building an ADAS application implies some challenges that are addressed in this paper. Firstly, all ADAS applications run on highly specific hardware devices embedded in the car with limited computation resources. In this work a novel embedded platform, iADASys, is developed and tested. The platform integrates the elements required to implement an artificial vision based ADAS application such as high performance processor with Deep Learning (DL) computation co-processors or multi-channel high resolution video streaming hardware. Secondly, this work implements an artificial vision application for traffic light detection based on deep neural networks. The model selected in this work is SSD_Mobilenet_V1 and it was trained using Bosch Small Traffic Light (BSTL) dataset. To fulfill real time requirement, the model image input resolution was maintained low at 300×300 pixel. However, the small object size in the dataset together with low resolution lead to poor detection performance. This situation was addressed by fine tuning the model training hyperparameters related to detection scales and aspect ratios. Lastly, the model is deployed in the hardware platform and its performance is measured. Model inference is executed on a specialized mathematical co-processor obtaining the required real time response. The object detection performance is also measured, obtaining promising results.",Yes,"논문 초록에서는 딥 뉴럴 네트워크 모델의 성능을 측정하고, 모델의 추론 성능을 하드웨어 플랫폼에서 평가했다고 명시되어 있습니다. 이는 정량적 평가가 수행되었음을 의미합니다."
Online Adjustment of Two-stage Inference for Knowledge Caching,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8932779,"With the rapid development of deep learning, many deep learning based smart services have emerged. These smart services usually consist of two components, the frontend user device and the back-end cloud server. The front-end device only collects queries from user and sends them to the server, and all operations of deep learning are computed in the server. This design has drawbacks of increasing load on the server and violating personal privacy. Knowledge caching is proposed in our prior work to mitigate these issues, which processes deep learning inference for frequently used queries of users in front-end devices. In this paper, in addition to cache a deep learning model for frequently used and privacy-related queries in the front-end device, we extend our prior work to implement the system on physical device and server. In particular, we design the online adjustment system for managing the status of devices and servers. This allows us to specify the process of caching the model, updating the cached model, and operating the entire system. We evaluate the system which is composed of NVIDIA Jetson Tegra X2 as the front-end device and the back-end server with TITAN Xp to confirm feasibility. As a result of evaluation, our new system shows better accuracy than the general model in the server.",No,"논문 초록에서는 시스템의 성능 평가와 관련된 내용이 언급되었지만, 구체적인 정량적 평가 방법이나 결과 수치에 대한 언급은 없습니다. 따라서 정량적 평가를 실시했다고 보기 어렵습니다."
Design of an Intelligent System for Sports Motion Recognition Based on Data Analysis Algorithms,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10709292,"This study is dedicated to the design and implementation of an intelligent sports motion recognition system based on data analysis algorithms, aiming to enhance the efficiency and safety of sports training and competitions. By collecting and analyzing athletes' motion data, the system is capable of recognizing and classifying various sports movements in real-time, providing coaches and athletes with immediate feedback and suggestions for improvement. The paper begins by reviewing related research in the field of sports motion recognition, particularly the application of machine learning and deep learning methods in motion recognition. Subsequently, we introduce the methodology of the system, including the detailed process of data collection, preprocessing, and algorithm selection. The system design section elaborately describes the architecture of the intelligent system, comprising hardware components and software implementation, as well as user interface design. A series of experiments were conducted to validate the effectiveness of the proposed system, indicating its high accuracy in recognizing a variety of sports movements. Moreover, we discuss the challenges and limitations encountered during the system implementation and propose potential directions for improvement. The results of this research are anticipated to significantly contribute to the scientific level of sports training and the performance of athletes.",Yes,"논문 초록에서 ""a series of experiments were conducted to validate the effectiveness of the proposed system""라고 언급되어 있어, 정량적 평가가 실시되었음을 알 수 있습니다. 또한, 높은 정확도를 언급하며 성과를 수치로 평가했음을 시사합니다."
Possibilistic Similarity Measures for Data Science and Machine Learning Applications,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9028115,"Measuring similarity is of a great interest in many research areas such as in data sciences, machine learning, pattern recognition, text analysis and information retrieval to name a few. Literature has shown that possibility is an attractive notion in the context of distinguishability assessment and can lead to very efficient and computationally inexpensive learning schemes. This paper focuses on determining the similarity between two possibility distributions. A review of existing similarity measures within the possibilistic framework is presented first. Then, similarity measures are analyzed with respect to their capacity to satisfy a set of required properties that a similarity measure should own. Most of the existing possibilistic similarity measures produce undesirable outcomes since they generally depend on the application context. A new similarity measure, called InfoSpecificity, is introduced and the similarity measures are categorized into three main methods: morphic-based, amorphic-based and hybrid. Two experiments are being conducted using four benchmark databases. The aim of the experiments is to compare the efficiency of the possibilistic similarity measures when applied to real data. Empirical experiments have shown good results for the hybrid methods, particularly with the InfoSpecificity measure. In general, the hybrid methods outperform the other two categories when evaluated on small-size samples, i.e., poor-data context (or poor-informed environment) where possibility theory can be used at the greatest benefit.",Yes,"논문 초록에서 ""Two experiments are being conducted using four benchmark databases""라고 언급하며, 실험을 통해 가능성 유사도 측정 방법의 효율성을 평가하고 있음을 명확히 하고 있습니다. 이는 정량적 평가가 수행되고 있음을 보여줍니다."
Which Features of Postural Sway are Effective in Distinguishing Parkinson’s Disease Patients from Controls? An Experimental Investigation,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9669828,"Computer-assisted quantification and analysis of postural sway may support identifying individuals affected by Parkinson’s disease (PD). Balancing, and its associated postural sway, is a complex process that requires the cooperation of several sensory systems in the brain. Unsurprisingly, a neurodegenerative disease can affect such processes, manifesting itself in the postural sway of affected individuals. Different aspects of postural sway can be quantified and represented as features, which can be used to distinguish between patients and controls. Our aim, inspired by a recent systematic literature review, was to experimentally determine whether sampling frequency and visual state had a meaningful impact on the effectiveness of features in distinguishing between the two groups, and whether overall discriminability could be improved using machine learning. We extracted 102 unique features from 78 postural sway recordings and found that the effectiveness (quantified by an effect size and the average area under the receiver operating characteristic curve) with a sampling frequency of 10 Hz was superior to 20, 40, and 100 Hz, though not with high confidence (quantified through Bayesian analysis). We also concluded that effectiveness under the eyes closed condition was higher than the eyes open condition (confirmed through Bayesian analysis), though combining features from both conditions was superior. Finally, we showed that using machine learning to analyse multiple features through feature selection resulted in higher discriminability in almost all cases. The code for these experiments have been released at https://github.com/Wenbo-G/pd-sway-analysis under the MIT license. When using our code, please cite this paper.",Yes,"논문 초록에서 102개의 특징을 추출하고, 이 특징들을 이용하여 파킨슨병 환자와 대조군을 구별하는 정량적 평가를 실시했다고 명확히 언급하고 있습니다. 또한, 효과 크기와 ROC 곡선 아래 면적 등 수치적 지표를 활용하여 평가를 수행한 것으로 보입니다."
Automated Diagnosis System for Outpatients and Inpatients With Cardiovascular Diseases,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9178348,"The identification of heart related diseases is challenging due to several contributory factors associated with patients, medical staff or medical materials used for diagnosis. Electrocardiogram (ECG) signal represents the electrical activity of the heart. It is the most common method used to diagnose patients with cardiovascular abnormalities. The evaluation commonly practiced by trained physicians can be sometimes subjective, time consuming and related to the observer status. This subjectivity can be more critical due to the double signification of the recorded ECG signals, mainly frequency and duration. In our paper, we present a comparative study of different Artificial Intelligence (AI) approaches as a very relevant tool to assist and improve the accuracy of cardiovascular diseases diagnosis. These models are trained on an online available MIT-BIH arrhythmia, normal rhythm sinus and BIDMC congestive heart failure databases and tested on our own collected data consisting of more than 72000 samples recorded in accordance with patients suffering from the same pathologies. The abnormal ECG signals are judged abnormal by comparison with normal heart beats. The work consists of testing and evaluating the performance of trained support vector machine (SVM), convolutional neural networks (CNN), quadratic discriminant, k-nearest neighbors and naïve Bayes as classifiers to correctly and efficiently classify newly unlabeled data. Further, methodology comprises continuous wavelet transform (CWT), discrete wavelet transforms (DWT), maximum overlap discrete transform (MODWT) and autoregressive modelling (AM) as feature extraction techniques. We tested the prelisted methods with principal component analysis (PCA) to evaluate the dimensionality reduction influence on the overall accuracy and runtime measures. The consistency of performance is evaluated using overall accuracy with confidence interval (CI), misclassification cost and runtime. The study resulted on an overall accuracy of 99.92% with a CI of 99.07-100% and 98.63% with a CI of 95.1%-100% using quadratic discriminant and KNN respectively, both with a certainty level of 99%. The developed approach is robust and accurate and can be used for automated diagnosis of cardiovascular diseases.",Yes,"논문은 다양한 AI 기법을 활용하여 심혈관 질환 진단의 성능을 정량적으로 평가하였으며, 전체 정확도, 신뢰구간, 오분류 비용, 실행 시간 등 구체적인 성능 지표를 제시하고 있습니다. 이러한 평가 지표들은 정량적 평가의 실시를 명확히 보여줍니다."
A Deep Learning Approach to Prevent Problematic Movements of Industrial Workers Based on Inertial Sensors,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9892409,"Nowadays, manufacturing industries still face difficulties applying traditional Work-related MusculoSkeletal Disorders (WMSDs) risk assessment methods due to the high effort required by a continuous data collection when using observational methods. An interesting solution is to adopt Inertial Measurement Units (IMUs) to automate the data collection, thus supporting occupational health professionals. In this paper, we propose a deep learning approach to predict human motion based on IMU data with the goal of preventing industrial worker problematic movements that can arise during repetitive actions. The proposed system includes an initial Madgwick filter to merge the raw inertial tri-axis sensor data into a single angle orientation time series. Then, a Machine Learning (ML) algorithm is trained with the obtained time series, allowing to build a forecasting model. The effectiveness of the developed system was validated by using an open-source dataset composed of different motions for the upper body collected in a laboratory environment, aiming to monitor the abduction/adduction angle of the arm. Firstly, distinct ML algorithms were compared for a single angle orientation time series prediction, including: three Long Short-Term Memory (LSTM) methods - a one layer, a stacked layer and a Sequence to Sequence (Seq2Seq) model; and three non deep learning methods - a Multiple Linear Regression, a Random Forest and a Support Vector Machine. The best results were provided by the Seq2Seq LSTM model, which was further evaluated for WMSD prevention by considering 11 human subject datasets and two evaluation procedures (single person and multiple person training and testing). Overall, interesting results were achieved, particularly for multiple person evaluation, where the proposed Seq2Seq LSTM has shown an excellent capability to anticipate problematic movements.",Yes,"논문은 딥러닝 모델을 사용하여 인간의 움직임을 예측하는 데 초점을 맞추고 있으며, 이를 위해 다양한 머신러닝 알고리즘의 성능을 정량적으로 평가하였음을 보여줍니다. 특히, 여러 모델의 예측 성능을 비교하고 최적의 모델을 선정하는 과정이 포함되어 있어 정량적 평가를 실시하고 있음을 알 수 있습니다."
Automating the Diagnosis of Cucumber Plant Diseases Using Machine Learning,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10877122,"Farmers all over the world struggle to fight plant diseases. However, the incorrect use of pesticides can waste time, effort, and money and can also be very harmful to the environment and human health. In this work, we present an empirical study that involves identifying two pathogens related to Cucumbers plant diseases: Powdery Mildew and Alternaria Cucumerina. The study aims to develop a computer-based solution based on deep learning and machine learning algorithms to detect these diseases. To achieve this, a dataset of hundreds of samples was collected from ordinary farms in Beqaa, an agricultural region 15 KM north of Amman, Jordan. Three machine learning models were created in this study using Support Vector Machines (SVM), Logistic Regression (LR), and Multi-layer perceptron algorithms. The constructed models were applied to the dataset after embedding the dataset images using the Convolutional Neural Networks (CNN) InceptionV3 pre-trained model. The model was tested and evaluated using cross-evaluation and F1-Score, CA, AUC, Precision, Recall, and Specificity, which all showed excellent results, particularly using the SVM algorithm. The constructed methods are intended to be deployed to farms in their field condition environments using a CCTV system that can capture images of plants during growth, which can help identify plant diseases at that right stage, which would save time, effort, and money and reduce the impact of wrong and overuse of pesticides on consumers and the environment.",Yes,"논문 초록에서 Support Vector Machines, Logistic Regression, Multi-layer perceptron 등 다양한 머신러닝 모델을 사용하여 정량적 평가를 실시했다고 명시되어 있습니다. 또한, F1-Score, CA, AUC, Precision, Recall, Specificity와 같은 평가 지표를 활용하여 모델 성능을 평가한 점이 이를 뒷받침합니다."
Casting Fault Detection by Deep Convolution Neural Networks,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10009971,"The gold standard for fault identification in the casting process is the human visual inspection though that includes human error and it is time-consuming. In this work, to automate the inspection process in casting production three deep learning-based artificial intelligence systems for detecting manufacturing flaws in submersible pump impellers are created. The suggested casting fault detectors intend to create a system for fault identification in casting goods that are automated, reliable, and accurate. Here on the top view image data of submersible pump impellers, two transfer learning-based convolution neural networks and one lightly structured convolution neural network are created and verified. The performance of the suggested models is measured in terms of accuracy, sensitivity, precision, and f1-score, and then compared with the state-of-the-art works. The best performance among the proposed casting fault detection systems are 99.88% accuracy, 100% precision, 99.77% recall, and 99.88% f1-score in binary classification and this outperformed previous related work.",Yes,"논문 초록에서 성능 평가를 위해 정확도, 민감도, 정밀도, F1-스코어 등 정량적 지표를 사용하여 모델의 성능을 평가했다고 명시되어 있습니다. 이는 정량적 평가를 실시하고 있음을 보여줍니다."
Optic disc determination in retinal images with deep features,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8404339,"Deep learning has attracted so many researchers in the image processing and machine learning communities. So many new applications have been presented with DL day by day. Thus, in this paper, we propose a hybrid approach to detect the optic disc in retinal images by using deep Convolutional Neural Networks (CNN) and K-Nearest Neighbor (KNN) classifier. More specifically, we extract effective deep features from the fc6 layer of a pre-trained CNN model and classify them into optic disc and non-optic disc classes with KNN classifier. The AlexNet is considered for the pre-trained CNN model which extracts 4096 dimensional feature vector for each patch image. To this end, three retinal image datasets are considered for construction of the training and test sets. 500 optic disc patches and 1565 non-optic disc patches of size 280×280 are collected and then resized to 227×227 for feature extraction and construction of the KNN classifier setting. In addition, 165 retinal images are used for testing the presented hybrid approach. A series of experimental works have been carried out for showing the efficiency of the proposed approach. Accuracy, sensitivity and specificity values are calculated. According to the obtained results, 95.74% accuracy, 84.46% sensitivity and 99.08% specificity values are recorded. These results are quite encouraging for related future works.",Yes,"논문 초록에서 정확도, 민감도, 특이도와 같은 정량적 평가 지표를 계산했다고 명시되어 있습니다. 이러한 지표들은 모델의 성능을 수치적으로 평가하는 정량적 평가의 대표적인 예입니다."
Smart Ice Cloud Sensing (SMICES): An Overview of its Submillimeter Wave Radiometer,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9883671,"The Smart Ice Cloud Sensing (SMICES) is an active/passive sensor. SMICES is sponsored by NASA Earth Science Technology Office (ESTO) under Instrument Incubator Program 19 (IIP-19) awarded to Northrop Grumman Corporation (NGC) and Jet Propulsion Laboratory (JPL). The instrument is designed to measure upper tropospheric and lower stratospheric cloud ice and water vapor. SMICES uses a suite of passive radiometers that are constantly conically scanning to locate ice clouds. The ice clouds are located using an artificial intelligence controller that identifies key labels related to the ice cloud. Once an ice cloud is identified, the artificial intelligence controller activates and targets the on-board radar. While the SMICES instrument is currently being developed for an airborne demonstration, the final goal is to deploy it as a small satellite (SmallSat) instrument in low-Earth orbit (LEO). The onboard AI controller will significantly reduce DC power consumption of the satellite mission. This will enable the SMICES system to be hosted on a smaller platform with fewer solar cells and significantly drive down mission costs while maintaining the quality of scientific data. This work presents the latest development on the SMICES microwave radiometer.",No,"초록에서는 SMICES 시스템이 ice cloud를 감지하기 위해 인공지능 컨트롤러와 레이더를 사용하는 내용이 언급되어 있지만, 구체적인 정량적 평가 방법이나 수치 데이터 분석에 대한 언급은 없습니다. 따라서 논문이 정량적 평가를 실시하고 있다고 보기 어렵습니다."
Micro Expression Recognition Using Convolution Patch in Vision Transformer,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10250810,"Humans possess an intrinsic ability to hide their true emotions. Micro-expressions are subtle changes in facial muscles that are involuntary by nature and easy to hide. To address these issues, several machine and deep learning models have been proposed in the past few years. Convolution neural network (CNN) is a deep learning method that has widely been adopted in vision-related tasks due to its remarkable performance. However, CNN suffers from overfitting due to a large number of trainable parameters. Additionally, CNN cannot capture global information with respect to an input image. Furthermore, the identification of important regions for the classification of micro-expressions is a challenging task. Selfattention mechanism addresses these issues by focusing on key areas. Furthermore, specific transformers, known as vision transformers are widely explored in vision-related applications. However, existing vision transformers divide an input image into a fixed number of patches due to which local correlation of image pixels is lost. Further, a vision transformer relies on self-attention mechanism which effectively captures global dependencies but does not exploit the local spatial relationships in an image. In this work, we propose a vision transformer based on convolution patches to overcome this problem. The proposed algorithm generates c number of feature maps from input images using c filters through convolution operation. These feature maps are then applied to a transformer model as fixed-size image patches to perform classification. Thus, the proposed architecture leverages advantages of both convolutional layers and transformer, and captures both spatial information and global dependencies respectively, leading to improved performance. The performance of the proposed model is evaluated on three benchmark datasets: CASMEI, CASME-II, and SAMM and compared with state-of-the-art machine and deep learning models, which generated classification accuracy of 95.97%, 98.59%, and 100%, respectively.",Yes,"논문 초록에서 제안된 모델의 성능을 평가하기 위해 세 가지 벤치마크 데이터셋에서 실험을 수행하고, 각각의 데이터셋에 대해 높은 분류 정확도를 보고하고 있습니다. 이는 정량적 평가를 실시했음을 명확히 보여줍니다."
Convolution Neural Networks based lungs disease detection and Severity classification,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10128188,"Classification is a crucial component of Computer Aided Diagnosis (CADx) systems. This phase comprises the extraction of features. Deep features have emerged as a new topic of study in numerous disciplines, including medical imaging. However, these works contain flaws, such as excessive classification, and do not reflect the real world. This paper provides an overview of deep learning for detecting lung illness in medical photos. In the past five years, just one review article has been published on deep learning for lung illness diagnosis. We investigate utilizing deep learning to detect and categorize Convolution neural network (CNN) numerous lung illnesses from chest X-ray images. We developed a pipeline for segmenting chest X-ray (CXR) images before classification and compared the performance of our framework to that of existing techniques. To recover lung characteristics, the Binary Spotted Hyena optimizer (BSHO) was used in this study. We demonstrated that simple models and classifiers, such as shallow CNN, can compete with complex systems. Furthermore, we validated our method using publicly available lung datasets from Shenzhen and Montgomery and compared its efficacy to that of existing methods. Despite having fewer trainable parameters, our technique outperformed the top performing models trained on the Montgomery dataset in terms of accuracy. In addition, although being computationally cheaper, our CNN-BSHO model performed nearly as well as the top solution on the Shenzhen dataset. This research employed four classifiers, including Support Vector Machine (SVM), Nave Bayes, Random Forest, and Visual Geometry Group (VGG). Using CNN-BSHO, an accuracy of 98.324% was reached.",Yes,"논문 초록에서 다양한 분류기(SVM, Nave Bayes, Random Forest, VGG)를 사용하여 성능 평가를 수행했다고 언급하며, 정확도와 같은 정량적 지표를 제시하고 있습니다. 이는 정량적 평가가 실시되고 있음을 보여줍니다."
Cyber Situation Awareness with Active Learning for Intrusion Detection,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9020599,"Intrusion detection has focused primarily on detecting cyberattacks at the event-level. Since there is such a large volume of network data and attacks are minimal, machine learning approaches have focused on improving accuracy and reducing false positives, but this has frequently resulted in overfitting. In addition, the volume of intrusion detection alerts is large and creates fatigue in the human analyst who must review them. This research addresses the problems associated with event-level intrusion detection and the large volumes of intrusion alerts by applying active learning and cyber situation awareness. This paper includes the results of two experiments using the UNSWNB15 dataset. The first experiment evaluated sampling approaches for querying the oracle, as part of active learning. It then trained a Random Forest classifier using the samples and evaluated its results. The second experiment applied cyber situation awareness by aggregating the detection results of the first experiment and calculating the probability that a computer system was part of a cyberattack. This research showed that moving the perspective of event-level alerts to the probability that a computer system was part of an attack improved the accuracy of detection and reduced the volume of alerts that a human analyst would need to review.",Yes,"논문 초록에서 두 실험을 통해 샘플링 방법과 분류기 성능 평가, 그리고 공격 확률 계산 등 정량적 평가를 수행한 내용을 언급하고 있습니다. 이러한 실험 결과를 통해 성능 향상과 정확도 개선을 검증하는 것으로 보아 정량적 평가를 실시하고 있다고 판단됩니다."
Automate Traditional Interviewing Process Using Natural Language Processing and Machine Learning,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9418115,"Nowadays, almost everything is equipped with technology. People can save time by using modern day technological applications in the most convenient way. Smart Interviewing System is one such software/tool which automates the traditional interviewing process using modern Natural Language Processing techniques and deep learning applications. The system will be mainly beneficial for interviewers and HR management employees working for different organizations who conduct technology related interviews. The system works with human voice and writing patterns. The system converts human language into system understandable text-based inputs, and these are used as inputs in the automated interviewing process. The system then checks the accuracy of the answers which candidates provided on the both oral interviews/ technical interviews and written tests. Later, the system automatically predicts scores for each answer using concepts of the deep learning. Interviewers can reduce the effort that they have to put in for selecting the most suitable candidates who are qualified enough to work with their organization. SIS is developed based on modern DL and NLP concepts using Python programming language alongside with ReactJS Framework. This system checking and evaluating candidate more accurately in every stage of the interview using advance evaluation parameters than human oriented evaluations. Above process lead system to find more human errors which critically can be affected to future of the organizations. Because of that, it can be led organizations to find best human resources comparing to the traditional interviewing process by sacrificing less time and effort.",Yes,"논문 초록에서 시스템이 후보자의 답변에 대해 정량적 평가를 실시한다고 명시되어 있으며, 딥러닝을 활용하여 답변의 정확도를 체크하고 점수를 예측하는 과정을 포함하고 있기 때문에 정량적 평가가 수행되고 있다고 판단됩니다."
Evaluation of Intelligent Resource Allocation Methods for Interference-Limited Satellite Networks,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10376128,"Satellite systems serve as a crucial tool for non-terrestrial networks, offering a solution to areas where terrestrial network coverage is limited. With the advanced capabilities of modern satellite systems that leverage frequency reuse across multiple beams, the provision of efficient 6G services becomes possible worldwide. However, achieving this efficiency requires an optimal resource allocation (RA) strategy that considers the interference-limited environment and the constraints of limited power and bandwidth. This research paper provides a comprehensive review of existing studies on RA problems in interference-limited multi-beam satellite systems, specifically exploring low-complexity methods. The paper thoroughly investigates the operational principles underlying various RA methods that use simple machine learning algorithms. Additionally, it conducts an in-depth analysis of the advantages and disadvantages associated with these methods. To validate the effectiveness of the proposed low-complexity techniques, the paper presents simulation results obtained from a multi-beam satellite system operating in a Low Earth Orbit (LEO). These results serve as evidence for the efficacy of employing simple RA methods based on linear machine learning.",Yes,논문 초록에서 시뮬레이션 결과를 통해 제안된 저복잡도 자원 할당 방법의 효과를 검증했다고 명시되어 있습니다. 이는 정량적 평가가 수행되었음을 의미합니다.
Gas Discrimination & Quantification using Sensor Array with 3D Convolution Regression Dual Network,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9660938,"Smart sensor system design requires intelligent data processing, which analyzes raw time-series sensor data to efficiently and precisely discriminate and quantify target gases. The work presented here utilizes the response of twin gas sensor arrays for gases such as ethanol, ethylene, methane, and carbon monoxide to discriminate and quantify the target gases. We propose a 3D convolution neural-based regression dual network (3D-CNRDN) for both gas quantification and discrimination. The spatiotemporal correlation of sensor array responses inspired us to design the deep neural network for the gas concentration estimation model. The sensor array set is spatially correlated, and all the twin array responses are temporally related. 3D-CNRDN uses raw time-series gas sensor array data. The data is fed to the network as the 3D pattern, which contains 2D spatial information varying with third dimension time to recognize patterns that eventually predict the concentration. The model evaluation shows that the proposed methods are an effective technique for gas quantification and identification with RMSE=0.3179 and classification accuracy 94.37%. Furthermore, the proposed method outperforms and provides higher discrimination accuracy and lower RMSE than other machine learning and deep learning methods.",Yes,"논문 초록에서 가스 농도 추정을 위한 정량적 평가를 RMSE(0.3179)를 통해 수행했다고 명시되어 있습니다. 또한, 가스 구별 정확도(94.37%)와 RMSE를 활용한 평가가 언급되어 있어 정량적 평가가 실시되고 있음을 알 수 있습니다."
Fairness Meets Cross-Domain Learning: A Benchmark of Models and Metrics,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10487929,"Deep learning-based recognition systems are deployed at scale for real-world applications that inevitably involve our social life. Although of great support when making complex decisions, they might capture spurious data correlations and leverage sensitive attributes (e.g., age, gender, ethnicity). How to factor out this information while maintaining high performance is a problem with several open questions, many of which are shared with those of the domain adaptation and generalization literature which aims at avoiding visual domain biases. In this work, we propose an in-depth study of the relationship between cross-domain learning (CD) and model fairness, by experimentally evaluating 14 CD approaches together with 3 state-of-the-art fairness algorithms on 5 datasets of faces and medical images spanning several demographic groups. We consider attribute classification and landmark detection tasks: the latter is introduced here for the first time in the fairness literature, showing how keypoint localization may be affected by sensitive attribute biases. To assess the analyzed methods, we adopt widely used evaluation metrics while also presenting their limits with a detailed review. Moreover, we propose a new Harmonic Fairness (HF) score that can ease unfairness mitigation model comparisons. Overall, our work shows how CD approaches can outperform state-of-the-art fairness algorithms and defines a framework with dataset and metrics as well as a code suite to pave the way for a more systematic analysis of fairness problems in computer vision (Code available at: https://github.com/iurada/fairness_crossdomain).",Yes,"논문 초록에서 여러 평가 지표를 사용하여 방법들을 평가했다고 명시되어 있으며, 새로운 공정성 점수인 Harmonic Fairness (HF) 점수도 제안하고 있어 정량적 평가를 실시하고 있음을 알 수 있습니다. 따라서, 이 논문은 정량적 평가를 수행하는 것으로 판단됩니다."
A Hybrid Approach for Usability Evaluation of Learning Management Systems Using Machine Learning Algorithms,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10893160,"This research full paper describes a hybrid approach based on data, questionnaire answers, and machine learning algorithms to predict usability scores in Learning Management Systems (LMSs) to improve student learning and satisfaction. Students need to achieve their learning goals by interacting with LMSs. To attain these goals, usability evaluation ensures effectiveness (task completion), efficiency (time measurement), and satisfaction (positive attitude). Usability evaluation usually follows questionnaires, user testing of the LMS, and expert reviews. Although these methods are widely used due to several benefits, they face challenges related to trying these software systems multiple times until the system satisfies student needs, human subjectivity perception, and lack of software system adaptability. We propose this hybrid approach to face these challenges, promote student engagement with the system, and create a better design in the LMS courses. The aim is to identify features extracted from the LMS to predict usability scores with machine learning techniques. We evaluated this strategy through a case study with data collected from undergraduate students at a public university in the United States. The students' tasks were answering a quiz, posting in a forum, and uploading an assignment. These activities in the LMS allow the extraction of ten features into the machine learning algorithms. These attributes are time quiz, time forum, time assignment, grade quiz, word count message post, file size, file type, clicks module quiz, clicks module forum, and clicks module assignment. The four targets are from scores of the System Usability Scale and UseLearn questionnaires. Random Forest produces the best performance of average mean square error and root mean square error among machine learning algorithms. The results are promising, though there are alternatives for improvements. Our proposed approach contributes to the engineering and computing education field by providing a predictive tool for usability scores to improve the student learning experience and the components of the LMS.",Yes,"논문은 머신러닝 알고리즘을 활용하여 학습관리시스템(LMS)의 사용성 점수를 예측하는 정량적 평가를 실시하고 있습니다. 구체적인 성능 평가 지표(평균제곱오차, 루트평균제곱오차 등)를 통해 정량적 분석이 수행된 것을 확인할 수 있습니다."
SMOTE-MRS: A Novel SMOTE-Multiresolution Sampling Technique for Imbalanced Distribution to Improve Prediction of Anemia,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10721227,"Anemia is a widespread worldwide health problem that has a substantial effect on groups who are particularly susceptible. The objective of this work is to improve the diagnosis of anemia by creating a hybrid machine learning model called SMOTE-MRS. This model combines SMOTE, K-Means Clustering, and Random Over Sampling techniques. The model aims to enhance diagnosis accuracy and ultimately improve healthcare outcomes, specifically in Indonesia, by resolving the imbalance in the dataset. The SMOTE-MRS model mitigates the issue of imbalanced datasets by combining the techniques of SMOTE, K-Means clustering, and random oversampling. K-Means clustering first divides the dataset into K groups. SMOTE then produces artificial instances of the underrepresented class inside every cluster. Random oversampling is a technique that replicates instances of the minority class to make the dataset balanced and enhance the training of machine learning models. The research evaluated the performance of Random Forest (RF), Naïve Bayes (NB), and Support Vector Machine (SVM) models in predicting anemia, using the SMOTE-MRS technique. The SMOTE-MRS algorithm exhibited outstanding performance, achieving scores of 0.973 for Accuracy, 0.990 for Recall, 0.968 for Precision, 0.979 for F1-Score, and 0.994 for AUC. These findings demonstrate its exceptional capacity to effectively handle class imbalance and enhance prediction accuracy. The SMOTE-MRS algorithm has outstanding performance on a wide range of datasets, such as those related to anemia, diabetes, breast cancer, and kidney failure datasets. This showcases its robustness and versatility in many predictive modeling scenarios. The findings demonstrate that SMOTE-MRS outperforms standard approaches such as SMOTE, SMOTE-ENC, and ROS in effectively addressing class imbalance. The research affirms the better performance of SMOTE-MRS in addressing class imbalance for the prediction of anemia. SMOTE-MRS surpasses traditional approaches, attaining exceptional results in all measures. Future studies should prioritize the optimization of SMOTE-MRS to minimize small performance declines, conduct a comparative analysis with other approaches, and validate its adaptability across various domains. Furthermore, it is advisable to include SMOTE-MRS in deep learning models and real-time applications.",Yes,"논문 초록에서 여러 성능 지표(Accuracy, Recall, Precision, F1-Score, AUC)를 사용하여 모델의 성능을 정량적으로 평가했다고 명확히 언급하고 있습니다. 이는 정량적 평가를 실시하고 있음을 보여줍니다."
Detection of Cyber-attacks using Deep Convolution in Honeyed Framework,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10150916,"A network-related environment called a “honeyed framework” served to defend official network resources against harm. This framework creates a scenario that motivates the intrusive person to engage in resource-stealing activity. To recognise an unauthorised assault, this framework applied the Attack-detection-procedure. Here, we attempt to identify DoS attacks using the suggested Honeyed framework system. In order to safeguard your network from assaults, NIDS (Network Intrusion Detection System) is one of the first security solutions to make it easier to identify intrusions. In this work, we offer a system that reveals an assault while validating the defense against it. The new cyber security benchmark IoT dataset is used in this white paper to assess the most recent machine learning techniques. This work’s major goal is to develop an architecture that can foresee and stop DDOS attacks, malware, and botnet attacks using these Honeyed designs. Deep Convolution Reinforcement Neural Networks are used for network surveillance and to categories network users from potential threats (DCRNN). A two-step technique of network understanding is used to enhance the functionality of the suggested solution. DSAE (Deep Sparse Auto Encoder) is used for feature engineering challenges at the initial step of the processing process, data pre-processing. The Deep Convolution Reinforcement Neural Network learning strategy is used in the second step to facilitate categorization. The honeyed firewall and web server are then implemented, following the deployment of the honeyed framework. The DCRNN deployment is finished, and users can now be monitored and analyzed as well as data on network users collected. In this study, data from a loT environment was used to test the effectiveness of the published technique. This data included the heterogeneous datasets ""IoT-23,"" ""NetML-2020,"" and ""LITNET-2020."" With contemporary methods for network discovery, the statistical relevance of this strategy is evaluated.",Yes,"논문 초록에서 딥러닝 기법을 활용하여 네트워크 공격을 감지하는 시스템을 개발하고 있으며, 이를 평가하기 위해 다양한 IoT 데이터셋을 사용하여 정량적 평가를 실시한 것으로 보입니다. 따라서, 정량적 평가가 수행되고 있다고 판단됩니다."
Explaining Cyber Risks in Transportaion 5.0: A Data Driven Approach,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10848812,"The primary objective of the research is to explore the cybersecurity risks associated with AI-enabled intelligent transportation systems (Transportation 5.0) within the context of developing future smart cities. In Transpiration 5.0, the critical infrastructure increasingly relies on automated systems, which enhances the threat of ransomware attacks, specifically targeting vital cyber-physical systems (CPS), smart grids, and intelligent transportation systems (ITS). The paper explores transportation ransomware attack data to incorporate advanced visualization and extract relevant data attributes for cyber risk evaluation. The study uses the NIST risk management framework and ISACA risk quantification to develop a cyber risk evaluation method. With the findings of the literature review, the research highlights ransomware as a significant threat to intelligent transportation systems (ITS), given the negative impact of malware on IoT, IIoT, and network-connected devices. While substantial research exists on malware detection techniques, performance, accuracy, and cloud-based strategies, it’s crucial for organizations to comprehend the risks of ransomware attacks to implement effective security controls and enable cyber excellence. The research executes exploratory data analysis on the given dataset to find out the correlation between different attributes such as severity, data loss, affected systems, and ransom amount for evolving a risk method to evaluate cyber risk. The focus is to simplify the risk evaluation process by fitting the right data attributes into a standard risk management framework and risk formula for broader reusability. The method was applied to different transportation modes to calculate the risk scores respectively and generate insights accordingly. The overall analysis supports that effective risk predictions along with consistent monitoring can help to control ransomware attack incidents and improve cyber resiliency. This paper proposes a data-driven approach for cyber risk assessment in transportation, applicable to other cyber-attacks. However, it highlights the need of synthetic data integration for a generic solution.",Yes,"논문 초록에서 데이터 분석, 데이터 속성 추출, 탐색적 데이터 분석 등 정량적 평가를 수행한 내용이 명확하게 언급되어 있습니다. 또한, 위험 점수 계산과 관련된 수치적 방법론을 적용하여 정량적 평가를 실시하고 있음을 알 수 있습니다."
Evaluation of Topic Models and Information Retrieval Methods in Support of Lessons Learned and Knowledge Management,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10608962,"A lesson learned is the application of previous experiences to improve decision-making and organizational efficiency. The lack of learning from past organizational mistakes and successes has contributed to extended schedules, increased program costs, and excessive program rework. Applying the lessons learned process is critical in meeting program objectives, mitigating risks, and improving organizational effectiveness by avoiding costly errors. This type of learning requires communication between the source of the knowledge and the receiver(s) of the lesson to magnify the benefits of a lesson learned. A significant factor in gathering, maintaining, sharing, and reviewing lessons learned is for an organization to implement a knowledge management system or a lessons learned database. This system/database allows the team members access to all previous lessons learned, which, as a result, allows the organization to learn from past mistakes/successes by applying that knowledge in the present and future. There is limited research on an automatic lessons learned/knowledge management database that removes the need for users to perform manual searching and provides highly relevant results to the users. One significant step in constructing an automatic lessons learned/knowledge management database is the implementation of topic models. Topic models are machine learning algorithms produced to identify the foundational semantic structures of corpora using Bayesian hierarchical modeling. This research evaluates topic models intending to improve relevancy in lessons learned query searches in knowledge management/lessons learned databases. Widely utilized topic models such as the Latent Dirichlet Allocation (LDA) and Latent Semantic Indexing (LSI) are investigated in this paper in addition to the Term Frequency – Inverse Document Frequency (TF-IDF), Hierarchical Dirichlet Process (HDP), and Random Projections (RP) topic models. The TF-IDF topic model outperformed all topic models evaluated in this work.",Yes,"논문 초록에서 여러 가지 토픽 모델(예: LDA, LSI, HDP, RP)과 관련된 평가를 수행했다고 명시되어 있으며, 특히 TF-IDF 모델의 성능 비교 결과를 제시하고 있어 정량적 평가가 실시된 것으로 보입니다. 이러한 내용은 평가와 비교를 위한 수치적 분석이 포함되었음을 시사합니다."
Heart Disease Diagnosis Using Deep Learning,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10434227,"Cardiovascular disease is a leading cause of death in the general population, and late detection significantly impacts the patient survival rates. Factors like age, sex, cholesterol level, sugar level, and heart rate influence heart problems, making expert evaluation challenging due to the high number of variables. This manuscript proposes a novel approach using deep learning methods and feature augmentation techniques for evaluating patient’s risk of cardiovascular disease. The results show a significant improvement, achieving a precision of 90%, outperforming other state-of-the-art methods by 4.4%. Given the complexity and severity of cardiovascular diseases, an efficient and accurate heart attack prediction system becomes crucial. In this context, the paper utilizes Recurrent Neural Networks (RNN) as a powerful classification algorithm in the domain of deep learning to predict the likelihood of heart-related diseases in patients. The proposed model combines deep learning and data mining to provide accurate results with minimal errors, addressing the limitations of existing medical data mining and machine learning techniques. This work serves as a direction and precedent for the development of a new generation heart attack prediction platform, potentially aiding in the early detection and treatment of heart diseases, especially silent heart attack, which often goes undiagnosed and poses significant challenges to healthcare professionals.",Yes,"논문 초록에서 정량적 평가를 위해 정확도(precision)와 성능 향상 수치(4.4%)를 제시하고 있으며, 딥러닝 모델의 성능을 수치로 평가하는 내용이 포함되어 있습니다. 이는 정량적 평가를 실시하고 있음을 보여줍니다."
Generating Healthcare Time Series Data for Improving Diagnostic Accuracy of Deep Neural Networks,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9421374,"Data scarcity and class imbalance are common occurrences in healthcare datasets and have an adverse effect on classification performance of machine learning models. Artificial data generation in various applications can be used to handle these challenges. This article proposes a guided evolutionary synthesizer (GES), a tool derived from principles of genetic algorithm, and designed to generate artificial healthcare time series data for improving classification performance of machine learning models. We conducted a series of promising and confirmatory preliminary experiments performance using traditional machine learning and nonresidual convolutional neural network models to evaluate the effectiveness of GES synthetic on data classification. Motivated by the preliminary results, we conducted eight detailed experiments using residual neural network (ResNet), which demonstrated the flexibility of GES and the effectiveness of GES synthetic data in improving the classification performance of deep neural networks. These experiments use GES generated electrocardiogram (ECG) and electroencephalogram (EEG) datasets. Our findings show that models trained with GES synthetic data performed better than models trained with regular perturbed data, had better diagnostic performance for both EEG and ECG datasets, achieved better performance with lower training volume for EEG dataset, eased learning biases seen in the literature for ECG normal sinus and premature ventricular complex rhythms, and had better classification outcomes than comparable related work models trained with similar ECG classes.",Yes,"논문은 GES를 이용한 인공 데이터 생성의 효과를 평가하기 위해 여러 실험을 수행하였으며, 이 실험들에서 모델 성능을 정량적으로 비교 분석하였음을 보여줍니다. 따라서, 정량적 평가가 실시되고 있다고 판단됩니다."
Smart Contract Vulnerability Detection Using Deep Learning Algorithms on EVM bytecode,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10577852,"In the quickly changing world of blockchain technology, it is critical to guarantee the security of the self-executing contracts, written in programming languages like Solidity called smart contracts. Not all security vulnerabilities in smart contracts will be found by human code reviews and security audits using traditional methods. Deep learning networks have become a promising answer to this problem. In this paper, we present the architecture of two models—using convolutional and recurrent neural networks—that are intended to effectively discover five vulnerabilities in smart contracts. To train and validate the models, we used a dataset that includes 106474 audited smart contracts taken from the public Ethereum blockchain. Instead of the source code that is typically used by most deep learning-based solutions, the models receive input in the form of Ethereum Virtual Machine (EVM) bytecode. Across all five vulnerabilities, the Recurrent Neural Network model has an average micro F1-score of 0.93, whereas the Convolutional Neural Network achieves an average micro F1-score of 0.89. Through comparative research with various deep learning systems and static analysis tools, we have determined that EVM bytecode may be leveraged as a feature to detect vulnerabilities in smart contracts.",Yes,"논문은 딥러닝 모델을 사용하여 스마트 계약의 취약점을 정량적으로 평가하는 성능 지표인 F1-score를 제시하고 있으며, 이를 통해 모델의 성능을 수치로 평가하고 있음을 보여줍니다. 따라서, 정량적 평가를 실시하고 있다고 판단됩니다."
5G Networks Security Mitigation Model: An ANN-ISM Hybrid Approach,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10841375,"The advent of Fifth-Generation (5G) networks has introduced significant security challenges due to increased complexity and diverse use cases. Conventional threat models may fall short of addressing these emerging threats effectively. This paper presents a new security mitigation model using artificial neural network (ANN) with interpretive structure modeling (ISM) to improve the 5G network security system. The main goal of this study is to develop a 5G network security mitigation model (5GN-SMM) that leverages the predictive capabilities of ANN and the analysis of ISM to identify and mitigate security threats by providing practices in 5G networks. This model aims to improve the accuracy and effectiveness of security measures by integrating advanced computational practices with systematic modeling. Initially, a systematic evaluation of existing 5G network security threats was conducted to identify gaps and incorporate best practices into the proposed model. In the second phase, an empirical survey was conducted to identify and validate the systematic literature review (SLR) findings. In the third phase, we employed a hybrid approach integrating ANN for real-time threat detection and risk assessment and utilizing ISM to analyze the relationships between security threats and vulnerabilities, creating a structured framework for understanding their interdependencies. A case study was conducted in the last stage to test and evaluate 5GN-SMM. The given article illustrates that the proposed hybrid model of ANN-ISM shows a better understanding and management of the security threats than the conventional techniques. The component of the ANN then comes up with the potential of the security breach with improved accuracy, and the ISM framework helps in understanding the relationship and the priorities of the threats. We identified 15 security threats and 144 practices in 5G networks through SLR and empirical surveys. The identified security threats were then analyzed and categorized into 15 process areas and five levels of 5GN-SMM. The proposed model includes state-of-the-art machine learning with traditional information security paradigms to offer an integrated solution to the emerging complex security issues related to 5G. This approach enhances the capacity to detect threats and contributes to good policy enforcement and other risk-related activities to enhance safer 5G networks.",Yes,"논문 초록에서 인공지능 신경망(ANN)과 계층적 구조 모델링(ISM)을 활용하여 정량적 평가와 실험적 검증을 수행했다고 명시되어 있습니다. 또한, 사례 연구를 통해 제안된 모델의 성능을 평가하는 과정이 포함되어 있어 정량적 평가가 실시된 것으로 판단됩니다."
Big Data and the Application of IoT Systems,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10579030,"As IoT devices become more common, security must be a priority. Many devices lack built-in protection due to design oversights and resource constraints. These limitations make them vulnerable to hacking and unable to support sophisticated security software or automatic updates. Attackers exploit these weaknesses to access and manipulate customer settings despite some devices using SSL/TLS protocols. With over 25 trillion IoT devices, achieving complete security is nearly impossible. Intrusion detection and prevention systems struggle to keep up with new attack methods, leaving devices vulnerable to various attacks like Mirai Botnet, Denial of Service, Synflood, and Man in the Middle. Furthermore, intelligent home automation systems, medical Internet devices, and building automation equipment handle sensitive user information that must be appropriately monitored. As a result, proposing an intrusion detection system for Internet of Things devices is vital to limiting the threat surface and protecting consumer data. Many literature reviews have proposed a solution using Deep Learning (DL) models. However, we found that Deep Learning requires high processing power, which is unsuitable for constraint devices. This work proposes a framework using machine learning classifiers to detect various attacks. We evaluated the classifiers against a variety of attack data. The accuracy of each classifier was recorded as follows: LR (Logistic Regression) has 97%, SVC (Support Vector Machine) has 98%, Extreme Gradient Boosting Random Forest (XGBRF) has 99%, K-Nearest Neighbors (KNN) has 99%, AdaBoost (AB) is 99% accurate, Random Forest (RF) has 99%, Decision Tree (DT) has 99%, and Extreme Gradient Boosting (XGB) has 99%.",Yes,"논문 초록에서 여러 머신러닝 분류기들의 정확도를 평가하는 정량적 평가가 수행되었음을 명확히 언급하고 있습니다. 각 분류기의 성능이 수치로 제시되어 있어, 정량적 평가를 실시한 것으로 판단됩니다."
Intelligent Feedback and Evaluation for the Assessment and Improvement of Student Peer Reviews,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10747900,"Research into peer evaluation shows positive effects on student achievement and attitudes. To foster authentic peer reviews, students need to know their peer reviews will be seen and graded. However, the time-consuming nature of assessing feedback makes it impractical for instructors to evaluate thousands of feedback items generated by students in massive online courses. This paper describes the development of a deep learning (DL) tool to help assess the quality of feedback written by students in a peer-review system. We report tool development progress built upon years of student meta-feedback data that consists of numeric scores and written evaluations of the feedback received. We describe: the underlying DL platform, the labeled data set with which the algorithm was trained, the supervised training process, and the performance evaluation of the resulting three-class multiclass classifier. The evaluation showed satisfactory reliability when compared to student meta-feedback evaluations. We conclude by identifying issues to be addressed and the applications for this tool in massive online courses, including but not limited to giving formative feedback to students as they evaluate peers and helping identify underperforming reviewers.",Yes,"논문은 딥러닝 기반 평가 도구를 개발하고, 그 성능을 평가하는 과정을 포함하고 있어 정량적 평가를 실시하고 있음을 보여줍니다. 특히, 세 가지 분류기 성능 평가와 관련된 수치적 지표를 언급하고 있어 정량적 평가가 수행되고 있음을 알 수 있습니다."
A Closer Look at Evaluating the Bit-Flip Attack Against Deep Neural Networks,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9897693,"Deep neural network models are massively deployed on a wide variety of hardware platforms. This results in the appearance of new attack vectors that significantly extend the standard attack surface, extensively studied by the adversarial machine learning community. One of the first attack that aims at drastically dropping the performance of a model by targeting its parameters stored in memory, is the Bit-Flip Attack (BFA). In this work, we point out several evaluation challenges related to the BFA. First, the lack of an adversary’s budget in the standard threat model is problematic, especially when dealing with physical attacks. Moreover, since the BFA presents critical variability, we discuss the influence of some training parameters and the importance of the model architecture. This work is the first to present the impact of the BFA against fully-connected architectures that present different behaviors compared to convolutional neural networks. These results highlight the importance of defining robust and sound evaluation methodologies to properly evaluate the dangers of parameter-based attacks as well as measure the real level of robustness offered by a defense.",No,"초록에서는 평가 방법론에 대한 논의와 평가의 중요성을 강조하지만, 구체적인 정량적 평가 방법이나 수치적 결과를 제시하는 내용은 포함되어 있지 않습니다. 따라서, 논문이 정량적 평가를 실시하고 있다고 보기 어렵습니다."
Survey of Machine Learning-Based Predictions of Photovoltaic Power Outputs,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10374517,"Solar Photovoltaic (PV) energy has been deployed at exponential rates since the last decade to produce power from renewable and green resources as a contribution to the causes of climate change and global warming. PV power generation is subject to very dynamic changes due to its dependence on the environment and the geography, often fluctuating erratically. The variability of PV power generation poses electric grid system stability, reliability, and planning downturns. Hence, grid operations could operate at higher levels of performance and efficiencies through adequate grid scheduling that primarily relies on accurate prediction of photovoltaic power output. Due to the paramount importance of the topic, the research community investigated several forecasting strategies that rely on numerical methods, probabilistic methods, physical models and machine learning-based (ML-based) techniques. The present paper presents a comparative review of the literature targeting ML-based algorithms for short-term PV power output prediction. A complementary case study exposes a much-needed homogeneous comparison of the state-of-the-art ML-based forecasters, trained on a dataset from the University of Liège. Model structural enhancement for the state-of-the-art is proposed and evaluated in the light of literature findings.",Yes,"논문 초록에서 여러 예측 전략과 특히 머신러닝 기반 알고리즘을 대상으로 한 비교 연구를 수행하고 있음을 언급하고 있습니다. 또한, 사례 연구를 통해 ML 기반 예측 모델의 성능 평가와 비교를 실시하는 것으로 보아, 정량적 평가가 이루어지고 있음을 알 수 있습니다."
VANET Meets Deep Learning: The Effect of Packet Loss on the Object Detection Performance,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8746657,"The integration of machine learning and inter- vehicle communications enables various active safety measures in internet-of-vehicles. Specifically, the environmental perception is processed by the deep learning module from vehicular sensor data, and the extended perception range is achieved by exchanging traffic-related information through inter-vehicle communications. Under such condition, the intelligent vehicles can not only percept the surrounding environment from self-collected sensor data, but also expand their perception range through the information sharing mechanism of Vehicular Ad-hoc Network (VANET). However, the dynamic urban environment in VANET leads to a number of issues, such as the effect of packet loss on the real-time perception accuracy of the received sensor data. In this work, we propose a point cloud object detection module via an end-to-end deep learning system and enable wireless communications between vehicles to enhance driving safety and facilitate real-time 3D mapping construction. Besides, we build a semi- realistic traffic scenario based on the Mong Kok district in Hong Kong to analyze the network performance of data dissemination under the dynamic environment. Finally, we evaluate the impact of data loss on the deep-learning-based object detection performance. Our results indicate that data loss beyond 50% (which is a common scene based on our simulation) can lead to a rapid decline of the object detection accuracy.",Yes,"논문 초록에서 제시된 연구는 데이터 손실이 객체 검출 성능에 미치는 영향을 평가하는 실험을 포함하고 있으며, 이를 통해 정량적 평가를 실시하고 있음을 알 수 있습니다. 또한, 데이터 손실 비율에 따른 성능 저하를 구체적으로 분석하는 내용이 포함되어 있습니다."
WIP: Use of a Self-Executing Notebook Based on Matlab's Live Editor for the Development of Autonomous Learning Competency in an Analog Communications Course,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10893526,"This innovative practice WIP paper describes how autonomous learning competency is developed in a course called “Communications Theory 1” that covers analog communications topics within the Telecommunications Engineering Program. To this end, all course material has been redesigned as a self-executing notebook using Matlab Live Editor11https://www.mathworks.com/products/matlab/live-editor.htm1 and is delivered chapter by chapter throughout the semester. This allows students to read the course content and interact with the simulations, modifying them freely to explore the session theory in greater depth and, finally, recognize relevant limits and characteristics. Within the course platform, based on Moodle, the contents have been accompanied by exercises in the Matlab Grader model, which allow feedback to the student when answering the questions provided, validating the developed code. This work helps to strengthen their knowledge in parallel to the activities carried out in the classroom. Since the self-executing notebook provides the information necessary to understand the behavior of the different analog communication techniques seen in the course, in the final chapter, all the knowledge is integrated into an activity that combines the flipped classroom and the puzzle technique, allowing students through teamwork, fully develop the final chapter of the course with a high level of autonomy. This work will be evaluated with the support of rubrics that will allow us to know its progression in the different learning outcomes related to the specific competencies developed in the course and the advancement of generic competencies, including autonomous learning. As a work in progress, initial measurements in applying the self-executing notebook indicate high student satisfaction with the notebook's content and the associated activities. Additional assessments are then planned to refine the teaching-learning cycle and improve course outcomes. Finally, new activities are proposed to complement the training by applying AI technologies and using new laboratory resources.",Yes,"논문 초록에서 평가를 위한 rubrics와 학생의 학습 진행 상황을 측정하는 방법이 언급되어 있으며, 이를 통해 정량적 평가가 실시되고 있음을 알 수 있습니다. 또한, 학생 만족도와 추가 평가 계획이 언급되어 있어 평가 활동이 포함되어 있음을 확인할 수 있습니다."
Triple Diseases Prediction System using Deep Learning Techniques,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10493563,"With the existing deep learning models in predicting multiple diseases primarily focus on analyzing individual diseases in isolation, lacking a unified system for multi-disease prediction. This project presents an approach to predict multiple diseases using Flask API, with a specific focus on brain tumors, COVID-19 and pneumonia. The proposed work represents a significant contribution to the field of disease prediction, harnessing the power of deep learning algorithms and modern web application development. The primary focus is on disease prediction, with a particular emphasis on ensuring accuracy and accessibility for end-users. The initial phase of this research involves data collection, where relevant datasets of various diseases are gathered. These datasets serve as the foundation for training and validating the deep learning models. Two prominent deep learning algorithms, Sequential CNN and VGG16, are employed for this purpose. These algorithms are chosen for their ability to handle complex data and recognize patterns within medical images and other health-related data. The core of the research involves training the deep learning models using the collected datasets. This step is crucial in enabling the models to learn and generalize from the provided data, ultimately enhancing their predictive capabilities. The models are modified to elevate their performance and accuracy. Following the training phase, the models are rigorously tested to evaluate their predictive accuracy. This assessment is vital in gauging the real-world applicability of the models in medical diagnosis. To make these powerful disease prediction models accessible to a wider audience, a front-end web application is developed.",Yes,"초록에서 모델의 성능을 평가하기 위해 ""predictive accuracy""를 평가하는 내용이 언급되어 있습니다. 이는 정량적 평가가 수행되고 있음을 시사하며, 모델의 성능 검증을 위한 구체적인 평가 과정이 포함되어 있음을 알 수 있습니다."
Gamified and Artificial Intelligence-Assisted Knowledge Base in a Social Platform for Self-Learning in Higher Education,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10788662,"This paper proposes a technical model for a self-learning platform in higher education that integrates gamification, artificial intelligence, an online knowledge base, and a social network. Using WordPress as the central platform, specific tools such as GamiPress, AI Engine, BuddyPress, and BetterDocs are evaluated. Unlike previous studies, this work uniquely combines these technologies to address specific challenges in higher education, such as student engagement and personalized learning. Through an exhaustive literature review and a rigorous comparison of available plugins, it is argued that WordPress is a viable option for implementing this solution. This study provides a solid foundation for future implementations and empirical evaluations, presenting evidence on the effectiveness of integrating these tools in enhancing self-directed education.",No,"초록에는 기술 모델과 도구의 평가 및 비교에 대한 언급이 있으나, 구체적인 정량적 평가 방법이나 결과에 대한 언급은 포함되어 있지 않다. 따라서 본 논문이 정량적 평가를 실시했다고 보기 어렵다."
Exploit Detection and Mitigation Technique of Cache Side-Channel Attacks using Artificial Intelligence,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10404798,"As a persistent danger to computer security, cache side-channel attacks take advantage of minute flaws in microarchitectures to access sensitive data without authorization. In-depth analysis of these attacks’ numerous forms and related Common Vulnerabilities and Exposures (CVEs) is provided in this study report. The study emphasizes cache side-channel attacks’ practical ramifications and how they affect system security. The methods for identifying these threats are examined, with an emphasis on how machine learning and deep learning approaches might be used to strengthen security precautions. The research offers useful insights via pseudo code and data structure figures that highlight the necessity of real-time monitoring and detection tactics in reducing cache side-channel vulnerabilities. Artificial intelligence is used to design proactive countermeasures. The research article calls for proactive security measures to thwart these developing risks in addition to illuminating the complicated landscape of cache side-channel attacks. The contribution to this domain goes beyond theoretical discussion and includes actual application. This paper demonstrates the critical relevance of real-time monitoring and detection tactics in the fight to defend systems from cache side-channel attacks via the presentation of pseudo code and data structure diagrams. The results of this work provide guidance for future research and highlight the crucial value of interdisciplinary cooperation in the continuous quest for safe computing systems.",Yes,"논문 초록에서 머신러닝과 딥러닝 접근법을 활용하여 캐시 사이드 채널 공격을 탐지하고 방지하는 방법을 제시하며, 실시간 모니터링과 탐지 전략을 강조하고 있습니다. 또한, pseudo code와 데이터 구조 도표를 통해 구체적인 평가 방법을 보여주고 있어 정량적 평가를 실시하고 있음을 시사합니다."
An Analysis of Travelling Salesman Problem Utilizing Hill Climbing Algorithm for a Smart City Touristic Search on OpenStreetMap (OSM),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8567045,"Travelling Salesman Problem (TSP) can be applied to find the most efficient route to travel between various nodes. The goal is to make smart cities to be created by heuristic algorithms on the real maps to perform some tasks through TSP. Therefore, Hill Climbing heuristic search algorithm which is generally used for mathematical optimization problems in Artificial Intelligence (AI) field has been preferred in this study. This application takes a city from the OpenStreetMap (OSM), which is a real map as an input given to the algorithm, and calculates a path to visit all the nodes on the related route. The output was intended to be found in the shortest possible way and in the least possible time. On the market, there are some travelling, public transport and discovery applications or games on the smart maps. Also there are some publications about TSP and metaheuristic approaches in the literature but the sources are generally commercial products and for limited cities. There is no application that takes all the cities as a source and makes a travel plan for tourists. This study intended to create an open-source, location independent travel plan advisor and develop an indigenous product. Application was tested for Rome and Ankara as an instance but because a flexible working area OSM was used, application can be generated for all the routes and also various applications can be developed by researchers based on this study.",Yes,"논문 초록에서 최적 경로를 계산하는 과정에서 ""shortest possible way""와 ""least possible time""을 목표로 하는 정량적 평가가 수행되었음을 시사합니다. 또한, 알고리즘의 성능을 평가하기 위해 실험 결과를 분석하는 내용이 포함되어 있을 가능성이 높습니다."
ML Based Interactive Disease Prediction Model,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9752947,"The application of Machine learning algorithms to predict diseases is one of the finest methodology to reduce heavy work load on doctors and related medical staff. Based on the World Health Organization (WHO) report, about 85% heart disease deaths are due to Heart Attacks and Heart Strokes. In India the average death rate due to cardiovascular diseases is about 272 per 10,000 population which is greater than global average of 235 per 10,000 population. From the recent survey results, which was released by the Union Ministry of Family and Health Welfare (MoFHW), the Diabetes disease positive ratio is gradually increasing in India. 11.5 percent people were tested positive for Diabetes among urban and rural Indians who are with age 45 and above. Even there is availability of wide range of treatment methods of heart stroke patients & diabetes, Heart attack with Diabetes is the major cause of death in all parts of rural and urban areas of entire India. There are several factors causing heart and diabetes problems which include Age, Gender, Blood Pressure, Glucose levels, Skin thickness and Insulin. These are easily measured in primary care facility centres. The accurate estimation and analysis of heart & diabetes disease patients reports data may help in predicting future heart problems including diabetes. Globally, the application of computerized machine learning methods to predict future problems is in trend now. The Health Monitoring Departments and Fields uses machine learning algorithms to predict and analyse in a wider way to solve problems in fraction of seconds. From the famous proverb “Prevention is Better Than Cure”, if we apply this to medico and health field we can save people from major Heart Diseases (HD's) along with Diabetes. The proposed Dual disease prediction technique is user interactive based method. The proposed method observe inputs from the end user with realistic data to predict heart and diabetes disease. In the presented work, we used Logistic regression model (LR) and Support vector machine (SVM) model for prediction of diseases. The proposed model works with 85 and 78 percent accuracy in prediction of heart and diabetes diseases respectively.",Yes,"논문 초록에서 로지스틱 회귀와 서포트 벡터 머신과 같은 정량적 머신러닝 모델을 사용하여 질병 예측을 수행한다고 명확히 언급하고 있습니다. 또한, 각각의 모델이 특정 정확도(85%와 78%)로 질병을 예측하는 성과를 제시하여 정량적 평가가 이루어지고 있음을 보여줍니다."
Increasing anomaly handling efficiency in large organizations using applied machine learning,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6606717,"Maintenance costs can be substantial for large organizations (several hundreds of programmers) with very large and complex software systems. By large we mean lines of code in the range of hundreds of thousands or millions. Our research objective is to improve the process of handling anomaly reports for large organizations. Specifically, we are addressing the problem of the manual, laborious and time consuming process of assigning anomaly reports to the correct design teams and the related issue of localizing faults in the system architecture. In large organizations, with complex systems, this is particularly problematic because the receiver of an anomaly report may not have detailed knowledge of the whole system. As a consequence, anomaly reports may be assigned to the wrong team in the organization, causing delays and unnecessary work. We have so far developed two machine learning prototypes to validate our approach. The latest, a re-implementation and extension, of the first is being evaluated on four large systems at Ericsson AB. Our main goal is to investigate how large software development organizations can significantly improve development efficiency by replacing manual anomaly report assignment and fault localization with machine learning techniques. Our approach focuses on training machine learning systems on anomaly report databases; this is in contrast to many other approaches that are based on test case execution combined with program sampling and/or source code analysis.",Yes,"논문 초록에서 ""두 개의 머신러닝 프로토타입을 개발하였으며, 이를 평가하고 있다""라고 명시되어 있어 정량적 평가가 수행되고 있음을 알 수 있습니다. 또한, 평가 대상 시스템들이 언급되어 있어 실험적 검증이 이루어지고 있음을 시사합니다."
Optimizing Cloud Security: A Study of Effective Cybersecurity Measures for Organizations,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10823273,"With cloud computing gradually forming the bedrock of organizational systems, the protection of data in the cloud remains important. This study aims to examine potential security measures that organizations can employ to safeguard their data in cloud systems. The study concerns the literature review of existing threats including data leaks, insider threats, malware, and advanced persistent threats (APTs), and assesses the efficiency of various security solutions. The combined IAM, data encryption, and a network security strategy, integrating AI and ML in the proposed model will help build a strong defense against cloud threats. Information was gathered from interviews, questionnaires, CSA reports, cybersecurity incident repositories, as well as CSP records. The dataset was pre-processed by thoroughly removing or masking any identifiable data from the dataset. This has been done in terms of such categories as Response Time Reduction, Incident Mitigation Rate, Resource Utilization Efficiency, and User Satisfaction. These findings showed favorable changes in all measures in comparison to benchmark models. The proposed model has realized 92% of the Incident Mitigation Rate, 85% of the Response Time Reduction, 78% of the Resource Utilization Efficiency, and an 88% level of User satisfaction. These results show that the model is not only capable of solving security incidents but is also efficient in managing resources and serves the purpose of a real-life IT security professional. The same was observed when carrying out the epoch-wise and batch size-wise analysis, which corroborated the reliability and portability of the model. The strategies and solutions highlighted provide valuable recommendations for improving cloud security and protecting organizational information against emerging cyber threats.",Yes,"논문 초록에서 Response Time Reduction, Incident Mitigation Rate, Resource Utilization Efficiency, User Satisfaction 등 다양한 정량적 평가 지표를 사용하여 보안 모델의 성능을 평가하고 있음을 명확히 언급하고 있습니다. 이러한 지표들을 통해 정량적 평가가 실시되고 있음을 알 수 있습니다."
Analysis of Attention Span of Students using Deep Learning,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10575321,"This research work presents an experimental work of the Analysis of Attention Span of Students using Deep Learning, a novel application employing deep learning techniques for assessing student engagement in educational settings. The system incorporates facial recognition, eye tracking, and head pose analysis to offer real-time insights into students' attentiveness during lessons.The introduction outlines the motivation behind the research, emphasizing its significance in the dynamic landscape of education. The report addresses the project’s relevance in optimizing learning environments, delivering personalized education, and addressing challenges in remote learning scenarios.The implementation overview details the integration of key components and the calculation of real-time metrics related to student attention. Practical applications of the system are discussed, highlighting its role in educational adaptability, early intervention, and the generation of data-driven insights for continuous improvement in teaching methodologies. The conclusion summarizes key findings and discusses the potential implications of the Analysis of Attention Span of Students using Deep Learning. This research work aims to contribute to the discourse surrounding educational technology, emphasizing adaptability and personalization for an enriched learning experience and accuracy is measured. Moreover, end user interface is implemented, and impact is analyzed.",Yes,"논문 초록에서 실시간 지표 계산과 관련된 정량적 평가가 이루어지고 있음을 언급하고 있으며, 학생의 집중력 분석을 위해 딥러닝 기법을 활용하여 구체적인 수치와 데이터를 측정하는 것으로 보입니다. 이러한 내용은 정량적 평가가 수행되고 있음을 시사합니다."
A Smart Operator Assistance System Using Deep Learning for Angle Measurement,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9599587,"Manual workstations play a critical role in flexible assembly lines by enabling human responses to reconfiguration that is faster than machine responses. As a result, human is more adaptive and sometimes unreplaceable by machines in complex assembly. However, with the increasing complexity of tasks, product quality has become highly susceptible to human error due to increments in operators’ cognitive load. One of the errors that affect assembly quality is the operator’s use of a handheld tool with an unfavorable working angle when handling the workpiece. In this case, an assistive mechanism to remind workers about the wrong working angle is necessary to support the process. To this end, this study proposes an angle monitoring system to inspect the working angle of handheld tools and provide feedback in real time with minimal interruption to the assembly process. The proposed system consists of an angle measurement model and an action recognition model, which are both built using deep-learning-based object detection algorithm. Besides, the system was designed with flexibility that it is applicable to different tools and assembly tasks. A case study on fastening a high-end graphical processing unit card is investigated to evaluate their performance. Results show 95.83% and 99.83% accuracies of the models. In practice, the proposed study is expected to facilitate assembly quality by preventing the failure of angle-related operations in a timely and reliable manner.",Yes,"논문 초록에서 제안된 시스템이 딥러닝 기반의 객체 감지 알고리즘을 활용하여 정량적 평가를 실시하고 있음을 보여줍니다. 또한, 모델의 성능을 95.83%와 99.83%의 정확도로 평가한 구체적인 수치가 제시되어 있어 정량적 평가가 수행되고 있음을 알 수 있습니다."
Developing and Validating the Contextual Technology Andragogy/Pedagogy Entrepreneurship Work Content Knowledge Model: A Framework for Vocational Education,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10676317,"Purpose: The present study aimed to integrate artificial intelligence technology (ChatGPT) with an in-depth literature review to explore knowledge dimensions of professional teaching and information and communication technology (ICT) integration models in TVET, and utilize the Delphi technique and ChatGPT to examine, enhance, and validate a newly proposed model for professional teaching and ICT integration in TVET.Methods: Three rounds of the Delphi technique were applied to develop and validate this new model. Artificial intelligence tool (ChatGPT) with an in-depth literature review were used to explore knowledge dimensions for TVET education. In Round 1, ChatGPT was used to transform the technological pedagogical content knowledge (CK) model for TVET instruction. A new suggested model was developed called the contextual technology andrology/pedagogy entrepreneurship work CK (CTA/PEWCK) model. Ten experts from the TVET sector participated in Round 2, and 39 participated in Round 3 to validate the new suggested model.Findings: The findings revealed that the fifteen knowledge dimensions extracted from this new suggested model presented essential knowledge for TVET education.Conclusion: Applying the CTA/PEWCK model offers professional development opportunities for TVET teachers that focus on hands-on experiences to develop competencies for sustainable development (ESD), enabling an integrated approach to knowledge dimensions, procedures, and attitude.",Yes,"논문 초록에서 Delphi 기법과 ChatGPT를 활용하여 모델을 개발하고 검증하는 과정을 언급하며, 이를 통해 정량적 평가가 이루어졌음을 시사합니다. 특히, 전문가 참여와 검증 과정을 통해 모델의 타당성을 평가하는 정량적 방법이 사용된 것으로 보입니다."
A Wearable High Blood Pressure Classification Processor Using Photoplethysmogram Signals through Power Spectral Density Features,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9869847,"High blood pressure (BP) is a major source of health problems related to mental stress, cardiac issues, kidney problems, vision, and brain. High BP bursts can damage and rupture blood vessels and cause strokes. Therefore, it is quite important to continuously monitor it for high BP patients. Conventional BP monitoring devices a) can cause discomfort and b) not suitable for intermittent monitoring. The photoplethysmographic (PPG) signals measure the volume changes in the human blood through human skin. This work presents a high BP classification processor using PPG signals through an artificial intelligence (AI) based boosted circuit. A data set of 25 participants was collected. Ten out of the 25 participants were high blood pressure patients with systolic BP (SBP) and, diastolic BP (DBP) values higher than 140mmHg and 90mmHg, respectively. The AI boosted circuit calculates the power spectral densities, power spectral densities difference, and the sum of the consecutive difference between PPG signals. The features are forwarded to a small 3-level Decision Tree (DT) classifier. The decision tree classifier classifies the high SBP and DBP as high or normal/low with 96.2% classification accuracy. The SBP values ≥ 130mmHg and < 130mmHg were classified as HIGH SBP or LOW/NORMAL SBP respectively. Similarly, the DBP values ≥ 80mmHg and < 80mmHg were classified as HIGH DBP or LOW/NORMAL DBP, respectively. The system was implemented on an Artix-7 FPGA which consumes power of ≈18.23uW @ 50 MHz.",Yes,"논문 초록에서 Power Spectral Densities와 차이값 등 다양한 정량적 특징들을 계산하여 분류 성능을 평가하고 있으며, 96.2%의 분류 정확도를 보고하고 있습니다. 이는 명확한 정량적 평가를 실시하고 있음을 보여줍니다."
Development and Research of English Defect Reporting Software Based on Natural Language Processing,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10788281,"This paper aims to explore an innovative English defect reporting software that utilizes natural language processing (NLP) techniques, particularly hybrid neural networks and attention mechanisms, to improve the accuracy and readability of English defect reporting. The research focuses on English pronunciation defect recognition and aims to provide software developers with an intelligent defect report writing and review tool by integrating advanced algorithms and simulation techniques. Firstly, this study proposes an English pronunciation defect recognition model based on hybrid neural networks and attention mechanisms. The model uses deep learning algorithms to automatically identify and correct pronunciation errors in reports, while using attention mechanisms to improve the ability to capture key information in the text. This integrated approach effectively improves the language quality of defect reporting and reduces the communication barriers caused by language problems. Secondly, a comprehensive natural language processing system is developed, which not only includes the pronunciation defect recognition module, but also includes grammar checking, vocabulary suggestion and context understanding. Through the organic combination of these functions, the system can provide users with a full range of language support to ensure the professional and clear defect report. Finally, the simulation experiment of the system algorithm is carried out to evaluate its performance in practical application. The experimental results show that the developed system performs well in identifying pronunciation defects and providing language recommendations, significantly improving the quality of defect reporting.",Yes,"논문 초록에서 시스템의 성능을 평가하기 위해 시뮬레이션 실험을 수행했다고 명시되어 있으며, 실험 결과를 통해 시스템의 성능을 정량적으로 평가한 것으로 보입니다. 따라서, 논문은 정량적 평가를 실시하고 있다고 판단됩니다."
A Domain-Adapted Machine Learning Approach for Visual Evaluation and Interpretation of Robot-Assisted Surgery Skills,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9808117,"In this study, we present an intuitive machine learning-based approach to evaluate and interpret surgical skills level of a participant working with robotic platforms. The proposed method is domain-adapted, i.e., jointly utilizes an end-to-end learning approach for smoothness detection and domain knowledge-based metrics such as fluidity and economy of motion for extracting skills-related features within a given trajectory. An advantage of our approach compared to similar stochastic or deep learning models is its intuitive and transparent manner for extraction and visualization of skills-related features within the data. We illustrate the performance of our proposed method on trials of the JIGSAWS data set as well as our own experimental data gathered from Phantom Premium 1.5A Haptic Device. This approach utilized t-SNE technique and provides visualized low-dimensional representation for different trials that highlights nuanced information within the executive task and returns unusual or faulty trials as outliers far away from their normal skill or participant clusters. This information regarding the input trajectory can be used for evaluation and education applications such as learning curve analysis in surgical assessment and training programs.",Yes,"논문 초록에서 정량적 평가를 위해 다양한 지표와 기술(예: 유동성, 운동의 경제성, t-SNE를 통한 저차원 표현)을 활용하여 데이터를 분석하고 시각화하는 방법을 제시하고 있습니다. 이러한 방법들은 명확한 수치와 지표를 통해 성능을 평가하는 정량적 평가의 실시를 보여줍니다."
Fingerprint generation and authentication though Adaptive convolution generative adversarial network (ADCGAN),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10178664,"Fingerprints are crucial in identification of humans. The uniqueness of finger prints makes it an interesting subject. Fingerprints are termed as a technique used to define, assess, and quantify a person's physical and behavioral property. Deep learning has made its application in all the major fields such as natural language processing, computer vision and speech processing. Deep learning has also found its application in the important subject of fingerprint synthesis and biometric. The ever-growing complexity of fingerprint authentication issues, from cellphone authentication to airport security systems, seems to be best handled by these models. In recent years, deep learning-based models have been used more and more to raise the accuracy of various fingerprint recognition systems. The persuasive capacity of Generative Adversarial Networks (GANs) to generate believable instances can be credibly taken from an existing distribution of samples. GAN exhibits exceptional performance on data generation-based tasks and also encourages study in privacy and security. In this work, using Adaptive Deep Convolution Generative Adversarial Networks (ADCGAN), we develop a model that generates and authenticate the fingerprints. A Socofing dataset was trained on ADGAN model. The model gave 92% accuracy. The conduct of fingerprint research has been made possible due to ADGAN, without restrictions related to the confidential nature of biometric data.",Yes,"논문 초록에서 모델의 성능 평가를 위해 92%의 정확도를 제시하고 있으며, 이는 정량적 평가를 실시했음을 보여줍니다. 따라서, 논문은 정량적 평가를 수행하고 있다고 판단됩니다."
Analysis and Evaluation of Sentiments in Online Communities,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10522446,"In this research paper, we focus on understanding people's feelings and opinions in online social forums, like social media platforms and discussion boards. These forums are crucial for conversations and sharing information online. Our main goals are to explain what sentiment analysis is, discuss the unique challenges of analyzing sentiments in social forums, review different methods used for sentiment analysis, and see how well they work in this context. We highlight the growing importance of sentiment analysis for grasping public opinions, spotting trends, and making better decisions in the fast-paced world of social forums. We explore the difficulties in sentiment analysis here, like dealing with casual language, understanding context, and the specifics of different topics discussed. By looking at various sentiment analysis techniques, such as rule-based methods, machine learning, and combinations of both, we aim to understand which ones are most useful for social forums. We also talk about the measures used to evaluate these techniques and stress the importance of having diverse and representative data to train these models. We provide examples of how sentiment analysis can be used, like monitoring brands or understanding political discussions. Finally, we discuss where future research in sentiment analysis for social forums could go, including improving models to handle messy text, making them work better across different topics, and considering ethical issues like privacy and bias. Our paper aims to contribute to the ongoing progress in sentiment analysis, offering insights into the challenges and opportunities in understanding user feelings in online social forums. We hope this will help guide future research to develop better sentiment analysis models for these platforms, which are both effective and ethical.",Yes,"논문 초록에서 다양한 감성 분석 기법과 그 평가 방법에 대해 논의하고 있음을 명확히 언급하고 있습니다. 또한, 평가 지표와 모델 성능 측정을 위한 방법론에 대해 다루고 있어 정량적 평가를 실시하고 있음을 알 수 있습니다."
Ethical Impact Identification of a Dementia Behaviour Monitoring System,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10581932,"The identification of ethical impacts is the first phase of Ethical Impact Assessments, which are used to evaluate the ethical implications of new technologies. Using a structured methodology, this paper explores the identification of ethical impacts of a video-based tool for monitoring dementia-related behaviours. By reflecting on autonomy, dignity, non-maleficence, beneficence, justice and privacy, our work contributes to a broader understanding of the ethical landscape surrounding the use of Artificial Intelligence (AI) and computer vision in healthcare. Our contribution goes beyond the specific aspects of this system as we address consent, privacy and autonomy, factors that are relevant to any technology for people with dementia. We call for the integration of ethical considerations into the design and implementation of AI technologies, ensuring that innovations not only advance clinical care, but also respect fundamental ethical principles.",No,"초록에서는 윤리적 영향을 식별하는 과정에 대해 논의하고 있으나, 구체적인 정량적 평가 방법이나 수치적 분석이 언급되지 않습니다. 따라서 이 논문은 정량적 평가를 실시하고 있다고 보기 어렵습니다."
Artificial Intelligence and Students Learning: A Study on Outcome of Technological Usage (AI) In Higher Education Platform,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10113027,"Artificial intelligence (AI) is presumptively driving technological force of the primary this century, and may work nearly every trade, if not human endeavors at large. Businesses and governments worldwide are running huge sums of cash into an awfully big range of implementations, and dozens of start-ups square measure being funded to the tune of billions of dollars. AI is one altogether those aspects of recent life relating to that the majority individuals have some awareness, and notwithstanding acknowledge we've little information. In fact, for several AI is similar with golem robots, which might be as a result of news relating to AI is sort of regularly illustrated with a picture of a golem or a digital brain. Meanwhile, the dystopian footage of front robots keep firmly within the realm of phantasy. This study discusses on what student ought to learn within the age of AI, however will AI enhance and remodel education. The analysis is administered with well-structured form and picked up responses from Teaching colleges and students experiencing computer science in education. the current study aiming at application of AI in higher education, an empirical approach has been wanting to verify the possible analysis findings. exploitation convenient sampling, around 320 responses were collected from AI users. Results shows Outcome of Technological Usage of AI (OTUAI) has been dominantly factorized into 3 dominant factors. there’s vital distinction among demographic profile teams in factors of OTUAI. Impact of demographic profile, usage of technology and medium of instruction on overall OTUAI has been identified.",Yes,"논문 초록에서 ""an empirical approach has been wanting to verify the possible analysis findings""라고 명시되어 있으며, ""around 320 responses were collected""와 같은 구체적인 데이터 수집 내용이 포함되어 있어 정량적 평가가 실시되고 있음을 보여줍니다."
Artificial Intelligence Agents to Support Data Mining for SoS Modeling of Space Systems Design,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9172802,"The complex and multidisciplinary nature of space systems and mission architectures is especially evident in early stage of design and architecting, where systems stakeholders have to keep into account all the aspects of a project, including alternatives, cost, risk, and schedule and evaluate various potentially conflicting metrics with a high level of uncertainty. Though aerospace engineering is a relatively young discipline, stakeholders in the field can rely on a vast body of knowledge and good practices for space systems design and architecting of space missions. These guidelines have been identified and refined over the years. However, the increase in size and complexity of applications in the aerospace discipline highlighted some gaps in this approach: first, the amount of available information is now very large and originates from multiple sources, often with diverse representations, and useful data for trade space analysis or analysis of all potential alternatives can be easily overlooked; second, the variety and complexity of the systems involved and of the different domains to be kept into account can generate unexpected interactions that cannot be easily identified; third, continuous advancements in the field of aerospace resulted in the development of new approaches and methodologies, for which a common knowledge database is not existing yet, thus requiring substantial effort upfront. To address these gaps and support both decision making in early stage of space systems design and increased automation in extraction of necessary data to feed working groups and analytical methodologies, we propose the training and use of Artificial Intelligence agents. These agents can be trained to recognize not only information coming from standardized representations, for example Model Based Systems Engineering diagrams, but also descriptions of systems and functionalities in plain English. This capability allows each agent to quantify the relevance of publications and documents to the query for which it is trained. At the same time, each agent can recognize potentially useful information in documents which are only loosely connected to the systems or functionalities on which the agent has been trained, and which would possibly be overlooked in a traditional literature review. The search for pertinent sources can be further refined using keywords, that let the user specify more details about the systems or functionality of interest, based on the intended use of the data. In this work we illustrate the use of Artificial Intelligent agents to sort space habitat subsystems into NASA Technology Roadmaps categories and to identify relevant sources of data for these subsystems. We demonstrate how the agents can support the retrieval of complex information required to feed existing System-of-Systems analytic tools and discuss challenges of this approach and future steps.",Yes,"논문 초록에서 인공지능 에이전트를 훈련시키고 활용하는 방법을 제시하며, 이들이 문서의 관련성을 정량적으로 평가할 수 있음을 암시하고 있습니다. 또한, 이러한 평가를 통해 복잡한 정보를 정리하고 분석하는 데 도움을 주는 것으로 보이기 때문에 정량적 평가를 실시하고 있다고 판단됩니다."
Batch-mode active learning for technology-assisted review,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7363867,"In recent years, technology-assisted review (TAR) has become an increasingly important component of the document review process in litigation discovery. This is fueled largely by dramatic growth in data volumes that may be associated with many matters and investigations. Potential review populations frequently exceed several hundred thousands documents, and document counts in the millions are not uncommon. Budgetary and/or time constraints often make a once traditional linear review of these populations impractical, if not impossible — which made ""predictive coding"" the most discussed TAR approach in recent years. A key challenge in any predictive coding approach is striking the appropriate balance in training the system. The goal is to minimize the time that Subject Matter Experts spend in training the system, while making sure that they perform enough training to achieve acceptable classification performance over the entire review population. Recent research demonstrates that Support Vector Machines (SVM) perform very well in finding a compact, yet effective, training dataset in an iterative fashion using batch-mode active learning. However, this research is limited. Additionally, these efforts have not led to a principled approach for determining the stabilization of the active learning process. In this paper, we propose and compare several batch-mode active learning methods which are integrated within SVM learning algorithm. We also propose methods for determining the stabilization of the active learning method. Experimental results on a set of large-scale, real-life legal document collections validate the superiority of our method over the existing methods for this task.",Yes,"논문 초록에서 여러 배치 모드 활성 학습 방법을 제안하고 이를 실험을 통해 검증하는 내용을 다루고 있어, 정량적 평가를 실시하고 있음을 알 수 있습니다. 실험 결과를 통해 제안된 방법의 우수성을 검증하는 과정이 포함되어 있습니다."
Sports Video Data Classification using Yolov5 Model,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10249850,"The machine learning along with computer vision has helped widely in classification of sports videos. Deep learning techniques are also being used to perform research in this domain. The video frames are the most significant components of the sports classification system. There are many models that have been used to classify sports videos. The objective of this work is to develop a classifier for different sports activity recognition using video data with high accuracy and probability. Sports dataset has been used from Kaggle [10]. This framework has been created for applications related to sports, object detection, game identification, recognition, analysis, players’ tracking, and performance. This framework consists of various intermediary processes. At first, preprocessing has been carried out in this framework by converting input sports video into video frames. Then skeletonization has been carried out using computer vision. Finally, feature extraction and classification has been done using the Yolov5 model that has been trained with the dataset. Accuracy and loss graphs have been generated using prediction metrics for this model to evaluate the accuracy of this framework. The accuracy of the framework is more than 90% according to the results we have obtained.",Yes,논문 초록에서 정확도와 손실 그래프를 포함하여 모델의 성능을 평가하는 지표를 사용했다고 명시되어 있습니다. 이는 정량적 평가를 실시하고 있음을 보여줍니다.
Detection Mechanism of Money Laundering based on Random Walk and Skip-Grim Model,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9909113,"Money laundering means that criminals use the services provided by banks to transfer a large amount of illegal funds to untraceable destination accounts. Most of the related works are rule-based and machine learning based anti-money laundering systems. However, the anti-money laundering systems based on machine learning are affected by the data scale of money laundering transactions. The rule-based anti-money laundering systems require a lot of manual work and cannot adapt to the changing money laundering behavior. Therefore, this paper designs a money laundering detection mechanism based on random walk and skip-grim model. This detection mechanism preferentially constructs an account transfer graph. Then, on this basis, it generates random transfer trajectories for each account using the random walk algorithm. Thereafter, the transfer characteristics of each user are automatically analyzed from the random transfer trajectories utilizing the skip-grim model. Finally, it compares the extracted transfer characteristics of different users and combines the cosine similarity to identify illegal money laundering users. Last, we use python programming language and cbank dataset to evaluate the performance of the proposed scheme, and we compare our work with the related works, flowscope and Martin jullum. The extensive simulation results validate that, the proposed scheme has better identification effect, correctly identifying more than 80% of the money laundering accounts, and the misjudgment rate is less than 20 %.",Yes,"논문 초록에서 제안된 검출 메커니즘의 성능을 평가하기 위해 파이썬 프로그래밍 언어와 cbank 데이터셋을 사용하여 실험을 수행했다고 명시되어 있습니다. 또한, 실험 결과를 통해 성능을 정량적으로 평가한 것으로 보입니다."
"Deep Learning for Aspect-Level Sentiment Classification: Survey, Vision, and Challenges",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8726353,"This survey focuses on deep learning-based aspect-level sentiment classification (ASC), which aims to decide the sentiment polarity for an aspect mentioned within the document. Along with the success of applying deep learning in many applications, deep learning-based ASC has attracted a lot of interest from both academia and industry in recent years. However, there still lack a systematic taxonomy of existing approaches and comparison of their performance, which are the gaps that our survey aims to fill. Furthermore, to quantitatively evaluate the performance of various approaches, the standardization of the evaluation methodology and shared datasets is necessary. In this paper, an in-depth overview of the current state-of-the-art deep learning-based methods is given, showing the tremendous progress that has already been made in ASC. In particular, first, a comprehensive review of recent research efforts on deep learning-based ASC is provided. More concretely, we design a taxonomy of deep learning-based ASC and provide a comprehensive summary of the state-of-the-art methods. Then, we collect all benchmark ASC datasets for researchers to study and conduct extensive experiments over five public standard datasets with various commonly used evaluation measures. Finally, we discuss some of the most challenging open problems and point out promising future research directions in this field.",Yes,논문 초록에서 다양한 평가 지표와 표준화된 데이터셋을 활용하여 여러 방법을 실험하고 비교하는 내용을 언급하고 있습니다. 이는 정량적 평가를 실시하고 있음을 시사합니다.
A Chest X-ray Image Retrieval System for COVID-19 Detection using Deep Transfer Learning and Denoising Auto Encoder,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9458223,"The COVID-19 pandemic is the defining global health crisis of our time which is currently challenging families, communities, health care systems, and government all over the world. It is critical to detect and isolate the positive cases as early as possible for timely treatment to prevent the further spread of the virus. It was found in few early studies that patients present abnormalities in chest radiography images that are characteristic of those infected with COVID-19. In the current context, a rapid, accessible and automated screening tool based on image processing of chest X-rays (CXRs) would be much needed as a quick alternative to PCR testing, especially with commonly available X-ray machines and without the dedicated test kits in labs and hospitals. Several classifications based approaches have been proposed recently with encouraging results to detect pneumonia based on CXRs using supervised deep transfer learning techniques based on Convolutional Neural Networks (CNNs). These black box approaches are mainly non-interactive in nature and their prediction represents just a cue to the radiologist. This work focuses on issues related to the development of such an automated system for CXRs by performing discriminative feature learning using deep neural networks with a purely data driven approach and retrieving images based on an unknown query image and performing retrieval evaluation on currently available benchmark datasets towards the goal of realistic comparison and real clinical integration. The system is trained and tested on an image collection of 1700 CXRs obtained from two different resources with encouraging results based on precision and recall measures in individual deep feature spaces. It is hoped that the proposed system as diagnostic aid would reduce the visual observation error of human operators and enhance sensitivity in testing for Covid-19 detection.",Yes,"논문 초록에서 정량적 평가를 위해 ""precision and recall measures""를 사용하여 성능 평가를 수행했다고 명시되어 있습니다. 이는 구체적인 수치와 지표를 통해 시스템의 성능을 정량적으로 평가했음을 의미합니다."
Construction of a Meteorological Data Support Vector Machine Drought Prediction Model Based on Machine Learning Algorithms,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10699072,"In recent years, the proliferation of machine learning algorithms in drought prediction has revolutionized the field, leveraging their robust data processing and pattern recognition abilities to offer fresh perspectives and methodologies. This article specifically employs machine learning to develop a support vector machine (SVM) drought prediction model grounded in meteorological data, aiming to enhance prediction accuracy. Following a comprehensive literature review outlining the fundamentals of machine learning and its applications in drought forecasting, the article delves into the construction process of the SVM-based model in detail. Experimental analysis validates the model’s strengths, revealing that despite Decision Tree and Linear Regression algorithms demonstrating improved accuracy trends (ranging from 0.7-0.86 and 0.65-0.87, respectively), the SVM algorithm consistently outperforms them, achieving superior prediction accuracy. This underscores the conclusion that the SVM algorithm is a highly effective tool for drought prediction, offering precision that surpasses traditional methods.",Yes,"논문 초록에서 SVM 모델의 성능을 평가하기 위해 정확도와 같은 정량적 지표를 사용하여 실험 분석을 수행했다고 명시되어 있습니다. 또한, Decision Tree와 Linear Regression 알고리즘과의 비교를 통해 정량적 평가가 이루어졌음을 알 수 있습니다."
Fine-Grained In-Context Permission Classification for Android Apps Using Control-Flow Graph Embedding,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10298328,"Android is the most popular operating system for mobile devices nowadays. Permissions are a very important part of Android security architecture. Apps frequently need the users' permission, but many of them only ask for it once—when the user uses the app for the first time—and then they keep and abuse the given permissions. Longing to enhance Android permission security and users' private data protection is the driving factor behind our approach to explore fine-grained context-sensitive permission usage analysis and thereby identify misuses in Android apps. In this work, we propose an approach for classifying the fine-grained permission uses for each functionality of Android apps that a user interacts with. Our approach, named DroidGem, relies on mainly three technical components to provide an in-context classification for permission (mis)uses by Android apps for each functionality triggered by users: (1) static inter-procedural control-flow graphs and call graphs representing each functionality in an app that may be triggered by users' or systems' events through UI-linked event handlers, (2) graph embedding techniques converting graph structures into numerical encoding, and (3) supervised machine learning models classifying (mis)uses of permissions based on the embedding. We have implemented a prototype of DroidGem and evaluated it on 89 diverse apps. The results show that DroidGem can accurately classify whether permission used by the functionality of an app triggered by a UI-linked event handler is a misuse in relation to manually verified decisions, with up to 95% precision and recall. We believe that such a permission classification mechanism can be helpful in providing fine-grained permission notices in a context related to app users' actions, and improving their awareness of (mis)uses of permissions and private data in Android apps.",Yes,"논문 초록에서 제안하는 방법은 그래프 임베딩과 머신러닝 모델을 활용하여 권한 사용의 적합성을 정량적으로 평가하는 방식을 채택하고 있으며, 실험 결과도 정량적 평가 지표(정확도, 정밀도, 재현율)를 제시하고 있습니다. 따라서, 논문은 정량적 평가를 실시하고 있다고 판단됩니다."
Creating Realities: An In-Depth Study of AI-Driven Image Generation with Generative Adversarial Networks,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10726281,"The field of artificial intelligence has witnessed significant advancements with the advent of Generative Adversarial Networks, revolutionizing image generation techniques. The literature review covers seminal works and recent advancements, highlighting the evolution of image generation techniques. Taxonomy is developed to classify methods based on their underlying principles and applications across various domains including art, fashion, healthcare, and entertainment. Comparative analysis evaluates the effectiveness, efficiency, and applicability of different models, utilizing metrics corresponding Inception Score and Frechet Inception Distance. By conducting a thorough review of existing literature and technologies, we explore the evolution of GAN architectures, from their inception to the latest innovations. We examine various GAN models, including DCGAN, StyleGAN, and CycleGAN, assessing their effectiveness in generating high-fidelity images across diverse applications. In addition to this comprehensive analysis, we present our own implementation of a GAN model tailored for specific image generation tasks. Our model is tested on multiple datasets to evaluate its performance, highlighting improvements in training stability and image quality. We discuss the architectural choices, optimization techniques, and training procedures employed in our implementation. Furthermore, we address the challenges faced in the field, such as mode collapse, training instability, and the need for largescale datasets. Our findings offer valuable insights into optimizing GAN performance and propose potential directions for future research. This comprehensive analysis serves as a foundational reference for researchers and practitioners aiming to leverage GANs for advanced image generation tasks, pushing the boundaries of what is visually conceivable through artificial intelligence.",Yes,"논문은 다양한 GAN 모델의 성능 평가를 위해 Inception Score와 Frechet Inception Distance와 같은 정량적 지표를 사용하여 평가를 실시하고 있습니다. 또한, 제안된 모델의 성능을 검증하기 위해 여러 데이터셋에서 실험을 수행하는 등 정량적 평가를 수행하는 내용이 포함되어 있습니다."
Exploring Pretrained Models and Transfer Learning Techniques for Image Retrieval,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10307272,"In recent years, the field of content-based image retrieval (CBIR) has witnessed significant advancements and garnered immense attention. With the increase of digital imagery across various domains, the need for effective image search and retrieval techniques has become increasingly important. Pre-trained deep neural networks have arisen as effective tools for image analysis and feature extraction due to their ability to learn complex visual representations from vast amounts of data. By harnessing the power of pre-trained deep neural networks, such as AlexNet, ResNet, VGG16, and GoogLeNet, researchers seek to enhance CBIR systems. This paper explores the significance of utilizing pre-trained networks for content-based image retrieval (CBIR). It includes a literature review discussing similar CNN architectures & their applications as well as identifying research gaps. The paper conducts a comparative study of the four pre-trained networks: AlexNet, ResNet, VGG16, and GoogLeNet, evaluating their performance and suitability for CBIR. It also demonstrates transfer learning techniques to fine tune AlexNet and VGG16 models using MNIST and Fashion MNIST dataset. Evaluation using LRAP as a metric revealed good performance for both models, with AlexNet consistently outperforming VGG16, albeit with longer execution times.",Yes,"논문 초록에서 LRAP라는 평가 지표를 사용하여 모델의 성능을 정량적으로 평가했다고 명시되어 있습니다. 또한, 여러 네트워크의 성능 비교와 평가 결과를 제시하는 내용이 포함되어 있어 정량적 평가가 실시된 것으로 판단됩니다."
Sentiment Analysis and Opinion Mining on Social Media Using Machine Learning,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10696144,"Sentiment analysis on social media is a Natural Language Processing practice used to extract subjective information and opinions from user-generated content on various social media platforms, such as Twitter, Facebook, and Instagram. The goal of the proposed work is to perform sentiment analysis on social media data related to a particular topic or brand, such as a product launch or a social issue. Social media data will be collected using relevant APIs or web scraping tools and pre-processed by cleaning and filtering out irrelevant or spam content This data is helpful for users as well as for the management to make informed decisions. Because micro-blog posts are usually very brief and informal, traditional opinion mining algorithms struggle to handle this type of content, making the subject challenging to tackle. Semantic and syntactic analysis in Sentiment Net was addressed in the previous lexicon-based sentiment analysis approach. The proposed suggestion is to produce an automation-based sentiment analysis method, which is less expensive in spite of this system's requirement is least. Consequently, in this work, introduces a novel system architecture that is capable of automatically analyzing the sentiments contained in these communications. We use this algorithm in conjunction with manually annotated social media data for sentiment analysis. This system's machines are capable of autonomously have knowledge to extract data. In the proposed system, a sentiment analysis model, such as a lexicon-based machine learning model, is applied to classify the sentiment of the content as positive, negative, or neutral. Twitter data is utilized for training, validating and testing the tweets based on their emotions, the emojis too are classified. The experimental findings validate our system's effectiveness in sentiment analysis in real-world social media applications.",Yes,"논문 초록에서 머신러닝 모델을 활용하여 감성 분석을 수행한다고 명시되어 있으며, 실험 결과를 통해 시스템의 효과성을 검증했다고 언급하고 있습니다. 이는 정량적 평가가 이루어지고 있음을 시사합니다."
Using Unsupervised Machine Learning Methods and the Nasa Snowex Swesarr Instrument to Study How Snow Water Equivalent is Changing with Climate Change,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10641609,"The Snow Water Equivalent Synthetic Aperture Radar and Radiometer (SWESARR) is a dual microwave instrument meant to fill in information gaps in the remote sensing data of Snow Water Equivalent (SWE). The aim of this work is to improve and validate SWESARR measurements of SWE for areas with tree canopy using unsupervised machine learning methods. This information is critical to NASA’s SnowEx mission for understanding the spatial and temporal variability of snow. SWE is an integral part of the climate system and affects many other climate-related processes, thus an accurate understanding of how SWE is changing with climate change is crucial for future water resource management. We have made use of a suite of parameters to help in identifying features most important in predicting SWE in areas that have missing satellite data due to vegetation. Our aim is to validate and improve SWESARR measurements using unsupervised machine learning clustering algorithms with the goal of being able to better quantify spatial and temporal changes of SWE due to climate change.Other relevant datasets that have been central to identifying parameters for predicting SWE and data validation have been from the ASO (Airborne Snow Observatory), NSIDC (National Snow and Ice Data Center), and ground snow pit observations taken by the SnowEx field work team. This work is a result of NASA’s SnowEx team based out of Goddard Space Flight Center within the Climate Change Research Initiative at NASA GISS.",Yes,"논문 초록에서 SWE(눈 물 함량)를 정량적으로 평가하기 위해 다양한 데이터와 파라미터를 활용하고 있으며, 이를 검증하고 개선하기 위한 방법으로 정량적 평가를 실시하는 것으로 보입니다. 또한, 기계 학습 클러스터링 알고리즘을 사용하여 SWE의 공간적 및 시간적 변화를 정량적으로 분석하는 내용이 포함되어 있습니다."
Towards Better ML-Based Software Services: An Investigation of Source Code Engineering Impact,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10234350,"In recent years, the development of machine learning-based solutions for software services, particularly for source code, has grown rapidly. It is witnessed that many machine learning models for software services require the input of source code snippets in a desired form of abstract syntax tree (AST), which is mostly generated from an external tool. However, such data pre-processing tasks could be done by different engineering tools, and the impact of these tools towards final models is often neglected. In this work, we aim to investigate the source code engineering impacts towards machine learning-based software services. Three different types of parsing tools are identified, which are parser generator, parsing library and parser developed for a certain purpose. They are thoroughly evaluated towards the impacts on the prediction model of Code2Vec for the prediction task of the method name in Java language. The collective result on the Java-small dataset shows that the generated ASTs differ a lot in terms of source code structures and contents when using different parsing tools. The difference could influence the performance of the trained model significantly. Our result suggests that when machine learning models are implemented for software services, especially for code-related tasks, the selection of parsing tools should be thoroughly considered during the data pre-processing stage. While there are some interesting findings on Java-med and Java-small, we anticipate this work could provide some insights for better ML-based software service solutions from the perspective of source code engineering.",Yes,"논문 초록에서 다양한 파싱 도구의 성능 평가와 그 영향에 대한 정량적 분석이 수행되었음을 시사하는 실험 결과를 언급하고 있습니다. 특히, Java-small 데이터셋에 대한 실험을 통해 모델 성능에 미치는 차이를 정량적으로 평가한 것으로 보입니다."
Machine Learning-Based Security Test Model and Evaluation for SIP-Based DoS Attacks,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9894217,"In recent years, with the development of IP-based systems, circuit-switched systems have rapidly started to be replaced by packet-switched systems in communication infrastructures and operators have started to prefer VoIP systems more due to their advantages such as cost and resource efficiency. However, since VoIP (Voice over Internet Protocol) systems are equally open to all threats to which IP-based systems are open, researchers have proposed different methods for obtaining strong security solutions. Recently, rule-based systems have been replaced by machine learning-based systems in many areas and different machine learning-based solutions have been suggested for VoIP security.In this study, a machine learning-based solution was proposed for detecting SIP flooding attacks within the scope of DoS (Denial of Service) attacks which is one of the current threats to VoIP infrastructure. For this purpose, a test environment was created on a previously developed simulation infrastructure, primarily normal traffic and attack traffic were generated, and then the effectiveness of certain machine learning methods in the classification of traffic was tested with the labeled data obtained.When the results are evaluated with the parameters based on the working conditions, it is observed that the related methods can produce meaningful results.",Yes,"논문 초록에서 다양한 머신러닝 방법을 사용하여 트래픽 분류의 효과를 평가했다고 명시되어 있습니다. 또한, 실험 환경에서 수집된 라벨링된 데이터를 활용하여 성능을 검증하는 정량적 평가가 수행된 것으로 보입니다."
System Level Knowledge Representation for Complexity,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9447091,"To develop systems capable of high level cognitive functions such as intelligence, it is necessary to formally capture different types of knowledge, so that they can be used to support complex processes, such as inference and reasoning. The design and engineering of Intelligent Systems to support large distributed socio technical processes increasingly leverages converging techniques from Artificial Intelligence, Knowledge Representation (KR) and Cognitive Architectures. This is resulting in multi layered architectures and AI technologies which one the one hand offer unprecedented capabilities, on the other hand present innumerable, often inconceivable risks. Sophisticated conceptual structures are necessary not only to support the modeling, validation and explanation of complex engineered systems, but primarily to support cognition and conceptualization of the complexities involved, for designers, developers, end users and any stakeholder. Depending on the cognitive makeup of observers, and on the knowledge available, complexity can be conceptualized and traversed following a diversity of methods and patterns. Sometimes complexity can be broken down into cognitively accessible chunks, in other cases however, it cannot be broken down without losing essential information about the system as a whole. Addressing the need to develop cognitive artifacts, methods and techniques that can capture and represent complexity, this paper proposes the outline of conceptual structure that bridges existing approaches which tend to distinguish between cognitive engineering and Knowledge Representation, with the aim to integrate technical and socio technical systems dimensions. The paper presents considerations about cognitive aspects of complex systems theory and practice. It anticipates a convergence between cognitive architectures and KR, introduces the notion of System Level Knowledge Representation and applies it to navigate socio technical complexity in systems engineering. A summary of related work where the System Level Knowledge Representation is being developed and evaluated is also provided.",No,"초록에서는 시스템의 복잡성을 표현하기 위한 개념적 구조와 이론적 접근 방식을 제시하고 있으며, 관련 작업의 개발과 평가에 대한 언급이 있지만, 구체적인 정량적 평가 방법이나 실험적 데이터, 수치 분석이 포함된 내용은 언급되지 않습니다. 따라서 이 논문은 정량적 평가를 실시하고 있다고 보기 어렵습니다."
5G D2D Transmission Mode Selection Performance & Cluster Limits Evaluation of Distributed AI and ML Techniques,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9530792,"5G D2D Communication promises improvements in energy and spectral efficiency, overall system capacity, and higher data rates. However, to achieve optimum results, it is essential to select wisely the Transmission mode of the D2D Device to form clusters in the most advantageous positions in terms of Sum Rate and Power Consumption. Towards this end, this paper investigates the use of Distributed Artificial Intelligence (DAI) and innovative D2D, Machine Learning (ML) approaches (i.e., DAIS, FuzzyART, DBSCAN and MEC) to achieve satisfactory results in terms of Spectral Efficiency (SE), Power Consumption (PC) and execution time, with the creation of clusters and back-hauling links in D2D network under existing Base Station. Additionally, this paper focuses on a small number of Devices (i.e., <=200), targeting the identification of the limits of each approach in terms of the low number of devices. More specifically, we investigate when an operator must consider implementing a D2D network (that requires extra complexity), therefore when the cluster members are sufficient enough to achieve better results than the classic mobile network. So, this research identifies where it is beneficial to form a cluster, investigate the critical point that gains increases rapidly and in the end, examine the applicability of 5G requirements. Additionally, prior work presented a Distributed Artificial Intelligence (DAI) Solution/Framework in D2D, and a DAIS Transmission Mode Selection (TMS) plan was proposed. In this paper, DAIS is further examined, improved in terms of thresholds evaluation (i.e., Weighted Data Rate (WDR), Battery Power Level (BPL)), evaluated, and compared with other approaches (AI/ML). The results obtained demonstrate the exceptional performance of DAIS and FuzzyART, compared to all other related approaches in terms of SE, PC, execution time and cluster formation. Also, results show that the investigated AI/ML approaches are also beneficial for Transmission Mode Selection (TMS) in 5G D2D communication, even with fewer devices (i.e., >=5 for clustering, >=50 for backhauling) as lower limits.",Yes,"논문 초록에서 다양한 정량적 평가 지표인 Spectral Efficiency (SE), Power Consumption (PC), 실행 시간 등을 측정하고 비교하는 내용을 언급하고 있습니다. 또한, 여러 AI/ML 기법의 성능을 평가하는 실험 결과를 제시하는 것으로 보아 정량적 평가를 실시하고 있음을 알 수 있습니다."
A Small-Scale Temperature Forecasting System using Time Series Models Applied in Ho Chi Minh City,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9994437,"Urban living benefits greatly from weather forecasting since it may lower weather-related losses, safeguard public health and safety and promote both economic growth also quality of life. The main goal of this work is to develop a small-scale temperature forecasting system employing a cutting-edge time series model. In order to do so, data on Ho Chi Minh City's temperature is gathered. The performance of several time series models based on machine learning and deep learning is then evaluated for input data of various lengths. To create a small-scale temperature forecasting system, the best model is chosen. The suggested approach is particularly well suited for a smart agricultural indoor temperature forecasting system, which cannot be accomplished with any large-scale temperature forecasting systems.",Yes,"논문 초록에서 여러 시간 시계열 모델의 성능을 평가하는 과정이 언급되어 있으며, 이를 통해 최적의 모델을 선정하는 절차가 포함되어 있음을 알 수 있습니다. 이는 정량적 평가가 수행되고 있음을 의미합니다."
Prediction of Insurance Premium using Machine Learning with an Adaptive Approach,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10307009,"The insurance market is very large and expanding day by day. There are many parameters to consider before deciding on insurance premiums. Sometimes it becomes difficult to browse all the documents before applying for insurance, so it is necessary to understand the insurance industry and point out issues related to competition in that industry. This type of company is very interested in forecasting. The goal of this article is to find accurate predictions based on considering different dimensions of machine learning to reduce the company's financial losses. Machine learning helps companies to optimize their services with greater accuracy and fewer losses. It can also help insurance companies effectively screen cases, evaluate them more accurately, and make accurate cost forecasts. This research work uses machine learning-based methods like linear regression, KStar, and Random Forest and suggests a suitable method to produce results with high accuracy and less relative error. In addition to this, it demonstrates how to create a specific data subset that can be used to test and train a machine learning system. The effectiveness of the suggested strategy is assessed by contrasting the estimated value with the actual value of the simulated data. Insurance firms are capable to construct consistent financial structures, such as monthly premiums or payroll taxes, to provide funds to pay for the medical benefit agreements that are defined in insurance policies by calculating the whole risk of the expenses associated with health care and the medical system.",Yes,"논문 초록에서 머신러닝 기법을 사용하여 보험료 예측의 정확도를 평가하고 있으며, 실제 값과 예측 값을 비교하는 방법으로 정량적 평가를 실시하고 있음을 언급하고 있습니다. 따라서 정량적 평가가 수행되고 있다고 판단됩니다."
A proposed Crypto-Ransomware Early Detection(CRED) Model using an Integrated Deep Learning and Vector Space Model Approach,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9031182,"Crypto-ransomware is a malware category that targets user-related files to encrypt them and hold them to ransom. The irreversible effect of crypto-ransomware attacks entails early detection before it starts encrypting the files. Although several works have been proposed to detect such attacks at the pre-encryption phase before the encryption takes place, the main limitation of these works is the way in which they define the boundaries of the pre-encryption phase. That is, these studies determine the pre-encryption boundaries based on tracking the first call of any cryptography-related Application Programming Interface (API). However, relying on the first call of cryptography-related APIs to delineate the pre-encryption boundaries is not accurate as these APIs might be related to other (normal) tasks done by the crypto-ransomware, such as unpacking and/or decrypting the metamorphic payload, before the ransomware starts the malicious activities. In that case, the collected pre-encryption data lack many relevant pre-encryption attack patterns that come after the mistakenly-identified pre-encryption boundary. Such data insufficiency adversely affects the accuracy of the detection model and increases the rate of false alarms. To overcome such limitations, this paper proposes an early detection model (CRED) that can determine the pre-encryption boundaries and collect the data related to this phase more accurately. Unlike the extant research, the CRED model employs data-centric and process-centric detection approaches to combine both IRP and API data. These data will then be used to train a deep learning-based model. The CRED model will be evaluated using a data-benchmark collected by executing real-world crypto-ransomware samples downloaded from a widely-used repository. The performance of the detection model will be validated using the k-fold cross validation and compared against the models proposed by the existing works.",Yes,"논문 초록에서 딥러닝 기반 모델을 훈련시키기 위해 데이터를 사용한다고 명시되어 있으며, 이를 평가하기 위해 교차 검증(k-fold cross validation)을 실시한다고 언급하고 있습니다. 이는 정량적 평가가 수행되고 있음을 보여줍니다."
BMI-based framework for teaching and evaluating robot skills,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6907749,"Brain Machine Interface systems provide ways of communication and control of a variety of devices that range from domestic appliances to humanoid robots. Most BMI systems are designed exclusively to control devices using low-level commands, or high-level commands when devices with pre-programmed functionalities are available. In this paper, we build on our previous work on BMI-based Learning System in which we presented a different approach for designing BMI systems that incorporate learning capabilities that relieve the user from tedious low-level control. In this work, we extend the capabilities of our framework to allow a user to be able to teach and evaluate a robotic system by using a BMI. We provide general system architecture and demonstrate its applicability in new domains such as teaching a humanoid robot object manipulation skills and evaluating its performance. Our approach consists of 1) tele-operating robot's actions while robot's camera collects object's visual properties, 2) learning manipulation skills (i.e. push-left, lift-up, etc.) by approximating a posterior probability of commonly performed actions when observing similar properties, and 3) evaluating robot's performance by considering brain-based error perception of the human while he/she passively observes the robot performing the learned skill. This technique consists of monitoring EEG signals to detect a brain potential called error related negativity (ERN) that spontaneously occurs when the user perceives an error made by the robot. By using human error perception, we demonstrate that it is possible to evaluate robot actions and provide feedback to improve its learning performance. We present results from five human subjects who successfully used our framework to teach a humanoid robot how to manipulate diverse objects, and evaluate robot skills by visual observation.",Yes,"논문은 로봇 기술의 평가와 학습 능력을 포함하는 프레임워크를 제시하며, 로봇의 성능을 정량적으로 평가하는 방법으로 EEG 신호를 이용한 오류 인지(ERN)를 활용하고 있습니다. 이를 통해 정량적 평가가 수행되고 있음을 알 수 있습니다."
Implementation and Comparison of U-net networks for Automatic COVID-19 Lung Infection Segmentation,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9955782,"With the big number of COVID-19 patients, efficient detection tools are necessary. In this work, we proposed an automatic detection and quantification tool based on deep learning model. The architecture used is U-Net architecture, one of the most known for medical applications. This network was introduced as a binary semantic segmentation tool. It uses a dataset of 100 images, seventy-two of them for training, ten for validation, and eighteen for testing. The model will be compared with other deep learning models and evaluated using several evaluation metrics. The results have shown an accuracy of 0.958, sensitivity of 0.900, dice coefficient of 0.726, and a specificity of 0.962. Compared with other related works, our network has the best accuracy and specificity. The obtained results show the ability of the model as a binary segmentation tool to separate infection tissue and healthy tissue.",Yes,"논문 초록에서 모델의 성능 평가를 위해 정확도, 민감도, Dice 계수, 특이도와 같은 여러 평가 지표를 사용했다고 명시되어 있습니다. 이는 정량적 평가를 실시하고 있음을 보여줍니다."
Cloud Based AIVR Training System for Emergency Rescue,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10858818,"This paper mainly discusses the current situation and existing problems of training exercises in emergency medicial scenarios, as well as the importance and necessity of developing an AI training system for emergency medical scenarios. First, we introduce the current status of emergency medical training and emphasize the potential value of AI technology in this field. Then, the goal of developing an AI training system is defined as improving the efficiency and quality of medical education and training. We summarize the advantages of AI technology in emergency medical exercises and make a review and selection analysis of its related technologies. In the design and implementation stage, we describe in detail the requirement analysis, function design, system architecture, and core module development of the emergency medical AI training system. After system integration and testing, we verified the feasibility and effect of the system. In the process of evaluation and optimization, we evaluated the performance and user experience of the system and put forward optimization strategies and security considerations for the problems. In the application case analysis, we collect user feedback to verify its efficiency and carry out an in-depth analysis of the advantages and disadvantages of the system. Finally, in the conclusion and prospect part, we summarize the research results, point out the existing problems and improvement directions and look forward to the future development trends and challenges of AI training systems for emergency medical scenarios.",No,"논문 초록에서는 시스템의 설계, 구현, 평가 및 사용자 피드백을 다루고 있지만, 구체적인 정량적 평가 방법이나 수치적 성과 지표에 대한 언급이 없습니다. 따라서 정량적 평가를 실시했다고 보기 어렵습니다."
Artificial Intelligence for Traffic Prediction and Estimation in Intelligent Cyber-Physical Transportation Systems,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10269085,"A cyber-communication infrastructure is required for physical components like control systems, sensors, actuators, and the environment to communicate and collaborate in real-time effectively. This is what cyber-physical systems (CPSs) provide. Deep Learning (DL) techniques have sped up and improved the progress of Intelligent Transportation Systems (ITS) in recent years, especially in problem domains traditionally addressed with analytical or statistical solutions. In addition to advancing driverless vehicle development to a new level, the improvements brought about by DL applications have led to better traffic organization and scheduling, increased security and safety on transit roads, reduced maintenance costs, and optimized performance for public transportation ride-sharing companies. The primary goal of this work is to offer a complete study and awareness of the uses of DL models on ITS, as well as to demonstrate the development in ITS research that has been owing to DL studies. This article briefly introduces the reader to various DL methods before thoroughly examining and describing how these methods are now being used in the transportation sector. Deep learning models are trained on this real-world traffic information to detect better and forecast the probability of crashes. This work aims to do just that by providing a multi-perspective assessment of deep learning-based techniques for traffic forecasting. This paper offers a summary and taxonomy of current traffic forecast systems. We provide a compilation of the most cutting-edge methods currently used for traffic forecasting. In addition, we assess the efficacy of various approaches using a public, real-world dataset and provide an evaluation and analysis of our findings. These findings demonstrate that, related to state-of-the-art shallow models, a deep model is superior at traffic detection and achieves equivalent results in terms of traffic prediction. We suggest a new deep learning framework, an Attention-based hybrid Convolutional Neural network with Long Short Term Memory (LSTM) (AHCNLS), to perform real-time traffic prediction from a data mining approach to enhance driver and passenger safety. The suggested approach considers the spatial and temporal connection between GPS trajectories and contextual elements. Using a publicly available dataset, our proposed technique is evaluated and shown to have advantages over competing methods.",Yes,"논문 초록에서 다양한 딥러닝 모델을 사용하여 교통 예측을 수행하고, 이를 평가하기 위한 실험과 분석이 포함되어 있음을 명확히 언급하고 있습니다. 또한, 공개 데이터셋을 활용한 성능 평가와 비교 연구를 통해 정량적 평가를 실시하고 있음을 알 수 있습니다."
Prediction of Type 2 Diabetes using Metagenomic Data and Identification of Taxonomic Biomarkers,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10600811,"Nowadays, different molecular levels of -omics data on diseases are generated and analyzing these data with machine learning methods is one of the popular research topics. Among these data, the use of metagenomic data to facilitate the diagnosis, detection and treatment of diseases is increasing day by day. Type 2 diabetes (T2D) is a chronic disease characterized by insulin resistance and progressive dysfunction of pancreatic beta cells. While the number of people with diabetes is increasing by around 8% annually, the cost of treating the disease is rising by 18% per year. Therefore, the number of studies on the diagnosis, development and progression of T2D is increasing over time. The aim of this study is to achieve higher machine learning performance by using fewer metagenomic features and to achieve better classification performance by reducing computational costs. In this study, we compare the performance of three different methods using T2D-related metagenomic data. First, the MetaPhlAn tool is used to calculate the taxonomic species and their relative abundances in each sample. The SVM-RCE, RCEIFE and microBiomeGSM tools used in this study are methods that perform classification by grouping and scoring features and are known to work well on complex datasets. In this study, the best results were obtained with the RCE-IFE tool with an AUC of 0.72 with an average of 125 features information. In addition, key taxonomic species identified by these tools as associated with T2D are presented in comparison to the literature.",Yes,"논문 초록에서 여러 기계 학습 방법을 사용하여 분류 성능을 평가하고 있으며, 특히 AUC(Area Under the Curve)와 같은 정량적 지표를 통해 성능을 평가하고 있음을 명확히 언급하고 있습니다. 이는 정량적 평가를 실시하고 있음을 보여줍니다."
Performance Analysis of Various Deep Learning Models in Lung Cancer Detection and Classification Using Medical Images,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10748430,"Lung cancer remains a prevalent and deadly disease, accounting for millions of deaths globally each year. Early detection and accurate diagnosis of lung cancer are pivotal in improving patient outcomes and survival rates. Traditional diagnostic methods often face limitations in sensitivity and specificity, necessitating the exploration of advanced technological solutions. This research paper explores the application of deep learning models, specifically Convolutional Neural Networks (CNNs), ResNet50, MobileNetV2 and VGG-16 architectures, in the detection and classification of lung cancer from medical imaging data. The primary objective of this study is to develop and evaluate deep learning-based models capable of identifying lung cancer patterns in radiological images, notably X-rays and CT scans. These models leverage the inherent capacity of deep learning to automatically extract intricate features and patterns from complex image data, aiding in the precise identification of cancerous regions. The paper reviews the strengths and limitations of existing approaches examining their efficacy in identifying and classifying lung nodules in achieving reliable and robust results. Furthermore, it addresses the challenges associated with utilizing deep learning in medical diagnosis, such as data scarcity, bias, and interpretability. Through meticulous analysis and experimentation, we aim to evaluate the potential of deep learning models to revolutionize lung cancer detection, paving the way for improved patient outcomes and early intervention strategies.",Yes,초록에서 여러 딥러닝 모델의 성능을 평가하는 실험과 분석이 수행되었음을 언급하고 있습니다. 이를 통해 정량적 평가가 이루어졌음을 알 수 있습니다.
Enhancing IoT-Botnet Detection using Variational Auto-encoder and Cost-Sensitive Learning: A Deep Learning Approach for Imbalanced Datasets,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10223613,"The Internet of Things (IoT) technology has rapidly gained popularity with applications widespread across a variety of industries. However, IoT devices have been recently serving as a porous layer for many malicious attacks to both personal and enterprise information systems with the most famous attacks being botnet-related attacks. The work in this study leveraged Variational Auto-encoder (VAE) and cost-sensitive learning to develop lightweight, yet effective, models for Io'Ivbotnet detection. The aim is to enhance the detection of minority class attack traffic instances which are often missed by machine learning models. The proposed approach is evaluated on a multi-class problem setting for the detection of traffic categories on highly imbalanced datasets. The performance of two deep learning models including the standard feed forward deep neural network (DNN), and Bidirectional-LSTM (BLSTM) was evaluated and both recorded commendable results in terms of accuracy, precision, recall and F1-score for all traffic classes.",Yes,"논문 초록에서 모델의 성능 평가를 위해 정확도, 정밀도, 재현율, F1-score와 같은 정량적 지표를 사용했다고 명시되어 있습니다. 이는 정량적 평가를 실시하고 있음을 보여줍니다."
Determining the optimum TMS and PS of overcurrent relays using the Firefly Algorithm for solving the relay coordination problem,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9418021,"To determine optimal solutions, Artificial intelligence (AI) was used to a number of problems by evolutionary search and metaheuristic algorithms. They are being used in numerous problems related to modern power systems, such as economic load dispatch and coordination of relays. Overcurrent relays (OCRs) coordination is a major issue in the distribution system (DS) protection. To minimize the overall operating time of the relays and set the optimum values of the relay, the coordination should be done correctly. Make sure that when a fault happens, the least damage is incurred. The application of the firefly algorithm (FA) for optimal coordination of relays is presented in this paper. Using MATLAB, the algorithm was implemented and evaluated upon various systems, two of which are discussed in this work. The obtained results by the firefly algorithm (FA) and genetic algorithm (GA) are analyzed and compared.",Yes,"논문 초록에서 최적화 문제를 해결하기 위해 알고리즘을 적용하고, 그 결과를 평가하는 과정이 언급되어 있습니다. 특히, Firefly Algorithm과 Genetic Algorithm의 성능을 비교 분석하는 내용이 있어 정량적 평가가 실시되고 있음을 알 수 있습니다."
Variational Autoencoders and Wasserstein Generative Adversarial Networks for Improving the Anti-Money Laundering Process,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9446893,"There has been much recent work on fraud and Anti Money Laundering (AML) detection using machine learning techniques. However, most algorithms are based on supervised techniques. Studies show that supervised techniques often have the limitation of not adapting well to new irregular fraud patterns when the dataset is highly imbalanced. Instead, unsupervised learning can have a better capability to find anomalous and irregular patterns in new transaction. Despite this, unsupervised techniques also have the disadvantage of not being able to give state-of-the-art detection results. We propose a suite of unsupervised and deep learning techniques to implement an anti-money laundering and fraud detection system to resolve this limitation. The system leverages three deep learning models: autoencoder (AE), variational autoencoder (VAE), and a generative adversarial network. We preprocess the given dataset to separate the Transaction Date attribute into its base components to capture time-related fraud patterns. Also, Wasserstein Generative Adversarial Network (WGAN) is used to generate fraud transactions, which are then mixed with the base dataset to form a more balanced mixed dataset. These two datasets are used to train the AE and VAE models. We built two versions of the AE model (single-loss and multi-loss) besides a novel method of calculating the anomaly score threshold, called Recall-First Threshold (RFT), which helps enhance the model's performance. Experimental results demonstrated that the False Positive Rate (FPR) drops down to as low as 7% in the proposed multi-loss AE model. In comparison, we achieved an accuracy of 93%, with 100% of the fraud transactions recalled successfully.",Yes,"논문 초록에서 여러 딥러닝 모델(자동인코더, 변이형 오토인코더, Wasserstein GAN)을 사용하여 실험을 수행하고, 그 성능을 평가하는 지표(예: FPR, 정확도, 재현율)를 제시하고 있다. 이는 정량적 평가를 실시하고 있음을 보여준다."
Analysis of Deep Learning-based MIMO Detectors,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10393665,"Multiple-Input Multiple-Output (MIMO) communication systems have become a fundamental technology in modern wireless networks due to their ability to enhance data rates and system capacity. However, traditional MIMO detection algorithms face significant challenges, including increasing complexity and performance degradation with growing system dimensions. Deep learning has shown great promise in various domains in recent years, leading researchers to explore its potential in addressing MIMO detection capability. This paper provides a comprehensive overview of deep-learning-based MIMO detection techniques, presenting an extensive literature review and taxonomy of approaches. We conduct a comparative analysis with conventional techniques and evaluate the detection performance of deep learning-based approaches. The paper also compares the required number of FLOPs operations to identify the potential of each detection method.",Yes,"논문 초록에서 딥러닝 기반 MIMO 검출 기법의 성능 평가를 위해 비교 분석과 검출 성능 평가를 수행했다고 명시되어 있습니다. 또한, 각 검출 방법의 FLOPs 연산 수를 비교하는 정량적 평가도 포함되어 있어 정량적 평가를 실시하고 있음을 알 수 있습니다."
Use of Compression Analytics to Detect Deception,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10386884,"This paper describes the development and application of compression-based machine learning (ML) combined with part of speech (PoS) analysis to detect deception. Multiple data sets, including research associated with papermills, social media, and online reviews were used to test these methods. Our research is especially concerned with achieving reliable performance with minimal parameters and data preprocessing. The core idea draws from scientific literature suggesting that subtle, yet predictable linguistic cues can be indicative of intentionally deceptive writing. Part of speech parsing was chosen as a means to represent how the person was communicating as opposed to the content of the writing. The contribution of this paper beyond existing literature is demonstrating the robustness of the application of compression-based ML across a variety of data sets and using explainability to validate that the results are consistent with the underlying psychology. These methods have relatively few parameters and are easy to apply while still providing the best performance among the methods we tested. We present the results of studies over six data sets. In addition to the classification results, we also perform an explainability analysis that shows what parts of speech contributed the most to the performance. for the compression-base ML. These results are largely consistent between data sets and match the underlying psychology research.",Yes,"논문 초록에서 여러 데이터 세트에 대해 분류 성능을 평가하는 결과를 제시하며, 정량적 평가를 수행했음을 암시하는 내용을 포함하고 있습니다. 또한, 성능 검증과 설명 가능성 분석을 통해 정량적 평가의 실시를 확인할 수 있습니다."
Deep Coupled Joint Distribution Adaptation Network: A Method for Intelligent Fault Diagnosis Between Artificial and Real Damages,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9288756,"Deep learning techniques have been widely applied for intelligent fault diagnosis. However, these techniques require large amounts of labeled data from a particular machine, which is demanding for real-world applications. Alternatively, models can be developed based on artificial damages and be applied for industrial data with real damages. In that case, a major challenge arises since the distributions of those artificial and real damages are greatly different, which results in severe performance degradation of conventional deep models. In this work, a model named deep coupled joint distribution adaptation network (DCJDAN) is proposed to address the large domain discrepancy between artificial and real damages. By utilizing two untied deep convolutional networks, the proposed method allows the source- and target-stream networks to focus on learning domain-representative features, providing flexibility for explicitly modeling the domain discrepancy. To ensure a more effective knowledge transferring, a regulation term is adopted to force the untied coupled networks to stay similar since the source domain and the target domain are related. The joint distribution adaptation module is further adapted to minimize the domain discrepancy, which considers both the marginal and conditional distribution differences and provides more accurate distribution matching. The effectiveness of the proposed method is evaluated based on three bearing data sets with artificial and real damages. As reported, the proposed method achieves an average accuracy of 98.17% for all tasks, which outperforms several state-of-the-art deep domain adaptation models and improves the diagnosis performance compared with the conventional deep learning models.",Yes,"논문 초록에서 ""a regulation term is adopted""와 ""the joint distribution adaptation module is further adapted to minimize the domain discrepancy""와 같은 표현을 통해 정량적 평가를 수행했음을 알 수 있습니다. 또한, ""the effectiveness of the proposed method is evaluated based on three bearing data sets""와 ""achieves an average accuracy of 98.17%""라는 구체적인 성과 지표를 제시하여 정량적 평가를 실시했음을 명확히 보여줍니다."
Tool Wear and Surface Quality Monitoring Using High Frequency CNC Machine Tool Current Signature,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8472037,In this paper a machine learning approach for tool wear monitoring (TWM) and surface quality detection is proposed using high frequency current samples of a CNC turning machine main terminal. Significant frequency based features related to tool wear and surface quality are selected by univariate filter methods. Supervised machine learning methods including Support Vector Machine (SVM) and Random Forest Ensemble (RFE) are used to estimate tool wear and surface quality. Best hyper-parameter combinations of the proposed models are evaluated and found by grid search methods. Experimental studies are conducted on a CNC turning machine using a test work piece and the classification and accuracy results are presented. The presented methodology makes the set up of an on-line system for tool condition monitoring and an estimation of the work piece surface quality by the use of inexpensive and easy to install measurement hardware possible.,Yes,"논문 초록에서 Support Vector Machine (SVM)과 Random Forest Ensemble (RFE)와 같은 supervised machine learning 기법을 사용하여 공구 마모와 표면 품질을 추정하는 과정을 언급하고 있습니다. 또한, 하이퍼파라미터 최적화와 실험 결과의 정확도 평가를 통해 정량적 평가가 수행되고 있음을 알 수 있습니다."
An Efficient Ensemble Ranking Model for IoT-based Crop-Precision-Prediction(CPP) in Agriculture,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10690002,"In recent years, agriculture has undergone substantial technical transformation using Internet of Things and Artificial Intelligence, to realize smoothly production scenarios. In this work, a new disease identification application by machine learning is proposed for IoT microcontrollers and plant diseases, which has a high degree of accuracy reaching to 91.45%. In this research we also review the most common traditional and innovative technique used to promote and sustain the agricultural growth, focusing on the Smart Farming systems based on IoT. This research aims to compare several traditional to modern methods, detailing the evolution of technologies and their benefic impact on agricultural productivity. Alongside this in-depth review, the research also engages in a comparative analysis of different approaches to smart farming, with a particular focus on building and evaluating small pilot systems. This assessment is crucial in determining the most strategic approach to developing and enhancing these systems, enabling researchers to achieve a certain degree of systemic optimization. Integrating IoT is one of the main benefits of this study, with the following information further highlighting the main application in agricultural sector: In the field of agriculture, the integration of Internet of Things such as sensors can reduce the need for manual labor and maximize efficiency in farms. For instance, IoT devices can smartly perform planting processes and monitor soil information in real time. Then, the collected information can be distributed to related devices for decision-making and resource management. This could lead to improved agricultural productivity. Furthermore, the study also describes the effectiveness of the new machine learning application as it reached a 98.45 per cent accuracy in detecting more than four types of plant diseases which could be useful in agriculture for helping to prevent the spread of disease.",Yes,"논문 초록에서 정량적 평가를 위해 정확도(accuracy) 수치를 제시하며, 병해충 식별 및 농업 생산성 향상에 대한 성과를 수치로 평가하고 있음을 보여줍니다. 이는 정량적 평가를 실시하고 있음을 의미합니다."
Rate Insight: A Comparative Study on Different Machine Learning and Deep Learning Approaches for Product Review Rating Prediction in Bengali Language,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10055515,"In this contemporary era of digital marketing, ecommerce has emerged as one of the most preferred methods for day-to-day shopping. Ever since the COVID-19 pandemic, online shopping behavior has forever changed to less or no human-to-human interaction. As a result, it is getting more difficult for e-commerce enterprises to observe and evaluate market trends, particularly when done through consumer behavior analysis. To identify behavioral patterns and customer review-rating discrepancies, extensive analysis of product reviews is a substantial research field. Lack of benchmark corpora and language processing techniques, predicting review ratings in Bengali has become increasingly problematic. This paper thoroughly analyzes the approach to product review rating prediction for Bengali text reviews exploiting our own constructed dataset that was collected from an e-commerce website called DarazBD1. We acquired product reviews with labels known as ratings of five sentiment classes, from ""1"" to ""5"". It is noteworthy that we established a well-balanced dataset using our automated scraping system and a significant amount of time and effort is spent to maintain quality standards through the human annotation process. Exploration of multiple approaches to machine learning models such as logistic regression, random forest, multinomial naïve Bayes, and support vector machine, the best classification accuracy score of 78.63% is achieved by SVM. Subsequently, using Word2Vec, FastText, and GloVe embeddings with three deep neural network(DNN) architectures: CNN, Bi-LSTM, and a combination of CNN and Bi-LSTM, CNN+Bi-LSTM gave the highest accuracy score of 75.25% among the DNN architectures.",Yes,"논문 초록에서 다양한 기계 학습 및 딥러닝 모델을 사용하여 제품 리뷰 평점 예측의 정량적 평가를 수행했다고 명확히 언급하고 있습니다. 또한, 정확도 점수와 같은 성능 지표를 제시하여 평가가 이루어졌음을 알 수 있습니다."
The Use of Arabic Language COVID-19 Tweets Analysis in IoT Applications,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9693080,"Social media platforms have become one of the most powerful tools for organizations and individuals to publish news and express thoughts or feelings. With the increasingly enormous number of internet users in Saudi Arabia, the need raised to analyze Arabic posts. Since the emergence of COVID-19 in the latest 2019, it lefts economies and businesses counting the cost while governments fight the spread of the virus with new compartmentalization measures. Keeping in view the importance of quick and timely data analysis and sharing for policy actions, Artificial intelligence (AI) has played a crucial role in facilitating the exchange of views and information between scientists and decision-makers during the Coronavirus pandemic, and they continue to do so. This work mined to these content-related tweets to see how people’s feelings and expressions are changing. The results of this analysis can be used with integration with several IoT technologies to reduce the impact of covid-19 and drive new decisions in this field. For this goal, we proposed a Machine Learning (ML) models that can classify both of the sentiment and topic of Modern Standard Arabic (MSA) tweets and achieve high accuracy results.",Yes,논문 초록에서 머신러닝 모델을 사용하여 감정과 주제를 분류하는 정량적 평가를 실시했다고 명시되어 있습니다. 이는 데이터 분석과 모델의 성능 평가를 포함하는 정량적 평가의 수행을 의미합니다.
Deep Q-Learning for Channel Optimization in MRCP BMI Systems: A Teleoperated Robot Implementation,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10539979,"Brain–machine interface (BMI) systems utilize brain signals to control external devices. Such systems can assist brain injury survivors who are partly or entirely unable to move the affected parts of the body. Electroencephalogram (EEG), a non-invasive method for recording brain signals in different locations of the subject’s scalp, is commonly used in such applications due to its cost-effectiveness and portability. Although EEG signals provide high temporal features, the signals are not robust due to both internal and external noises. Using all available EEG channels causes the system’s performance to deteriorate. Therefore, it is important to select the most informative channels to improve the system performance while reducing computation complexity. In this work, we propose a new Deep Q-Network (DQN)-based method to identify the best EEG channel combination for motor-related cortical potential tasks. The deep learning model is used to evaluate the DQN’s selected channels and provide feedback in terms of recognition rate. To evaluate the DQN’s performance, we compared the results with Genetic Algorithm and Backward Elimination channel optimization methods. Confusion matrix and recognition rates shows that the proposed DQN-based EEG channel optimization outperforms other methods. In addition, the results demonstrated that the DQN approach significantly reduced the number of channels while improving the BMI recognition rates. Furthermore, the EEG signals of optimized channels are used to control a teleoperated robotic hand in real time. The results of this work demonstrate the effectiveness of EEG channel optimization for the Internet of Things implementation of BMI systems.",Yes,"논문 초록에서 DQN 기반 방법을 사용하여 채널 선택의 성능을 평가하기 위해 인식률(Recognition rate)과 혼동 행렬(Confusion matrix)을 활용한 정량적 평가를 실시했다고 명시되어 있습니다. 또한, 다른 채널 최적화 방법과의 비교를 통해 성능 향상을 수치로 보여주고 있어 정량적 평가가 수행되고 있음을 알 수 있습니다."
Interpreting Training Aspects of Deep-Learned Error-Correcting Codes,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10206783,"As new deep-learned error-correcting codes continue to be introduced, it is important to develop tools to interpret the designed codes and understand the training process. Prior work focusing on the deep-learned TurboAE has both interpreted the learned encoders post-hoc by mapping these onto nearby ""interpretable"" encoders, and experimentally evaluated the performance of these interpretable encoders with various decoders. Here we look at developing tools for interpreting the training process for deep-learned error-correcting codes, focusing on: 1) using the Goldreich-Levin algorithm to quickly interpret the learned encoder; 2) using Fourier coefficients as a tool for understanding the training dynamics and the loss landscape; 3) reformulating the training loss, the binary cross entropy, by relating it to encoder and decoder parameters, and the bit error rate (BER); 4) using these insights to formulate and study a new training procedure. All tools are demonstrated on TurboAE, but are applicable to other deep-learned forward error correcting codes (without feedback).",Yes,"논문 초록에서 다양한 정량적 평가 방법들이 언급되고 있으며, 특히 Fourier 계수, 손실 함수 재구성, 비트 오류율(BER) 등 구체적인 수치적 지표와 도구들을 활용하여 훈련 과정과 성능을 분석하는 내용을 다루고 있습니다. 이러한 내용은 정량적 평가를 실시하고 있음을 보여줍니다."
Digital intelligent virtual assistant (DIVA) with natural speech and accent recognition,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9770703,"A Virtual Assistant (VA) system is a computer program that recognizes designated language voice commands and executes tasks on the user's behalf. This paper aims to conduct a state-of-the-art review for Digital Intelligent Virtual Assistant (DIVA) and their extended use for diverse users. Furthermore, the paper proposes a workflow scheme which takes into account accent recognition, voice registration and gives more manual control to the users. The proposed design considers the user ease and their struggles with technology; hence the proposed system is destined to serve as a mobile application. The VA encompasses techniques such as Natural Language Processing, Speech Pattern Recognition, Machine Learning and Language Data Statistical Analysis to accomplish the aforementioned user goals. Subsequently, this research will indulge in data analysis using questionnaires filled out anonymously and the results of this survey will allow us to validate our hypothesis. The analysis results are expected to demonstrate how users view their Digital Virtual Assistants and address their concerns regarding security, accent support, control and ease of use. Finally the paper summarizes the findings, methodology and results obtained through questionnaires and highlighting the potential for future works.",Yes,"논문 초록에서 설문조사를 통한 데이터 분석과 결과 검증을 언급하며, 정량적 평가를 실시하고 있음을 시사합니다. 또한, 설문조사 결과를 통해 가설을 검증하는 과정이 포함되어 있어 정량적 평가가 수행되고 있음을 알 수 있습니다."
Machine Learning Algorithms for Detecting Phishing Websites,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10910759,"Despite the quick growth of the digital world, phishing attempts still constitute a serious threat to the security of online banking transactions. The goal of this research project is to evaluate the usage of machine learning algorithms to detect websites that are used to spread phishing messages. This work specifically considers complex feature engineering and algorithm selection approaches. The detection method is enhanced by the application of optimal model, which is utilized to extract and evaluate text-based elements from phishing websites. It is done with optimal model. DNSPython and Python-Whois are the technologies utilized to finish gathering domain-related data. However, Scikit-learn makes the process of putting machine learning models into practice easier. The objectives that AutoML aids in achieving include efficient model selection and optimization. This has the important advantage of making it possible to automatically identify the algorithms with the highest performance levels. The objective of this research endeavour is to enhance the accuracy and robustness of phishing detection systems through the utilization of diverse methodologies and technologies. Additionally, the study makes an effort to clarify how machine learning would be able to successfully counteract the increasingly complex phishing methods. Through improving the automatic identification of phishing-related websites, our program seeks to contribute to the creation of safer online environments.",Yes,"The abstract mentions the evaluation of machine learning algorithms and the use of optimal models to assess text-based elements, indicating that quantitative assessments are conducted. These evaluations typically involve performance metrics and statistical analysis, which are characteristic of quantitative evaluation methods."
Very Large Scale Distributed Training Data and Federated Learning: A Case Study in DAS,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10223813,"FOTAS is an optoelectronic system used to measure acoustic signal values along the length of a fiber optic cable. By creating an acoustic profile along the length of the fiber optic cable, the system uses deep learning to detect and classify events in the physical environment. It provides high detection accuracy over long distances, it is reliable against electromagnetic interference, and it is also reliable during harsh working conditions. In order to train deep learning models known to the FOTAS system, the data must be stored in a central location. However, the migration of data is difficult because of its large size. After installing sensors in various regions and collecting data, it is very expensive to migrate this data to a server for model training. In addition to the difficulties that may emerge from data migration, problems related to data security may also occur. Federated learning enables model training on a given device by using data from server and client devices, which eliminates the need for a problematic data migration process. Client devices process data locally and share model weights with the server device. Therefore, there is no need to transfer large amounts of data. In this study, we apply the federated learning method on the FOTAS system and compare the results with the results from using classical methods. By selecting two client devices and one central device, we transferred model weights between remote devices. By choosing asynchronous device features, we observed how the federated learning system responds to asynchronous conditions. Based on the results of our study, we can conclude that federated learning can be used in commercial systems.",No,"논문 초록에서는 정량적 평가를 수행했음을 명시하거나 언급하지 않으며, 주로 방법론과 시스템의 적용에 관한 설명에 초점이 맞춰져 있다. 따라서, 정량적 평가의 실시 여부를 판단하기 어렵다."
A novel fast face recognition algorithm based on multi-dimension neural network model and boundary feature extraction technique,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8117727,"The manuscript addresses the subject of measured learning, which is the learning of a dissimilarity work from an arrangement of similar or dissimilar example pairs. The domain plays an important part in many machine learning applications, for example, those related to face acknowledgment or face retrieval. All the more specifically, themanuscript expands on the late Improved Measure Knowledge (IMK) strategy. Improved Measure Knowledge (IMK) has been appeared to perform exceptionally well for face retrieval tasks, however the algorithm depends on the computation of a weak measured which is extremely tedious. Themanuscript demonstrates how, by bringing scatter into the weak projectors, the meeting time can be decreased up when compared to Improved Measure Knowledge (IMK), with no performance misfortune. The manuscript also acquaints an unequivocal way with control the rank of the so-obtained measurements, allowing settling in advance the measurement of the feature space. The proposed ideas are experimentally validated on a face retrieval task with three unique signatures.",Yes,"논문 초록에서 제안된 방법들이 실험을 통해 검증되었으며, 정량적 평가를 통해 성능을 측정했음을 시사하는 내용이 포함되어 있습니다. 특히, ""실험적으로 검증""되었다는 표현이 정량적 평가의 수행을 의미합니다."
Privacy protection strategies in mobile crowdsensing from the framework perspective,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10718827,"In the era of Industrial 5.0, privacy protection in mobile crowdsensing (MCS) becomes even more important to achieve the goals of being human-centric, resilient, and sustainable. To address privacy challenges in MCS environments, this paper first conducts a systematic literature review to identify the research gap in MCS privacy protection and classify privacy protection strategies in terms of key phases of a MCS process. Then a six-dimensional framework for MCS privacy protection integrating user perspective, interaction perspective, and system security perspective is proposed. This comprehensive framework addresses the multifaceted privacy protection limitations identified in MCS process by examining the intersections between these dimensions. Then its effectiveness is demonstrated by case study ‘MCS for personalized healthcare’. This framework balances privacy and data utility, empowers users with transparent policies and control interfaces, and employs AI-driven adaptive security measures. Additionally, it provides a research roadmap for sustainable and resilient privacy protection in the context of Industrial 5.0, offering a comprehensive and user-centric solution to evolving privacy challenges.",No,"논문 초록에서는 프레임워크 제안과 사례 연구를 통해 개인정보 보호 전략을 설명하고 있으나, 구체적인 정량적 평가 방법이나 실험 결과에 대한 언급이 없습니다. 따라서 정량적 평가를 실시했다고 보기 어렵습니다."
Multi-Task Fusion for Improving Mammography Screening Data Classification,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9618960,"Machine learning and deep learning methods have become essential for computer-assisted prediction in medicine, with a growing number of applications also in the field of mammography. Typically these algorithms are trained for a specific task, e.g., the classification of lesions or the prediction of a mammogram’s pathology status. To obtain a comprehensive view of a patient, models which were all trained for the same task(s) are subsequently ensembled or combined. In this work, we propose a pipeline approach, where we first train a set of individual, task-specific models and subsequently investigate the fusion thereof, which is in contrast to the standard model ensembling strategy. We fuse model predictions and high-level features from deep learning models with hybrid patient models to build stronger predictors on patient level. To this end, we propose a multi-branch deep learning model which efficiently fuses features across different tasks and mammograms to obtain a comprehensive patient-level prediction. We train and evaluate our full pipeline on public mammography data, i.e., DDSM and its curated version CBIS-DDSM, and report an AUC score of 0.962 for predicting the presence of any lesion and 0.791 for predicting the presence of malignant lesions on patient level. Overall, our fusion approaches improve AUC scores significantly by up to 0.04 compared to standard model ensembling. Moreover, by providing not only global patient-level predictions but also task-specific model results that are related to radiological features, our pipeline aims to closely support the reading workflow of radiologists.",Yes,"논문 초록에서 AUC 점수와 같은 정량적 평가 지표를 사용하여 모델의 성능을 평가했다고 명확히 언급하고 있습니다. 또한, 다양한 평가 결과를 통해 제안한 방법의 효과를 수치로 보여주고 있어 정량적 평가를 실시하고 있음을 알 수 있습니다."
Parcel Damage Classification using Computer Vision: A Deep Learning Approach for Shipment Quality Assessment,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10503363,"The provision of parcel quality is critical in today’s shipping and logistic fields. Quick and accurate identification of parcel damage plays a significant role in preventing financial losses and customer satisfaction. This paper develops a novel classification for package damage which is enabled using computer vision and the deep learning (DL) approach. In this study, a combination of a convolutional neural network (CNN) with a support vector machine (SVM) was used to classify multiple parcel damages like scratches, deformation as well and cracks. This is an alternative means that gives a true picture of the reliability of ships. Firstly, this proposed work concentrates on the parcel’s assessment in the field of logistics – a demand for reliable and automatic technologies. Several key quantitative measures are used rigorously to evaluate the efficiency of the employed DL algorithm in correctly classifying/identifying and categorizing various package damages. These results show that DL has an impressive accuracy rate of 98.8% in the classification of package defects and may be practically applicable in field applications. Finally, the implications on shippers, logistics suppliers as well as those related to e-business are assessed. Issues arising from the results entail less cargo loss, improved quality control, and enhanced customer happiness among others. In particular, computer vision and DL have excellent technique for classifying parcel damage to contribute to the domain. This research will be important for the logistics and shipping business within a short period. This methodology is designed to automate the assessment of the quality of shipments that meet an important requirement along this chain. This could be a game changer whereby it would boost operational efficiency and ensure better service delivery.",Yes,"논문 초록에서 여러 핵심 정량적 평가 지표들이 사용되었음을 명확히 언급하고 있으며, 특히 딥러닝 알고리즘의 정확도(98.8%)와 같은 수치적 성과를 제시하고 있습니다. 따라서 정량적 평가를 실시하고 있다고 판단됩니다."
Error Vulnerabilities and Fault Recovery in Deep-Learning Frameworks for Hardware Accelerators,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9203738,"Hardware accelerators such as GP-GPUs, Tensor Cores, and Deep-Learning Accelerators (DLA) are increasingly being used in real-time settings such as autonomous vehicles (AVs). In such deployments, any software errors and process failures in hardware systems can lead to critical faults in AVs. Therefore, assessing and mitigating hardware accelerator faults are critical requirements for safety-critical systems. Past work on this subject focused on simulated and injected software and hardware faults to understand and analyze the behavior of the software stack and the entire system. However, programming errors and process failures caused when using software frameworks must also be considered. In this paper, we present experiments which show that widely used deep-learning frameworks are vulnerable to programming mistakes and errors. We first focus on memory-related programming errors caused by applications using deep-learning frameworks that facilitate high-performance inferencing. We next find that a reset to recover from any fault imposes significant time penalties in reloading a pre-trained deep neural network model. To reduce these fault recovery times, we propose fault recovery mechanisms that checkpoint and resume the network based on the inference stage when an error is detected. Finally, we substantiate the practical feasibility of our approach and evaluate the improvement in recovery times11A demo video clip demonstrating our recovery algorithm has been uploaded to Youtube: https://www.youtube.com/watch?v=xwUYdJdA5oM.. We use a case-study with real-world applications on an Nvidia GeForce GTX 1070 GPU and an Nvidia Xavier embedded platform, which is commonly used by multiple automotive OEMs.",Yes,"논문 초록에서 실험을 통해 fault recovery 시간을 측정하고, 제안한 복구 메커니즘의 실용성을 평가하는 내용을 언급하고 있습니다. 이는 정량적 평가를 수행했음을 보여줍니다."
Enhancing Sentiment Analysis Accuracy on IMDB Reviews Through Ensemble Machine Learning Techniques,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10417873,"In the rapidly evolving field of sentiment analysis, the IMDB movie review dataset has become one of the key benchmarks for evaluating the performance of machine learning models. This paper presents a comprehensive study of various machine learning models applied to the dataset, focusing on positive and negative reviews. We delve into the intricacies of advanced models such as BERT, LSTM, and GRU. The novelty of this work lies in the application of ensemble methods, specifically voting functions and stacking, to improve the accuracy of sentiment classification. We propose original techniques that leverage the strengths of individual models, mitigating their weaknesses through a collaborative approach. The ensemble methods used outperform single-model approaches, demonstrating improved accuracies in the classification of both positive and negative reviews. This research contributes to the ongoing discourse in sentiment analysis, offering fresh perspectives and techniques that enhance sentiment classification accuracy. The findings underscore the potential of ensemble methods in machine learning.",Yes,"논문 초록에서 여러 머신러닝 모델의 성능을 평가하고, 앙상블 방법을 통해 정확도를 향상시키는 연구를 수행했다고 명시되어 있습니다. 이는 정량적 평가를 실시했음을 시사하며, 성능 비교와 향상에 대한 구체적인 수치적 결과를 기대할 수 있습니다."
Recurrent Neural Network-Based Prediction of TCP Transmission States from Passive Measurements,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8548064,"Long Short-Term Memory (LSTM) neural networks are a state-of-the-art techniques when it comes to sequence learning and time series prediction models. In this paper, we have used LSTM-based Recurrent Neural Networks (RNN) for building a generic prediction model for Transmission Control Protocol (TCP) connection characteristics from passive measurements. To the best of our knowledge, this is the first work that attempts to apply LSTM for demonstrating how a network operator can identify the most important system-wide TCP per-connection states of a TCP client that determine a network condition (e.g., cwnd) from passive traffic measured at an intermediate node of the network without having access to the sender. We found out that LSTM learners outperform the state-of-the-art classical machine learning prediction models. Through an extensive experimental evaluation on multiple scenarios, we demonstrate the scalability and robustness of our approach and its potential for monitoring TCP transmission states related to network congestion from passive measurements. Our results based on emulated and realistic settings suggest that Deep Learning is a promising tool for monitoring system-wide TCP states from passive measurements and we believe that the methodology presented in our paper may strengthen future research work in the computer networking community.",Yes,"논문 초록에서 LSTM 기반 RNN을 사용하여 TCP 전송 상태를 예측하는 모델을 구축하고, 이를 정량적 평가를 통해 성능을 검증했다고 명시되어 있습니다. 또한, 다양한 시나리오에서 실험을 수행하여 방법의 확장성과 강인성을 평가했다고 언급되어 있어 정량적 평가가 실시된 것으로 판단됩니다."
Detecting polarization in ratings: An automated pipeline and a preliminary quantification on several benchmark data sets,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8258231,"Personalized recommender systems are becoming increasingly relevant and important in the study of polarization and bias, given their widespread use in filtering information spaces. Polarization is a social phenomenon, with serious consequences, in real-life, particularly on social media. Thus it is important to understand how machine learning algorithms, especially recommender systems, behave in polarized environments. In this paper, we study polarization within the context of the users' interactions with a space of items and how this affects recommender systems. We first formalize the concept of polarization based on item ratings and then relate it to the item reviews to investigate any potential correlation. We then propose a domain independent data science pipeline to automatically detect polarization using the ratings rather than the typical properties used to detect polarization, such as item's content or social network topology. We perform an extensive comparison of polarization measures on several benchmark data sets and show that our polarization detection framework can detect different degrees of polarization and outperforms existing measures in capturing an intuitive notion of polarization. Our work is an essential step toward quantifying and detecting polarization in ongoing ratings and in benchmark data sets, and to this end, we use our developed polarization detection pipeline to compute the polarization prevalence of several benchmark data sets. It is our hope that this work will contribute to supporting future research in the emerging topic of designing and studying the behavior of recommender systems in polarized environments.",Yes,"논문 초록에서 ""polarization detection framework""와 ""polarization measures""를 사용하여 정량적 평가를 수행했다고 명시되어 있습니다. 또한, 여러 벤치마크 데이터 세트에서의 비교와 ""polarization prevalence"" 계산 등 구체적인 정량적 분석이 이루어졌음을 보여줍니다."
Analyzing Public Sentiment: A Deep Dive into Twitter Discourse on the 2022 No Confidence Motion in Pakistan,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10473299,"Twitter, among other widely used social media platforms, is a prominent space for the global expression of feelings and opinions. In Pakistan, political parties actively utilize Twitter to connect with the public, fostering a continuous exchange of viewpoints. This results in a substantial daily volume of millions of tweets covering diverse political topics. This study conducts sentiment analysis on tweets gathered from the X platform (formerly Twitter) concerning a significant political event in Pakistan during the year 2022. The event was related to the No Confidence Motion which resulted in the dismissal of sitting Prime Minister Imran Khan. This work prepares dataset which comprises of 10000 tweets and is publicly available on GitHub. Tweets are classified as positive, negative, or neutral by using machine learning, deep learning, and transformers. Then, the comparison is made between these approaches using benchmark evaluation measures such as recall, precision, and F1-score. Multilingual BERT, a deep learning approach, turns out to be the best classifier for the collected tweets with the highest F1-score of 77.27%.",Yes,"논문은 감성 분석을 위해 머신러닝, 딥러닝, 트랜스포머 등 다양한 방법을 사용하여 정량적 평가를 실시하고 있으며, 평가 지표로서 재현율, 정밀도, F1-score를 활용하고 있습니다. 이러한 평가 지표를 통해 모델의 성능을 수치적으로 측정하고 있기 때문에 정량적 평가를 수행하고 있다고 판단됩니다."
Cross-Evaluation of Deep Learning-based Network Intrusion Detection Systems,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10410724,"Network Intrusion Detection Systems are essential tools for protecting networks against attacks. Deep Learning approaches are increasingly employed in developing these systems due to their versatility and effectiveness. However, the common procedure for training and testing Deep Learning models typically leverages traffic data entirely collected from the operational network managed by a single organization, posing privacy and security concerns in sharing these data. As a result, the assessment of the performance of these models in real-world scenarios is significantly hindered. On the other hand, given the wide variety of existing attacks and the emergence of new attack types, it is crucial to evaluate the robustness of Intrusion Detection Systems when the network context varies. Indeed, it is highly desirable that the effectiveness of trained Deep Learning models is not severely impacted when ported into other networks.To this aim, in this work, we exploit various single-modal and multimodal Deep Learning approaches and leverage a cross-evaluation procedure to assess their capability to distinguish malicious from benign traffic in different network contexts. Furthermore, we investigate the impact of various informative fields extracted from traffic on the generalization capability of models. Our cross-evaluation leverages three recent public-available network attack datasets related to diverse scenarios. The results obtained suggest that the availability at training time of traffic generated by attacks conducted in the operational network is crucial for designing a robust Intrusion Detection System that keeps working with minimal Fl-score degradation, when the network context changes.",Yes,"논문 초록에서 다양한 딥러닝 접근법과 교차 평가 절차를 활용하여 모델의 성능을 평가하는 과정을 언급하고 있습니다. 특히, 여러 네트워크 환경에서의 일반화 능력을 검증하기 위해 공개 데이터셋을 이용한 정량적 평가를 실시하는 것으로 보입니다."
On Sparsity Measures In Deep Subspace Clustering,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9776918,"Traditional clustering methods groups data points according to attributes such as similarity, continuity, neighbor-hood information, etc. overlooks the structural properties of the data. Consequently, prevalent clustering approaches to below-par performance in real-world applications. Unlike traditional clustering approaches, subspace clustering methods attempt to group datapoints keeping the inherent structure and rank-related properties of the data into account. Despite the rapid growth in deep learning-based approaches, very few works have utilized deep learning for the subspace clustering task. This work introduced an auto-encoder-based deep learning architecture consisting of a self-expressive layer for the deep subspace clustering task. We use smoothed L2, L0.5 and Frobenius norms instead of the actual measures for ease of optimization task. We also explored the efficacy of sparsity measures that characterize the self-representation coefficient matrix of the self-expressive layer. The experiments conducted on standard datasets suggest that the application of efficient sparsity measures improves the performance of the subspace clustering approach and results in superior performance compared to the previous deep subspace clustering approaches.",Yes,"논문 초록에서 ""experiments conducted on standard datasets""와 ""application of efficient sparsity measures improves the performance""라는 표현을 통해 정량적 평가가 수행되었음을 알 수 있습니다. 또한, 성능 향상에 대한 비교와 실험 결과를 제시하는 것으로 보아, 정량적 평가가 포함되어 있다고 판단됩니다."
Driver Drowsiness Detection Using Deep Learning,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10169941,"Driver drowsiness is a major cause of road accidents worldwide, and a drowsy driver is a serious threat to road safety [1]. To address this issue, researchers have developed various driver drowsiness detection systems that can alert the driver before a mishap occurs. In this paper, we present a comprehensive review of driver drowsiness detection systems, including their underlying techniques, advantages, and limitations. We examine the most commonly used techniques for detecting driver drowsiness, such as physiological measures, eye-tracking, and machine learning approaches. We also highlight the challenges associated with the development and implementation of such systems, including variability in individual sleep patterns, changing environmental conditions, and the trade-off between accuracy and user-friendliness. This review aims to provide a critical analysis of the state-of-the-art in driver drowsiness detection systems, and to identify research gaps and future directions for improving road safety. The document describes the functional and non-functional requirements of the system, including video input, eye detection, blink detection, EAR calculation, drowsiness detection, alert mechanism, user settings, accuracy, speed, robustness, portability, security, and user-friendliness. This study presents a driver drowsiness detection system based on machine learning algorithms and physiological signals, including electroencephalogram (EEG) and electrocardiogram (ECG).",Yes,"논문 초록에서 머신러닝 알고리즘과 생리적 신호(EEG, ECG)를 이용한 운전자 졸음 인식 시스템을 제시하고 있으며, 이를 정량적으로 평가하는 방법이 포함되어 있을 가능성이 높습니다. 따라서, 정량적 평가를 실시하고 있다고 판단됩니다."
Enhancing Text-Independent Speaker Verification through Advanced Deep Representation Feature Analysis with Neural Networks,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10739109,"Speaker Verification (SV) identifies individuals II. RELATED WORK by evaluating their distinctive vocal qualities. Text-independent speaker authentication is an important task in speech recognition and security applications. This proposes an extended fine-grained analysis of deep representation features for text-independent speaker verification using neural networks. This paper uses a Combination of CNN and RNN Neural Network Models for verification. Two Machine Learning Models Random Forest Classifier and AdaBoost Classifier was implemented on speaker verification system, but the neural network model outperforms both the models. The model achieves the accuracy of 96.4%. The approach has numerous practical uses across different security and access control systems, as well as in speech recognition technologies.",Yes,"논문 초록에서 모델의 정확도(96.4%)와 같은 성능 평가 지표를 제시하여 정량적 평가를 실시하고 있음을 보여줍니다. 또한, 여러 머신러닝 모델과 비교하여 성능을 수치로 평가하는 내용이 포함되어 있습니다."
Machine Learning Applied to Kidney Disease Prediction: Comparison Study,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8944799,"Machine learning has earned a remarkable position in healthcare sector because of its capability to enhance the disease prediction in healthcare sector. Artificial intelligence and Machine learning techniques are being used in healthcare sector. Nowadays, one of the world's crucial health related problem is kidney disease. It is increasing day by day because of not maintaining proper food habits, drinking less amount of water and lack of health consciousness. So we need some technique that will continuously monitor health condition effectively. Here, we have proposed an approach for real time kidney disease prediction, monitoring and application (KDPMA). Our aim is to find an optimized and efficient machine learning (ML) technique that can effectively recognize and predict the condition of chronic kidney disease. In this work, we used ten most popular machine learning technique to predict kidney disease. In this process, the data has been divided into two sections. In one section train dataset got trained and another section got evaluated by test dataset. The analysis results show that Decision Tree Classifier and Gaussian Naive Bayes achieved highest performance than the other classifiers, obtaining the accuracy score of 100% and 1 recall(Sensitivity) score. Now we are developing mobile application based on the best output results classifier technique to predict Kidney Disease from patient report.",Yes,논문 초록에서 여러 머신러닝 기법의 성능 평가를 위해 정확도(accuracy)와 민감도(recall)와 같은 정량적 지표를 사용했다고 명시되어 있습니다. 이는 정량적 평가를 실시하고 있음을 보여줍니다.
Unveiling MIMETIC: Interpreting Deep Learning Traffic Classifiers via XAI Techniques,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9527948,"The widespread use of powerful mobile devices has deeply affected the mix of traffic traversing both the Internet and enterprise networks (with bring-your-own-device policies). Traffic encryption has become extremely common, and the quick proliferation of mobile apps and their simple distribution and update have created a specifically challenging scenario for traffic classification and its uses, especially network-security related ones. The recent rise of Deep Learning (DL) has responded to this challenge, by providing a solution to the time-consuming and human-limited handcrafted feature design, and better clas-sification performance. The counterpart of the advantages is the lack of interpretability of these black-box approaches, limiting or preventing their adoption in contexts where the reliability of results, or interpretability of polices is necessary. To cope with these limitations, eXplainable Artificial Intelligence (XAI) techniques have seen recent intensive research. Along these lines, our work applies XAI-based techniques (namely, Deep SHAP) to interpret the behavior of a state-of-the-art multimodal DL traffic classifier. As opposed to common results seen in XAI, we aim at a global interpretation, rather than sample-based ones. The results quantify the importance of each modality (payload- or header-based), and of specific subsets of inputs (e.g., TLS SNI and TCP Window Size) in determining the classification outcome, down to per-class (viz. application) level. The analysis is based on a publicly-released recent dataset focused on mobile app traffic.",Yes,"논문 초록에서 Deep SHAP와 같은 XAI 기법을 활용하여 모델의 행동을 해석하는 글로벌 해석을 수행했다고 명시되어 있습니다. 또한, 특정 입력 특징의 중요도를 정량적으로 평가하는 내용이 포함되어 있어 정량적 평가를 실시하고 있음을 알 수 있습니다."
Artificial Intelligence Approach in the Detection of Lung Diseases Developing Post-COVID-19 with Lung Images,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10416075,"Although it is known that the COVID-19 process is over, the subsequent damage caused by COVID-19 on the body is undeniable. The SARS-CoV-2 virus has been shown to be responsible for causing acute respiratory distress in a large number of COVID-19 cases. When the literature is reviewed, Thorax Computed Tomography is recommended to evaluate permanent lung damage in individuals recovering from COVID-19. When tomography images are examined, the respiratory systems of patients who have had COVID-19 are significantly affected by the virus. In the study, thorax CT images of patients who had COVID-19 and then came back to the hospital and were diagnosed with COPD and Bronchiectasis were examined with artificial intelligence methods. The study consists of two stages. First, COVID-19, COPD, and Bronchiectasis datasets were trained with pre-trained deep-learning models. Then, only the COVID-19 dataset was trained with the GAN algorithm, and the model weights were recorded. Tests were performed on the COPD and Bronchiectasis dataset with the recorded model weight. The performance metric ratios of the training results obtained with the COVID-19 dataset and test trained individually and the combination of three classes was compared in the test environment. As a result of the proposed study, the highest performance rate for the classification method made in the first step was found to be 99% in the pre-trained DenseNet201 model. In the second step of the study, model weights were recorded on the COVID-19 dataset trained with the GAN algorithm and tested on COPD and Bronchiectasis datasets. Lower loss rates are observed in the GAN algorithm compared to the models in the first stage of the study.",Yes,"논문 초록에서 다양한 딥러닝 모델의 성능 평가 결과를 수치로 제시하며, 최고 성능률이 99%에 달하는 성과를 보고하고 있습니다. 이는 정량적 평가를 실시했음을 명확히 보여줍니다."
Decoding Gender on Social Networks: An In-depth Analysis of Language in Online Discussions Using Natural Language Processing and Machine Learning,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10386655,"In today’s digital era, the internet is an indispensable platform for self-expression, facilitating communication, idea sharing, and community formation. Language, a pivotal tool in these online interactive spaces, is vital in reflecting personal identities, notably gender identification. This paper investigates gender identification on online discussion platforms, recognizing the crucial role of language in reflecting personal identities. The study employs Natural Language Processing techniques and machine learning algorithms to analyze data from a public discussion website. Beginning with a comprehensive literature review, the research explores the nexus between gender and language in online and offline contexts. The methodology involves data gathering, extensive preprocessing, and in-depth exploratory analysis, employing statistical methods and graphical representations. The study then rigorously evaluates their accuracy and effectiveness by applying diverse algorithms and models for gender-based text categorization. Results indicate the superior performance of transformer models, particularly distilBERT, in categorizing gender accurately. Additionally, the research underscores the challenges of gender-neutral analysis, emphasizing the need for inclusive methodologies in non-binary gender classification. The study contributes to the broader field of gender studies, providing valuable insights for future research and discussions on the interplay of gender and language in online spaces.",Yes,"논문 초록에서 다양한 알고리즘과 모델을 적용하여 성별 분류의 정확도와 효과를 평가했다고 명시되어 있습니다. 또한, 성별 기반 텍스트 분류의 성능을 정량적으로 검증하는 방법론이 언급되어 있어 정량적 평가를 실시하고 있음을 알 수 있습니다."
2D Wavelet-Scalogram Deep-Learning for Seizures Pattern Identification in the Post-Hypoxic-Ischemic EEG of Preterm Fetal Sheep,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10340425,"Neonatal seizures after an hypoxic-ischemic (HI) event in preterm newborns can contribute to neural injury and cause impaired brain development. Preterm neonatal seizures are often not detected or their occurrence underestimated. Therefore, there is a need to improve knowledge about preterm seizures that can help establish diagnostic tools for accurate identification of seizures and for determining morphological differences. We have previously shown the superior utility of deep-learning algorithms for the accurate identification and quantification of post-HI microscale epileptiform transients (e.g., gamma spikes and sharp waves) in preterm fetal sheep models; before the irreversible secondary phase of cerebral energy failure starts by the bursts of high-amplitude stereotypic evolving seizures (HAS) in the signal. We have previously developed successful deep-learning algorithms that accurately identify and quantify the micro-scale transients, during the latent phase. Building up on our deep-learning strategies, this work introduces a real-time deep-learning-based pattern fusion approach to identify HAS in the 256Hz sampled post-HI data from our preterm fetuses. Here, for the first time, we propose a 17-layer deep convolutional neural network (CNN) classifier fed with 2D wavelet-scalogram (WS) images of the EEG patterns for accurate seizure identification. The WS-CNN classifier was cross-validated over 1812 manually annotated EEG segments during ~6 to 48 hours post-HI recordings. The classifier accurately recognized HAS patterns with 97.19% overall accuracy (AUC = 0.96).Clinical relevance—The promising results from this preliminary work indicate the ability of the proposed WS-CNN pattern classifier to identify HI-related seizures in the neonatal preterm brain using 256Hz EEG; the frequency commonly used clinically for data collection.",Yes,"논문 초록에서는 딥러닝 알고리즘을 이용하여 EEG 패턴을 정량적으로 평가하는 방법을 제시하고 있으며, 특히 97.19%의 정확도를 갖는 분류기를 개발했다고 언급되어 있습니다. 이는 정량적 평가를 실시하고 있음을 명확히 보여줍니다."
Modeling and Assessment of Machine Learning Models for Solar Radiation Forecast,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10328258,"Solar radiation significantly impacts the energy received from the sun in a specific area, crucial for planning non-conventional renewable energy power plants like solar photovoltaic or solar thermal systems. Variability in this resource, influenced by climate and geography, poses challenges for solar integration planning. Numerical models estimate solar resource but lack realtime and future responses. Machine Learning (ML) offers heuristic predictive tools, using extensive datasets and algorithms for quantifying and forecasting solar radiation. A proposed ML model incorporates geolocation and links primary resource with climate data from diverse Colombian cities. It consists of three stages: clustering, estimation, and response, utilizing ML predictors selected by criteria and literature review. Model response is validated using statistical methods, providing accurate solar resource predictions.",Yes,"논문 초록에서 머신러닝 모델의 성능을 검증하기 위해 통계적 방법을 사용했다고 언급되어 있으며, 모델의 응답이 정확하다고 평가하는 내용이 포함되어 있습니다. 이는 정량적 평가가 실시되고 있음을 시사합니다."
Diagnosis of Sepsis Based on Potential Immune-Related Biomarker and Machine Learning Method,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10013813,"Sepsis is known as an extreme response by the human body to an infection which often leads to life-threading complications in patients. In this work, we propose a novel method to identify potential biomarkers and effective algorithms for diagnosing sepsis based on blood transcriptome data. A panel including fifteen immune-related genes has been identified as an effective gene combination for the diagnosis of sepsis. The proposed immune-related gene biomarkers have been selected carefully through a sequential selection procedure, which combines immune-related gene selection, differential gene expression analysis, and gene importance calculated from machine learning algorithms to address the most informative gene expression markers. The cross-validation procedure in combination with different machine-learning algorithms is applied for estimating diagnosis performance related to gene combinations and machine-learning algorithms. The selected gene combinations corresponding to each machine learning model are then tested separately using various machine learning methods. The performance results on the testing data, which are an AUC score of 99.54%, a sensitivity of 98.09%, a specificity of 89.65%, and an accuracy of 96.26%, show that the identified gene biomarkers and proposed algorithm are effective and have the potential for practical applications in clinical diagnosis.",Yes,"논문 초록에서 다양한 성능 지표(AUC, 민감도, 특이도, 정확도)를 사용하여 진단 성능을 정량적으로 평가하고 있음을 명확히 언급하고 있습니다. 이러한 지표들은 정량적 평가 방법의 대표적인 예입니다."
Exploring the Application of Large Language Models in Detecting and Protecting Personally Identifiable Information in Archival Data: A Comprehensive Study*,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10386949,"This comprehensive study investigates the application of Large Language Models (LLMs) for detecting and protecting Personally Identifiable Information (PII) in archival data, a pressing concern for archives under the mandate to increase public access while safeguarding personal privacy. The paper juxtaposes traditional supervised learning methods against LLMs’ unsupervised capabilities in PII detection, unveiling LLMs as viable alternatives capable of achieving satisfactory performance levels without the need for extensive training datasets. Through empirical analysis, the study validates the feasibility of LLMs in identifying sensitive information within large volumes of archival material. The findings highlight LLMs’ significant interpretability, providing understandable rationale behind PII identification—a feature that not only enhances trust in AI applications but also aids archival staff in the review process. This research contributes novel insights into the intersection of AI and archival science, presenting LLMs as powerful tools for addressing the twin challenges of data accessibility and privacy.",Yes,"논문 초록에서 실험적 분석과 검증을 통해 LLMs의 PII 탐지 능력을 평가하는 내용이 포함되어 있습니다. 이는 정량적 평가를 실시하고 있음을 시사하며, 성능 검증과 관련된 구체적인 분석이 수행되었음을 알 수 있습니다."
Identifying multiscale hidden states to decode behavior,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8513242,"A key element needed in a brain-machine interface (BMI) decoder is the encoding model, which relates the neural activity to intended movement. The vast majority of work have used a representational encoding model, which assumes movement parameters are directly encoded in neural activity. Recent work have in turn suggested the existence of neural dynamics that represent behavior. This recent evidence motivates developing dynamical encoding models with hidden states that encode movement. Regardless of their type, encoding models have vastly characterized a single scale of activity, e.g., either spikes or local field potentials (LFP). In our recent work we developed a multiscale representational encoding model to simultaneously characterize and decode discrete spikes and continuous field activity. However, learning a multiscale dynamical model from simultaneous spike-field recordings in the presence of hidden states is challenging. Here we present an unsupervised learning algorithm for estimating a multiscale state-space model with hidden states and validate it using spike-LFP activity during a reaching movement. We use the learned multiscale statespace model and a corresponding decoder to identify hidden states from spike-LFP activity. We then decode the movement trajectories using these hidden states. We find that the identified states can accurately decode the trajectories. Moreover, we demonstrate that adding LFP to spikes improves the decoding accuracy, suggesting that our unsupervised learning algorithm incorporates information across scales. This learning algorithm could serve as a new tool to study encoding across scales and to enhance future BMI systems.",Yes,"논문 초록에서 제시된 연구는 다중 스케일 상태-공간 모델을 학습하기 위해 무감독 학습 알고리즘을 사용하고 있으며, 이를 통해 행동을 디코딩하는 정량적 평가를 수행하고 있음을 보여줍니다. 또한, 디코딩 정확도를 평가하는 내용이 포함되어 있어 정량적 평가가 실시되고 있음을 알 수 있습니다."
"Performance, Efficiency, and Target Setting for Bank Branches: Time Series With Automated Machine Learning",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10004502,"Setting targets for the bank branches and distribution of annual targets to the branches and portfolio managers, quarterly, is a crucial process for decision making and strategic planning in the banking industry. Performance of the bank branches and portfolio managers are also evaluated by the quarterly divided targets to the branches and portfolio managers. In this study, the focus is on performance prediction by using state-of-art machine learning algorithms. A novel automated machine learning approach with combined algorithm selection and hyperparameter optimization is also applied for each of the branches since all the branches might have different customer segmentation and behavior. Moreover, the postconditions are executed to finalize the target calculation and distribution over the performance predictions. The study shows the success of the methodology with a successful application of 98% accuracy in the prediction and majority of branch target calculations. An end-to-end solution found to the seasonality and periodicity problem, which is the biggest problem faced by branches while achieving their goals. Also, the novel approach increases the success of branch targets by 10% in overall. The most significant innovation this study provides to the literature and practitioners is that, unlike classical studies, it solves the seasonality and periodicity problem through multiple time series modeling. The target setting procedure was employed by the largest financial institution in Turkey, Ziraat Bank, to evaluate the operating performance of its branches. The empirical study demonstrates the applicability of the proposed model in the banking sector. The outputs of the study are implemented in real life for all retail branches of Ziraat Bank. In addition, the study awarded the most innovative use of AI/ML, the most innovative project for in-house implementation related to the innovative aspect of the work, by the Global FinTech Innovation Awards 2022.",Yes,"논문 초록에서 머신러닝 알고리즘을 활용한 성능 예측과 목표 설정의 성공률(98%) 등 정량적 평가를 수행한 결과를 제시하고 있습니다. 또한, 모델의 정확도와 성공률 향상 등 수치 기반의 평가 지표를 통해 성과를 분석하고 있음을 알 수 있습니다."
DrunaliaCap: Image Captioning for Drug-Related Paraphernalia With Deep Learning,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9184936,"Image captioning is a process of generating textual descriptions of images. In recent years, research on publicly available large-scale datasets and deep learning-based algorithms has promoted the development of this field. However, little research has been conducted on captioning images of drug-related paraphernalia that, despite being an important topic for both drug prevention and police enforcement, is not covered by existing image captioning studies. In this paper, we propose DrunaliaCap—a deep learning-based system for autogenerating both “factual” (what is in the image) and “functional” (the usage of each paraphernalia during drug-taking) descriptions of images of drug-related paraphernalia. We constructed a new dataset containing 20 categories of drug-related items and trained deep learning-based models for the proposed system. We further proposed a method to evaluate and optimize the generation of captions to prevent them from missing important knowledge. Experiments were conducted to validate the performance of the newly proposed dataset and method. We analyzed the experimental results and discussed the significance, limitations, and potential applications of our work.",Yes,"논문 초록에서 ""Experiments were conducted to validate the performance""라는 문구를 통해 실험을 통한 성능 평가, 즉 정량적 평가가 수행되었음을 알 수 있습니다. 또한, 제안된 데이터셋과 방법의 성능을 분석하는 과정이 포함되어 있어 정량적 평가가 이루어졌다고 판단됩니다."
A Review on AI-powered Advancements in Climate Finance and its Impact,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10498959,"As humanity works progressively to address climate change, the combination of artificial intelligence (AI) and climate financing offers a hopeful path for significant progress. The objective of this project is to examine the strategic implementation of AI technology to improve many areas of climate financing. This research evaluates the capacity of AI algorithms to streamline and automate operations in climate financing organizations, resulting in improved operational efficiency and decreased administrative costs. Furthermore, we have examined the possible uses of AI-driven algorithmic trading in the realm of environmentally-friendly finance. We have assessed its influence on market behavior, the availability of funds, and the distribution of resources towards sustainable investments. In addition, we examine the ethical and regulatory factors related to the implementation of AI in this particular setting. The study examines the influence of algorithmic trading on green finance, with a focus on potential opportunities for collaboration between the public and private sectors. This research offers useful insights into utilizing AI technology to tackle climate-related concerns and promote sustainability in financial decision-making, with a specific emphasis on practical applications.",Yes,"논문 초록에서 AI 알고리즘의 성능 평가와 관련된 내용을 언급하며, AI 기술의 활용과 그 영향에 대한 분석이 포함되어 있음을 보여줍니다. 이는 정량적 평가가 수행되고 있음을 시사합니다."
Transformative Impact of Artificial Intelligence and Cybersecurity on Bitcoin's Trajectory,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10563543,"This study delves into the intertwined roles of Artificial Intelligence (AI) and cybersecurity in the evolution of Bitcoin, analyzing their pivotal influence on the cryptocurrency's trajectory. By employing a mixed-methods approach, including a literature review, quantitative data analysis, and expert interviews, the paper explores how AI enhances transactional efficiency and cybersecurity measures fortify the integrity of Bitcoin's blockchain. The research investigates the dual impact of AI-driven market analysis and automated trading systems, alongside the development of robust cybersecurity protocols essential for fraud detection and network defense. The findings illustrate the dynamic interplay between technological innovation and financial security, revealing a transformative effect on Bitcoin's market behavior and regulatory landscape.",Yes,"논문 초록에서 ""quantitative data analysis""라는 표현이 명시되어 있으며, 이를 통해 정량적 평가가 수행되고 있음을 알 수 있습니다. 또한, 연구 방법에 포함된 정량적 데이터 분석이 논문의 핵심 부분임을 시사합니다."
Statistical Features Versus Deep Learning Representation for Suspicious Human Activity Recognition,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9942440,"For many years, researchers have been interested in human activity recognition for many reasons, including preventing crimes before they occur, preventing acts of sabotage, and securing people and facilities. Human activity recognition using deep learning is the focus of many researchers. Techniques for human activity recognition that rely on sensors worn by a person with his limbs and torso are impractical and the only useful way to recognize the human activity especially in public places is through video clips of surveillance cameras. In this paper i compared the performance of CNN with different models such as Inception, ResNet, Inception-ResNet, MobileNet V2, NASNet and PNASNet and the performance of handcrafted features such as statistical features (shape moments like mean, Skew, Kurtosis, etc.) in terms of their human activity recognition accuracy and also compared the results with the state-of-the-art methods. In my research i used suspicious activities included in the HMDB data set (falling to the floor, punching, kicking and shooting a gun) to evaluate the statistical features and also to evaluate the different modern CNN architectures. The experimental results in the case of using statistical features confirmed the superiority of the Support vector machine (SVM) than other classifiers. My experimental results indicated that the CNN with NASNet architecture achieves the best performance of the six CNN architectures but when comparing the performance with the statistical features method, I found the superiority of statistical features with a support vector machine classifier. This paper contributes to studying the effectiveness of using modern CNN architectures in recognizing suspicious human activity and found that these techniques depend on the quality of images, whether the activity is individual or group. This study enables the researcher to evaluate and compare the different modern CNN architectures in suspicious human activity recognition and compare them also with models that use the hand-crafted features represented in the statistical features on an objective and fair basis The remainder of this paper is organized as follows: Section 1 provides the related work. Section 2 describes an action recognition system using Hand-crafted features. Section 3 presents the experimental results and Section 4 concludes the paper.",Yes,"논문 초록에서 다양한 정량적 평가 방법이 사용되었음을 명확히 언급하고 있습니다. 특히, 통계적 특징과 CNN 모델의 성능을 비교하는 실험 결과를 통해 정량적 평가를 실시했음을 알 수 있습니다."
Sleep Analysis for Fatigue of Crewmembers with Deep Multi-Task Learning,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9986945,"This paper targets to investigate the potential performance of crewmembers given the sleep quality surveillance. The fatigue of crewmembers can significantly affect flight safety and service quality. The quantification and prediction of fatigue is highly desired in practice, and lead to better control of the crewmember arrangement and scheduling. Though the working status can be related to many inherent causal factors, sleep quality plays a major role in fatigue. In this work, we propose to develop an end-to-end system to collect the sleep data with wearable devices, and explore its relations with the popular fatigue indexes, e.g., Karolinska Sleepiness Scale (KSS), Psychomotor Vigilance Task (PVT), and NASA Task Load Index (NASA-TLX). Specifically, we collected the sleep time and quality measurement of 256 crewmembers for three days before the flight, and the corresponding KSS, PVT, and NASA-TLX during or just after the flight. Then, a multi-task deep learning framework is developed to learn the mapping from sleep to fatigue indexes. We trained and evaluated on 200 and 56 crewmembers with the quantified results showing that fatigue is highly predictive with the sleep data. The learned deep learning model can potentially be applied to the pre-flight crewmember screen to avoid the fatigue driving and service.",Yes,"논문은 수면 데이터와 피로 지수 간의 관계를 학습하기 위해 다중 작업 딥러닝 모델을 개발하고 평가하는 과정을 포함하여, 정량적 평가를 실시하고 있음을 보여줍니다. 또한, 피로 예측의 정확성을 검증하기 위해 수치화된 결과를 제시하고 있습니다."
Sparse Sample Train Axle Bearing Fault Diagnosis: A Semi-Supervised Model Based on Prior Knowledge Embedding,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10262175,"Data-driven fault diagnosis models often exhibit limited generalization abilities when trained on small sample sizes, as commonly encountered in complex working environments such as train bearing systems. To address this challenge, incorporating domain knowledge into machine learning models has been proposed. Specifically, prior knowledge in the form of wavelet packet decomposition and information entropy features was extracted to characterize fault-related physical phenomena. Convolutional neural networks (CNNs) supplemented this approach by learning general features. An attention mechanism fused the two feature types, emphasizing the prior knowledge. Extreme gradient boosting (XGBoost) classification was then applied for fault discrimination. In addition, a self-training method semi-supervised the model during training. The approach was evaluated on three bearing datasets against deep learning and machine learning baselines. Results showed the method achieved over 70% accuracy with only 30 labeled samples per class, outperforming the semi-supervised baseline. This lightweight, knowledge-driven solution provides a foundation for efficient fault diagnosis from limited data in complex fault scenarios. Overall, the study demonstrated an effective method for addressing small sample size challenges in machine fault diagnosis.",Yes,"논문 초록에서 모델의 성능 평가를 위해 정확도(70% 이상)를 측정하는 정량적 평가가 수행되었음을 명확히 언급하고 있습니다. 또한, 여러 데이터셋과 비교 기준을 통해 성과를 수치로 제시하여 정량적 평가를 실시했음을 알 수 있습니다."
COVID-19 Detection Using Fusion-Based Deep Learning Models,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10346927,"The COVID-19 pandemic has been one of the most challenging crises attacking the world in the last three years. Many systems have been introduced in the field of COVID-19 detection. In this research, deep learning models for the detection of COVID-19 with a probability of the presence of COVID-19 are proposed. The COVID-19 dataset is split into 70% training and 30% testing using the holdout method. For the deep learning model, the CT images are fed into the model without feature extraction, and three different deep learning DL models (convolutional neural networks (CNN), GoogleNet, and residual nets (ResNet50)) are trained and evaluated. The three deep learning models are fused to obtain high accuracy, and get better performance. The trained models are evaluated using accuracy, precision and recall evaluation metrics. The experiments show that the best model is the deep-based fusion model by which the system achieved 96.4%, 96.2%, and 96.2% for accuracy, precision, and recall, respectively. Comparing our study with the related work proves the powerful and high performance of the proposed methodologies.",Yes,"논문 초록에서 정확도, 정밀도, 재현율과 같은 정량적 평가 지표를 사용하여 딥러닝 모델의 성능을 평가했다고 명시되어 있습니다. 이러한 평가 지표들은 정량적 평가의 실시를 보여줍니다."
CPSoSaware: Cross-Layer Cognitive Optimization Tools & Methods for the Lifecycle Support of Dependable CPSoS,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9155036,"Cyber-physical Systems of Systems (CPSoS) are large complex systems where physical elements interact with and are controlled by a large number of distributed and networked computing elements as well as human users. Their increasingly stringent demands on efficient use of resources, high service and product quality levels and, of course low cost and competitiveness on the world market introduce big challenges related to the design operation continuum of dependable connected CPSs. The CPSoSaware project aims at developing the models and software tools to allocate computational power/resources to the CPS end devices and autonomously determining what cyber-physical processes will be handled by the devices' heterogeneous components (CPUs, GPUs, FPGA fabric, software stacks). The project relies on Artificial Intelligence (AI) support to strengthen reliability, fault tolerance and security at system level and also to lead to CPS designs that work in a decentralized way, collaboratively, in an equilibrium, by sharing tasks and data with minimal central intervention. The CPSoSaware system will interact with the human users/operators through extended reality visual and touchable interfaces increasing situational awareness. The CPSoSaware system will be evaluated: i) in the automotive sector, in mixed traffic environments with semi-autonomous connected vehicles and ii) in the manufacturing industry where inspection and repair scenarios are employed using collaborative robots.",No,"논문 초록에서는 시스템의 모델링, 소프트웨어 도구 개발, AI 지원 등을 언급하고 있지만, 구체적인 정량적 평가 방법이나 실험 결과에 대한 언급은 없습니다. 따라서 정량적 평가를 실시하고 있다고 보기 어렵습니다."
COPPTCHA: COPPA Tracking by Checking Hardware-Level Activity,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9049424,"User privacy is an extremely important concern for mobile applications. Recently, the Federal Trade Commission (FTC) has penalized multiple mobile application developers, such as TikTok and BabyBus for violating privacy regulations. Privacy concerns are more critical for children, who do not comprehend the risks associated with transmitting private information like geospatial location. The Children's Online Privacy Protection Act (COPPA) is an online privacy regulation platform to monitor data usage by mobile applications designed for children. Existing research on detecting whether an application complies with certain privacy regulations is performed either by analyzing the application binary or by dynamic monitoring of network at runtime. However, as explained in related work, both methods have their respective demerits. We propose COPPTCHA, a Hardware performance counter (HPC)-based technique to detect whether a children's app abides by the COPPA regulations. HPCs are special purpose registers found in all processors that measure system level events. Since the proposed method is hardware-based, it is difficult to undermine it compared to software-based COPPA compliance detection. COPPTCHA has no hardware overhead, since HPC data collection is integral to all industry standard processors. The HPC readings of applications running on a smartphone are classified using machine learning based classifiers to detect COPPA compliance. Our experiments employing a Moto-G4 smartphone shows that COPPTCHA can detect COPPA-violating apps with ≥ 99% accuracy.",Yes,"논문 초록에서 HPC 데이터를 수집하고 이를 머신러닝 분류기를 통해 분석하는 과정을 통해 정량적 평가를 실시하고 있음을 명확히 언급하고 있습니다. 따라서, 정량적 평가가 수행되고 있다고 판단됩니다."
StressAlly: A Smartphone-Based Stress Companion Recommender System for Students,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10437258,"Stress has become an increasing concern among college students. Passive sensing techniques allow the extraction of stress-related parameters from a student. These techniques use highly resource-intensive machine learning algorithms to predict the stress levels of a student from these parameters. However, the current techniques do not provide any social communication solution for students suffering from stress. In this work, we propose StressAlly, a stress companion recommender system. The system comprises two modules, the stress score predictor and the stress companion recommender. The stress score predictor incorporates edge computing and deploys lightweight in-app inferences. The stress score predictor calculates the stress level in the scale 0–4 in the smartphone using the Artificial Neural Network (ANN) Regressor and sends it to the server. The Stress companion recommender provides similar stress levels of students to each student using the User-User Collaborative Filtering technique. We achieved training MAE and loss of 0.7478 and 1.0298, respectively. We get a test Mean Absolute Error (MAE) of 0.737 on the unseen data. We evaluate the CPU, memory, time delay, and network performance of StressAlly on the server and the Android smartphone. StressAlly utilizes 188 MB memory and 25% CPU on the smartphone.",Yes,"논문은 스트레스 수준을 0-4의 척도로 정량적으로 평가하는 방법을 제시하며, ANN 회귀 모델을 통해 MAE(평균 절대 오차)를 계산하여 평가하고 있다. 또한, 시스템의 성능 평가를 위해 CPU, 메모리, 시간 지연 등 정량적 지표를 사용하고 있어 정량적 평가를 실시하고 있음을 알 수 있다."
Pilot Workload Prediction from ECG Using Deep Convolutional Neural Networks,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8802158,"Pilot workload monitoring plays an important role in aviation safety. Heart rate, heart rate variability, and respiration rate have been shown to correlate with pilot workload and can be measured using electrocardiograms (ECG). Traditional machine learning approaches rely on manually extracting features from ECG, which is a difficult and time-consuming process. Recent years witnessed the success of deep neural networks, especially deep convolutional neural networks (CNNs), in computer vision and related domains; however, the application of deep CNNs onto the ECG data faces challenges on both data insufficiency and lack of tailored CNN architectures. With a small training set, this work proposes the use of transfer learning with pre-trained deep CNNs for the prediction of pilot workload. Two ECG-derived visual representations, spectrograms and scalograms, are compared for their performance on the prediction. Experimental results indicate that the scalograms perform better (at 51.35%) than spectrograms (at 45.85%) in predicting three levels of pilot workload. With the scalograms, using the pre-trained deep CNNs as ""off-the-shelf"" feature extractors yields better performance than fine-tuning the deep CNNs (at 42.44%) for the ECG data. The deep features are visualized using dimension reduction with t-sne.",Yes,"논문 초록에서 딥러닝 모델을 사용하여 파일럿 작업 부하를 예측하는 실험을 수행하고 있으며, 성능 평가를 위해 정확도(퍼포먼스 지표)를 제시하고 있습니다. 이는 정량적 평가를 실시하고 있음을 보여줍니다."
Software Agents Situated in Primary Distribution Networks: A Cooperative System for Fault and Power Restoration Management,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4302509,"In this paper, extended research upon the potentials of implementing distributed artificial intelligence technology to achieve high degrees of independency in distribution network protection and restoration processes is presented. The work that has already been done in the area of agent-based and/or knowledge-based applications and expert systems is briefly reviewed. The authors justify the need to distribute activities in contradiction to the centralized methodologies. A proper model of the real environment is introduced in order to define the designing parameters of a prototype agent entity, which is the part of a cooperative network-management system. The system's goal is to autonomously perform effective fault management upon medium-voltage power distribution lines. The structure of the agent entity is then described by means of the agent behaviors being implemented. The cooperative operations of the proposed system and its computer simulation are presented. Simulation results are being evaluated. Finally, general conclusive remarks are made.",Yes,"논문 초록에서 시뮬레이션 결과를 평가하고 있다는 언급이 있으며, 이를 통해 정량적 평가가 수행되고 있음을 알 수 있습니다. 따라서, 논문은 정량적 평가를 실시하고 있다고 판단됩니다."
WIP: Building a Research Experience for Undergraduates in Quantum Machine Learning,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10893516,"This work in progress research-to-practice study describes the development of a new undergraduate research training site on Quantum Machine Learning (QML), hosted at Arizona State University, a large Hispanic-Serving Institution. The objectives of this project are to a) recruit and prepare students from diverse pathways to increase representation of those traditionally underrepresented in QML research, b) increase awareness of career opportunities in the QML field, c) engage students in theoretical and experimental quantum information processing and machine learning (ML), d) motivate students to continue QML research into graduate school, and e) provide professional development training including presenting to stakeholders, developing publications/patents, and building an awareness on social implications, ethics, and privacy. The project adopts an integrative theory, application, and hands-on training approach by immersing undergraduate students in ML algorithm and quantum computing studies with hands-on quantum circuit design tasks. Participants are embedded in research labs, guided by graduate students and faculty mentors on quantum computing research studies. The program is evaluated by both the Center for Evaluating the Research Pipeline (CERP) and an independent evaluator. Formative and summative assessments include pre- and post-surveys, a mid-point check-in survey, and a document review of program deliverables. Findings are described in a final evaluation report. This paper describes the importance of introducing QML research at the undergraduate level, methods for recruiting a diverse group of participants, program format, research projects, and preliminary program evaluation results.",Yes,"논문 초록에서 프로그램의 평가를 위해 사전-사후 설문조사, 중간 점검 설문조사, 문서 검토 등 다양한 정량적 평가 방법이 실시되고 있음을 언급하고 있습니다. 이러한 평가 방법들은 정량적 평가의 실시를 명확히 보여줍니다."
Empirical Evaluation of Embedding Models in the Context of Text Classification in Document Review in Construction Delay Disputes,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10825997,"Text embeddings are numerical representations of text data, where words, phrases, or entire documents are converted into vectors of real numbers. These embeddings capture semantic meanings and relationships between text elements in a continuous vector space. The primary goal of text embeddings is to enable the processing of text data by machine learning models, which require numerical input. Numerous embedding models have been developed for various applications. This paper presents our work in evaluating different embeddings through a comprehensive comparative analysis of four distinct models, focusing on their text classification efficacy. We employ both K-Nearest Neighbors (KNN) and Logistic Regression (LR) to perform binary classification tasks, specifically determining whether a text snippet is associated with 'delay' or 'not delay' within a labeled dataset. Our research explores the use of text snippet embeddings for training supervised text classification models to identify delay-related statements during the document review process of construction delay disputes. The results of this study highlight the potential of embedding models to enhance the efficiency and accuracy of document analysis in legal contexts, paving the way for more informed decision-making in complex investigative scenarios.",Yes,"논문 초록에서 네 가지 다른 임베딩 모델을 평가하는 비교 분석을 수행했다고 명시되어 있으며, K-최근접 이웃(KNN)과 로지스틱 회귀(LR)를 사용하여 이진 분류 작업을 수행했다고 언급되어 있습니다. 이는 정량적 평가가 실시되고 있음을 보여줍니다."
Personalizing the Prediction: Interactive and Interpretable machine learning,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8768705,"While many applications with machine learning provide enough utilities for users, they mostly target average of users. Although it might be acceptable in certain domains, there are domains such as health and medical-care where it is crucial to provide personalized service. In such cases, personalization of machine learning model usually does not depend on end users to make change to the system. As machine learning models are black-box, the only information that the users can acquire is input and output of certain decision made by the model. Thus, with no reason behind specific prediction provided by the system, users cannot understand how the system works and make amendments to the system. This shortcoming is directly related to users' credibility in the system. In this paper, we present an interface where the system provides users the reason behind the decision made by the machine learning model and users provide feedback to the model. Moreover, we present the principle behind the suggested interface and prototype that instantiates the suggested interface. Our interface's effectiveness is evaluated through users' surveys regarding two main attributes: (1) how well users understand the system and more importantly, (2) how it influences users to trust in the system.",No,"논문 초록에서는 사용자 이해와 신뢰에 영향을 미치는 인터페이스와 피드백 시스템을 제시하고 있지만, 정량적 평가를 실시했다는 구체적인 언급은 없습니다. 따라서, 정량적 평가를 실시했다고 판단하기 어렵습니다."
SAARSNet: A Deep Neural Network for COVID-19 Cases Diagnosis,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9436536,"The global spread of the COVID-19 is a continuously evolving situation and it is still a major risk on the health of people around the world. A huge number of people are infected by this deadly virus and the number is still getting increased day by day. At this time, no specific vaccines or treatments of COVID-19 are found. Numerous ways are offered to detect COVID-19 such as swab test, CDC and RT-PCR tests. All of them can detect corona virus in different ways but they are not recommended by the reason of their limited availability, inaccurate results, high false-negative rate predicates, high cost and time consuming. Hence, medical radiography and Computer Tomography (CT) images were suggested as the next best alternative of RT -PCR and other tests for detecting Covid-19 cases. Recent studies found that patients with COVID-19 cases are present abnormalities in chest X-Ray images. Motivated by this, many researchers propose deep learning systems for COVID-19 detection. Although, these developed AI systems have shown quite promising results in terms of accuracy, they are closed source and unavailable to the research community. Therefore, in the present work, we introduced a deep convolutional neural network design (SAARSNet) designed to detect COVID-19 cases from chest X-Ray images. 1292 X-Ray images have been used to train and test the proposed model. the images have been collected from two open-source datasets. The input images are progressively resized into (220 by 150 by 3) in order to decrease the training time of the system and improve the performance of the SAARSNet architecture. Furthermore, we also investigate how SAARSNet makes predictions under three different scenarios with the aim of distinguishing COVID-19 class from both Normal and Abnormal classes as well as gaining deeper perceptions into critical factors related to COVID-19 cases. We also used the confusion metrics for evaluating the performance of SAARSNet CNN in an attempt to measure the true and false identifications of the classes from the tested images. With the proposed architecture promising results has been achieved in all of the three different scenarios. Although, there are some misclassified cases of COVID-19, the corresponding performance was best in detecting both Normal and Abnormal cases correctly. Furthermore, in the three classes scenario, normal class has been achieved 100% positive predictive value while optimistic results have been investigated in detecting COVID-19 and abnormal classes.",Yes,"논문 초록에서 ""confusion metrics""를 사용하여 성능 평가를 실시했다고 명시되어 있으며, 다양한 시나리오에서 모델의 성능을 정량적으로 측정했다고 언급하고 있습니다. 이는 정량적 평가가 수행되었음을 보여줍니다."
Using Machine Learning Algorithms to Improve Education Process,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9960034,"One of the main goals of any educational institution is high quality education, taking into account the shortcomings of the education system. Currently, in the field of education, one of the urgent problems is the identification of signs that affect student performance. Machine learning algorithms are used to determine these features. Machine learning algorithms are being implemented in various spheres of society today. Giants from all over the world, such as Amazon, Google, Apple, identify customer-related problems using machine learning algorithms. In addition, a number of machine learning methods in economics, banking and medicine, manufacturing and industry can improve the work of specialists. Aiming at better performance and better understanding of the obtained results, binding models had been applied at the data selection and integration stages. The article discusses the collection of databases, learning algorithms, analysis of algorithms and the definition of features. In the research work, a database is created that includes the physiological and psychological characteristics of students. The program is executed in the Python programming environment. Predictions are based on databases with machine learning algorithms. Linear regression methods, the Support Vector Machine method and Random Forest are used, and work is devoted to determine the best algorithm. Algorithms are evaluated using regression evaluation metrics. The results of the study provide the best algorithm and the necessary marks for individual academic performance.",Yes,"논문 초록에서 머신러닝 알고리즘을 사용하여 학생 성과를 예측하고, 알고리즘의 성능을 평가하는 내용이 포함되어 있습니다. 이는 정량적 평가를 실시하고 있음을 보여줍니다."
Hybrid Quantum-Classical Machine Learning for Near Real-time Space to Ground Communication of ISS Lightning Imaging Sensor Data,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10099338,"Near real-time sensor data is growing exponentially faster than our ability to sense and make sense of it as the current classical computing and supercomputing approaches require an enormous volume of computational resources, storage, and training time. Quantum computing is posed to exponentially outperforms today's high-performance computers and accelerate the evolution of information occurring in classical systems and sensor networks. The Lightning Imaging Sensor (LIS) mounted on the International Space Station (ISS) locates, senses, and detects lightning activities from low Earth orbit and measures radiant energy at millisecond timing over a broad regional spectrum. In this paper, we are introducing a space-to-ground hybrid quantum-classical machine learning architecture to demonstrate the application potential and the feasibility of Hybrid Quantum Neural Networks using the ISS LIS lightning dataset and a corresponding background dataset as inputs (1) to train a classical deep neural network model (2) where the feature extraction outputs are encoded as quantum states using multiple calibrated quantum encoding patterns (3) then used as part of a quantum feature mapping process, (4) allowing for enhanced hybrid QNN training, optimization, and auto-differentiation, setting the path towards polynomial advantage. The following is how the rest of the paper is structured: The introduction is covered in section I, and the motivation and our contribution are covered in section II. Section III presents related works. Section IV describes the NRT lightning imaging sensor. Section V describes the space- to-ground hybrid quantum architecture. Section VI. Space-to-ground hybrid quantum-classical machine learning architecture. Section VII describes quantum machine learning. Section VIII presents a performance analysis. Finally, section XI concludes the research paper.",Yes,"논문 초록에서 정량적 평가를 위해 성능 분석(Section VIII)을 수행했다고 명시되어 있으며, 하이브리드 양자-고전적 머신러닝 아키텍처의 적용 가능성과 성능을 평가하는 내용이 포함되어 있습니다. 이는 정량적 평가가 이루어지고 있음을 시사합니다."
Exploring Technological Success Factors of Big Data in E-Learning Systems,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10218073,"Big data plays an important role in the development of e-learning systems. There are many factors affecting its implementation and success with e-learning systems. This study aims to identify the implementation success factors related to big data within e-learning systems. To identify these elements, a comprehensive examination of the literature was done by using exploratory and single-case research approaches, the study used Basrah University as the case study to assess the success factors of big data in their e-learning system. Additionally, survey and expert interviews were conducted to validate the literature review’s conclusions and identify further factors. The collected data were analyzed using NVivo software to identify themes and sub-themes. To assess the quantitative survey data, machine learning methods are combined with qualitative analysis using a Random Forest Classifier. The finding showed that five factors should be considered which can aid in the creation of more efficient e-learning systems namely: Positive Impact on Students, Faculty/Staff Support and Training, Effective Content Design, System Functionality and Usability, and Assessment and Feedback. The results of this study can be used to improve learning outcomes by developing more efficient big data analytics-integrated e-learning systems.",Yes,논문 초록에서 머신러닝 방법과 정량적 설문 데이터를 활용하여 성공 요인을 평가했다고 명시되어 있습니다. 이를 통해 정량적 평가가 실시되고 있음을 알 수 있습니다.
Ship Space-Time AIS Trajectory Data Compression Method,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9760355,"As the ship Automatic Identification system (Automatic Identification Systems, AIS) mandating the use of a large number of static and dynamic information related to the ship automatically through the shore-based or spaceborne terminal is passed to the maritime system and the shipping company, as an effective water traffic monitoring and management provides the necessary data to support. But because the ship is most of the time when navigating in high speed to or only minor adjustments, that receives a huge ship AIS trajectory data is invalid and redundant information, such a huge data increases the cost of computer memory, reduce the efficiency of data server calls. Therefore, it is important to study how to compress invalid and redundant information based on the main structural features of the AIS trajectory. This paper addresses the problem of many invalid and redundant information generated by Automatic Identification Systems (AIS), and conducts a study to effectively compress invalid and redundant information while preserving the main structural features of ship AIS trajectories. The main research work of this paper is to construct a compression method of ship space-time AIS trajectory data based on Douglas-Peucker (DP) algorithm and select the multiple thresholds to compress the upbound and down-bound ship AIS trajectories respectively. The DTW algorithm is used to evaluate the compression effect, and obtain the optimal compression threshold. Experimental results show that DP algorithm can efficiently compress ship AIS track data and retain pivotal feature points.",Yes,"논문 초록에서 DTW 알고리즘을 사용하여 압축 효과를 평가하는 내용을 언급하고 있어, 정량적 평가가 실시되고 있음을 알 수 있습니다. 또한, 최적의 압축 임계값을 찾기 위해 실험적 방법을 활용하는 점도 정량적 평가의 특징을 보여줍니다."
Research on Sustainable Management of Grid Companies Based on Artificial Intelligence,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10150589,"With the advancement of power systems, grid operations monitoring has become more complex. To ensure the sustainable operation of the grid, it is important to quickly and dynamically extract a small amount of data from a large amount of real-time data, closely related to grid security, and accurately identify system security risks in a timely manner. In this regard, this paper proposes an artificially intelligent sustainable management system for the grid, which has achieved remarkable results. The main contribution of this paper is the development of a risk identification model for microgrids using artificial intelligence and the DEMATEL method. Firstly, the paper identifies the risk factors involved in the microgrid from four aspects, including the generation side, distribution side, demand side, and human factors, through a comprehensive literature review, expert survey, and brainstorming. Secondly, an artificial intelligence and DEMATEL-based microgrid risk factor identification method is employed to clarify the importance and perturbation relationship of each risk factor of the microgrid. Finally, the paper classifies all factors into two categories, cause factors, and effect factors, and ranks the importance of each factor. To further demonstrate the effectiveness of the proposed model, a wind power prediction algorithm based on data mining technology and an improved SVM algorithm, and a PV power prediction algorithm based on a deep neural network are established. After comparing and analyzing the performance of the constructed algorithms with other algorithms, the DBN prediction model is proposed, which has an absolute error probability of 62.9% within 1%, surpassing the other algorithms and meeting the engineering needs. Moreover, the paper proposes risk control measures on the power generation side, which can significantly reduce the risks involved in power generation. In summary, the paper proposes an artificially intelligent sustainable management system for the grid, which includes a risk identification model for microgrids, and prediction models for wind and PV power generation. The paper's findings provide valuable insights for researchers and practitioners in the field of grid operation and management. The proposed models have shown remarkable results, and the risk control measures can significantly reduce the risks involved in power generation, contributing to the sustainable operation of the grid.",Yes,"논문 초록에서 다양한 평가 방법과 성능 비교를 통해 제안된 모델들의 우수성을 검증하는 내용이 포함되어 있습니다. 특히, 예측 모델의 성능을 다른 알고리즘과 비교 분석하는 정량적 평가가 수행된 것으로 보입니다."
Evaluation of Resting-State EEG Patterns in Female Schizophrenia and Addiction Patients Using Convolutional Neural Networks,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10837566,"Machine learning aids in accurately diagnosing psychiatric disorders, impacting individuals' quality of life and society, by identifying and classifying them efficiently. Traditional diagnoses of psychiatric disorders relied on subjective assessments, which are time-consuming, costly, and human biased; machine learning offers faster, cheaper, and more accurate solutions. The aim of this study was to evaluate patterns of relationship in female schizophrenic and addictive disorder patients by the application of computational techniques to analyze resting-state electroencephalography (EEG) data signals obtained via machine learning with a view to identify distinctive patterns or features that can help medical practitioners to differentiate between the two patient groups. The study utilized data on beta waves collected from the forehead of the human subjects with the electrodes in positions fp1 and fp2. A review of published literature in the field of diagnosis of mental health disorders using machine learning was also conducted in order to identify current trends on the subject and identify possible research gaps for further research. The results show the relationships between age, education, IQ, and AB.D.beta a.FP1/FP2 assessed using correlation coefficients and p-values show a weak negative relationship between age and AB.D.beta a.FP1/FPI/FP2. The correlation coefficients are -0.1054, -0.1722, and -0.0975, respectively. The p-values for these relationships are 0.6407, 0.4435, and 0.4962, indicating that the correlations are not significant. Age, education and IQ did not appear to have a significant impact on the AB.D.beta a.FP1/FPI/FP2 patterns in the studied female patients. Our study investigates the efficacy of convolutional neural networks (CNNs) in diagnosing psychiatric disorders in females. We achieved an accuracy of 84.3% using CNNs for evaluating EEG patterns.",Yes,"논문 초록에서 CNNs(Convolutional Neural Networks)를 활용하여 EEG 패턴을 평가하는 연구를 수행했다고 명확히 언급하고 있으며, 이를 통해 정량적 평가가 이루어졌음을 알 수 있습니다. 또한, 정확도(84.3%)와 같은 수치적 성과 지표를 제시하여 정량적 평가가 실시되었음을 보여줍니다."
Type Learning for Binaries and Its Applications,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8588310,"Binary type inference is a challenging problem due partly to the fact that during the compilation much type-related information has been lost. Most existing research work resorts to program analysis techniques, which can be either too heavyweight to be viable in practice or too conservative to be able to infer types with high accuracy. In this paper, we propose a new approach to learning types for binary code. Motivated by “duck typing,” our approach learn types for recovered variables from their features and properties (e.g., related representative instructions). We first use machine learning to train a classifier with basic types as its levels from binaries with debugging information. The classifier is then used to learn types for new and unseen binaries. While for composite types, such as pointer and struct, a points-to analysis is performed. Finally, several experiments are conducted to evaluate our approach. The results demonstrate that our approach is more precise, both in terms of correct types and compatible types, than the commercial tool Hex-Rays, the open source tool Snowman, and a recent tool EKLAVYA using machine learning. We also show that the type information our proposed system learns is capable of helping detect malware.",Yes,"논문 초록에서 ""several experiments are conducted to evaluate our approach""라고 명시되어 있으며, 이를 통해 정량적 평가가 수행되었음을 알 수 있습니다. 또한, 실험 결과를 통해 제안된 방법의 성능을 비교하고 평가하는 내용이 포함되어 있습니다."
Proposing Causal Sequence of Death by Neural Machine Translation in Public Health Informatics,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9744474,"Each year there are nearly 57 million deaths worldwide, with over 2.7 million in the United States. Timely, accurate and complete death reporting is critical for public health, especially during the COVID-19 pandemic, as institutions and government agencies rely on death reports to formulate responses to communicable diseases. Unfortunately, determining the causes of death is challenging even for experienced physicians. The novel coronavirus and its variants may further complicate the task, as physicians and experts are still investigating COVID-related complications. To assist physicians in accurately reporting causes of death, an advanced Artificial Intelligence (AI) approach is presented to determine a chronically ordered sequence of conditions that lead to death (named as the causal sequence of death), based on decedent's last hospital discharge record. The key design is to learn the causal relationship among clinical codes and to identify death-related conditions. There exist three challenges: different clinical coding systems, medical domain knowledge constraint, and data interoperability. First, we apply neural machine translation models with various attention mechanisms to generate sequences of causes of death. We use the BLEU (BiLingual Evaluation Understudy) score with three accuracy metrics to evaluate the quality of generated sequences. Second, we incorporate expert-verified medical domain knowledge as constraints when generating the causal sequences of death. Lastly, we develop a Fast Healthcare Interoperability Resources (FHIR) interface that demonstrates the usability of this work in clinical practice. Our results match the state-of-art reporting and can assist physicians and experts in public health crisis such as the COVID-19 pandemic.",Yes,논문 초록에서 BLEU 점수와 세 가지 정확도 지표를 사용하여 생성된 사망 원인 시퀀스의 품질을 정량적으로 평가했다고 명시되어 있습니다. 이는 정량적 평가를 실시하고 있음을 보여줍니다.
Post COVID-19 Twitter user’s Emotions Classification using Deep Learning Techniques in India,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9395899,"Social Media platforms contain a huge data collection of shared and personal thinking with respect to a wide assortment of subjects, communicated and spread ceaselessly by their users. Among those platforms, Twitter is gaining immense popularity. This research work proposes a system to computationally measure the emotions of live tweets by their users and emotions regarding the government's decision on extending the lockdown. The system consists of dashboard with various functionalities. Main dashboard has country-wise data visualization of the emotions derived from the tweets, it has clickable map of India which shows state-wise data visualization as well. Live emotion prediction of tweets is achieved using Deep Learning tools. Tweet fetching is dynamic to get up-to-date data automatically. Resources tab is available for COVID-19 related statistics and news. 250 plus days since the initial stage COVID-19 case in the World, and 180+ days into the most punctual Lockdown Order of India, how is the people thinking in circumstances such as these? The Corona Virus imperils our physical wellbeing to be sure, however close by, social separating additionally represents a danger to our enthusiastic steadiness. Accordingly, it is vital to comprehend public emotions under COVID-19.",Yes,"논문 초록에서 딥러닝 도구를 사용하여 실시간 트윗의 감정을 예측하는 시스템을 제안하고 있으며, 감정 분류를 위한 정량적 평가가 수행되고 있음을 시사합니다. 또한, 데이터 시각화와 함께 감정 분석 결과를 수치로 표현하는 내용이 포함되어 있어 정량적 평가가 실시되고 있음을 알 수 있습니다."
Exploring the Potential of Locally Run Large Language (AI) Models for Automated Grading in Introductory Computer Science Courses,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10892816,"This innovative practice full paper describes the effectiveness of self-hosted large language models (LLMs) in assisting with the automatic grading of CSI assignments. Educators often rely on automated review of student code submissions in larger courses. Despite recent advancements, current systems primarily focus on assessing functionality, with important aspects such as code structure, efficiency, and style often relegated to secondary foci. LLMs provide an increasingly attractive addition to these systems to enhance those overlooked areas. Prior research has shown LLM's capable of assisting students in understanding and resolving programmer error messages, correcting syntax errors, providing enhanced explanations of code segments, or even generating code. The absence of freely available, purpose-designed LLMs for grading and providing feedback on code submissions prevents widespread adoption by educators. Remotely-hosted systems, such as fine-tuned GPT models, have shown promise, yet the associated risks of privacy breaches, ethical considerations, and recurring costs make this approach unfeasible as a universal solution. To mitigate these concerns, self-hosted open-source models are an alternative that can operate on consumer-grade hardware and prevent some privacy and security concerns. While no purpose-built solution yet exists, it is unclear if any existing models are powerful enough to facilitate automated grading. To explore these questions, we present a two-phase analysis, leveraging real grading data from a semester length, introductory CSI course with 124 students and nine programming projects. Nine stable LLM models were selected and repeatedly prompted to grade student submissions using the same context that a human teaching assistant (TA) was given. This paper analyzes 1,172,383 API requests, totaling 33.4 days of active runtime, evaluating model consistency, ability to adhere to specified constraints, and comparison to human-generated grades. The results show various models' inability to consistently grade assignments, albeit with some exceptions. The importance of providing comprehensive context to models was highlighted, as incomplete contexts resulted in worse performance. Other models struggled with longer prompts, delivering less consistent results. Despite disparities between AI-generated and human-assigned grades, the potential for refinement is clear; improved rubrics or selective fine-tuning could enhance model output. Future work will focus on analyzing models' qualitative justifications for grades, refining rubrics, training on domain-specific datasets, and fine-tuning the highest performing models to potentially improve grading accuracy.",Yes,"논문은 여러 모델을 대상으로 정량적 평가를 수행하여 모델의 일관성, 제약 준수 능력, 그리고 인간과의 성적 차이를 분석하고 있습니다. 1,172,383 API 요청과 33.4일간의 활성 런타임 데이터를 활용하여 정량적 데이터를 기반으로 평가한 점이 명확합니다."
Predicting nuclear fuel parameters by using machine learning techniques,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9650410,"Today, machine learning techniques are widely used to solve complex problems at computing level. One of these techniques is the vector support machine which has been used in various applications. This technique will be used to solve a problem relating to the nuclear industry and its control through the Treaty on the Non-Proliferation of Nuclear Weapons (NPT). Specifically, this work seeks to create a model capable of predicting certain parameters of importance in irradiated fuels, under an analysis of a number of characteristics. For this purpose, a simulated database, with a significant number of irradiated fuels, was used. The analysis process began with a treatment of the information, with the purpose of using machine learning tools. Subsequently, a validation process of the built model took place, where experimentation will contrast two models with different amounts of fuel characteristics. Finally, an Boruta analysis is carried out to analyze and obtain a measure of the importance over the importance parameters. The results showed that the two models obtained a high perform even when the number of features were substantially different. Even models with the use of hyperparameter tuning improve performance, as demonstrated below.",Yes,"논문 초록에서 모델의 성능을 검증하는 과정이 언급되어 있으며, 실험을 통해 두 모델의 성능을 비교하는 등 정량적 평가가 수행되었음을 알 수 있습니다. 또한, 하이퍼파라미터 튜닝을 통한 성능 향상도 언급되어 있어 정량적 평가가 이루어지고 있음을 확인할 수 있습니다."
QSAnglyzer: Visual Analytics for Prismatic Analysis of Question Answering System Evaluations,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8585733,"Developing sophisticated artificial intelligence (AI) systems requires AI researchers to experiment with different designs and analyze results from evaluations (we refer this task as evaluation analysis). In this paper, we tackle the challenges of evaluation analysis in the domain of question-answering (QA) systems. Through in-depth studies with QA researchers, we identify tasks and goals of evaluation analysis and derive a set of design rationales, based on which we propose a novel approach termed prismatic analysis. Prismatic analysis examines data through multiple ways of categorization (referred as angles). Categories in each angle are measured by aggregate metrics to enable diverse comparison scenarios. To facilitate prismatic analysis of QA evaluations, we design and implement the Question Space Anglyzer (QSAnglyzer), a visual analytics (VA) tool. In QSAnglyzer, the high-dimensional space formed by questions is divided into categories based on several angles (e.g., topic and question type). Each category is aggregated by accuracy, the number of questions, and accuracy variance across evaluations. QSAnglyzer visualizes these angles so that QA researchers can examine and compare evaluations from various aspects both individually and collectively. Furthermore, QA researchers filter questions based on any angle by clicking to construct complex queries. We validate QSAnglyzer through controlled experiments and by expert reviews. The results indicate that when using QSAnglyzer, users perform analysis tasks faster (p <; 0.01) and more accurately (p <; 0.05), and are quick to gain new insight. We discuss how prismatic analysis and QSAnglyzer scaffold evaluation analysis, and provide directions for future research.",Yes,"논문 초록에서 ""aggregate metrics""와 ""visualization""을 통해 데이터를 정량적으로 평가하는 방법을 사용하고 있음을 명확히 언급하고 있습니다. 또한, 실험과 전문가 검토를 통해 평가 분석의 효율성과 정확성을 검증하는 과정을 포함하고 있어 정량적 평가가 실시되고 있음을 알 수 있습니다."
Meta-Learning Applications in Digital Image Processing,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9145478,"In recent decades, advances in capture devices and the increase of available digital image data have stimulated the creation of methodologies for data processing that produce various forms of valuable models, such as descriptors, classifiers, approximations and visualizations. These models are often developed in the field of machine learning, which is characterized by a large number of available algorithms. These algorithms often do not have guidelines to identify the most appropriate one based on specific data to which they will be applied and the nature of the problem under analysis. There is a knowledge that allows to relate the features of the algorithms and data that present a good performance to fulfill a specific task, known as Meta-Knowledge, which can include information on algorithms, evaluation metrics to calculate similarity of datasets or relation of tasks. Being Meta-Learning the study of methods based on principles that explore the Meta-Knowledge to obtain efficient models and solutions, adapting the processes of Machine Learning and Data Mining. The research carried out in this work analyzes the applications and advantages offered by Meta-Learning in the field of digital image processing. To carry out this task, different types of images, characterizers, and feature analysis techniques are used. The results obtained show that methodology based on Meta-Learning is efficient when applied in the processing of digital images for identification and storage of experience generated by developing methodologies for classification of different types of images, obtaining a high performance with respect to an evaluation metrics. This statement means that Meta-Learning allows recommending the most appropriate methodology to perform the processing of a specific type of image based on features of the dataset under analysis and the type of specific task to be performed.",Yes,"초록에서 다양한 평가 지표를 활용하여 높은 성능을 달성했다고 언급하며, 실험 결과를 통해 방법론의 효율성을 검증하는 내용이 포함되어 있습니다. 이는 논문이 정량적 평가를 실시하고 있음을 시사합니다."
Implementation of Deep Joint Source-Channel Coding on 5G Systems for Image Transmission,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10333673,"Deep joint source-channel coding (JSCC) has been attracting attention for achieving task-oriented communication. It replaces traditional information source coding and channel coding with a deep learning-based autoencoder, directly mapping information sources such as images to IQ symbols. For images, it is claimed to avoid the cliff effect and achieve a higher peak signal noise ratio (PSNR) even in low SNR regions. While related work has assumed various propagation channel models and validated the effectiveness of Deep JSCC, there are few reports confirming its principles through experiments. Specifically, to the best of our knowledge, there are no reported examples of experiments of Deep JSCC in 5G systems. In this paper, we present a proof-of-concept of Deep JSCC in a 5G system. We modified commercially available 5G base stations (gNB) and 5G terminals to enable input and output of IQ data from external devices. We connect the 5G devices using coaxial cables and attenuators, transmit and receive JSCC signals, and evaluate the PSNR. The results demonstrate that even when communicating at power levels lower than the minimum receiver sensitivity specified in the receiver’s datasheet, the image can be successfully restored with less than 1 dB degradation in PSNR compared with the simulation result.",Yes,"논문 초록에서 PSNR(peak signal noise ratio)를 평가하는 실험 결과를 제시하며, 실험을 통해 Deep JSCC의 성능을 정량적으로 평가하고 있음을 보여줍니다. 이를 통해 정량적 평가가 수행되고 있음을 알 수 있습니다."
Enhancing Essay Scoring with Adversarial Weights Perturbation and Metric-specific AttentionPooling,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10475720,"The objective of this study is to improve automated feedback tools designed for English Language Learners (ELLs) through the utilization of data science techniques encompassing machine learning, natural language processing, and educational data analytics. Automated essay scoring (AES) research has made strides in evaluating written essays, but it often overlooks the specific needs of English Language Learners (ELLs) in language development. This study explores the application of BERT-related techniques to enhance the assessment of ELLs’ writing proficiency within AES.To address the specific needs of ELLs, we propose the use of DeBERTa, a state-of-the-art neural language model, for improving automated feedback tools. DeBERTa, pretrained on large text corpora using self-supervised learning, learns universal language representations adaptable to various natural language understanding tasks. The model incorporates several innovative techniques, including adversarial training through Adversarial Weights Perturbation (AWP) and Metric-specific AttentionPooling (6 kinds of AP) for each label in the competition.The primary focus of this research is to investigate the impact of hyperparameters, particularly the adversarial learning rate, on the performance of the model. By fine-tuning the hyperparameter tuning process, including the influence of 6AP and AWP, the resulting models can provide more accurate evaluations of language proficiency and support tailored learning tasks for ELLs. This work has the potential to significantly benefit ELLs by improving their English language proficiency and facilitating their educational journey.",Yes,"논문 초록에서 ""hyperparameters""와 ""adversarial learning rate"" 등 정량적 평가와 관련된 내용을 언급하며, 모델 성능 향상을 위해 실험적 조정을 수행하는 것으로 보입니다. 또한, ""fine-tuning""과 ""performance"" 평가를 통해 정량적 평가가 이루어지고 있음을 시사합니다."
Multi-Layout Unstructured Invoice Documents Dataset: A Dataset for Template-Free Invoice Processing and Its Evaluation Using AI Approaches,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9481217,"The daily transaction of an organization generates a vast amount of unstructured data such as invoices and purchase orders. Managing and analyzing unstructured data is a costly affair for the organization. Unstructured data has a wealth of hidden valuable information. Extracting such insights automatically from unstructured documents can significantly increase the productivity of an organization. Thus, there is a huge demand to develop a tool that can automate the extraction of key fields from unstructured documents. Researchers have used different approaches for extracting key fields, but the lack of annotated and high-quality datasets is the biggest challenge. Existing work in this area has used standard and custom datasets for extracting key fields from unstructured documents. Still, the existing datasets face some serious challenges, such as poor-quality images, domain-related datasets, and a lack of data validation approaches to evaluate data quality. This work highlights the detailed process flow for end-to-end key fields extraction from unstructured documents. This work presents a high-quality, multi-layout unstructured invoice documents dataset assessed with a statistical data validation technique. The proposed multi-layout unstructured invoice documents dataset is highly diverse in invoice layouts to generalize key field extraction tasks for unstructured documents. The proposed multi-layout unstructured invoice documents dataset is evaluated with various feature extraction techniques such as Glove, Word2Vec, FastText, and AI approaches such as BiLSTM and BiLSTM-CRF. We also present the comparative analysis of feature extraction techniques and AI approaches on the proposed multi-layout unstructured invoice document dataset. We attained the best results with BiLSTM-CRF model.",Yes,"논문 초록에서 다양한 AI 기법과 특징 추출 기법을 사용하여 정량적 평가를 수행했다고 명시되어 있습니다. 또한, 최적의 성과를 도출하기 위해 비교 분석을 진행하는 등 평가 과정이 포함되어 있음을 알 수 있습니다."
Decoding of Auditory Imagination Activity Based on Machine Learning Methods,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10075201,"The decoding of brain signals has important research value and is also full of challenges. In recent years, the fMRI technology is more and more widely used in the brain signals decoding because of its high spatial resolution and non-invasive characteristic. The existing brain region template provides a powerful tool for brain region decoding research, and the obtained functional connectivity matrix quantifies the correlation between brain regions. The development of pattern recognition technology has created a favorable technical foundation for the study of fMRI data, including a variety of mature machine learning methods such as support vector machine. In this paper, the fMRI data of 24 healthy subjects was measured when they performed the auditory imagination under different sound and scene conditions, then the functional connectivity matrices of brain regions were obtained and to be classified by several pattern recognition methods, such as optimized support vector machine, naive Bayes, and logistic regression. At last, the classification methods were compared according to the classification accuracy. Compared with related works, Methods of data acquisition and the accuracy of the results are better than previous job. The method can help psychologists and neuroscientists perform the brain signal decoding with high efficiency and quality. At the same time, the research is helpful to reveal the neural mechanism of auditory imagination and auditory perception, deepen our understanding of human brain auditory information processing, help the computer to simulate human hearing, and use the correlation of brain signals to help the deaf and mute people to carry out related activities, which has good social benefits.",Yes,"논문 초록에서 여러 분류 방법(지원 벡터 머신, 나이브 베이즈, 로지스틱 회귀)을 사용하여 분류 정확도를 평가하는 정량적 평가를 실시했다고 명확히 언급하고 있습니다. 따라서 정량적 평가가 수행되고 있음을 알 수 있습니다."
Evaluation of fruit selection with ensemble model in the Peruvian industry,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10326089,"This paper allows to evaluate fruits with the ensemble algorithm with artificial vision, besides, it evaluates the systematic review with the PRISMA methodology thought the last 10 years. Our findings are the application of TensorFlow and self-supervised multi-network fusion classification models. Some researchers describe classification errors. The deep learning methodology is also an efficient way of classifying and applying algorithms that optimally analyze features such as color, shape, and texture of the object. On the other hand, we can implement artificial intelligence to this work since in recent years it has been developing in all industrial sectors and is bringing positive results. Finally, it uses a case study with the limitations to admit safe practices in a company dedicated to agricultural production and also over time that when studying the last cycle and at the same time working, the availability of time is limited to be able to use it in a work area. The results are an mean absolute error for size evaluation of 92.92%, color evaluation with 93.23%, and the assessment of the maturity, defects and quality of 97.72% after the evaluation of 1271 research articles with the systematic review process.",Yes,"논문 초록에서 정량적 평가를 위해 평균 절대 오차, 색상 평가, 성숙도, 결함 및 품질 평가와 같은 구체적인 수치와 정확도를 제시하고 있습니다. 이는 정량적 평가를 실시하고 있음을 명확히 보여줍니다."
An Estimation of the Performance of Deep Learning Based Hard Link Boot Caffe Neural Network for Network Anomaly Detection,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10452430,"As internet technology has rapidly advanced in recent years, so too has the range of cyber-attacks. In the current state of affairs in the cyber world, the ability to detect such attacks is more crucial than ever. Researchers from a wide variety of fields have increasingly looked to machine learning (ML) and deep learning (DL) techniques to help them solve their difficulties. In this study, we provide a system for identifying network attacks using deep learning. In this work, initially the database was retrieved and data preprocessing was done by using the Minmax error splash method. Then the attack related features are extracted using the Sigmoid polychain component analysis. Then Stochastic convergence Adam optimization algorithm was used for feature selection. The purpose of using optimization is to improve the classifier accuracy. This technique extracts a specialized features that are related to malicious code that can be used to classify the attack. The extracted features are given as a input to the Hard link boot caffe memory neural network classifier. The presented method is evaluated on a NSL-KDD dataset, achieving a high attack detection accuracy, which makes it the best among the competing approaches.",Yes,논문 초록에서 성능 평가를 위해 NSL-KDD 데이터셋을 사용하여 공격 탐지 정확도를 측정했다고 명시되어 있습니다. 이는 정량적 평가를 실시했음을 보여주는 명확한 증거입니다.
Analysis and review of current deep learning techniques for dental image segmentation with a novel deep neural network,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10235850,"Dental image segmentation is an important task in dental image analysis and plays a crucial role in various dental applications, such as diagnosis, treatment planning, and clinical research. With the advent of different imaging modalities, there has been a significant increase in the complexity and variability of dental images, thus making the dental image segmentation task more challenging. Recent advancements in deep learning techniques have led to significant improvements in dental image segmentation accuracy and efficiency. In this paper, some of the current deep-learning techniques that are used for dental image segmentation on various imaging modalities have been discussed. A comprehensive review is carried out, which provides the details of current deep learning methodologies, including types of deep architecture used, different imaging modalities, and datasets along with their applications and shortcomings. Additionally, a novel deep learning methodology based on a dual stream encoder and decoder architecture is proposed for automatically segmenting panoramic images. The evaluation is carried out on 1000 image dataset and is measured by dice coefficient, jaccard index, accuracy, precision and recall. The proposed methodology performs better than the state-of-the-art deep segmentation models.",Yes,"논문 초록에서 제안된 딥러닝 방법의 성능 평가를 위해 dice 계수, jaccard 지수, 정확도, 정밀도, 재현율 등 정량적 지표를 사용했다고 명시되어 있습니다. 또한, 1000개 이미지 데이터셋에 대한 평가 결과를 제시하며 정량적 평가를 실시했음을 보여줍니다."
Laparoscope Manipulating Robot (LMR) Navigation using Deep Learning-based Surgical Instruments Detection,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9980059,"During laparoscopic surgery, several items, including the laparoscope and all the surgical instruments must be manipulated at the same time. This paper presents the implementation of a surgical instrument detection system based on the deep learning methodology to work with the Laparoscope Manipulating Robot (LMR). Two procedures in this work are object detection on surgical instruments and then laparoscope navigation. The position information of detected surgical instruments is feed-backed to navigate the laparoscope automatically. The object detection comprises three main processes, the training, validating, and testing processes. Dataset in the experiments were gathered from 5 various public YouTube video clips related to gynecologic surgery. The previous work has compared various algorithms on surgical instrument detection. YOLOv4 provided the best performance with the validation result of the detection model across the experiment datasets with F1-score of 93.50% at the Confidence Threshold over 48% on the average during the training process. Hence YOLOv4 has been chosen to be assigned to the object detector. And as for the navigation process in the real-time surgical operation, once all surgical instruments have been detected, the focus of the laparoscope should be in the center among those instruments. The center position of each detected surgical instrument has been used to calculate the center of the laparoscope. To validate the viability of on-the-fly surgical instrument detection and laparoscope navigation, the proposed system has been implemented and tested on two test-cases of gynecologic surgery with the soft-tissue cadavers. The real tests have shown that the proposed method works well with two and three surgical instruments detection, but not with a single instrument detection, as the information on the position of a single surgical instrument detected is not enough to navigate the laparoscope to a designated object.",Yes,"논문은 딥러닝 기반의 수술 기구 검출 시스템을 개발하고, 이를 통해 수술 기구의 위치 정보를 정량적으로 평가하는 실험을 수행하였음을 보여줍니다. 특히, YOLOv4 알고리즘의 성능을 F1-score와 검증 결과를 통해 평가하는 등, 정량적 평가가 실시되고 있음을 알 수 있습니다."
"On the Evaluation, Management and Improvement of Data Quality in Streaming Time Series",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9845398,"The Internet of Things (IoT) technologies plays a key role in the Fourth Industrial Revolution (Industry 4.0). This implies the digitisation of the industry and its services to improve productivity. To obtain the necessary information throughout the different processes, useful data streams are obtained to provide Artificial Intelligence and Big Data algorithms. However, strategic decision-making based on these algorithms may not be successful if they have been developed based on inadequate low-quality data. This research work proposes a set of metrics to measure Data Quality (DQ) in streaming time series, and implements and validates a set of techniques and tools that allow monitoring and improving the quality of the information. These techniques allow the early detection of problems that arise in relation to the quality of the data collected; and, in addition, they provide some mechanisms to solve these problems. Later, as part of the work, a use case related to industrial field is presented, where these techniques and tools have been deployed into a data management, monitoring and data analysis platform. This integration provides additional functionality to the platform, a Decision Support System (DSS) named DQ-REMAIN (Data Quality REport MAnagement and ImprovemeNt), for decision-making regarding the quality of data obtained from streaming time series.",Yes,"논문 초록에서 데이터 품질을 측정하기 위한 지표를 제안하고, 이를 검증하는 기술과 도구를 구현했다고 명시되어 있습니다. 또한, 이러한 기술들이 데이터 품질을 모니터링하고 향상시키는 데 사용된다는 점에서 정량적 평가가 실시되고 있음을 알 수 있습니다."
Feature Extraction and Selection for Identifying Faults in Contactors Using Fiber Bragg Grating,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10192542,"Switching devices are used in a wide application field to control and protect electrical systems. Failures in such equipment cause a loss of reliability in electrical facilities, which can lead to catastrophic consequences. The main advantage of using optical sensors is their immunity to the electromagnetic field, allowing installation in unfeasible locations compared to other technologies presented in related works. Consequently, the proposed approach consists of a new application employing fiber Bragg grating (FBG) to measure dynamic strain signals while switching a low-voltage contactor and develop a signal processing algorithm to extract and select features for classification using supervised learning methods. The models were trained and validated with different measurement sets, dividing them into intermediate and critical wear-out stages. The test procedures were carried out in a controlled manner replacing the contactor’s main internal components. Two feature extraction methods were evaluated. The first calculates the power spectral density (PSD) and the switching time, while the second considers the coefficients generated by the wavelet scattering transform (WST). With maximum relevance and minimum redundancy (mRMR) and the support vector machine (SVM) algorithms, it was possible to identify components states, obtaining an accuracy of 99.4% for cross validation, 100% for validation dataset, and 86.4% for the new test dataset. The results demonstrate that the proposed system can recognize critical faults and is promising to be applied in other types of commutation equipment in future applications striving to increase the complexity of the evaluated devices.",Yes,"논문 초록에서 다양한 특징 추출 방법과 분류 알고리즘을 사용하여 성능 평가를 수행한 내용을 언급하고 있으며, 정확도와 검증 결과를 제시하고 있어 정량적 평가를 실시하고 있음을 알 수 있습니다."
Artificial intelligence and computer science in education: From kindergarten to university,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7757570,"Artificial Intelligence (AI) already plays a major role in our daily life (e.g. intelligent household appliances like robotic vacuum cleaners or AI-based applications like Google Maps, Google Now, Siri, Cortana, ...). Sound knowledge about AI and the principles of computer science will be of vast importance for future careers in science and engineering. Looking towards the near future, jobs will largely be related to AI. In this context literacy in AI and computer science will become as important as classic literacy (reading/writing). By using an analogy with this process we developed a novel AI education concept aiming at fostering AI literacy. The concept comprises modules for different age groups on different educational levels. Fundamental AI/computer science topics addressed in each module are, amongst others, problem solving by search, sorting, graphs and data structures. We developed, conducted and evaluated four proof-of-concepts modules focusing on kindergarten/primary school as well as middle school, high school and university. Preliminary results of the pilot implementations indicate that the proposed AI education concept aiming at fostering AI literacy works.",Yes,"논문 초록에서 네 개의 파일럿 모듈을 개발, 수행, 평가했다고 언급하며, 이 과정에서 초등학교부터 대학까지 다양한 교육 수준에서의 교육 효과를 검증하는 평가를 실시했음을 시사합니다. 따라서 정량적 평가가 이루어졌다고 판단됩니다."
Paddy Leaf Disease Detection Using Fine-tuned EfficientNetB4 Convolutional Neural Network,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10726047,"Agriculture remains the backbone of many countries since it acts as the main source of income and food. In this regard, different food crops are significant in the global economy, where rice occupies a very central position as one of the most important staple foods in many Asian countries. However, rice cultivation encounters various diseases at the different stage affecting either the quality or the rate of growth in the crop. Diagnosis of these diseases can be tiresome by applying traditional methods and use of naked eyes because symptoms of most diseases are often related. Therefore, the use of automated systems and the integration of such systems adds more realization to disease detection, hence informing the farmer to take appropriate measures on time to minimize crop or plant losses in order to yield quality produce. In the last several years different approaches utilizing image processing, machine learning, and deep learning algorithms have been investigated by researchers to create effective automatic systems. Therefore, this paper aims at optimizing several of the existing highly accurate deep learning-based state-of-art Convolutional neural networks for the early detection of different rice crop diseases, also known as paddy leaf diseases. This work also pointed out a comparative assessment of the utilized techniques through precision, accuracy, recall, and F1-score metrics with a finetuned EfficientNetB4 model with an optimum F1-score of approximately 99. 7%.",Yes,"논문 초록에서 정밀도(precision), 재현율(recall), F1-score 등 다양한 정량적 평가 지표를 사용하여 딥러닝 모델의 성능을 평가했다고 명시되어 있습니다. 이는 정량적 평가가 실시되고 있음을 보여줍니다."
Adapting Software Architectures to Machine Learning Challenges,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9825909,"Unique developmental and operational characteristics of machine learning (ML) components as well as their inherent uncertainty demand robust engineering principles are used to ensure their quality. We aim to determine how software systems can be (re-) architected to enable robust integration of ML components. Towards this goal, we conducted a mixed-methods empirical study consisting of (i) a systematic literature review to identify the challenges and their solutions in software architecture for ML, (ii) semi-structured interviews with practitioners to qualitatively complement the initial findings and (iii) a survey to quantitatively validate the challenges and their solutions. We compiled and validated twenty challenges and solutions for (re-) architecting systems with ML components. Our results indicate, for example, that traditional software architecture challenges (e.g., component coupling) also play an important role when using ML components; along with new ML specific challenges (e.g., the need for continuous retraining). Moreover, the results indicate that ML heightened decision drivers, such as privacy, play a marginal role compared to traditional decision drivers, such as scalability. Using the survey we were able to establish a link between architectural solutions and software quality attributes, which enabled us to provide twenty architectural tactics used to satisfy individual quality requirements of systems with ML components. Altogether, the results of the study can be interpreted as an empirical framework that supports the process of (re-) architecting software systems with ML components.",Yes,"논문 초록에서 설문조사를 통해 정량적 검증을 수행했다고 명확히 언급하고 있으며, 이를 통해 정량적 평가가 이루어졌음을 알 수 있습니다. 따라서, 논문은 정량적 평가를 실시하고 있다고 판단됩니다."
Patient's Pain Recognition by Using Deep Models Based on Transfer Learning,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10076192,"Undetected pain threatens the quality of human life by prevents them from understanding the nature of their pain. Therefore, an urgent need to find an alternative that can recognize pain in patients suffering from difficulty in express their pain for reasons related to age or the ability of explain feeling of pain. The structure of a proposed system depends on the transfer learning technique, where two pre-trained deep convolution neural network (ResNet-50and Xception) models, have been used as a feature extractor. These models receive the images from the database, which was collected especially for this work from 100 subjects of (10–55) ages in different times and natural environments. Extracted features, which formed a features vector, were taken from the Global Average Pooling (GAP) layer. These feature vectors are passed to a supervised classification method such as Support Vector Machine (SVM), K-Nearest Neighbour (KNN), and build a Deep Neural Network (DNN) classifier from scratch. The proposed model's performance was evaluated by comparing it with related work, which adopted the concept of a pre-trained model and used the database collected in a natural environment in the training and testing process. The proposed model demonstrates outstanding results by the combination of exploiting the Transfer Learning (TL) technique in the Xception model and building the DNN as a classifier. The accuracy of the proposed model was 98.17% which demonstrates promising results.",Yes,"논문 초록에서 다양한 정량적 평가 지표(예: 정확도 98.17%)를 사용하여 제안된 모델의 성능을 평가했다고 명시되어 있습니다. 또한, 여러 분류기와 비교 실험을 통해 성과를 수치로 제시하고 있어 정량적 평가를 실시하고 있음을 알 수 있습니다."
Deep Learning Transfer with AlexNet for chest X-ray COVID-19 recognition,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9451239,"The COVID-19 is a new disease from the virus SARS-CoV-2, the infection can cause respiratory illness with symptoms such as cough, fever, and, in severe cases, pneumonia. Early diagnosis is crucial for the correct treatment to reduce as much as possible the stress in the healthcare system. The need for auxiliary diagnostic tools has increased as there are no accurate automated toolkits available. Application of advanced artificial intelligence (AI) techniques coupled with radiological imaging can be helpful for the accurate detection of this disease. In this study, we have applied learning transfer to a convolutional neural network known as AlexNet for binary chest X-ray recognition (COVID-19 vs Healthy). We have fine-tunned AlexNet for our specific problem. The first layer, which works with RGB images, is replaced for images in a single intensity (grayscale). 11,312 chest X-ray images from six public databases were used to train the network. Among them are samples of healthy people and samples that present the effect of pneumonia and COVID-19 diseases. The results prove that deep learning with chest X-ray images can extract significant biomarkers related to COVID-19, since the obtained accuracy, sensitivity and specificity were 96.5%, 98.0%, and 91.7%, respectively. ROC analysis and confusion matrices are used to validate the results of the fine-tunned AlexNet network.",Yes,"논문 초록에서 정확도, 민감도, 특이도와 같은 정량적 평가 지표를 제시하며, ROC 분석과 혼동 행렬을 사용하여 모델의 성능을 평가했다고 명시하고 있습니다. 이는 정량적 평가를 실시했음을 보여줍니다."
Smart Safety Surveillance System: Personal Protective Equipment and Drowsiness Detection in Industrial Environments,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10724032,"The Intelligent Safety Surveillance System (ISSS) for Industrial Environments is a comprehensive solution designed to enhance workplace safety by monitoring Personal Protective Equipment (PPE) compliance and detecting worker drowsiness. Leveraging computer vision and machine learning technologies, the ISSS provides real time monitoring and proactive alerting mechanisms. This system employs strategically positioned cameras to detect and recognize PPE items such as helmets, safety masks, and gloves. Deep learning algorithms analyze video feeds to identify instances of noncompliance, triggering immediate alerts to workers and supervisors for corrective action. In addition to PPE compliance monitoring, the ISSS utilizes cameras equipped with infrared sensors to monitor workers’ facial expressions and eye movements for signs of drowsiness. Machine learning models are trained to recognize patterns indicative of drowsiness, such as drooping eyelids or prolonged eye closure. Upon detecting these signs, the system alerts workers and supervisors, mitigating the risk of accidents caused by fatigue-related errors. By combining advanced technologies with proactive safety measures, the ISSS aims to create a safer work environment in industrial settings. Its ability to detect non-compliance and drowsiness in real-time enables timely intervention, ultimately reducing the risk of workplace accidents and injuries.",Yes,"논문 초록에서 시스템의 성능 평가를 위해 딥러닝 알고리즘과 머신러닝 모델을 활용하여 PPE 및 졸음 징후를 분석하는 과정을 언급하고 있으며, 이는 정량적 평가를 실시했음을 시사합니다. 또한, 실시간 모니터링과 경고 메커니즘이 언급되어 있어 시스템의 성능을 수치로 평가했을 가능성이 높습니다."
SLEEP-SEE-THROUGH: Explainable Deep Learning for Sleep Event Detection and Quantification From Wearable Somnography,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10102486,"Evidence is rapidly accumulating that multifactorial nocturnal monitoring, through the coupling of wearable devices and deep learning, may be disruptive for early diagnosis and assessment of sleep disorders. In this work, optical, differential air-pressure and acceleration signals, acquired by a chest-worn sensor, are elaborated into five somnographic-like signals, which are then used to feed a deep network. This addresses a three-fold classification problem to predict the overall signal quality (normal, corrupted), three breathing-related patterns (normal, apnea, irregular) and three sleep-related patterns (normal, snoring, noise). In order to promote explainability, the developed architecture generates additional information in the form of qualitative (saliency maps) and quantitative (confidence indices) data, which helps to improve the interpretation of the predictions. Twenty healthy subjects enrolled in this study were monitored overnight for approximately ten hours during sleep. Somnographic-like signals were manually labeled according to the three class sets to build the training dataset. Both record- and subject-wise analyses were performed to evaluate the prediction performance and the coherence of the results. The network was accurate (0.96) in distinguishing normal from corrupted signals. Breathing patterns were predicted with higher accuracy (0.93) than sleep patterns (0.76). The prediction of irregular breathing was less accurate (0.88) than that of apnea (0.97). In the sleep pattern set, the distinction between snoring (0.73) and noise events (0.61) was less effective. The confidence index associated with the prediction allowed us to elucidate ambiguous predictions better. The saliency map analysis provided useful insights to relate predictions to the input signal content. While preliminary, this work supported the recent perspective on the use of deep learning to detect particular sleep events in multiple somnographic signals, thus representing a step towards bringing the use of AI-based tools for sleep disorder detection incrementally closer to clinical translation.",Yes,"논문 초록에서 다양한 수면 이벤트와 신호에 대해 정량적 평가 지표(예: 정확도 0.96, 0.93, 0.76 등)를 제시하며, 예측 성능을 수치로 평가하고 있음을 보여줍니다. 또한, 신뢰도 지수와 정량적 데이터(신뢰도 인덱스, 민감도 등)를 활용하여 평가를 수행하고 있음을 알 수 있습니다."
Extracting Human Levels of Trust in Human–Swarm Interaction Using EEG Signals,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10423920,"Trust is an essential building block of human civilization. However, when it relates to artificial systems, it has been a barrier to intelligent technology adoption in general. This article addresses the gap in determining levels of trust in scenarios that include humans interacting with a swarm of robots. Electroencephalography (EEG) recordings of the human observers of the different swarms allow for extracting specific EEG features related to different trust levels. Feature selection and machine learning methods comprise a classification system that would allow recognition of different levels of human trust in those human–swarm interaction scenarios. The results of this study suggest that EEG correlates of swarm trust exist and are distinguishable in machine learning feature classification with very high accuracy. Moreover, comparing common EEG features across all human subjects used in this study allows for the generalization of the classification method, providing solid evidence of specific areas and features of the human brain where activations are related to levels of human–swarm trust. This work has direct implications for effective human–machine teaming with applications to many fields, such as exploration, search and rescue operations, surveillance, environmental monitoring, and defense. In these applications, quantifying levels of human trust in the deployed swarm is of utmost importance because it can lead to swarm controllers that adapt their output based on the human's perceived trust level.",Yes,"논문 초록에서 EEG 신호를 이용하여 신뢰 수준을 분류하는 머신러닝 방법을 제시하고 있으며, 이를 통해 정량적 평가가 이루어지고 있음을 알 수 있습니다. 또한, 높은 정확도의 분류 성능과 일반화 가능성을 언급하여 정량적 평가의 실시를 명확히 보여줍니다."
Using Business Intelligence Dashboard for Sustainable Urban Water Security Monitoring,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10150119,"This paper presents the findings from the experts on the effective factor of monitoring dashboards for urban water security. The urban water security dashboard monitors the water quality, availability, and other relevant indicators. Although monitoring dashboards exist, there are potential improvements in the context of urban water security. The study integrates the technological factors in the domain area. An expert review is conducted to get confirmation from professionals in the chosen sector about the effective factors for the dashboards from the IT perspective. This methodology uses qualitative via face-to-face and online sessions. Thematic analysis and content validity index (CVI) have been used to evaluate the experts' review. The findings show security and knowledge discovery is the main factor emphasised. The experts deemed visual design the least priority when creating a business intelligence dashboard. Experts also recommend embedding Artificial Intelligence (AI) with the data analysis for dashboards. The discussion identified challenges and future work for this research. The discussion identified three potential areas of future research in water security and informatics: i) investigating other dimensions of effective dashboards, ii) conducting additional research on the environmental dashboard, and iii) investigating dashboards' real-world application in urban water security.",Yes,"초록에서 내용 분석과 평가를 위해 내용 타당도 지수(CVI)와 주제 분석이 사용되었으며, 이는 정량적 평가 방법을 포함하는 것으로 보입니다. 또한, 전문가 검토를 통한 평가 과정이 언급되어 있어 정량적 평가가 실시된 것으로 판단됩니다."
Empowered Artificial Intelligence Approach using Intuitionistic Fuzzy based Deep Neural Network for Chronic Diseases Prediction,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10582074,"Managing the increasing prevalence of chronic illnesses is a major worldwide health concern. It's important to understand the medical problem, its stages, types, and available treatments. The most important component in the early diagnosis of chronic diseases might enhance the diagnostic procedure more successfully. Medical professionals can diagnose a process with the help of numerous artificial intelligence tools. However, ambiguity, irrelevance, and inconsistency in the disease dataset have an impact on the classification accuracy. Conventional machine learning techniques are inadequate for managing scenarios of uncertainty that arise in datasets related to chronic illnesses. To anticipate chronic diseases, each characteristic in the suggested work is represented with a hesitation index. In order to compute the hesitation degree as a more informative procedure in determining the association among features, the belongingness and non-belongingness aspects of the intuitionistic fuzzy concept are induced in the prediction process. This work effectively manages the large chronic illness dataset by developing an intuitionistic fuzzy hesitation index-based similarity measure to weed out unimportant and strongly associated characteristics and enhance the classification model. Utilizing the scored feature information, the deep neural network modifies its hyper parameter to address the overfitting issues that frequently arise in DNNs. The performance of the empowered intuitionistic fuzzy-based deep neural network (EIF-DNN) is analyzed using five distinct chronic conditions, including hypertension, diabetes, hepatitis, cancer, and stroke. Comparing the proposed EIF-DNN against the current versions of multi-layered networks, the simulation results show that it produces promising results in predicting chronic diseases at an early stage.",Yes,"논문 초록에서 제안된 방법이 특징의 점수화와 분류 성능 평가를 포함하여 정량적 평가를 수행하고 있음을 시사하는 실험 결과를 언급하고 있습니다. 또한, 다양한 만성 질환에 대한 예측 성능을 비교 분석하는 내용이 있어 정량적 평가가 실시된 것으로 판단됩니다."
Ambulatory Behavior Assessment Using Deep Learning,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10340595,"This work leverages a custom implementation of a deep neural network-based object detection algorithm to detect people and a set of assistive devices relevant to clinical environments. The object detections form the basis for the quantification of different ambulatory activities and related behaviors. Using features extracted from detected people and objects as input to machine learning models, we quantify how a person ambulates and the mode of ambulation being used.Clinical relevance— This system provides the data required for clinicians and hospitalized patients to work together in the creation, monitoring, and adjustment of ambulatory goals.",Yes,"논문은 딥러닝 기반 객체 검출 알고리즘을 활용하여 사람과 관련 기기를 감지하고, 이를 바탕으로 다양한 보행 활동과 행동을 정량적으로 평가한다고 명시하고 있습니다. 또한, 감지된 데이터를 이용해 보행 방식과 활동을 수치화하는 과정을 포함하고 있어 정량적 평가를 실시하는 것으로 판단됩니다."
HealthMine: A Tool for Social Media Text Mining in Health,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9297002,"Social media has become a major source of information in recent years, with millions of posts every minute if not seconds. Containing information on various topics like health, politics and sports, one cannot deny that social media has become a good leverage for the field of data analytics. The objective of this work was to apply techniques of text mining, data analytics, and machine learning to Implement a web application, HealthMine, which extracts and classifies relevant data collected from social media platforms, namely Twitter and MedHelp, following a health-related user query. This would spare the user the burden of filtering out irrelevant information and focusing more on what is relevant. However, since content on social media is user-generated, the reliability is dubitable and the advice of a certified medical practitioner is always recommended. The main purpose of the tool is to allow users to share experiences. The tool was evaluated using 1400 tweets and 1800 MedHelp posts and it was found that Naive Bayes Classifier yielded the best accuracy among other classifiers, with an accuracy of 86.3 and 76.6 for Twitter and Medhelp respectively.",Yes,"논문 초록에서 ""The tool was evaluated using 1400 tweets and 1800 MedHelp posts""라는 문구를 통해 정량적 평가가 실시되었음을 명확히 언급하고 있습니다. 또한, 여러 분류기들의 정확도를 제시하여 구체적인 수치로 평가 결과를 제시하고 있습니다."
End-to-end Gesture Recognition Framework for the Identification of Allergic Rhinitis Symptoms,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9881698,"Human Gesture Recognition (HGR) using smart wearable IoT devices has emerged as a new field in human-centered computing regarding various domains. Though there are many research works related to data processing methodologies and Neural Networks architectures in this field, a lack of research on how to efficiently identify and interpret the AI models’ exports into human gestures is observed. This paper proposes an innovative end-to-end approach of how to solve and evaluate effectively a major part of HGR problems in a real-world scenario, in real-time. This is achieved with the effective utilization of data processing methods, the adoption, and extension of a cutting-edge Deep Learning model architecture, as well as the introduction and implementation in practice of innovative methods, both for interpretation and evaluation, that increase the trustworthiness of the model’s predictions.As a case study, we deployed the introduced pipeline into a real-world scenario of gestures’ identification and classification regarding allergic symptoms. We adopted multidisciplinarity by collaborating with recognized allergists that validated the whole approach in real patients via two pilot phases. As a result, by delivering a real-world application of our approach, we achieved a superior performance concerning the reliability of the pipeline, being 91.6% in our laboratory pilot phase and 81.4% in patients’ pilot data. Lastly, it is worth mentioning here that our framework can be employed in most HGR problems with minor modifications in data processing and learning procedure configuration.",Yes,"논문 초록에서 데이터 처리 방법, 딥러닝 모델 아키텍처의 채택, 그리고 성능 평가와 관련된 구체적인 수치(91.6%, 81.4%)를 언급하며 정량적 평가를 실시하고 있음을 보여줍니다. 이러한 내용은 연구의 성과를 수치로 측정하고 검증하는 정량적 평가가 수행되었음을 의미합니다."
Complex Network Measures for Data Classification,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9533608,"Complex networks have become an increasingly relevant research topic in machine learning, with many learning systems in the literature successfully exploring complex network properties and measures. In data classification, the use of complex networks allows the detection of structural and topological patterns related, for example, to the formation pattern of the input data. Some measures of complex networks have already been used in this sense. However, a systematic study capable of characterizing such measures in the context of data classification is lacking in the literature. In this work, we evaluate comparatively the predictive performance of some measures. Specifically, eight complex network measures were selected from the literature, namely: assortativity, average local clustering coefficient, average degree, betweenness, average shortest path length, closeness, global clustering coefficient and eigenvector centrality. For our analyses, both artificial and real-world data sets were considered. The results show that measures such as average shortest path and assortativity, besides presenting high predictive capability, are also more robust to the variation of the network structure. In summary, this research paves a way to support other related works in selecting more appropriate complex network measures for data classification.",Yes,"논문 초록에서 8개의 복합 네트워크 측정값을 선택하여 예측 성능을 비교 평가하는 정량적 분석을 수행했다고 명확히 언급하고 있습니다. 또한, 실험을 통해 측정값들의 예측 능력과 구조 변화에 대한 강인성을 평가하였음을 알 수 있어 정량적 평가가 실시된 것으로 판단됩니다."
Design of a data acquisition system to be used in fault diagnosis,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7483298,"In Machine learning, the availability of reliable datasets to be used by training algorithms is a widely posed problem. In this perspective, this work represents a design of a data acquisition system that allows the collection of data from a real world industrial machine (Direct Current motor machines). The goal of this data collection is the construction of a fault diagnosing tool by using heterogeneous data. Those heterogeneous data are collected from different types of sensors measuring different types of variables that are directly related to the industrial system. Owing to this data collection, one can build machine learning models such as Bayesian networks, Artificial Neural Networks, etc. Those models can be used in fault detection, diagnosis and prognosis.",No,"논문 초록에서는 데이터 수집 시스템의 설계에 초점을 맞추고 있으며, 정량적 평가 또는 실험 결과에 대한 언급이 없습니다. 따라서 정량적 평가를 실시하고 있다고 보기 어렵습니다."
Development of a Fuzzy Variable Rate Irrigation Control System Based on Remote Sensing Data to Fully Automate Center Pivots,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10316268,"Growing agricultural demands for the global population are unlocking the path to developing innovative solutions for efficient water management. Herein, an intelligent variable rate irrigation system (fuzzy-VRI) is proposed for decision-making to achieve optimized irrigation in various delimited zones. The proposed system automatically creates irrigation maps for a center pivot irrigation system for a variable rate application of water. Primary inputs are satellite imagery on remotely sensed soil moisture (SSM), soil-adjusted vegetation index (SAVI), canopy temperature (CT), and nitrogen content (NI). The system relates these inputs to set reference values for the rotation speed controllers and individual openings of each central pivot sprinkler valve. The results showed that the system can detect and characterize the spatial variability of the crop and further, the fuzzy logic solved the uncertainties of an irrigation system and defined a control model for high-precision irrigation. The proposed approach is validated through the comparison between the recommended irrigation and actual irrigation at two field sites, and the results showed that the developed approach gives an accurate estimation of irrigation with a reduction in the volume of irrigated water of up to 27% in some cases. Future research should implement the fuzzy-VRI real-time during field trials in order to quantify its effect on irrigation use, yield, and water use efficiency. Note to Practitioners—This work is motivated by the objective of managing irrigation more efficiently. It will be a site-specific irrigation management tool and we proposed a theoretical framework that aims an artificial intelligence approach to automatically create optimal control maps for a center pivot irrigation system. At the heart of this system will be the fuzzy logic, which will define the reference values for the rotation speed controllers and the individual opening of each center pivot sprinkler valve. Currently, there is a lack of these types of systems which ends up generating an increase in demand for more intelligent, automated, and accurate systems. The proposed system will be based on decision-making - whether to apply more or less water - and will use remote sensing data, therefore, the innovative irrigation system will efficiently describe the spatial variability of the crop. The results indicate that edaphoclimatic variables, when well combined with fuzzy logic, can resolve uncertainties and nonlinearities of an irrigation system and define a control model for high precision irrigation. However, it will not always be possible to reduce water consumption, but this technology has many uses to increase farm profitability.",Yes,"논문은 정량적 평가를 위해 실제 필드 비교를 통해 추천 관개량과 실제 관개량을 비교하는 방법을 사용하였으며, 최대 27%의 관개수량 절감 효과를 수치로 제시하고 있습니다. 이러한 평가 방법은 정량적 평가의 특징을 갖추고 있습니다."
First CE Matters: On the Importance of Long Term Properties on Memory Failure Prediction,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10020671,"Dynamic random access memory failures are a threat to the reliability of data centres as they lead to data loss and system crashes. Timely predictions of memory failures allow for taking preventive measures such as server migration and memory replacement. Thereby, memory failure prediction prevents failures from externalizing, and it is a vital task to improve system reliability. In this paper, we revisited the problem of memory failure prediction. We analyzed the correctable errors (CEs) from hardware logs as indicators for a degraded memory state. As memories do not always work with full occupancy, access to faulty memory parts is time distributed. Following this intuition, we observed that important properties for memory failure prediction are distributed through long time intervals. In contrast, related studies, to fit practical constraints, frequently only analyze the CEs from the last fixed-size time interval while ignoring the predating information. Motivated by the observed discrepancy, we study the impact of including the overall (long-range) CE evolution and propose novel features that are calculated incrementally to preserve long-range properties. By coupling the extracted features with machine learning methods, we learn a predictive model to anticipate upcoming failures three hours in advance while improving the average relative precision and recall for 21% and 19% accordingly. We evaluated our methodology on real-world memory failures from the server fleet of a large cloud provider, justifying its validity and practicality.",Yes,"논문은 머신러닝 방법을 활용하여 메모리 실패를 예측하는 모델을 개발하고, 이를 평가하기 위해 정량적 지표(정확도, 정밀도, 재현율 등)를 사용하여 성능을 측정하고 있습니다. 따라서, 정량적 평가를 실시하고 있다고 판단됩니다."
Admission control with online algorithms in SDN,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7502884,"By offloading the control plane to powerful computing platforms running on commodity hardware, Software Defined Networking (SDN) unleashes the potential to operate computation intensive machine learning tools and solve complex optimization problems in a centralized fashion. This paper studies such an opportunity under the framework of the centralized SDN Admission Control (AC) problem. We first review and adapt some of the key AC algorithms from the literature, and evaluate their performance under realistic settings. We then propose to take a step further and build an AC meta-algorithm that is able to track the best AC algorithm under unknown traffic conditions. To this aim, we exploit a machine learning technique called Strategic Expert meta-Algorithm (SEA).",Yes,"논문 초록에서 다양한 AC 알고리즘의 성능 평가를 언급하며, 실험적 또는 시뮬레이션을 통한 정량적 평가를 수행했음을 시사합니다. 또한, 제안하는 메타-알고리즘의 성능 추적을 위해 정량적 평가가 필요하므로, 정량적 평가를 실시하는 것으로 판단됩니다."
Day-ahead forecasting of regional photovoltaic production using deep learning,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9300538,"Power production based on solar energy is directly related to the state of the atmosphere. As the atmospheric state is undergone, this connection makes the solar energy a non-dispatchable source as opposed to controllable renewable sources such as hydroelectricity. In a context of growing photovoltaic generation, accurate forecast tools at regional scale are then increasingly important to grid operators. Indeed, forecasts allow getting information about future production over the next minutes, hours and days. Forecasting tools offer the possibility of a better grid management strategy specifically for transmission system operator (TSO) that are responsible for balancing renewable power production. High forecast accuracy could also lead to reduced costs for energy trading. In light of this situation, this study focuses on the development and analysis of a regional forecasting tool based on a deep learning approach. The selected model consists in a combination of a convolutional neural network (CNN) with a long short-term memory architecture (LSTM). The CNN layers allow extracting spatial features from Numerical Weather Prediction outputs while the LSTM part supports the temporal relationship. The day ahead regional forecast for Germany is chosen as a case study. The CNN-LSTM is compared to the classical Random Forest model known to be one of the reference techniques for this kind of problematic. Simpler deep learning models are also tested to validate the improvement brought by the CNN-LSTM architecture. All the comparisons are based on the classical root mean squared error (RMSE) metrics. The main result of this study shows that CNN-LSTM model can improve forecast accuracy when compared to state-of-the-art Random Forest. As expected, this improvement is strongly correlated to the amount of historical data which must cover several years according to the sensitivity study realized in this work.",Yes,논문 초록에서 RMSE (root mean squared error)와 같은 정량적 평가 지표를 사용하여 CNN-LSTM 모델의 예측 성능을 비교하고 있음을 명확히 언급하고 있습니다. 이는 정량적 평가를 실시하고 있음을 보여줍니다.
Modeling Machine Learning to Solve Distribution Problems and the Number of Backlogs in Maintenance,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10406640,"The purpose of this research is the need to reduce backlogs and distribution for technician problems in the maintenance process. The distribution of work to technicians for maintenance will be effective in meeting the goals of the maintenance system of the University of the Thai Chamber of Commerce to be more efficient while reducing delays in maintenance by implementing Machine Learning (ML) using the form Support Vector Machine (SVM), while research is developed on the application UTCC-CMMS is able to work more comprehensively by allowing the application to act as a staff. The work related to maintenance can receive maintenance requests on the algorithm VSM to suitable technicians. and evaluate the performance as well. Also, contact purchasing or support external technicians in maintenance, resulting in faster maintenance there is a lot of backlog work reduced than before, allowing the technician and everyone to work together as well. The evaluation of operations in the past found that it received a score of 2.44. After the adoption of ML, it was found that the score was 4.44, representing an increase of 81.96%.",Yes,"논문 초록에서 머신러닝 기법인 Support Vector Machine (SVM)을 활용하여 작업 배분과 성능 평가를 수행했다고 명시되어 있으며, 성과 평가 점수의 변화도 제시되어 있어 정량적 평가가 실시되고 있음을 알 수 있습니다."
Sentiment Analysis of Social Media Data using Fuzzy-Rough Set Classifier for the Prediction of the Presidential Election,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9754173,"As an interdisciplinary research field, sentiment analysis is one of the momentous applications in Natural Language Processing, for quantifying the emotional value in vast data in the form of text available in social media networks to gain an understanding of the attitudes, opinions, and emotions expressed. There is a great deal of literature on the various approaches to address sentiment analysis with social media and this research focuses on Machine Learning techniques with Twitter data analysis. Special attention is drawn towards the classifiers based on the Fuzzy Set and Rough Set approach which are two powerful mathematical components of computational intelligence with its new dimension involved in the field of sentiment analysis. However, there is a minimal number of review papers discussing rough-fuzzy classifier involvement in sentiment analysis and there is a plethora of work that must be done with text mining in natural language processing. The mission of this study is to develop a sentiment-based classifier using machine learning and fuzzy-rough set theory. Further, it carries automatic sentiment classification with Twitter corpus collected during September 1st and November 15th, 2019 (two months before the election) regarding the case study for the prediction of results at the presidential election 2019, Sri Lanka. The fuzzy rough classifier is developed using the Fuzzy Rough Nearest Neighbor algorithm. The accuracy of the fuzzy rough set-based classifier is higher compared to other classifiers. The actual results of the presidential election of 2019 are tally with the predicted results of the classifier. Therefore, the current state of the art for the prediction of political sentiment with microblogging is probable with the social media data as witnessed with this case study and this can be used in other cases as well.",Yes,"논문 초록에서 ""accuracy of the fuzzy rough set-based classifier is higher""라는 표현을 통해 정량적 평가가 수행되었음을 알 수 있습니다. 또한, 실제 선거 결과와 예측 결과를 비교하는 내용이 있어 성능 평가가 이루어진 것으로 보입니다."
Anamoly Detection in Very Large Scale System using Big Data,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10059870,"Big data refers to a term that is used to describe vast amounts of data that have multiple kinds of Vs: velocity, variety, and volume. It could be semi-structured, unstructured, or even structured, making data analysis difficult. New architecture, methodologies, algorithms, and analytics are needed to extract hidden data and identify assaults on enormous amounts of data. It is quite challenging to identify assaults using conventional methods. This study provides a thorough analysis of malware detection in several sectors using deep learning and provides an overview of deep learning data. In networked computers, there have been more attacks. To protect a network, a strong intrusion detection system (IDS) is necessary. Reviewing the literature reveals that while some research has been conducted in this area, a thorough and in-depth investigation has not yet been carried out. For unanticipated and unpredictable assaults, many academics suggested an IDS employing deep learning, but not for big data. The present research design is based on three ensemble methods, Randam Forest, Decision tree regression, and Gradient Boosting Tree, as well as a deep learning-based intrusion detection system for large datasets named RNN that runs for 1,000 epochs with a learning rate complexity and diversity [0.01-0.5]. It is employed in the creation of the hybrid, safe, and scalable, which is based on big data and deep learning methods. In comparison to using just one classifier, the suggested classifiers provide a more accurate classification. Detection rate (99 percentage), false positive rate (1.5 percent), accuracy (99 percentage), and F-Measure (99.03%) are the experimental results. The results show that new anomaly detection methods work better in the big data context.",Yes,"논문은 대규모 데이터셋을 대상으로 하는 이상 탐지 방법을 제안하며, 실험 결과를 통해 성능 평가를 수행하고 있습니다. 이는 정량적 평가를 실시하고 있음을 보여줍니다."
Data Poisoning Attacks on Federated Machine Learning,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9618642,"Federated machine learning which enables resource-constrained node devices (e.g., Internet of Things (IoT) devices and smartphones) to establish a knowledge-shared model while keeping the raw data local, could provide privacy preservation, and economic benefit by designing an effective communication protocol. However, this communication protocol can be adopted by attackers to launch data poisoning attacks for different nodes, which has been shown as a big threat to most machine learning models. Therefore, we in this article intend to study the model vulnerability of federated machine learning, and even on IoT systems. To be specific, we here attempt to attacking a popular federated multitask learning framework, which uses a general multitask learning framework to handle statistical challenges in the federated learning setting. The problem of calculating optimal poisoning attacks on federated multitask learning is formulated as a bilevel program, which is adaptive to the arbitrary selection of target nodes and source attacking nodes. We then propose a novel systems-aware optimization method, called as attack on federated learning (AT2FL), to efficiently derive the implicit gradients for poisoned data, and further attain optimal attack strategies in the federated machine learning. This is an earlier work, to our knowledge, that explores attacking federated machine learning via data poisoning. Finally, experiments on several real-world data sets demonstrate that when the attackers directly poison the target nodes or indirectly poison the related nodes via using the communication protocol, the federated multitask learning model is sensitive to both poisoning attacks.",Yes,"논문 초록에서 정량적 평가를 위해 최적의 공격 전략을 수학적 최적화 문제로 공식화하고, 실험을 통해 공격 효과를 검증하는 내용을 포함하고 있습니다. 이는 정량적 평가를 실시하고 있음을 시사합니다."
An Empirical Performance Evaluation of Semantic-Based Similarity Measures in Microblogging Social Media,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8606643,"Measuring textual semantic similarity has been a subject of intense discussion in NLP and AI for many years. A new area of research has emerged that applies semantic similarity measures within Twitter. However, the development of these measures for the semantic analysis of tweets imposes fundamental challenges. The sparsity, ambiguity, and informality present in social media are hampering the performance of traditional textual similarity measures as ""tweets"", have special syntactic and semantic characteristics. This paper reviews and evaluates the performance of topological, statistical, and hybrid similarity measures, in the context of Twitter analysis. Furthermore, the performance of each measure is compared against a naïve keyword-based similarity computation method to assess the significance of semantic computation in capturing the meaning in tweets. An experiment is designed and conducted to evaluate the different measures through examining various metrics, including correlation, error rates, and statistical tests on a benchmark dataset. The potential weaknesses of semantic similarity measures in relation to Twitter applications of textual similarity assessment and the research contributions are discussed. This research highlights challenges and potential improvement areas for the semantic similarity of tweets, a resource for researchers and practitioners.",Yes,"초록에서 ""An experiment is designed and conducted to evaluate the different measures through examining various metrics, including correlation, error rates, and statistical tests""라고 명시되어 있어, 정량적 평가가 수행되고 있음을 알 수 있습니다. 따라서 이 논문은 정량적 평가를 실시하고 있다고 판단됩니다."
Hyperspectral Image Classification Using Random Forest and Deep Learning Algorithms,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9165588,"One of the purposes of hyperspectral remote sensing is to differentiate and identify the materials present on the Earth's surface by the spectral behavior of each object in the different regions of the electromagnetic spectrum. Such differentiation and identification can be accomplished through different image classification algorithms. However, there is no perfect classifier, since every algorithm has labeling errors. With the advent of orbital and aerial images of very high spatial and spectral resolution, the recognition of the materials present in urban environments is increasingly accurate. Thus, we thoroughly study different methodologies to identify the algorithm that presents the best results in the characterization of urban objects. The hyperspectral image used in the present study represents an area over Houston University - Texas and its surroundings, containing 48 spectral bands, with a spatial resolution of 1 meter and spectral range of 380 nm to 1050 nm. For the identification of 21 classes present in the study area, this paper analyzes two different classification methods: Deep Learning and Random Forest. To improve classification accuracy, performed the feature extraction. To obtain such preliminary results we used tools available in specific software as Normalized Difference Vegetation Index (NDVI), Minimum Noise Fraction (MNF), Principal Component Analysis (PCA) and Soil Adjusted Vegetation Index (SAVI). The image segmentation was performed using two different methods known as Multiresolution Segmentation and Spectral difference. Multiresolution segmentation needs parameters related to form and compactness. The best results were obtained with the values of form = 0.7 and compactness = 0.5, besides the scale of 10. From this, samples of all classes contained in the study area were selected for the training of the algorithms. This step is of paramount importance, as sample collection directly impacts the result of the classifications. After performing these steps, the information obtained from sample collection is entered into the data mining software (WEKA 3.8) to train the classification algorithms. The analysis of the results was performed by cross-validation, thus obtained the confusion matrix, calculated the Overall Accuracy (OA) and Kappa Index. The classification by the Random Forest method had an overall accuracy of 84.72% and a Kappa Index of 0.83. In turn, the Deep Learning algorithm had an overall accuracy of 81.32% and a Kappa index of 0.80. In this case, the classification by the Random Forest method presented better results for the hyperspectral image classification than the Deep Learning method. The accuracy difference obtained between the methods is not considered significant, so it is suggested for future work to analyze other complementary issues such as processing time.",Yes,"논문 초록에서 분류 알고리즘의 성능 평가를 위해 교차 검증(cross-validation)과 혼동 행렬(confusion matrix), 전체 정확도(Overall Accuracy), 카파 지수(Kappa Index)를 계산하는 정량적 평가 방법을 사용했다고 명시되어 있습니다. 이는 정량적 평가를 실시하고 있음을 보여줍니다."
Student and Lecturer Performance Enhancement System using Artificial Intelligence,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9315981,"The proposed research work develops a system to enhance the performance of university students and lecturers by providing an excellent statistical insight. Already existing research works have attempted to solve independent classroom challenges that are related to measuring the student attention and marking student attendance but the existing research works have not combined theimportant aspects into one system. Hence, the proposed research wor has been carried out on various main aspects such as attendance register, monitoring student behavior as well as lecturer performance and lecture summarization. The system will incorporate tools and technologies in the different domains of artificial intelligence, machine learning, and natural language processing. After implementing and testing the proposed method it has been concluded that the student activity recognition process has been performed much better than the other emotion and gaze components by providing 94.5% results. The proposed system can determine the lecturer's physical activities and the quality of the lecture content with a reasonable accuracy. The summarized lecture has showed 70% similarity to actual lecture content and student attendance by using Face Recognition was marked with 83% accuracy. This research concludes that the automation of major classroom activities will impact the students and lecturers positively. Also, this system yields valuable results and increases the productivity of higher education institutions in the future.",Yes,"논문 초록에서 학생 활동 인식, 강사 활동, 강의 내용 요약, 출석률 등 다양한 측정 지표에 대한 성과를 평가하는 내용이 포함되어 있어 정량적 평가가 실시되고 있음을 알 수 있습니다. 이러한 평가 결과는 각각의 성능 지표와 정확도를 수치로 제시하고 있습니다."
Towards Sustainable Deep Learning for Wireless Fingerprinting Localization,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9838464,"Location based services, already popular with end users, are now inevitably becoming part of new wireless infrastructures and emerging business processes. The increasingly popular Deep Learning (DL) artificial intelligence methods perform very well in wireless fingerprinting localization based on extensive indoor radio measurement data. However, with the increasing complexity these methods become computationally very intensive and energy hungry, both for their training and subsequent operation. Considering only mobile users, estimated to exceed 7.4 billion by the end of 2025, and assuming that the networks serving these users will need to perform only one localization per user per hour on average, the machine learning models used for the calculation would need to perform 65×1012 predictions per year. Add to this equation tens of billions of other connected devices and applications that rely heavily on more frequent location updates, and it becomes apparent that localization will contribute significantly to carbon emissions unless more energy-efficient models are developed and used. This motivated our work on a new DL-based architecture for indoor localization that is more energy efficient compared to related state-of-the-art approaches while showing only marginal performance degradation. A detailed performance evaluation shows that the proposed model produces only 58% of the carbon footprint while maintaining 98.7% of the overall performance compared to state of the art model external to our group. Additionally, we elaborate on a methodology to calculate the complexity of the DL model and thus the CO2 footprint during its training and operation.",Yes,"논문 초록에서 ""A detailed performance evaluation""과 ""a methodology to calculate the complexity of the DL model""이라는 표현을 통해 정량적 평가가 수행되었음을 알 수 있습니다. 이는 모델의 성능과 탄소 발자국을 수치로 평가하는 정량적 분석이 포함되어 있음을 시사합니다."
A Decision Support System For Retinal Image Defect Detection,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9153446,"Deep learning has become the de facto method for image classification. In this work, a common framework for decision support system is presented that can be reused for diagnosing multiple retinal clinical conditions. Retinal fundus images provide a non-invasive way to diagnose eye-related diseases like glaucoma and diabetic retinopathy (DR). State-of-the-art deep learning methods focus on the detection of key regions of the retina including fundus, optic disc and retinal vessels individually. In order to achieve acceptable precision and recall for a clinically deployable system, a decision support system that combines state-of-the-art deep learning system and relevant explainable features are built. The proposed method is tested on two retinal pathology use cases - glaucoma and for the detection of hard exudates that is critical in diagnosing DR. The proposed model is validated using DRIVE dataset with average Jaccard index of more than 96% for fundus, around 98% for OD and around 90% in identifying retinal vessels using a five-fold cross-validation. For disease detection, the above key regions are combined and validated using standard datasets with good outcomes.",Yes,"논문 초록에서 모델의 성능을 평가하기 위해 Jaccard 지수와 같은 정량적 지표를 사용하여 검증한 내용을 언급하고 있습니다. 또한, 교차 검증과 표준 데이터셋을 활용한 평가 결과를 제시하여 정량적 평가를 실시하고 있음을 알 수 있습니다."
Data Security Patterns for Critical Big Data Systems,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10366149,"With the words' current growth in technologies and digitalization, protecting data in massive data-driven systems has become a new challenge to overcome. Therefore, many measures, algorithms, and protocols are used and still under development to minimize risks of Data loss, manipulation, sniffing, or spying… In order to gain more in terms of security, privacy, and integrity levels. As important as this issue is, combined efforts from different disciplines (Network Security, Security Operations Center Analysis (SOC Analysis), Machine Learning (ML), and Deep Learning (DL) algorithms) are necessary to enhance Data protection. In this paper, we will expose some natural threats of Big Data, based on its definition, ethics, and suggestions to avoid these threats, or at least limit their effects. We will also show works related to big data security based on ML and shed light on Artificial Neural Networks (ANN) applications for data classification and threat detection. Then focus on Convolutional Neural Networks (CNN) to optimize parameters. We will try to find solutions for CNN limitations of hyperparameters tuning and rotating image feature extraction. Furthermore, we will discuss state of art results to understand the matter in a deeper sense and expose high-accuracy solutions with improvement path suggestions. Our work is going to come up with some natural threats, compare some existing methods, expose, and discuss results, and then suggest optimal ways to help increase data security, especially through improving CNN limitations.",Yes,"논문 초록에서 데이터 보안과 관련된 자연적 위협, 기존 방법 비교, 그리고 CNN의 한계 개선 방안 등을 다루며, 정량적 평가와 성능 향상 방안을 제시하는 내용이 포함되어 있어 정량적 평가를 실시하고 있다고 판단됩니다."
Computer-aided quality control of radiological systems,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=744753,"The problem of quality control of radiological systems is discussed in relation to the management and quantitative tools normally applied to it. An alternative approach is to consider the problem in terms of a control loop in which the sets of quality control measurements are compared with their previous values in the context of a numerical model of the system to produce quantitative corrections. A preliminary study of the method applied to mammographic quality control is discussed. By modelling the system with an appropriate set of simultaneous linear equations relating changes in the controlled parameters to the quality control measurements obtained, it is possible to identify quantitative changes in the controlled parameters from measured quality control data using the inverse of the model in matrix form. This method essentially encapsulates knowledge about the system in the form of the linear model. This is distinct from current work attempting to apply artificial intelligence knowledge-based techniques to the problem.",Yes,"논문 초록에서 시스템의 품질 관리를 위해 정량적 도구와 수치 모델을 활용하는 방법을 제시하고 있으며, 측정값과 이전 값의 비교를 통해 정량적 수정을 수행하는 방식을 설명하고 있습니다. 이러한 내용은 정량적 평가를 실시하는 것을 명확히 보여줍니다."
Traffic Light Recognition Using Deep Learning and Prior Maps for Autonomous Cars,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8851927,"Autonomous terrestrial vehicles must be capable of perceiving traffic lights and recognizing their current states to share the streets with human drivers. Most of the time, human drivers can easily identify the relevant traffic lights. To deal with this issue, a common solution for autonomous cars is to integrate recognition with prior maps. However, additional solution is required for the detection and recognition of the traffic light. Deep learning techniques have showed great performance and power of generalization including traffic related problems. Motivated by the advances in deep learning, some recent works leveraged some state-of-the-art deep detectors to locate (and further recognize) traffic lights from 2D camera images. However, none of them combine the power of the deep learning-based detectors with prior maps to recognize the state of the relevant traffic lights. Based on that, this work proposes to integrate the power of deep learning-based detection with the prior maps used by our car platform IARA (acronym for Intelligent Autonomous Robotic Automobile) to recognize the relevant traffic lights of predefined routes. The process is divided in two phases: an offline phase for map construction and traffic lights annotation; and an online phase for traffic light recognition and identification of the relevant ones. The proposed system was evaluated on five test cases (routes) in the city of Vitória, each case being composed of a video sequence and a prior map with the relevant traffic lights for the route. Results showed that the proposed technique is able to correctly identify the relevant traffic light along the trajectory.",No,"논문 초록에서는 딥러닝 기반의 교통 신호등 검출 및 인식을 제안하고 있으나, 정량적 평가에 대한 구체적인 언급이 없습니다. 따라서, 정량적 평가를 실시했는지 여부를 확실히 알 수 없습니다."
Anti-Corrosion Capacity Validation for Anti-Sulfur Type Electronic Passive Components by Way of Various Flower-of-Sulfur (FoS) Methodologies,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9696582,"Hardware reliability of Information Technology (IT) equipment can be easily affected by corrosive gases, moisture, contaminants and particulate matter. It can potentially cause electrical open failures due to sulfur corrosion (Ag2S) on the inner electrode of electronic passive components. In order to improve the robustness against sulfur corrosion, many vendors adopted gold-based and silver-palladium-based inner electrode designs (noble metal) as well as other solutions, including passivation cover and reverse structure designs. New IT equipment applications, including Artificial Intelligence (AI), Big Data, 5G, Internet of Things (IoT) and Edge Computing in recent years has proliferated the need of passive electronic components and the industry is facing passive component shortage. Therefore, quality control is becoming more critical in reducing poor quality risk. Flowers of Sulfur (FoS) is a popular method to validate the anti-sulfur corrosion capability of electronic passive components. However, the condition of single corrosive gas (sulfur vapor) is not enough to represent the accelerated corrosion exposure in field environments. It has been stipulated that typical testing methods as outlined in ASTM B809 and EIA-977 may not be totally effective in driving Anti-Sulfur Resistor (ASR) failure occurrence at 105°C/750 hours (test to pass), or even longer duration. Despite testing at those conditions, end-customers have reported sulfur corrosion-related failures. Therefore, it is necessary to develop an effective accelerated method for anti-sulfur corrosion capacity validation for anti-sulfur type electronic passive components. In this paper, three conditions of FoS test were carried out to validate the anti-sulfur corrosion capability of ASR components. We introduced chlorine-gas as another acceleration factor, and benchmarked it against ASTM B809 and EIA-977 FoS tests. Several analytical methods were used in this work, including, high resolution 3D X-Ray Microscope (3D X-Ray), Cross section polisher, (CP), Plasma Focused Ion Beam, (PFIB), Scanning Electron Microscopy (SEM) and Energy-Dispersive X-ray spectroscopy (EDX). Finally, we found that FoS with chlorine-gas condition is the most aggressive of all conditions.",Yes,"논문 초록에서 여러 분석 방법(고해상도 3D X-Ray Microscope, Cross section polisher, Plasma Focused Ion Beam, SEM, EDX)을 사용하여 정량적 평가를 실시하고 있음을 명확히 언급하고 있습니다. 이러한 분석 기법들은 실험 데이터의 정량적 측정을 가능하게 하며, 연구의 평가와 검증에 활용됩니다."
Unsupervised Domain Adaptation via Subspace Interpolating Deep Dictionary Learning: A Case Study in Machine Inspection,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10094819,"With the advent of industry 4.0, data-driven techniques have gained a lot of popularity for machine condition monitoring, ensuring reliable and safe operation of the machines. In most practical application scenarios, domain discrepancy may arise between the training (source domain) and test (target domain) data due to various factors like changes in the operating conditions, different sensor locations, etc. Traditional data-driven techniques fail to address this domain shift, and hence domain adaptation techniques are required to ensure reliable performance. This work presents an unsupervised domain adaptation method where labeled data is available only in the source domain via subspace interpolation using deep dictionary learning. Deep dictionaries learn rich representations from the data and hence are used for subspace interpolation to capture the domain shift and form a shared feature space for cross-domain analysis. The proposed method is evaluated for the challenging scenario of adaptation between different but related machines. Experimental results obtained with two publicly available bearing fault datasets are promising; the proposed method significantly outperforms all the state-of-the-art methods.",Yes,"논문 초록에서 ""Experimental results""라는 표현을 통해 실험을 수행하여 평가를 진행했음을 알 수 있습니다. 또한, 제안된 방법의 성능을 비교하는 과정이 포함되어 있어 정량적 평가가 실시된 것으로 판단됩니다."
Multi-Lingual Information Retrieval Using Deep Learning,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8493789,"The task of finding data files related to an information need from a group of information resources is known as Information Retrieval. In this work, the author propose a multi-lingual information retrieval system using deep learning. Input to the system is a question in sentencing form that can be processed by NLP tools. In the preprocessing phase, part-of-speech tagging of the input sentence is performed. A three layer neural network is used for creating word to vector representation. The word2vec model continuous-bag-of-words (CBOW) is used for this purpose. Then related words are obtained via word-2-vec using deep learning RNN. RNN is the recurrent neural network. Finally, results are obtained by calculating the cosine similarity score. For multi-lingual results, bilingual mapping is performed using CFILTs bilingual corpus. The tourism dataset is used for experimentation purposes.",Yes,"논문은 정량적 평가를 위해 코사인 유사도 점수 계산과 같은 수치 기반의 평가 방법을 사용하고 있으며, 실험을 통해 성능을 검증하는 과정을 포함하고 있습니다. 이러한 내용은 정량적 평가를 실시하고 있음을 보여줍니다."
Pollen Grains Classification with a Deep Learning System GPU-Trained,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9662170,"Traditional approaches to automatic classification of pollen grains consisted of classifiers working with feature extractors designed by experts, which modeled pollen grains aspects of special importance for biologists. Recently, a Deep Learning (DL) algorithm called Convolutional Neural Network (CNN) has shown a great improvement in performance in many computer vision tasks such as classification, due to this great performance the computational requirements have increased considerably; therefore, it is advisable to use new platforms such as the Graphics Processing Unit (GPU), which offer large computational resources for the development of new systems with CNN. This paper presents the GPU-Trained implementation of a DL system with the CNN algorithm, proposing a CNN model capable of running on a GPU in real-time for the automatic classification of 19 different pollen grains belonging to 14 different families, which are found in high concentrations in Mexico, and which are large interest in areas such as beekeeping, paleoecology, botany, allergology, agriculture among others. These areas seek to improve the collection of palynological data in terms of time and accuracy. In order to evaluate our model, evaluation tests were performed in the NVIDIA Jetson TX2 Developer Kit GPU. Experimental results achieves around 90% in CCR and Sensitivity in the proposed model. Additionally, the proposed model works at a processing speed of 6,826 Frames Per Second (FPS) and has approximately 50% fewer parameters than reported in related works.",Yes,"논문 초록에서 ""evaluation tests were performed""라는 표현을 통해 정량적 평가가 실시되었음을 명확히 하고 있습니다. 또한, CCR, Sensitivity, FPS 등 구체적인 수치로 성능을 평가한 내용을 포함하고 있어 정량적 평가가 이루어졌음을 알 수 있습니다."
Research on several major diseases based on machine learning models,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9948344,"Due to the continuous growth of disease types and past cases, it is more and more difficult to diagnose diseases only by manpower. Machine learning is a model mechanism that is sensitive to data and relies on a large amount of data to complete training. It is very suitable for medical diagnosis. Many scholars have tried to use ML to develop medical diagnosis systems, but they are basically not used in the real world at this stage. This article reviews the work related to medical detection of three major diseases (heart disease, cancer, and COVID-19), aiming to summarize previous experiences to help future scholars conduct research. Specifically, this paper summarizes the research status of the prediction of these three types of diseases based on machine learning methods, evaluate the accuracy and universality of the corresponding prediction models based on time as a clue, and use a comparative method to find out the progress researchers have made in this area and limitations still exist at this stage. And at the end of the article, the results and some potential work fields of the future in these studies are summarized.",Yes,"초록에서 연구들이 머신러닝 모델의 예측 정확도와 보편성을 평가하는 내용을 포함하고 있으며, 이를 통해 정량적 평가가 수행되고 있음을 알 수 있습니다. 따라서, 논문은 정량적 평가를 실시하고 있다고 판단됩니다."
Predicting Board Performance Using Classification Algorithms and Time Series Analysis,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10636861,"Higher Education Institutions are increasingly recognizing the value of Educational Data Mining (EDM), a method that collects and analyzes educational data. EDM can employ machine learning techniques to assess and predict students’ academic outcomes. This paper aims to apply EDM, integrating time series analysis and classification algorithms, to assist a university in the Philippines in improving its students’ performance on the Licensure Examination for Teachers. The study involved an in-depth literature reviews and applied feature selection techniques to determine the significance of specific attributes. Subsequently, a comparative analysis was undertaken among three classification algorithms to ascertain the most accurate model in predicting student’s examination performance. Various validation metrics were used to validate the results. Finally, the most optimal model was selected and integrated into the system. Moreover, the Rapid Application Development (RAD) model was employed to develop the “Board Prophet” system, which offers various functionalities. These includes an online dashboard for accessing historical data, time series analysis capabilities for predicting the university’s board performance, individual predictions of a students’ success or failure in the licensure examination, and proposed intervention plans based on the system’s predictions. Furthermore, the study’s findings revealed that the student’s General Weighted Average and Review Center were the two most significant attributes, with Decision tree outperforming other classification algorithms. The system features were assessed using ISO/IEC 25010 standards and the Technology Acceptance Model (TAM), with users showing high acceptance. These findings will empower the university make better decisions that will improve their students’ licensure examination performance.",Yes,"논문 초록에서 다양한 검증 지표를 사용하여 모델의 성능을 평가했다고 명시되어 있으며, 정량적 평가를 통해 최적의 분류 알고리즘을 선정하는 과정을 수행했다고 언급하고 있습니다. 따라서, 논문은 정량적 평가를 실시하고 있다고 판단됩니다."
Private Synthetic Data Generation for Mixed Type Datasets,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10825249,"In the face of escalating threats from privacy attacks on machine learning models, we propose a system that can artificially generate data that imitates real data but doesn’t contain any sensitive or personally identifiable information. The generated data, called synthetic data, will have the same semantic and statistical distribution as the original dataset but provide privacy guarantees. Compared to previous works that dealt with either structured or unstructured data separately, our work develops a complete hybrid pipeline for generating private synthetic datasets from complex datasets that consist of both structured (numerical or categorical) and unstructured data. The private synthetic data generated can be analyzed by collaborators and third parties without increasing the risks of leakage of sensitive data. We evaluate our system on Yelp reviews and drug side-effects datasets and calculate metrics for both quality and privacy. We introduce a context-aware exposure metric to quantify context-dependent memorization and use it along with exposure to evaluate privacy. Our evaluations demonstrate that our system generates meaningful private synthetic datasets that achieve good performance in characteristic similarity, utility, as well as privacy. Given these results, the generated synthetic data can be used by data scientists, researchers, and developers to address challenges related to data privacy, scarcity, diversity, and model testing in a wide range of applications including healthcare, insurance, and financial systems that rely on sensitive data.",Yes,"논문 초록에서 데이터의 품질과 프라이버시를 평가하기 위해 다양한 지표와 메트릭을 도입했다고 명시되어 있습니다. 특히, 특성 유사성, 유용성, 프라이버시를 평가하는 정량적 평가 방법이 언급되어 있어, 정량적 평가를 실시하고 있음을 알 수 있습니다."
Mining unstructured log files for recurrent fault diagnosis,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5990536,"Enterprise software systems are large and complex with limited support for automated root-cause analysis. Avoiding system downtime and loss of revenue dictates a fast and efficient root-cause analysis process. Operator practice and academic research have shown that about 80% of failures in such systems have recurrent causes; therefore, significant efficiency gains can be achieved by automating their identification. In this paper, we present a novel approach to modelling features of log files. This model offers a compact representation of log data that can be efficiently extracted from large amounts of monitoring data. We also use decision-tree classifiers to learn and classify symptoms of recurrent faults. This representation enables automated fault matching and, in addition, enables human investigators to understand manifestations of failure easily. Our model does not require any access to application source code, a specification of log messages, or deep application knowledge. We evaluate our proposal using fault-injection experiments against other proposals in the field. First, we show that the features needed for symptom definition can be extracted more efficiently than does related work. Second, we show that these features enable an accurate classification of recurrent faults using only standard machine learning techniques. This enables us to identify accurately up to 78% of the faults in our evaluation data set.",Yes,"논문 초록에서 decision-tree classifiers와 같은 기계 학습 기법을 사용하여 recurrent faults를 분류하는 과정을 언급하며, 이를 통해 정량적 평가가 이루어지고 있음을 알 수 있습니다. 또한, fault-injection 실험을 통해 성능을 평가하는 내용이 포함되어 있어 정량적 평가가 실시되고 있음을 확인할 수 있습니다."
A New Sentiment Analysis based Application for Analyzing Reviews of Web Series and Movies of Different Genres,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9058137,"This research paper proposes an application of sentiment analysis that works on the principle of machine learning. The proposed application provides a comparative analysis of web series and movies of different genres of a particular time period on the basis of sentiments of the viewers. Data is fetched from twitter through API keys and twitter access tokens. The movies and web series from the year 2017 to 2019 of four different genres were taken and sentiment analysis was performed on each web series and movie, which gives result in the form of positive reviews and negative reviews. The famous hashtag for each movie and web series are determined. The total number of tweet counts is 3000. A Table of each genre was formed that contained the name of movie and web series, percentage of positive sentiments of corresponding web series or movie and percentage of negative sentiments of corresponding movie or web series. The graphical representation of each genre was done to analyze the results graphically. The combined analysis was performed after calculating the average percentage reviews of a positive and negative sentiment of all the movies and web series of each genre. The graphical representation of the combined analysis is done to analyze the final results. Through the proposed application results were analyzed concluding that whether movies or web series of a particular genre in the year 2017-19 were more liked by the viewers.",Yes,"논문 초록에서 감성 분석을 통해 긍정 및 부정 리뷰의 비율을 정량적으로 계산하고, 각 장르별 평균 긍정 및 부정 비율을 도출하는 등 정량적 평가를 수행한 내용을 명확히 언급하고 있습니다. 또한, 그래프와 표를 활용하여 결과를 수치적으로 분석하는 과정이 포함되어 있어 정량적 평가가 이루어지고 있음을 알 수 있습니다."
Reinforcement learning with space carving for plant scanning,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10350600,"Optimal plant reconstruction is an essential element in automating our future agriculture. Computerized inspection of proper growth, nutrition, or pest infestation has become mandatory in fully autonomous in-door or micro-farm settings, shifting from fixed to moving camera systems. In industrial environments, plant scanning must work efficiently with a limited number of significant images to become economically viable. We present an adaptive learning algorithm for agricultural plant inspection robots, in particular, a specific type of reinforcement learning that we developed for our micro-farming platform created within the EU project ROMI. We suggest a new approach to 3D plant reconstruction by integrating the space carving technique with categorical Deep Q-Networks. Space carving leverages images captured from various positions to create a binary voxel grid, representing the occupied and unoccupied spaces of the scanned object. The proposed method incorporates partial 3D reconstructions of plants obtained through space carving, which get compared to a ground truth model to calculate the reward and guide scanning policies. We explain the algorithmic details and the 3D reconstruction technique in design, implementation, and evaluation. Experimental results confirm our approach’s effectiveness in improving the 3D plant reconstruction process, highlighting its potential for further applications in agriculture and related fields.",Yes,"논문 초록에서 제안하는 방법이 공간 조각 기술과 딥 Q-네트워크를 활용하여 3D 식물 재구성을 수행하며, 이 과정에서 정량적 평가를 위해 재구성 결과를 ground truth와 비교하여 성능을 측정하는 것으로 보입니다. 따라서, 정량적 평가를 실시하고 있다고 판단됩니다."
Evaluating Explainable AI Methods in Deep Learning Models for Early Detection of Cerebral Palsy,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10820328,"Early detection of Cerebral Palsy (CP) is crucial for effective intervention and monitoring. This paper tests the reliability and applicability of Explainable AI (XAI) methods using a deep learning method that predicts CP by analyzing skeletal data extracted from video recordings of infant movements. Specifically, we use XAI evaluation metrics — namely faithfulness and stability — to quantitatively assess the reliability of Class Activation Mapping (CAM) and Gradient-weighted Class Activation Mapping (GradCAM) in this specific medical application. We utilize a unique dataset of infant movements and apply skeleton data perturbations without distorting the original dynamics of the infant movements. Our CP prediction model utilizes an ensemble approach, so we evaluate the XAI metrics performances for both the overall ensemble and the individual models. Our findings indicate that both XAI methods effectively identify key body points influencing CP predictions and that the explanations are robust against minor data perturbations. Grad-CAM significantly outperforms CAM in the Relative Input Stability velocity (RISv) metric, which measures stability in terms of velocity. In contrast, CAM performs better in the Relative Input Stability bone (RISb) metric, which relates to bone stability, and the Relative Representation Stability (RRS) metric, which assesses internal representation robustness. Individual models within the ensemble show varied results, and neither CAM nor Grad-CAM consistently outperform the other, with the ensemble approach providing a representation of outcomes from its constituent models. Both CAM and Grad-CAM also perform significantly better than random attribution, supporting the robustness of these XAI methods. Our work demonstrates that XAI methods can offer reliable and stable explanations for CP prediction models. Future studies should further investigate how the explanations can enhance our understanding of specific movement patterns characterizing healthy and pathological development.",Yes,"논문은 XAI 평가 지표인 신뢰성(faithfulness)과 안정성(stability)을 사용하여 정량적 평가를 수행하고 있습니다. 또한, 다양한 정량적 지표를 통해 XAI 방법의 성능을 수치로 비교 분석하고 있어 정량적 평가를 실시하고 있음을 알 수 있습니다."
An Amalgamated Testability Measure Derived from Machine Intelligence,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10483429,"A testability measure provides test-related information about signal nodes of a circuit. Operations like test generation and test point insertion are exponentially complex in terms of the circuit size. Therefore, to be useful testability measure computation is kept linear, which makes the measures like controllabilities and observabilities, approximate. Well-known testability measures like SCOAP (Sandia controllability/observability analysis program) or COP (controllability and observability program) have played important roles in algorithms for test generation, test point insertion, and other test-related functions. Even the quantities such as distances of a node to primary input and output have been used as simple measures. Years of experience have shown that no single measure works for all situations – in test generation SCOAP may work best for one fault, while COP or distance do better for other faults in the same circuit. This study amalgamates all three measures mentioned here using the principal component analysis (PCA), an unsupervised machine learning procedure. This amalgamated measure, when used by a test generation program produced unexpected benefits. First, the measure reduced the test generation program backtracks for hard-to-detect faults below those by any single testability measure; the number of backtracks is a direct indicator of computing effort. Second, the backtracks reduced to 0 for several faults. This study tries to prove the efficacy of amalgamation by running categorical experiments, namely, testability analysis accuracy, ATPG improvements, and faults classification. In the continuing investigation, we plan to combine more testability measures into PCA. We will also investigate applications like test-point insertion and other test related functions in the future.",Yes,"논문 초록에서 PCA(주성분 분석)를 이용하여 여러 정량적 테스트 가능성 지표를 결합하는 방법을 제시하고 있으며, 이를 통해 테스트 생성의 효율성을 향상시키는 실험 결과를 언급하고 있습니다. 따라서 정량적 평가를 실시하고 있다고 판단됩니다."
ChartWalk: Navigating large collections of text notes in electronic health records for clinical chart review,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9904479,"Before seeing a patient for the first time, healthcare workers will typically conduct a comprehensive clinical chart review of the patient's electronic health record (EHR). Within the diverse documentation pieces included there, text notes are among the most important and thoroughly perused segments for this task; and yet they are among the least supported medium in terms of content navigation and overview. In this work, we delve deeper into the task of clinical chart review from a data visualization perspective and propose a hybrid graphics+text approach via ChartWalk, an interactive tool to support the review of text notes in EHRs. We report on our iterative design process grounded in input provided by a diverse range of healthcare professionals, with steps including: (a) initial requirements distilled from interviews and the literature, (b) an interim evaluation to validate design decisions, and (c) a task-based qualitative evaluation of our final design. We contribute lessons learned to better support the design of tools not only for clinical chart reviews but also other healthcare-related tasks around medical text analysis.",No,"논문 초록에서는 정량적 평가에 대한 언급이 없으며, 주로 사용자 인터페이스와 디자인 프로세스, 정성적 평가에 초점을 맞추고 있다. 따라서, 이 연구는 정량적 평가를 실시하고 있다고 보기 어렵다."
Integration of robust 3D modeling software into the design curriculum,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=841663,"Engineering technology design curriculum is compartmentalized, and the students are not ready for contribution to the design team. This allegation is partly true, as there is no effective means of student integration of design concept into an indusrially sound application, using an industrially robust three dimensional design and manufacturing package. This paper studies the effectiveness of an Engineering Technology Program-Design concentration, via the traditional emphasis without an industrially capable integrated CAD/CAM software. The program effectiveness is evaluated by outcome based program evaluation and review technique. Next the program is studied along a different stream with the integration of a capable and robust 3D CAD/CAM/analysis software package. The same criteria of program effectiveness is used to compare the achievement and performance of the program. This is an evaluative study of efforts to integrate the design curriculum with a comprehensive unifying design software. Twenty final year students in a capstone Machine and Tool Design course used the robust design software. At the culmination of the course they were asked about their design skill experience and the effectiveness of the course. The survey revealed that student learning and professional design development was enhanced with the use of an effective CAD/CAM integration tool that enabled students to synthesize design problems which were challenging and practical. The result of this research is crucial to the ABET-2000 outcome based evaluation criteria and its implementation.",Yes,"논문 초록에서 프로그램의 효과를 평가하기 위해 outcome-based program evaluation and review technique를 사용했다고 명시되어 있으며, 학생들의 설문조사를 통해 학습 경험과 설계 능력 향상 여부를 정량적으로 평가한 것으로 보입니다. 따라서, 정량적 평가를 실시하고 있다고 판단됩니다."
Advancing Solar Energy: Machine Learning Approaches for Predicting Photovoltaic Power Output,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10604373,"This research is primarily concentrated on predicting the output of photovoitaic power, an essential field in the study of renewable energy. The paper comprehensively reviews various forecasting methodologies, transitioning from conventional physical and statistical methods to advanced machine learning (ML) techniques. A significant shift has been observed from traditional point forecasting to machine learning-based forecasting in solar power. This transition offers a broader and more detailed perspective for power system operators. The core of this research lies in applying and comparing three distinct Machine Learning algorithms for forecasting photovoltaic power output. The primary aim is to evaluate each method's accuracy and to identify the algorithm with the lowest prediction error. This comparative analysis is crucial for determining the most effective machine learning forecasting method, significantly contributing to the more reliable and efficient integration of renewable energy into power systems.",Yes,논문 초록에서 세 가지 머신러닝 알고리즘을 적용하고 그 예측 정확도를 평가하는 비교 분석을 수행했다고 명시되어 있습니다. 이는 정량적 평가가 이루어지고 있음을 보여주는 명확한 증거입니다.
Ensemble Image Explainable AI (XAI) Algorithm for Severe Community-Acquired Pneumonia and COVID-19 Respiratory Infections,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9721585,"Since the onset of the COVID-19 pandemic in 2019, many clinical prognostic scoring tools have been proposed or developed to aid clinicians in the disposition and severity assessment of pneumonia. However, there is limited work that focuses on explaining techniques that are best suited for clinicians in their decision making. In this article, we present a new image explainability method named ensemble AI explainability (XAI), which is based on the SHAP and Grad-CAM++ methods. It provides a visual explanation for a deep learning prognostic model that predicts the mortality risk of community-acquired pneumonia and COVID-19 respiratory infected patients. In addition, we surveyed the existing literature and compiled prevailing quantitative and qualitative metrics to systematically review the efficacy of ensemble XAI, and to make comparisons with several state-of-the-art explainability methods (LIME, SHAP, saliency map, Grad-CAM, Grad-CAM++). Our quantitative experimental results have shown that ensemble XAI has a comparable absence impact (decision impact: 0.72, confident impact: 0.24). Our qualitative experiment, in which a panel of three radiologists were involved to evaluate the degree of concordance and trust in the algorithms, has showed that ensemble XAI has localization effectiveness (mean set accordance precision: 0.52, mean set accordance recall: 0.57, mean set FF1: 0.50, mean set IOU: 0.36) and is the most trusted method by the panel of radiologists (mean vote: 70.2%). Finally, the deep learning interpretation dashboard used for the radiologist panel voting will be made available to the community. Our code is available at https://github.com/IHIS-HealthInsights/Interpretation-Methods-Voting-dashboard.",Yes,"논문은 정량적 평가를 위해 여러 지표(예: decision impact, confident impact, localization accuracy 등)를 사용하여 실험 결과를 제시하고 있으며, 이를 통해 제안된 방법의 성능을 수치로 평가하고 있음을 보여줍니다. 또한, 다양한 정량적 지표와 실험 결과를 통해 방법의 효과를 체계적으로 검증하고 있습니다."
Green AI Quotient: Assessing Greenness of AI-based software and the way forward,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10298412,"As the world takes cognizance of AI's growing role in greenhouse gas(GHG) and carbon emissions, the focus of AI research & development is shifting towards inclusion of energy efficiency as another core metric. Sustainability, a core agenda for most organizations, is also being viewed as a core non-functional requirement in software engineering. A similar effort is being undertaken to extend sustainability principles to AI-based systems with focus on energy efficient training and inference techniques. But an important question arises, does there even exist any metrics or methods which can quantify adoption of “green” practices in the life cycle of AI-based systems? There is a huge gap which exists between the growing research corpus related to sustainable practices in AI research and its adoption at an industry scale. The goal of this work is to introduce a methodology and novel metric for assessing “greenness” of any AI-based system and its development process, based on energy efficient AI research and practices. The novel metric, termed as Green AI Quotient, would be a key step towards AI practitioner's Green AI journey. Empirical validation of our approach suggest that Green AI Quotient is able to encourage adoption and raise awareness regarding sustainable practices in AI lifecycle.",Yes,"논문 초록에서 ""Green AI Quotient""라는 새로운 정량적 지표를 제안하고 있으며, 이를 통해 AI 시스템의 친환경성을 평가하는 방법론을 개발했다고 명시되어 있습니다. 또한, 이 지표의 실증적 검증이 언급되어 있어 정량적 평가가 수행되고 있음을 알 수 있습니다."
Product Categorization by Title Using Deep Neural Networks as Feature Extractor,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9207093,"Natural Language Processing (NLP) has been receiving increasing attention in the past few years. In part, this is related to the huge flow of data being made available everyday on the internet, which increased the need for automatic tools capable of analyzing and extracting relevant information, especially from the text. In this context, text classification became one of the most studied tasks on the NLP domain. The objective is to assign predefined categories or labels to text or sentences. Important applications include sentence classification, sentiment analysis, spam detection, among many others. This work proposes an automatic system for product categorization using only their titles. The proposed system employs a state-of-the-art deep neural network as a tool to extract features from the titles to be used as input in different machine learning models. The system is evaluated in the large-scale Mercado Libre dataset, which has the common characteristics of real-world problems such as imbalanced classes, unreliable labels, besides having a large number of samples: 20,000,000 in total. The results showed that the proposed system was able to correctly categorize the products with a balanced accuracy of 86.57% on the local test split of the Mercado Libre dataset. It also surpassed the fourth place on the public rank of the MeLi Data Challenge with 91.19% of balanced accuracy, which represents less than 1% of the difference to the winner.",Yes,논문 초록에서 제안된 시스템의 성능을 평가하기 위해 정확도(86.57% 및 91.19%)와 같은 정량적 지표를 사용하여 평가 결과를 제시하고 있습니다. 이는 명확한 정량적 평가를 실시하고 있음을 보여줍니다.
Development of magnetic-sensor-based hand gesture recognition system for sign language,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10167092,"Sign language recognition is essential for the automatic translation of sign languages to enable communication for hearing-impaired people. This work proposes a system based on multiple magnetic sensors for recognizing hand gestures related to sign language alphabets. In particular, a magnetic detection system consisting of six magnetic sensor nodes measures the orientation of fingers and palms. A deep learning classification algorithm processes the measured orientation data. Experimental tests validate the proposed system and classification method. The results show that the proposed method provides close to 100% classification accuracy for 26 sign language alphabets under laboratory conditions. Thus, the feasibility of the proposed gesture recognition system for automatic translation of sign language alphabets is proved.",Yes,"논문 초록에서 실험 결과를 통해 26개의 수화 알파벳에 대해 거의 100%의 분류 정확도를 보여주었다고 명시되어 있어, 정량적 평가가 실시되었음을 알 수 있습니다. 또한, 실험을 통해 제안된 시스템과 분류 방법의 유효성을 검증하였다고 언급하고 있습니다."
Supervised named entity recognition in Assamese language,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7019728,"In each and every natural language nouns play a very important role. A subcategory of noun is proper noun. They represent the names of person, location, organization etc. The task of recognizing the proper nouns in a text and categorizing them into some classes such as person, location, organization and other is called Named Entity Recognition. This is a very essential step of many natural language processing applications that makes the process of information extraction easier. Named Entity Recognition (NER) in most of the Indian languages has been performed using rule-based, supervised and unsupervised approaches. In this work our target language is Assamese, the language spoken by most of the people in North-Eastern part of India and particularly in Assam. In Assamese language, Named Entity Recognition has been performed using the rule based and suffix stripping based approaches. Supervised learning technique is more useful and can be easily adapted to new domains compared to rule based approaches. This paper reports the first work in Assamese NER using a machine learning technique. In this paper Assamese Named Entity Recognition is performed using Naïve Bayes classifier. Since feature extraction plays the most important role in getting better performance in any machine learning technique, in this work our aim is to put forward a description of a few important features related to Assamese NER and performance measure of the system using these features.",Yes,"논문 초록에서 Naïve Bayes 분류기를 사용하여 Assamese NER 시스템의 성능을 평가하는 내용을 언급하고 있으며, 성능 측정을 위한 평가 지표와 특징 추출에 관한 설명이 포함되어 있습니다. 이는 정량적 평가가 실시되고 있음을 시사합니다."
Biomechanical Risk Evaluation Through Machine Learning Algorithms Fed with Features Extracted From sEMG of Neck Extensors,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10796263,"Work-related musculoskeletal disorders (WRMDs) affect millions of workers worldwide, posing substantial economic burdens on industries and healthcare systems. Prolonged exposure, repetitive tasks, awkward postures and intensive efforts are keys factors contributing to the development of WRMDs. Several quantitative or semi-quantitative methodologies are employed to evaluate the biomechanical risk and to prevent WRMDs in the occupational ergonomics field. However, these methods are still time-consuming and operator-dependent. Recently, the application of wearable sensors combined with artificial intelligence is providing remarkable results in terms of biomechanical risk assessment in the occupational ergonomics field. Therefore, in the present work, we examined the potential of Machine Learning (ML) models to differentiate between biomechanical risk categories as defined by the Revised NIOSH Lifting Equation (RNLE). The ML models were trained using time-domain and frequency-domain features extracted from surface electromyographic (sEMG) signals obtained from the neck extensor muscles of four healthy subjects during weight-lifting tasks. The study findings indicated that the Support Vector Machine algorithm performed the best, achieving an accuracy of 83.6% and an area under the receiver operating characteristic curve of 89.9%. However, the study was limited by its small sample size and the restricted age range of the volunteers. Future research involving a larger and more diverse population in terms of age and number of subjects could further validate the effectiveness of the proposed methodology.",Yes,"논문 초록에서 Support Vector Machine과 같은 머신러닝 알고리즘을 사용하여 biomechanical risk를 평가하는 정량적 평가를 실시했다고 명확히 언급하고 있습니다. 또한, 정확도와 ROC 곡선 아래 면적과 같은 수치적 성과 지표를 제시하여 정량적 평가가 수행되었음을 보여줍니다."
Fast and Lightweight UAV-based Road Image Enhancement Under Multiple Low-Visibility Conditions,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10150374,"The amalgamation of Unmanned Aerial Vehicle (UAV) based systems with models built on Artificial Intelligence (AI) and Computer Vision approaches have enabled several applications in urban planning and smart cities, such as remote health monitoring of roads and infrastructure. However, most of such existing models are trained and evaluated for clear lighting conditions, and they do not perform well under low visibility. This work proposes a fast and lightweight approach for deployment on UAV-based systems that can (i) detect the low-visibility condition in a road image captured by a UAV, and (ii) alleviate it and enhance the quality of the road image. The proposed approach achieves state-of-the-art results and thus establishes itself as an essential precursor to downstream Computer Vision tasks related to remote monitoring of roads, such as identification of different distress conditions.",Yes,"논문 초록에서 ""The proposed approach achieves state-of-the-art results""라는 표현을 통해 정량적 평가를 실시했음을 암시하고 있습니다. 또한, 저자들이 제안한 방법의 성능을 평가하기 위해 수치적 지표를 사용했을 가능성이 높습니다."
A Combined Method for Object Detection under Rain Conditions Using Deep Learning,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9799899,"The process of object detection utilizing deep learning is one of the most important deep learning applications and computer vision techniques, where one can learn image features in normal weather conditions and different rain conditions. Therefore, a deep convolutional neural network (DCNN) has become more important for object detection. Rain is a common and maj or factor in degrading image quality and decreasing object detection reliability. The main aim of this work is to remove rain streaks to get high reliability in detection process and decrease the error rate, in normal conditions and different rain conditions (light, medium and heavy). Firstly, the quality of the images is improved and removed rain streaks by de-raining algorithm that use the Deep Detail Network (DDN) method. Then the way deep learning is the main object detector, through use the YOLO to detect objects and determine its type. YOLOv3 and tiny-YOLOv3 have been determine from the literature review as the most suitable and efficient algorithms for detecting objects in real time after improving the image quality. The performance of these algorithms has been calculated and compared with each other. To evaluate the effectiveness of the devised approach (De-raining+YOLOv3), Fl-score, Recall, and Precision were computed. Using the proposed method combined from DDN with YOLOv3 technique (De-raining+YOLOv3), the mean of Fl-score of 95.02%, Recall of 97.22%, and a Precision of 92.92% were attained. Our presented approach is more resilient and accurate in object detection under rain conditions according to the findings of the results of the experiments. It is considered the best way for object detection under rain conditions with high reliability.",Yes,"논문 초록에서 Fl-score, Recall, Precision과 같은 정량적 평가 지표를 계산했다고 명시되어 있으며, 이를 통해 제안된 방법의 성능을 수치로 평가하고 있음을 알 수 있습니다. 따라서, 정량적 평가를 실시하고 있다고 판단됩니다."
Feature Selection and Design of Intrusion Detection System Based on k-Means and Triangle Area Support Vector Machine,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5431864,"Nowadays, challenged by malicious use of network and intentional attacks on personal computer system, intrusion detection system has become an indispensible and infrastructural mechanism for securing critical resource and information. Most current intrusion detection systems focus on hybrid supervised and unsupervised machine learning technologies. The related work has demonstrated that they can get superior performance than applying single machine learning algorithm in detection model. Besides, with the scrutiny of related works, feature selecting and representing techniques are also essential in pursuit of high efficiency and effectiveness. Performance of specified attack type detection should also be improved and evaluated. In this paper, we incorporate information gain (IG) method for selecting more discriminative features and triangle area based support vector machine (TASVM) by combining k-means clustering algorithm and SVM classifier to detect attacks. Our system achieves accuracy of 99.83%, detection rate of 99.88% and false alarm rate of 2.99% on the 10% of KDD CUP 1999 evaluation data set. We also achieve a better detection performance for specific attack types concerning precision and recall.",Yes,"논문 초록에서 feature selection과 성능 평가를 위해 정확도, 검출률, 오탐률 등 정량적 지표를 사용하여 평가하고 있음을 명확히 언급하고 있습니다. 따라서, 정량적 평가를 실시하고 있다고 판단됩니다."
Experimental validation of learning accomplishment,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=632677,"This paper reports on educational assessment: measures to validate that a subject has been learned. Outcomes described are from actual UCLA Computer Science courses, but the approach is independent of subject matter. There is a bibliography describing application of the methods presented here to other subjects and school levels. That bibliography summarizes an extensive literature including assessment in distance learning and elementary school situations. The text here outlines ideas and derivations, and the references enable deeper understanding, but a reader can use these procedures without either. The paper describes a way to apply them and to display students' learning. The paper contributes new ways to indicate student achievement and distinguish individuals with subject mastery from others tested. This is by figures shown here that enable teachers and students to understand and apply this form of testing. The measures use probability and are based on concepts of information. The method is generally applicable. It is related to earlier work on a computerized learning system called Plate that handled a wide variety of subjects at many educational levels. This paper describes ways to use an unconventional assessment approach to rapidly determine concepts not yet absorbed. New methods presented here are those the author developed in classes he taught. Ideas and tools in this paper could empower others to expand and enrich their teaching and the learning processes it is to assist.",Yes,"초록에서 교육 평가와 학습 성취를 검증하는 방법을 제시하며, 이를 정량적 평가로 수행하는 것으로 언급하고 있습니다. 또한, 확률과 정보 개념을 기반으로 한 측정 방법을 사용한다고 명확히 언급되어 있어 정량적 평가를 실시하고 있음을 알 수 있습니다."
Comparative Analysis of Different Neural Network Models for Speaker Gender Recognition by Voice,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10421302,"This study examines the exploration of gender identification using voice data investigating how different deep learning models perform in this field. The models analyzed include the Artificial Neural Network (ANN) 2D Convolutional Neural Network (2D-CNN) Feedforward Neural Network (FNN) and Long Short-Term Memory (LSTM). The voice dataset used in the research consists of 20 feature columns and a label column. It undergoes steps, such, as label encoding and feature scaling. The models are carefully evaluated using important performance metrics like loss and accuracy percentages. Notably the findings highlight the strengths of each model; the ANN and FNN models demonstrate accuracy rates while the 2D-CNN model excels at capturing spatial relationships and the LSTM model focuses on temporal dependencies. The main emphasis of this work is a thorough review of the literature on speech detection and voice analysis using deep learning techniques as well as standard approaches. Beyond academia this research has implications for voice-controlled systems and security measures. The strong performance of ANN and FNN models shows promise for real world integration with applications in voice-based authentication and virtual assistants. These findings provide insights for researchers and professionals interested in developing gender recognition systems by emphasizing the importance of considering model architectures along, with their unique capabilities when working with voice data. Overall, this research adds to our understanding of the strengths and limitations of learning models when it comes to analyzing voices, for gender recognition. It provides insights for research and practical applications, in this field.",Yes,초록에서 모델의 성능을 평가하기 위해 손실(loss)과 정확도(accuracy)와 같은 성능 지표를 사용했다고 명확히 언급하고 있습니다. 이는 정량적 평가가 실시되고 있음을 보여줍니다.
Stack Algorithm Implementation in Robot-Based Mixed Case Palletizing System,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10000343,"This paper documents the design procedure of a mixed case palletizing system using the ABB robot variant, IRB660. With the evolution of the e-commerce industry and rising volumes of stock-flow in warehouses and trading facilities, there has been a requirement for the automation of some of the most important operations. An automated palletizing system is a potential solution for this problem, to create optimized pallets with greater packing density and pallet support compared with the manual practices in operation. By completing this project, the authors will provide an entirely robotized palletizing system capable of responding to any customized packing order in a quick and efficient manner. The system is designed to handle 1000 or more cases per hour making it ideal for any warehouse or logistic facility dealing with a high number of stock-keeping units. Starting with a literature review and market research on the available systems, three different bin packing algorithms were stated: the Guillotine, MAXRECTS, and Skyline algorithms. Further, a new metric ‘percolation’ was introduced to measure and compare the packing quality of a pallet. The main section of this paper consists of a study of the design solution the authors have implemented for the AI stacking algorithm while introducing the palletizing UI used in the system. A data-driven 3D bin packing approach was considered for the stacking process which makes use of even-height super boxes to form dense and supported pallets. This method was chosen for its flexibility and reliable packing density of 80% made within a short time frame. Moving to the UI, a sample design of a graphical user interface (GUI) was first made in Figma while focusing on the different functionalities of the palletizing system before implementing the UI as a Windows Forms application. A 2D image of the ongoing pallet is displayed with several other customizing features such as selecting the stacking pattern and choosing different box/ pallet dimensions. Finally, a workcell was devised in RobotStudio® to simulate the operation and testing facilities of the authors' design solution. In close, this report satisfies all the design requirements with detailed descriptions and analyses of the team's approach.",No,"초록에서는 다양한 알고리즘과 설계 과정을 설명하고 있지만, 정량적 평가를 위한 구체적인 실험 데이터, 성능 지표 또는 수치 분석이 언급되지 않습니다. 따라서 논문이 정량적 평가를 실시했다고 보기 어렵습니다."
An Experimental Evaluation of a Cloud-Based Virtual Computer Laboratory Using Openstack,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8113328,"In previous work, we proposed a solution to facilitate access to computer science related courses and learning materials using cloud computing and mobile technologies. The solution was positively evaluated by the participants, but most of them indicated that it lacks support for laboratory activities. As it is well known that many of computer science subjects (e.g. Computer Networks, Information Security, Systems Administration, etc.) require a suitable and flexible environment where students can access a set of computers and network devices to successfully complete their hands-on activities. To achieve this criteria, we created a cloud-based virtual laboratory based on OpenStack cloud platform to facilitate access to virtual machine both locally and remotely. Cloud-based virtual labs bring a lot of advantages, such as increased manageability, scalability, high availability and flexibility, to name a few. This arrangement has been tested in a case-study exercise with a group of students as part of Computer Networks and System Administration courses at Kabul Polytechnic University in Afghanistan. To measure success, we introduced a level test to be completed by participants prior and after the experiment. As a result, the learners achieved an average of 17.1 % higher scores in the post level test after completing the practical exercises. Lastly, we distributed a questionnaire after the experiment and students provided positive feedback on the effectiveness and usefulness of the proposed solution.",Yes,"논문 초록에서 실험의 성공 여부를 측정하기 위해 사전 및 사후 수준 테스트를 실시했다고 명시되어 있으며, 이를 통해 정량적 평가가 수행되었음을 알 수 있습니다. 따라서, 논문은 정량적 평가를 실시하고 있다고 판단됩니다."
Lightweight EfficientNetB3 Model Based on Depthwise Separable Convolutions for Enhancing Classification of Leukemia White Blood Cell Images,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10100945,"Acute lymphoblastic leukemia (ALL) is a type of leukemia cancer that arises due to the excessive growth of immature white blood cells (WBCs) in the bone marrow. The ALL rate for children and adults is nearly 80% and 40%, respectively. It affects the production of immature cells, leading to an abnormality of neurological cells and potential fatality. Therefore, a timely and accurate cancer diagnosis is important for effective treatment to improve survival rates. Since the image of acute lymphoblastic leukemia cells (cancer cells) under the microscope is complicated to recognize the difference between ALL cancer cells and normal cells. In order to reduce the severity of this disease, it is necessary to classify immature cells at an early stage. In recent years, different classification models have been introduced based on machine learning (ML) and deep learning (DL) algorithms, but they need to be improved to avoid issues related to poor generalization and slow convergence. This work enhances the diagnosis of ALL with a computer-aided system that yields accurate results by using DL techniques. This research study proposes a lightweight DL-assisted robust model based on EfficientNet-B3 using depthwise separable convolutions for classifying acute lymphoblastic leukemia and normal cells in the white blood cell images dataset. The proposed lightweight EfficientNet-B3 uses less trainable parameters to enhance the performance and efficiency of the leukemia classification. Furthermore, two publicly available datasets are considered to evaluate the effectiveness and generalization of the proposed lightweight EfficientNet-B3. In addition, different measures are employed, such as accuracy, precision, recall, and f1-score, to evaluate the effectiveness of the proposed and baseline classifiers. In addition, a detailed analysis is given to evaluate and compare the performance and efficiency of the proposed with existing pre-trained and ensemble DL classifiers. Experimental results show that the proposed model for image classification achieves better performance and outperforms the existing benchmark DL and other ensemble classifiers. Moreover, our finding suggests that the proposed lightweight EfficientNet-B3 model is reliable and generalized to facilitate clinical research and practitioners for leukemia detection.",Yes,"논문 초록에서 정확도, 정밀도, 재현율, F1-score와 같은 정량적 평가 지표를 사용하여 제안된 모델의 성능을 평가했다고 명시되어 있습니다. 또한, 기존 방법과의 비교를 통해 성능 향상을 검증하는 실험 결과도 언급되어 있어 정량적 평가가 실시된 것으로 판단됩니다."
Blockchain and Machine Learning for Advanced Pattern Recognition in Biometric Security Systems,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10828862,"Blockchain and machine learning allow biometric security systems to recognize complex patterns. This study analyzes how two unique technologies may improve fingerprint system safety and reliability. To demonstrate blockchain and machine learning in biometrics. The main reason for this study is that fingerprint protection is becoming more important in today’s digital world. There needs to be strong name verification right away because there is more sensitive data and privacy issues. Traditional biometric systems have come a long way, but there are still problems with data security, privacy, and being able to grow. This study suggests important worries about how blockchain technology and machine learning might be able to improve pattern recognition, make security measures stricter, make data unchangeable, and reach the level of scalability needed for widespread use. Upon careful study of related approaches and works, biometric security could be improved by combining the decentralized and unchangeable record of blockchain with the pattern recognition abilities of machine learning. Ten important ways are looked at, and each one has its own pros and cons. A trio of CNNs, SVMs, and RNNs are used in the method we suggest. The suggested blockchain and machine learning fusion is shown to be better in a detailed analysis. The study ends with compared tables that show the parameters and performance evaluations of 10 similar systems.",Yes,"논문 초록에서 CNN, SVM, RNN 등 다양한 머신러닝 기법을 사용하여 성능 평가를 수행했다고 언급하고 있으며, 성능 평가와 관련된 비교 표를 통해 정량적 평가를 실시했음을 알 수 있습니다. 따라서, 이 논문은 정량적 평가를 실시하고 있다고 판단됩니다."
Fast Pedestrian Detection for Real-World Crowded Scenarios on Embedded GPU,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9535550,"The behavior of individuals in crowds in public places has gained enormously in importance last year, for example through distancing requirements. However, automatically detecting pedestrians in real-world uncooperative scenarios remains a very challenging task. Especially crowded areas in surveillance footage are not only challenging for automatic vision systems, but also for human operators. Furthermore, complex detection models do not scale easily and are not traditionally designed for on-device processing in resource-constrained smart cameras, which become more and more popular due to technical and privacy issues at large events. In this work, we propose a new Fast Pedestrian Detector (FPD) based on RetinaNet which is a fast and efficient architecture for embedded platforms. The proposed FPD provides near real-time and real-time detection of hundreds of pedestrians on embedded platforms, outperforming popular YOLO-based approaches traditionally tuned for speed. Furthermore, by evaluating our approach on several different Jetson platforms in terms of speed and energy profiles, we highlight the challenges related to the deployment of a deep learning based pedestrian detector on embedded platforms for smart surveillance cameras.",Yes,"논문 초록에서 제안하는 Fast Pedestrian Detector (FPD)의 성능을 평가하기 위해 속도와 에너지 프로파일 등 다양한 지표를 사용하여 정량적 평가를 실시했음을 암시합니다. 또한, 여러 Jetson 플랫폼에서의 성능 평가를 통해 구체적인 수치와 비교를 수행했을 것으로 보입니다."
FitMe: A Fitness Application for Accurate Pose Estimation Using Deep Learning,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9478168,"The advancements in deep learning have brought about crucial transformations in computer vision over the past two decades. Deep convolutional networks have found many applications in building fine-tuned models for implementation in vision-related tasks. Knowledge learned by deep learning models over enormous generic datasets can be transferred to be employed for much more specific tasks. In this work, are implementing the approach to provide health benefits to people. In the present work, we develop an application which help them in performing exercises without the help of a trainer and get instant feedback about the postures. We aim to make fitness accessible to all by removing barriers such as external hardware requirements and cost-based subscriptions. In this paper, we dive deep into the technical details about the application and the exact methodologies applied for building the same. Furthermore, results are evaluated after running the application over multiple scenarios and a comparative analysis is performed.",Yes,"논문 초록에서 ""results are evaluated""라는 표현을 통해 정량적 평가가 수행되었음을 시사합니다. 또한, 다양한 시나리오에서의 성능 검증과 비교 분석이 언급되어 있어 평가 방법이 포함되어 있음을 알 수 있습니다."
Automated Detection of Racial Microaggressions using Machine Learning,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9308569,"Microaggressions describe subtle often offensive comments or actions made by one individual to another. Typically, such comments or actions are made subconsciously with the offender potentially unaware of the impacts on the recipient. Currently, machine learning methods for racial microaggression detection are sparse with no, one, comparable approach to the one we propose further on. Automated detection in this work describes the method of finding microaggressions through the use of machine-learning algorithms. Efforts have been made for the detection of hate speech and harassment; providing us with a rather humble place to begin, as we explore further, such methods are proven ineffective. We propose a step forward in solving this problem with the demonstration of an automated racial microaggression detection method. Whilst racial hatespeech detection method provides us with an idea as to where we can start, we find further on, that microaggressions and hatespeech use very different features to portray their sentiment. This work aims to provide a technical review which explores the understanding of the automated racial microaggression detection, outlining the definitions of microaggressions currently described in the literature, with the presentation and assessment (through precision, callback and F-measure) of a promising approach in regards to racial microaggression detection. We also intend to analyse a case study in which we detect the presence of racial microaggressions within new reports with the intention of laying a foundation for the potential security-related applications of this work. Our further works begin to discuss this notion in a higher level of detail.",Yes,"논문 초록에서 정량적 평가를 위해 정밀도(precision), 재현율(callback), F-측정(F-measure) 등의 지표를 사용했다고 명시하고 있습니다. 이는 연구에서 정량적 평가를 실시했음을 보여줍니다."
Optimizing Convolutional Neural Network Hyperparameters for MNIST Image Classification: Insights and Implications,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10912098,"The recognition of handwritten digits has been among the most enduring fundamental problems explored in the field of machine learning and computer vision. The objective of this work is to design a state-of-art Convolutional Neural Network (CNN) for the image classification on the MNIST dataset to resolve issues related to data pre-processing and parameter tuning effectively. The work starts with standardizing the image data and then using one-hot encoding for the models that will improve the generalization and representation. The CNN structure followed in this work includes the convolutional layer, batch normalization, pooling layers, and fully connected layers with an efficient integration of features. To measure such performance indicators as accuracy, the given dataset is divided for training and validation. The results are also preprocessed to control for overfitting and convergence using back propagation with early stop to stop training when significant accuracy improvement is not observed and learning rate decay to encourage the model to search for better weights in the final stages of training. The model’s performance is tested and evaluated by using different epoch intervals and learning rates, and it is shown how critical it is to select the correct default hyperparameters for achieving efficiency. This paper also presents the approach for the practical application of the preprocessing of images and the systematic assessment in enhancing CNN-based handwritten digit recognition.",Yes,"논문 초록에서 모델의 성능을 평가하기 위해 정확도와 같은 성능 지표를 사용했다고 명시되어 있으며, 다양한 하이퍼파라미터 조합에 따른 성능 평가를 실시했다고 언급되어 있습니다. 이는 정량적 평가를 수행하고 있음을 보여줍니다."
Towards an intelligent system to manage IDS for IoT,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9766759,"Nowadays, the security of information system has become more and more important in our lives. Indeed, the appearance of 5G see 6G and technological progress which has given rise to the democratization of connected objects, thus increasing the related risks and making the task of information system security administrator more and harder. To remedy this, the researchers focused on several systems including IDS which is an Intrusion Detection System used in host and network security. However, this system generates a large number of alarms which must be managed by a security administrator, something which is not easy to do, but is necessary to guarantee an optimal level of security. In this work, we will present a system that helps the security administrator to properly detect and manage IDS alerts. This system is based on detecting attacks, collecting alerts generated by different IDS in a network of objects, analyzing these alerts and taking appropriate actions. We propose automation of said tasks based on artificial intelligence algorithms, especially Deep Learning. Our choice is directed towards the algorithm of the Artificial Neural Network (ANN) according to several criteria namely the performance and the speed of detection which is our major concern while combining it with the algorithm of Spider Monkey Optimization (SMO) for a good optimization of the entries. Our system aims to strengthen the second line of defense and make it more efficient and intelligent by equipping it with three intelligent engines namely, a detection engine, an analysis engine and an action engine. To illustrate the applicability of the proposed approaches, we begun to test the performance of detection by using different measures for example error of detection, training time and accuracy rate which have been obtained by testing with NSL-KDD dataset.",Yes,"논문은 딥러닝과 인공신경망(ANN)을 활용하여 IDS의 성능을 평가하는 실험을 수행하고 있으며, 검출 오류, 학습 시간, 정확도와 같은 정량적 지표를 사용하여 성능을 평가하고 있습니다. 따라서 정량적 평가를 실시하고 있다고 판단됩니다."
Transfer Learning on Trial: A Case Study to Apply Existing Models to Heterogeneous Datasets,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10145140,"Nowadays, transfer learning is getting more and more popular in both industry and academia. It enables people to benefit from current advanced AI technologies, which used to be only accessible to professional teams with the most powerful talents, software and hardware resources. It has been proved that transfer learning is the best available option to apply learned patterns for one problem to a different but related problem. But rare research has been done to evaluate the performance of employing an existing model to a less related problem. In this paper, we apply the pre-trained model in the computer vision field, VGG, to a radar dataset, Ionosphere, which is heterogeneous to the above vision data, and carry out extensive experiments. The results show that the classification accuracy is much lower than that in the early research work, and the application of transfer learning should depend on certain situations.",Yes,"논문 초록에서 ""extensive experiments""라는 표현을 사용하여 다양한 실험을 수행했음을 시사하며, 이는 정량적 평가를 실시했음을 의미합니다. 또한, ""classification accuracy""를 언급하여 성능 평가를 위한 정량적 지표를 사용했음을 알 수 있습니다."
Concepts of Engineering Education Innovation and Design Thinking: Implementing the CDIO-approach Themes,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10578801,"The CDIO Framework within engineering education is based on the idea that graduates should be capable of conceiving, designing, implementing, and operating (i.e., CDIO) complex systems within a team-based learning environment. As an approach to engineering education, it aims to create an active, experiential learning setting where product and process are considered fundamental to the curriculum. Modern pedagogical strategies and innovative teaching methods allow for the implementation of the CDIO approach, where students are supported to develop deep knowledge, manage the process of designing and exploiting new items and systems, and evaluate the impact of the scientific-technological process on society. This article will highlight aspects of this approach in the development of a practical quantum electronics session. In particular, it will focus on the developed principles of an innovative practice-targeted programme that can support the development of students' engineering thinking through the linkage of education and professional activities. As graduates, the students will need to be able to create innovative engineering systems as well as integrate their understanding of natural and technological sciences to generate novel concepts. They will also need to be proficient in professional ethics and have knowledge of business and entrepreneurship fundamentals. As such, this indicates the need for a strategically-focused curriculum that supports the development of a range of transversal skills required for industry. In this paper, the CDIO model is detailed as a means of transforming engineering education on a large scale. In order to develop the fundamental framework of creative awareness sessions for quantum technologies and their applications, this study attempted to further explore and provide more specific illustrations of the concepts relating to CIDO and to consider how they may be applied within an engineering context. The current work will present and evaluate the principles of an innovative teaching technique aimed at providing students with the opportunities to understand pioneering technologies for future applications.",No,"논문 초록에서는 정량적 평가에 대한 구체적인 언급이 없으며, 주로 교육 방법론과 개념적 접근에 초점을 맞추고 있다. 따라서, 정량적 평가를 실시하고 있다고 보기 어렵다."
α-Satellite: An AI-Driven System and Benchmark Datasets for Dynamic COVID-19 Risk Assessment in the United States,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9141399,"The fast evolving and deadly outbreak of coronavirus disease (COVID-19) has posed grand challenges to human society. To slow the spread of virus infections and better respond for community mitigation, by advancing capabilities of artificial intelligence (AI) and leveraging the large-scale and up-to-date data generated from heterogeneous sources (e.g., disease related data, demographic, mobility and social media data), in this work, we propose and develop an AI-driven system (named α-Satellite), as an initial offering, to provide dynamic COVID-19 risk assessment in the United States. More specifically, given a point of interest (POI), the system will automatically provide risk indices associated with it in a hierarchical manner (e.g., state, county, POI) to enable people to select appropriate actions for protection while minimizing disruptions to daily life. To comprehensively evaluate our system for dynamic COVID-19 risk assessment, we first conduct a set of empirical studies; and then we validate it based on a real-world dataset consisting of 5,060 annotated POIs, which achieves the area of under curve (AUC) of 0.9202. As of June 18, 2020, α-Satellite has had 56,980 users. Based on the feedback from its large-scale users, we perform further analysis and have three key findings: i) people from more severe regions (i.e., with larger numbers of COVID-19 cases) have stronger interests using our system to assist with actionable information; ii) users are more concerned about their nearby areas in terms of COVID-19 risks; iii) the user feedback about their perceptions towards COVID-19 risks of their query POIs indicate the challenge of public concerns about the safety versus its negative effects on society and the economy. Our system and generated datasets have been made publicly accessible via our website.",Yes,"논문 초록에서 시스템의 성능을 평가하기 위해 실험적 연구와 검증을 수행했다고 명시되어 있으며, 특히 5,060개 POI 데이터셋을 이용한 AUC 평가 결과(0.9202)를 제시하고 있어 정량적 평가를 실시하고 있음을 알 수 있습니다."
Discriminating Healthy and IUGR fetuses through Machine Learning models,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9926874,"The purpose of this study is to develop and understand whether Machine Learning models can classify Cardiotocographic (CTG) recordings of healthy fetuses or Intra Uterine Growth Restricted (IUGR) fetuses, highlighting how a large amount of data can have unexpected effects. We started from other findings in the literature to see what Machine Learning model remained consistent even with a large amount of data. The CTG records used in this study were collected at the Department of Obstetrics of the Federico II University Hospital in Naples, Italy, from 2013 to 2021. From this dataset, we chose 1548 IUGR fetuses and 1548 healthy fetuses to train our models. Each recording contained several parameters, ranging from features calculated on the entire CTG tracing, features calculated every 3 and 1 minute of recording and features related to the pregnant woman, such as age and week of gestation. We trained our machine-learning models on this dataset, checking the results obtained before and after adjusting the hyperparameters, noting that among the best models was Random Forest, which has already been present in other studies, and that the Multilayer Perceptron and the AdaBoost classifier were overall the best performing. This work can surely form a basis for future works in the fetal heart rate classification thus leading to real clinical applications.",Yes,논문 초록에서 여러 머신러닝 모델의 성능을 평가하고 하이퍼파라미터 조정을 통해 결과를 비교하는 등 정량적 평가를 실시했음을 명확히 언급하고 있습니다. 이는 데이터 분석과 모델 성능 측정을 통한 정량적 평가가 이루어졌음을 의미합니다.
Comparative Analysis of BERT-base Transformers and Deep Learning Sentiment Prediction Models,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10047651,"The state-of-the-art Bidirectional Encoder Representations from Transformers (BERT) and Deep Learning (DL) models are used for Natural Language Processing (NLP) applications. Social media marketing and customers positive sentiments play major role for many online businesses.It is a crucial task for companies to predict customers sentiment based on context from online reviews. Predicting accurate sentiment is a time-consuming and challenging task due to high volume of unstructured customers review dataset. There are many previous experimental results reveals the performance and inaccuracy issues on large scale customer reviews datasets. This paper presents the comparative analysis of experimental research work on BERT, Hybrid fastText-BILSTM, and fastText Trigram models overcome more accurate sentiment prediction challenges. We propose fine-tuned BERT and Hybrid fastText-BILSTM models for large customer review datasets. This comparative analysis results show that the proposed fine-tuned BERT model performs better compare to other DL models in terms of accuracy and other performance measures.",Yes,"논문 초록에서 BERT와 Deep Learning 모델들의 성능을 비교하는 실험적 연구를 수행했다고 명시되어 있습니다. 또한, 정확도와 성능 지표를 통해 평가를 진행했다고 언급되어 있어 정량적 평가가 실시된 것으로 판단됩니다."
Federated Learning in IoT: A Survey from a Resource-Constrained Perspective,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10874004,"The IoT ecosystem is able to leverage vast amounts of data for intelligent decision-making. Federated Learning (FL), a decentralized machine learning technique, is widely used to collect and train machine learning models from a variety of distributed data sources. Both IoT and FL systems can be complimentary and used together. However, the resource-constrained nature of IoT devices prevents the widescale deployment FL in the real world. This research paper presents a comprehensive survey of the challenges and solutions associated with implementing Federated Learning (FL) in resource-constrained Internet of Things (IoT) environments, viewed from 2 levels, client and server. We focus on solutions regarding limited client resources, presence of heterogeneous client data, server capacity, and high communication costs, and assess their effectiveness in various scenarios. Furthermore, we categorize the solutions based on the location of their application, i.e., the IoT client, and the FL server. In addition to a comprehensive review of existing research and potential future directions, this paper also presents new evaluation metrics that would allow researchers to evaluate their solutions on resource-constrained IoT devices.",Yes,"논문 초록에서 ""new evaluation metrics""를 제시한다고 언급하며, 이러한 지표를 통해 연구 결과를 평가할 수 있음을 시사합니다. 또한, 다양한 시나리오에서 솔루션의 효과를 평가하는 내용이 포함되어 있어 정량적 평가가 실시되고 있음을 알 수 있습니다."
[Research Paper] On the Use of Machine Learning Techniques Towards the Design of Cloud Based Automatic Code Clone Validation Tools,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8530729,"A code clone is a pair of code fragments, within or between software systems that are similar. Since code clones often negatively impact the maintainability of a software system, a great many numbers of code clone detection techniques and tools have been proposed and studied over the last decade. To detect all possible similar source code patterns in general, the clone detection tools work on syntax level (such as texts, tokens, AST and so on) while lacking user-specific preferences. This often means the reported clones must be manually validated prior to any analysis in order to filter out the true positive clones from task or user-specific considerations. This manual clone validation effort is very time-consuming and often error-prone, in particular for large-scale clone detection. In this paper, we propose a machine learning based approach for automating the validation process. In an experiment with clones detected by several clone detectors in several different software systems, we found our approach has an accuracy of up to 87.4% when compared against the manual validation by multiple expert judges. The proposed method shows promising results in several comparative studies with the existing related approaches for automatic code clone validation. We also present our experimental results in terms of different code clone detection tools, machine learning algorithms and open source software systems.",Yes,"논문 초록에서 머신러닝 기반의 접근법을 사용하여 코드 클론 검증의 정확도를 평가하는 실험 결과를 제시하고 있습니다. 이는 정량적 평가를 실시했음을 의미하며, 정확도 수치(87.4%)를 통해 성능을 수치로 측정하고 있음을 알 수 있습니다."
Understanding Memories of the Past in the Context of Different Complex Neural Network Architectures,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10342588,"Deep learning (primarily using backpropagation) and neuroevolution are the preeminent methods of optimizing artificial neural networks. However, they often create black boxes that are as hard to understand as the natural brains they seek to mimic. Previous work has identified an information-theoretic tool, referred to as R, which allows us to quantify and identify mental representations in artificial cognitive systems. The use of such measures has allowed us to make previous black boxes more transparent. Here we extend R to not only identify where complex computational systems store memory about their environment but also to differentiate between different time points in the past. We show how this extended measure can identify the location of memory related to past experiences in neural networks optimized by deep learning as well as a genetic algorithm.",Yes,"논문 초록에서 ""R""라는 정보이론적 도구를 사용하여 인공 신경망 내의 기억을 정량적으로 평가하는 방법을 확장했다고 명시되어 있습니다. 이는 정량적 평가를 실시하고 있음을 보여주는 명확한 증거입니다."
Optimized Random Forest Classifier for Drone Pilot Identification,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9181004,"Random forest is a powerful machine learning scheme which finds applications in real-time systems such as unmanned aerial vehicles. In such applications not only the classification performance is relevant but also several non-functional requirements including the classification time, the memory usage and the power consumption. This paper proposes a new approach to improve the real-time behavior of a random forest classifier. This is accomplished by reducing the number of evaluated nodes and branches as well as by reducing the branch length in the underlying binary decision trees with numerical split values. A hardware architecture is presented for the improved tree-based classification method. A proof-of-concept implementation on an FPGA platform and some preliminary results show the advantage of this approach compared to related work.",Yes,"논문 초록에서 ""preliminary results""와 ""performance""와 관련된 언급이 있으며, 이는 정량적 평가를 수행했음을 시사합니다. 또한, 제안된 방법의 성능 향상과 관련된 실험적 검증이 포함되어 있음을 알 수 있습니다."
Normal/Cataract Detection in Fundus Image Using Individual and Fused ResNet Features,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10894554,"The visual sensory information collected by the eyes is crucial for accurate perception and decision-making in the brain. Any ocular ailment will disrupt this process, perhaps resulting in mild to severe vision-related complications. Ocular ailments are primarily attributable to disease or senescence. Age-related eye illness is a prevalent concern that necessitates prompt detection and intervention. Cataract is a prevalent age-related ocular condition that results in mild to severe visual impairment and necessitates a small surgical intervention for correction. The image-guided identification of cataracts is a clinical practice, and this research intends to present a Deep Learning (DL) method to categorize Retinal Fundus Images (RFI) as normal or cataract. The proposed scheme comprises several phases: (i) image acquisition and resizing to 224×224 pixels, (ii) feature extraction utilizing a DL- model, (iii) optimal model selection, feature reduction with 50% dropout, and concatenation of serial features, and (iv) classification accompanied by 3-fold cross-validation to validate performance. This study evaluates the efficacy of the suggested DL-tool utilizing both traditional and fused-features. The experimental results of this work demonstrate that the fused-features technique achieves > 98% accuracy when applied to SM-based categorization.",Yes,"논문 초록에서 3-fold 교차 검증과 성능 평가를 포함한 실험 결과를 제시하며, 정확도와 같은 정량적 지표를 통해 성능을 평가하고 있음을 보여줍니다. 따라서, 정량적 평가를 실시하고 있다고 판단됩니다."
A Hybrid Model-Based Approach on Prognostics for Railway HVAC,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9907016,"Prognostics and health management (PHM) of systems usually depends on appropriate prior knowledge and sufficient condition monitoring (CM) data on critical components’ degradation process to appropriately estimate the remaining useful life (RUL). A failure of complex or critical systems such as heating, ventilation, and air conditioning (HVAC) systems installed in a passenger train carriage may adversely affect people or the environment. Critical systems must meet restrictive regulations and standards, and this usually results in an early replacement of components. Therefore, the CM datasets lack data on advanced stages of degradation, and this has a significant impact on developing robust diagnostics and prognostics processes; therefore, it is difficult to find PHM implemented in HVAC systems. This paper proposes a methodology for implementing a hybrid model-based approach (HyMA) to overcome the limited representativeness of the training dataset for developing a prognostic model. The proposed methodology is evaluated building an HyMA which fuses information from a physics-based model with a deep learning algorithm to implement a prognostics process for a complex and critical system. The physics-based model of the HVAC system is used to generate run-to-failure data. This model is built and validated using information and data on the real asset; the failures are modelled according to expert knowledge and an experimental test to evaluate the behaviour of the HVAC system while working, with the air filter at different levels of degradation. In addition to using the sensors located in the real system, we model virtual sensors to observe parameters related to system components’ health. The run-to-failure datasets generated are normalized and directly used as inputs to a deep convolutional neural network (CNN) for RUL estimation. The effectiveness of the proposed methodology and approach is evaluated on datasets containing the air filter’s run-to-failure data. The experimental results show remarkable accuracy in the RUL estimation, thereby suggesting the proposed HyMA and methodology offer a promising approach for PHM.",Yes,"논문 초록에서 RUL(remaining useful life) 추정을 위해 딥러닝 알고리즘인 CNN을 사용하여 정량적 평가를 실시하고 있음을 명확히 언급하고 있습니다. 또한, 제안된 방법의 효과를 평가하기 위해 실험 데이터와 성능 평가를 수행하는 것으로 보입니다."
Self-Driving Car: Simulation of Highly Automated Vehicle Technology using Convolution Neural Networks,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10068691,"Driver behaviour is a significant factor in the smooth driving of vehicles on the roads. 94 % of crashes and road accidents are prone to drivers' rash driving behaviour. To address issues related to road accidents and crashing of vehicles on the road, Highly Automated Vehicle (HAV) Technologies have been proposed. Self-Driving Cars are part of Highly Automated Tech-nologies having promising benefits ranging from Greater Road Safety, Greater Independence, Saving money, More Productivity, Reduced Congestion and Green House Gains. The current study focuses on the deployment of self-driving automobiles based on the Deep Learning paradigm. The automobile has been simulated on the Udacity simulator for convenience and safety. On the Udacity platform, a technique for training and simulating an unmanned vehicle model using a convolutional neural network has been developed. The data used to train the model is captured in the simulator and fed as input into the Deep CNN. Following data collection, Deep CNN is trained to have Safety Navigation by passing Steering, Throttle, Brake and Speed as Control Inputs. The use of three cameras considerably improves the precision of the navigation job. To manage the car, the steering wheel amount will be modified such that it runs in the centre of the lane. We evaluated the model using UDACITY's simulation system. The proposed model has been evaluated considering the-No of epochs vs loss calculation, as performance metrics, and was found that the proposed model has shown superiority with the existing works.",Yes,"논문 초록에서 모델의 성능 평가를 위해 ""number of epochs vs loss calculation""과 같은 성능 지표를 사용했다고 명시되어 있습니다. 이는 정량적 평가를 실시하고 있음을 보여줍니다."
Automatic Pulmonary Lobe Segmentation Using Deep Learning,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8759468,"Pulmonary lobe segmentation is an important task for pulmonary disease related Computer Aided Diagnosis systems (CADs). Classical methods for lobe segmentation rely on successful detection of fissures and other anatomical information such as the location of blood vessels and airways. With the success of deep learning in recent years, Deep Convolutional Neural Network (DCNN) has been widely applied to analyze medical images like Computed Tomography (CT) and Magnetic Resonance Imaging (MRI), which, however, requires a large number of ground truth annotations. In this work, we release our manually labeled 50 CT scans which are randomly chosen from the LUNA16 dataset and explore the use of deep learning on this task. We propose pre-processing CT image by cropping region that is covered by the convex hull of the lungs in order to mitigate the influence of noise from outside the lungs. Moreover, we use a hybrid loss function with dice loss to tackle extreme class imbalance issue and focal loss to force model to focus on voxels that are hard to be discriminated. To validate the robustness and performance of our proposed framework trained with a small number of training examples, we further tested our model on CT scans from an independent dataset. Experimental results show the robustness of the proposed approach, which consistently improves performance across different datasets by a maximum of 5.87% as compared to a baseline model. The annotations are public available https://github.com/deep-voxel/automatic_pulmonary_lobe_segmentation_using_deep_learning/ and are for non-commercial use only.",Yes,"논문 초록에서 제안된 딥러닝 모델의 성능을 검증하기 위해 다양한 실험을 수행했음을 시사하는 내용이 포함되어 있습니다. 특히, 여러 데이터셋에서의 성능 비교와 최대 성능 향상 수치를 언급하며 정량적 평가를 실시했음을 알 수 있습니다."
Tailoring Content with Keyword-Based Recommendation Engine Using Machine Learning,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10915535,"It is the information age thus; it is very important to understand how to personalize content in accordance with what appeals to a user. This work is conceptualized to be labeled ""Tailoring Content with Keyword-Based Recommendation Engine Using Machine Learning"". This work provides the applicative system catering for the experience of users by proposing personalization in terms of content. The core of the work is keyword-based recommendation engine chosen by the user to recommend posts as well as other contents believed to be of the user’s interest. A recommendation system uses various types of algorithms related to machine learning and a combination of data analysis technologies while considering the interaction of the user with posts, created, liked, or participated in. From this, it will then understand keen interests by a user and make recommendations based on those grounds. This will keep users interesting about the relevant content and help develop skills in areas they are interested in. Some scope includes designing a recommendation engine, developing it into an application, and measuring performance. This would be in the ability of doing so, with accuracies at all high degrees, when recommending this content, scalability, and also privacy for the users. It will be used to prove how machine learning techniques can be applied towards developing personalized user experience and, as a by-product, contribute to this field known as content recommendation systems.",Yes,"논문 초록에서 성능 측정과 관련된 내용이 언급되어 있으며, 추천 시스템의 성능 평가(accuracy, scalability, privacy 등)를 측정하는 부분이 포함되어 있다고 보여집니다. 이는 정량적 평가가 실시되고 있음을 시사합니다."
XTSC-Bench: Quantitative Benchmarking for Explainers on Time Series Classification,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10459958,"Despite the growing body of work on explainable machine learning in time series classification (TSC), it remains unclear how to evaluate different explainability methods. Resorting to qualitative assessment and user studies to evaluate explainers for TSC is difficult since humans have difficulties understanding the underlying information contained in time series data. Therefore, a systematic review and quantitative comparison of explanation methods to confirm their correctness becomes crucial. While steps to standardized evaluations were taken for tabular, image, and textual data, benchmarking explainability methods on time series is challenging due to a) traditional metrics not being directly applicable, b) implementation and adaption of traditional metrics for time series in the literature vary, and c) varying baseline implementations. This paper proposes XTSC-Bench, a benchmarking tool providing standardized datasets, models, and metrics for evaluating explanation methods on TSC. We analyze 3 perturbation-, 6 gradient- and 2 example-based explanation methods to TSC showing that improvements in the explainers' robustness and reliability are necessary, especially for multivariate data.",Yes,"논문 초록에서 XTSC-Bench라는 벤치마킹 도구를 제안하며, 다양한 설명 방법에 대한 정량적 평가를 위한 표준화된 데이터, 모델, 지표를 제공한다고 명시되어 있습니다. 또한, 3가지 유형의 설명 방법을 분석하여 정량적 평가를 수행하고 있음을 보여줍니다."
An experimental study of different machine and deep learning techniques for classification of encrypted network traffic,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9378257,"There is a continuous evolution in the technology industry with different types of devices being produced and connected to the internet. Multiple types of applications run on the different devices, thereby generating a complex and huge amount of traffic (i.e., Big Data) on the internet. This has made it difficult and challenging for different Internet Service Providers (ISPs) to maintain their service quality and keep their networks and services secure. It is important for service providers to have the ability to classify large and complex network traffic to help promote a better Quality of Service (QoS) and manage networks. In this paper, we utilize, apply and evaluate different machine and deep learning techniques for classification of encrypted network traffic to help in managing networks, and thereby, help in improving quality and security of network. A comparison between the different algorithms used is presented. The experiment results show that ANN+XGB, CNN+XGB, and CapsNet+XGB performed better than the LSTM+XGB and Ensemble model in the classification of encrypted network traffic with accuracies of 96%, 96%, 96%, 93%, and 95% respectively using a total of 23 statistical features. More statistical features were considered compared to other existing related works to improve the process of the classification and different hidden patterns associated with the statistical features. The results show the effectiveness of the machine and deep learning algorithms for the classififcation of encrypted network traffic into different categories.",Yes,"논문 초록에서 여러 머신러닝 및 딥러닝 기법의 성능을 평가하기 위해 실험을 수행했음을 명확히 언급하며, 각각의 알고리즘에 대한 정확도(accuracy) 수치를 제시하고 있습니다. 이는 정량적 평가가 이루어졌음을 보여줍니다."
Robust Brain Magnetic Resonance Image Segmentation for Hydrocephalus Patients: Hard and Soft Attention,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9098541,"Brain magnetic resonance (MR) segmentation for hydrocephalus patients is considered as a challenging work. Encoding the variation of the brain anatomical structures from different individuals cannot be easily achieved. The task becomes even more difficult especially when the image data from hydrocephalus patients are considered, which often have large deformations and differ significantly from the normal subjects. Here, we propose a novel strategy with hard and soft attention modules to solve the segmentation problems for hydrocephalus MR images. Our main contributions are three-fold: 1) the hard-attention module generates coarse segmentation map using multi-atlas-based method and the Vox-elMorph tool, which guides subsequent segmentation process and improves its robustness; 2) the soft-attention module incorporates position attention to capture precise context information, which further improves the segmentation accuracy; 3) we validate our method by segmenting insula, thalamus and many other regions-of-interests (ROIs) that are critical to quantify brain MR images of hydrocephalus patients in real clinical scenario. The proposed method achieves much improved robustness and accuracy when segmenting all 17 consciousness-related ROIs with high variations for different subjects. To the best of our knowledge, this is the first work to employ deep learning for solving the brain segmentation problems of hydrocephalus patients.",Yes,"논문 초록에서 하드 및 소프트 어텐션 모듈을 활용하여 뇌 MRI 영상의 세분화(세그멘테이션)를 수행하는 방법을 제시하고 있으며, 이를 통해 정량적 평가의 일환인 세분화 정확도와 강건성을 검증하는 내용을 포함하고 있다. 따라서, 정량적 평가를 실시하고 있다고 판단된다."
"Development of a biomimetic non-invasive radial pulse sensor: Design, calibration, and applications",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7090329,"The research work aims at developing a real time non-invasive metabolism and blood circulation surveillance system for monitoring human's health condition by sensing the various bio-signals on human body. Our goal is to use the developed system to study the functions and characters of organs and tissues that highly relate with the metabolism and blood circulation system, also it is expected to help modeling the entire circulation system. At Phase I of the research, in this paper we focus on developing a new low-cost, portable, high accuracy, non-invasive radial pulse sensor. Inspired by touch capability and related biomechanical advantage of human fingertip, the mechanical design of the sensor mimics the physiological structure of human fingertip. The designed biomimetic sensor is well calibrated using a high-accuracy force sensor and the model is accurately identified by the system identification method. The calibrated sensor is then applied to diagnose the arterial stiffness by measuring the augmentation index (AI) which is the important biomarker of vascular aging. Preliminary results demonstrate the sensor performance that it is capable of non-invasively, accurately and reliably measuring radial pulse signals at real time, as well can be used to quantitatively determine the vessel aging.",Yes,"논문은 센서의 성능을 정량적으로 평가하기 위해 고정밀 힘 센서를 사용하여 교정하였으며, 혈관 강직도를 진단하는 데 중요한 생체지표인 증강 지수(AI)를 측정하는 과정을 통해 정량적 평가를 실시하고 있음을 보여줍니다. 이러한 측정과 평가 과정은 정량적 평가의 실시를 의미합니다."
Blockchain Based Decentralized Technology For Internet Naming Systems,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10461759,"Domain Name Service (DNS) has become an essential element of the Internet in current era. The traditional DNS extends its authority down to the Top Level Domains (TLDs) and individual names before returning to the Root Server. To avoid the cons related to centralized authority scheme of the traditional DNS, recently many techniques based on the decentralized Internet with support of Blockchain (BC) are emerging. Hence, currently a variety of protocols and mechanisms are focusing on implementation of the Decentralized Naming Services which in turn supports concept of decentralized internet services. These Decentralized Naming Services are totally based on Blockchain architectures and provides various pros like resistance to single point of failure, resistance to censorship and permanent proof of ownership. Blockchain Domain Names act as Digital Identity in Decentralized Internet. Security is major concern in any DNS system and the similar challenges exists in the Blockchain DNS system too. Further, there is a lot of diversity being observed in decentralized internet space as a Domain name in a Blockchain DNS can refer to a website/portal or a wallet or a Non-Fungible Token (NFT) or simply be parked. Also, currently, there is rampant growth in development of decentralized applications with no standards implemented - neither across Blockchains nor regions. Hence, there is a need to detect security exploits carried out using malicious domains in Blockchain DNS system and implement mitigation measures accordingly. In this research work, we study and analyze malicious domain names in decentralized BC system. We explored Ethereum transaction dataset for detecting malicious transactions using Machine Learning (ML) and Deep Learning (DL) algorithms with good accuracy of 99% and 95% using Decision Tree and 1 Dimensional Convolutional Neural Network (CNN) respectively. We also applied ML techniques on Ethereum wallet dark list dataset for detection of domain names that were vii used for phishing attacks. We received 96% accuracy after handling data imbalance by Random Forest model. Model predicted nature of domain based on 17 features that were extracted from Ethereum wallet dark list dataset like number of consonants, vowels, digits, symbols and their ratios to length of domain.",Yes,"논문 초록에서 머신러닝과 딥러닝 알고리즘을 사용하여 악성 도메인 이름을 탐지하는 정량적 평가를 실시했다고 명시되어 있습니다. 또한, 다양한 모델의 정확도(99%, 95%, 96%)를 제시하며 성능 평가를 수행한 점이 이를 뒷받침합니다."
DC Series Arc Fault Detection Using Machine Learning in Photovoltaic Systems: Recent Developments and Challenges,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9287192,"DC arc faults, especially series arc faults, are becoming more common in photovoltaic (PV) systems. Without timely detection and interruption, such dangerous events can cause catastrophic fires, posing severe threat to human safety and properties. This paper presents a review on DC series arc fault detection using machine learning (ML) in PV systems. Technical details of applied ML methods, including conventional ML and deep learning (DL), in recent published paper are summarized and discussed. In addition, several popular ML methods are evaluated and compared using the same experimental datasets collected in laboratory to examine their effectiveness in DC series arc fault detection. Finally, practical challenges are identified, potential solutions are provided, and future research directions are recommended.",Yes,"논문 초록에서 여러 머신러닝 방법을 적용하여 DC 시리즈 아크 결함을 정량적으로 평가하고 있음을 언급하고 있습니다. 또한, 실험 데이터셋을 사용하여 ML 방법들의 효과를 비교하는 내용이 포함되어 있어 정량적 평가가 수행되고 있음을 알 수 있습니다."
Identifying Student Profiles Within Online Judge Systems Using Explainable Artificial Intelligence,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10024788,"Online Judge (OJ) systems are typically considered within programming-related courses as they yield fast and objective assessments of the code developed by the students. Such an evaluation generally provides a single decision based on a rubric, most commonly whether the submission successfully accomplished the assignment. Nevertheless, since in an educational context such information may be deemed insufficient, it would be beneficial for both the student and the instructor to receive additional feedback about the overall development of the task. This work aims to tackle this limitation by considering the further exploitation of the information gathered by the OJ and automatically inferring feedback for both the student and the instructor. More precisely, we consider the use of learning-based schemes—particularly, multi-instance learning (MIL) and classical machine learning formulations—to model student behavior. Besides, explainable artificial intelligence (XAI) is contemplated to provide human-understandable feedback. The proposal has been evaluated considering a case of study comprising 2500 submissions from roughly 90 different students from a programming-related course in a computer science degree. The results obtained validate the proposal: The model is capable of significantly predicting the user outcome (either passing or failing the assignment) solely based on the behavioral pattern inferred by the submissions provided to the OJ. Moreover, the proposal is able to identify prone-to-fail student groups and profiles as well as other relevant information, which eventually serves as feedback to both the student and the instructor.",Yes,"논문 초록에서 정량적 평가를 위해 머신러닝 모델을 활용하여 학생 행동 패턴을 예측하고, 학생 그룹과 프로필을 식별하는 내용을 언급하고 있습니다. 이는 명확히 정량적 분석과 평가를 수행하는 연구임을 보여줍니다."
Comparative Evaluation of Model Based Deep Learning Receivers in Coded MIMO Systems,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10757517,"Deep learning (DL) methods have shown potential in tackling the performance-complexity trade-off in multiple-input multiple-output (MIMO) detection. Unlike most studies that evaluate state-of-the-art (SoA) DL receivers in uncoded scenarios, our paper focuses on realistic coded MIMO systems. After a comprehensive literature review, three representative SoA model-based DL receivers viz: DetNet, OAMPNet2, and DUIDD (MMSE-PIC and LoCo-PIC) were selected and comprehensively evaluated. Our findings indicate that DL receivers such as DetNet and OAMPNet2, which base their classical designs on the principle of symbol denoising, fail to sustain their superior performances from uncoded systems to coded systems due to inaccurate residual noise statistics. In contrast, DUIDD, specifically designed for coded systems, achieves effective interference cancellation, resulting in improved coded bit error rates across i.i.d. Gaussian channels, suggesting promising avenues for future research. However, LoCo-PIC, which simplifies MMSE-PIC with a linear solution, suffers performance degradation in correlated urban microcell channels, highlighting the importance of considering the non-linear correlation impacts during detection. Additionally, this simplification leads to further degradation in out-of-distribution channel scenarios, emphasizing the need to address these impacts in realistic wireless systems with varying channel conditions.",Yes,"논문 초록에서 여러 딥러닝 기반 수신기들을 정량적으로 평가했다고 명시되어 있으며, 성능 비교와 평가 결과를 언급하고 있습니다. 이는 정량적 평가가 수행되었음을 보여줍니다."
Assessing the Efficacy of Machine Learning and Deep Learning in the Field of Cyber Security,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10487227,"The use of machine learning has become widespread across various fields because of its superior performance compared to conventional rule-based algorithms. As a result, these models have also been integrated into cyber security systems, Machine learning is being utilized to aid or possibly even supplant the role of human security analysts. However, it's important to evaluate the effectiveness of machine learning in cyber security with careful consideration, especially if complete automation of detection and analysis is being considered. This study provides an in-depth research focuses on machine learning techniques applied in intrusion, malware, and spam detection that are tailored towards security professionals. The primary objective of our study is to evaluate the degree of advancement or maturity of these techniques of ML-based cybersecurity solutions and to identify any limitations that could impede their effectiveness as detection mechanisms. To achieve this, we conducted a thorough literature review and performed experiments on enterprise systems and network traffic in real-world settings. Our goal is to gain understanding of the capabilities and limitations of ML solutions and provide actionable insights for their improvement.",Yes,"논문 초록에서 ""실험""을 수행했다고 언급하며, 실험을 통해 머신러닝 기반 사이버 보안 솔루션의 성능과 한계를 평가하는 내용을 다루고 있습니다. 이는 정량적 평가가 이루어지고 있음을 시사합니다."
An Artificial Intelligence Computer System for Analysis of Social-Infrastructure Data,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7264719,"Development of big data analysis technologies has been highly competitive among companies and organizations. An artificial intelligence (AI) computer system, based on the basic idea of automating big-data analysis, called ""H"" is proposed and evaluated in this paper. It automates big-data analysis by creating hundreds of thousands of candidate features related to an outcome. It was applied for analyzing work-log data in a logistics company. The evaluation results confirm the effect of the system on the productivity of the company, namely, a 5.23% improvement in productivity.",Yes,"논문 초록에서 시스템의 효과를 평가하기 위해 구체적인 수치인 ""5.23% improvement""라는 정량적 결과를 제시하고 있습니다. 이는 정량적 평가를 실시했음을 보여주는 명확한 증거입니다."
Deep Learning Approach for Automated Skin Disease Diagnosis,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10808369,"Skin diseases has been a significant challenge in healthcare, necessitating accurate and timely diagnosis for effective treatment. This paper presents research on the use of Convolutional Neural Networks (CNNs) for the categorization of skin illnesses. CNNs are a viable tool for automated skin disease detection since they successfully leverage the deep learning capabilities in image-based tasks. The research begins with a detailed review of existing methodologies and datasets in the domain of skin disease classification. Subsequently, we propose a novel CNN architecture tailored to address the unique challenges posed by dermatological images, such as variability in lesion size, color, and texture. The proposed model is trained and evaluated on a diverse and extensive dataset, ensuring its robustness and generalization capabilities across various skin conditions. The study delves into the interpretability of the CNN model, providing insights into the features learned during the training process. This analysis contributes to the understanding of how deep learning models make decisions in the context of dermatological diagnosis, enhancing the trustworthiness and acceptance of such automated systems in clinical settings. Furthermore, the paper investigates the impact of data augmentation techniques on model performance, addressing the scarcity of labeled dermatological datasets. By increasing the training data, we explore strategies to improve the model’s ability to generalize to unseen cases, thereby enhancing its practical utility. Experimental results are presented and compared with state-of-the-art approaches, proving the viability of the suggested CNN architecture.",Yes,"논문 초록에서 제안된 CNN 모델의 성능 평가를 위해 실험 결과를 제시하고 있으며, 이를 기존 방법과 비교하는 내용이 포함되어 있습니다. 이는 정량적 평가가 수행되고 있음을 시사합니다."
Advancing Intrusion Detection Precision Through Analysis of Diverse Classification Algorithms,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10698858,"This research commences a thorough examination of the possibilities for leveraging Machine Learning (ML) algorithms to support Intrusion Detection Systems (IDS). We make use of the Kyoto dataset, a standard for intrusion detection studies that includes a wide variety of network traffic patterns related to both benign and malevolent activity. We carefully review a range of machine learning (ML) methods, such as decision trees, random forests, logistic regression, K-Nearest Neighbors (KNN), and Support Vector Machines (SVM) with different kernel functions. The distinct advantages and disadvantages of each algorithm in identifying network anomalies are clarified by this thorough examination. In addition to examining the detection capabilities, we delve into the performance metrics of these algorithms, including accuracy, precision, recall, and F1-score, providing a comprehensive assessment of their effectiveness. We also investigate the computational efficiency of these models by analyzing their training times and the impact of different data splits on their performance. Specifically, we evaluate batch sizes using 80:20,70:30, and 60:40 training-to-test ratios to understand their influence on the training dynamics and the overall efficacy of the IDS. Furthermore, we explore the resilience of these algorithms against various forms of intrusions, such as data alteration attempts, unauthorized access attempts, and denial-ofservice (DoS) attacks. By investigating these state-of-the-art developments and promoting a broader comprehension of IDS approaches, this research ultimately contributes to the strengthening of cybersecurity defenses over time. This guarantees the confidentiality, integrity, and availability of their vital data assets while enabling enterprises to adjust and stay resilient against the constantly shifting threat landscape within complex IT infrastructures. The source code of our paper is available at the following linkhttps://github.com/Snehitha-Narasani/IDS-using-ML-algorithms",Yes,"초록에서 여러 머신러닝 알고리즘의 성능 평가를 위해 정확도, 정밀도, 재현율, F1-score 등 다양한 성능 지표를 사용했다고 명시되어 있습니다. 이는 정량적 평가가 실시되고 있음을 보여줍니다."
Machine Learning-based Services Provisioning for Intelligent Internet of Vehicles,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9596012,"This paper is aimed to deliver a Machine Learning (ML) based intelligent system that is capable of intelligently issuing services in a pre-defined environment setup that simulates a simple real-life scenario of Internet of Vehicle (IoV). First, a detailed discussion about Vehicular Ad Hoc Networks (VANETs) and IoVs is introduced stating the significant differences between both of them and why IoVs outplay VANETs. A thorough literature review about the fundamental aspects of IoV is clearly addressed. Following the literature review, an environment setup is constructed backed up with an empirically generated dataset. This then paves the way to examine two different Machine Learning classifiers, namely Binary Logistic Regression and Shallow Neural Network for our ML based intelligent system. Both classifiers are discussed in terms of mechanism and mathematical formulation. Finally, an analysis of both classifiers’ performance along with the necessary statistical measures are presented and discussed in addition to a conclusive comparison between both classifiers.",Yes,"논문 초록에서 두 가지 머신러닝 분류기(로지스틱 회귀와 얕은 신경망)를 사용하여 성능 평가를 수행했다고 명시되어 있습니다. 또한, 성능 분석과 통계적 측정을 통해 정량적 평가를 실시한 것으로 보입니다."
Iotsdl: Internet Of Things Security For Deep Learning Techniques-A Research Perspectives,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10128558,"The Internet of Things (IoT) is an important component of information technology. New trend technology is being developed during the Industnal 4.0 Revolution. IoT connects physical things from a variety of industries, including smart homes, wearable technology, vehicular ad hoc networks (VANETs), Healthcare and Smart Cities. The number of IoT applications has dramatically increased recently, and it is predicted that by 2030, there will be 131 billion linked devices, an increase of 13% each year on average. Security is a crucial issue in today’s IoT industry. In order to detect Internet of Things attacks and identify new types of intrusion to access a more secure network, using deep learning techniques in various models is a useful tool. This helps to overcome the challenges associated with securing IoT devices. The need for developing an attack-identification and classificationsystem for intrusion detection. We provide a study on the distinction between legitimate and malicious actions in order to distinguish abnormalities and intrusions, as well as Network traffic analysis to find new threats. This paper provides broad reviews of deep learning for Internet of Things Seurity. The Major contributions are helpful for researchers and academicians for further research in the direction of Internet of Things Security. This reviews studies by assessing their effectiveness using two kinds of fresh real-time traffic information. (i.e. Bot-IoT datasets and CSE-CIC-IDS2022). We evaluate ‘accuracy rate’, ‘ detection rate’ in many system.",Yes,논문 초록에서 'accuracy rate'와 'detection rate'와 같은 정량적 평가 지표를 사용하여 딥러닝 모델의 성능을 평가했다고 언급하고 있습니다. 이는 연구에서 정량적 평가를 실시하고 있음을 보여줍니다.
Linearized Analysis of Noise and Resolution for DL-Based Image Generation,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9918072,"Deep-learning (DL) based CT image generation methods are often evaluated using RMSE and SSIM. By contrast, conventional model-based image reconstruction (MBIR) methods are often evaluated using image properties such as resolution, noise, bias. Calculating such image properties requires time consuming Monte Carlo (MC) simulations. For MBIR, linearized analysis using first order Taylor expansion has been developed to characterize noise and resolution without MC simulations. This inspired us to investigate if linearization can be applied to DL networks to enable efficient characterization of resolution and noise. We used FBPConvNet as an example DL network and performed extensive numerical evaluations, including both computer simulations and real CT data. Our results showed that network linearization works well under normal exposure settings. For such applications, linearization can characterize image noise and resolutions without running MC simulations. We provide with this work the computational tools to implement network linearization. The efficiency and ease of implementation of network linearization can hopefully popularize the physics-related image quality measures for DL applications. Our methodology is general; it allows flexible compositions of DL nonlinear modules and linear operators such as filtered-backprojection (FBP). For the latter, we develop a generic method for computing the covariance images that is needed for network linearization.",Yes,"논문은 딥러닝 기반 이미지 생성 방법의 노이즈와 해상도를 정량적으로 평가하기 위해 선형화 분석을 적용하고 있으며, 이를 통해 이미지 품질 특성을 수치적으로 평가하는 방법을 제시하고 있습니다. 또한, 다양한 수치 평가와 계산 도구를 활용하여 정량적 평가를 수행하는 내용을 포함하고 있습니다."
DEEPFAKE Image Synthesis for Data Augmentation,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9839427,"Field of medical imaging is scarce in terms of a dataset that is reliable and extensive enough to train distinct supervised deep learning models. One way to tackle this problem is to use a Generative Adversarial Network to synthesize DEEPFAKE images to augment the data. DEEPFAKE refers to the transfer of important features from the source image (or video) to the target image (or video), such that the target modality appears to animate the source almost close to reality. In the past decade, medical image processing has made significant advances using the latest state-of-art-methods of deep learning techniques. Supervised deep learning models produce super-human results with the help of huge amount of dataset in a variety of medical image processing and deep learning applications. DEEPFAKE images can be a useful in various applications like translating to different useful and sometimes malicious modalities, unbalanced datasets or increasing the amount of datasets. In this paper the data scarcity has been addressed by using Progressive Growing Generative Adversarial Networks (PGGAN). However, PGGAN consists of convolution layer that suffers from the training-related issues. PGGAN requires a large number of convolution layers in order to obtain high-resolution image training, which makes training a difficult task. In this work, a subjective self-attention layer has been added before 256 × 256 convolution layer for efficient feature learning and the use of spectral normalization in the discriminator and pixel normalization in the generator for training stabilization - the two tasks resulting into what is referred to as Enhanced-GAN. The performance of Enhanced-GAN is compared to PGGAN performance using the parameters of AM Score and Mode Score. In addition, the strength of Enhanced-GAN and PGGAN synthesized data is evaluated using the U-net supervised deep learning model for segmentation tasks. Dice Coefficient metrics show that U-net trained on Enhanced-GAN DEEPFAKE data optimized with real data performs better than PGGAN DEEPFAKE data with real data.",Yes,"논문 초록에서 AM Score와 Mode Score를 사용하여 생성된 데이터의 성능을 정량적으로 평가하는 내용을 언급하고 있습니다. 또한, Dice Coefficient와 같은 지표를 통해 데이터의 품질과 모델 성능을 수치로 평가하는 과정을 포함하고 있어 정량적 평가를 실시하고 있음을 알 수 있습니다."
Extracting Ancient Maya Structures from Aerial LiDAR Data using Deep Learning,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10115095,"The advent of LiDAR technology has had a revolutionary impact on archaeological prospection by vastly enlarging the coverage of ancient landscapes and consequently the number of ancient surface features. However, manual analysis by experts requires a significant time and money investment. This paper describes a deep learning model developed to segment, i.e., label, the semantics of objects of interest as a means to augment or supplant manual labeling of LiDAR data. The U-Net deep learning model forms the backbone of the system which has shown success in providing accurate outputs on similar LiDAR data set. The trained U-Net model is integrated into an inference pipeline to transform expansive LiDAR datasets into labeled output images. Work focuses on the classification of two semantic types: (1) platforms and (2) annular structures whose attributes, e.g., location, shape, and distribution, play an important role in improving our understanding of ancient Maya civilizations. This article provides a deep learning-based system that efficiently extracted these structures. CNN-generated inferences were compared against expert-labeled features to measure algorithm performance. Results for a LiDAR survey of 479 sq. km. indicate that the CNN provides an IoU performance of 0.82 and 0.74 for annular structures and platforms respectively. The discussion further analyzes how IoU performance relates to the viability of this approach as an aid or substitute for manual labeling.",Yes,논문 초록에서 CNN 기반 딥러닝 모델의 성능 평가를 위해 IoU(Intersection over Union) 지표를 사용하여 정량적 평가를 실시했음을 명확히 언급하고 있습니다. 이는 구조물 분류의 정확도를 수치로 측정하는 정량적 평가를 수행했음을 의미합니다.
Investigation of Dynamic Eccentricity in Interior Permanent Magnet Synchronous Motor through Finite Element Method and Machine Learning,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10696743,"Interior permanent magnet synchronous motors (IPMSM) are strong competitors to other motors in commercial and traction applications due to their high efficiency and high speed. As non-uniform air gaps are difficult to identify at the beginning level, over 10% of faults occurring in PMSM are eccentricity-related. This work investigates the effect of dynamic eccentricity in an IPMSM through finite element analysis and a machine learning approach. In this work, an IPMSM of 550 W & 220 V finite element model in ANSYS Maxwell is considered. Eccentric damages ranging from 10% to 40% were included in the model and evaluated for further study. Motor characteristics such as stator current, and radial flux density are compared for both normal and eccentric conditions. Data on motor winding current and air gap flux (radial component) were acquired from the finite element model and faults were examined utilizing MATLAB machine learning tools. The ensemble bagged trees algorithm is employed to analyze the fault which provides an accuracy of 82.5% for stator current.",Yes,"논문은 유한 요소 해석과 머신 러닝 기법을 활용하여 전동기의 특성 데이터를 정량적으로 평가하고 있으며, 특히 결함 진단의 정확도를 수치로 제시하고 있습니다. 이러한 내용은 정량적 평가를 실시하고 있음을 명확히 보여줍니다."
UbeHealth: A Personalized Ubiquitous Cloud and Edge-Enabled Networked Healthcare System for Smart Cities,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8382164,"Smart city advancements are driving massive transformations of healthcare, the largest global industry. The drivers include increasing demands for ubiquitous, preventive, and personalized healthcare, to be provided to the public at reduced risks and costs. Mobile cloud computing could potentially meet the future healthcare demands by enabling anytime, anywhere capture and analyses of patients' data. However, network latency, bandwidth, and reliability are among the many challenges hindering the realization of next-generation healthcare. This paper proposes a ubiquitous healthcare framework, UbeHealth, that leverages edge computing, deep learning, big data, high-performance computing (HPC), and the Internet of Things (IoT) to address the aforementioned challenges. The framework enables an enhanced network quality of service using its three main components and four layers. Deep learning, big data, and HPC are used to predict network traffic, which in turn are used by the Cloudlet and network layers to optimize data rates, data caching, and routing decisions. Application protocols of the traffic flows are classified, enabling the network layer to meet applications' communication requirements better and to detect malicious traffic and anomalous data. Clustering is used to identify the different kinds of data originating from the same application protocols. A proof of concept UbeHealth system has been developed based on the framework. A detailed literature review is used to capture the design requirements for the proposed system. The system is described in detail including the algorithmic implementation of the three components and four layers. Three widely used data sets are used to evaluate the UbeHealth system.",Yes,"논문 초록에서는 딥러닝, 빅데이터, HPC 등 다양한 정량적 기법을 활용하여 네트워크 트래픽 예측과 데이터 분석을 수행했다고 언급하고 있습니다. 또한, 세 가지 데이터 세트를 사용하여 시스템을 평가했다고 명시되어 있어 정량적 평가가 실시되고 있음을 알 수 있습니다."
Exploring the Influence of Emotional States in Peer Interactions on Students’ Academic Performance,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10367874,"Contribution: An AI model for speech emotion recognition (SER) in the educational domain to analyze the correlation between students’ emotions, discussed topics in teams, and academic performance.Background: Research suggests that positive emotions are associated with better academic performance. On the other hand, negative emotions have a detrimental impact on academic achievement. This highlights the importance of taking into account the emotional states of the students to promote a supportive learning environment and improve their motivation and engagement. This line of research allows the development of tools that allow educators to address students’ emotional needs and provide timely support and interventions. Intended Outcome: This work analyzes students’ conversations and their expressed emotions as they work on class activities in teams and investigates if their conversations are course-related or not by applying topic extraction to the conversations. Furthermore, a comprehensive analysis is conducted to identify the correlation between emotions expressed by students and the discussed topics with their performance in the course in terms of their grades. Application Design: The student’s performance is formatively evaluated, taking into account a combination of their scores in various components. The core of the developed model comprises a speech transcriber module, an emotion analysis module, and a topic extraction module. The outputs of all these modules are processed to identify the correlations. Findings: The findings show a strong positive correlation between the expressed emotions of “relief” and “satisfaction” with students’ grades and a strong negative correlation between “frustration” and grades. Data also shows a strong positive correlation between course-related topics discussed in teams and grades and a strong negative correlation between noncourse-related topics and grades.",Yes,"논문은 학생들의 감정, 토픽, 성적 간의 상관관계를 분석하기 위해 정량적 평가를 실시하고 있으며, 구체적인 수치와 상관관계 분석을 통해 연구 결과를 도출하고 있다. 이러한 분석은 정량적 평가의 전형적인 특징을 반영한다."
Enhancing IC Fault Diagnosis with Ensemble Learning Models: A Random Forest Perspective,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10827897,"This paper presents a comprehensive study on the application of ensemble learning models, specifically the Random Forest algorithm, for the intelligent diagnosis of faults in integrated circuits (ICs). The significance of accurate and efficient fault detection in the semiconductor industry is underscored, highlighting the need for advanced diagnostic techniques. The study reviews the landscape of traditional and machine learning-based IC fault diagnosis methods, leading to a focused discussion on ensemble learning. The theoretical framework underpinning the Random Forest model is explored, elucidating its ensemble learning principles and algorithmic components. The methodology section details the data preprocessing, feature selection, and model configuration, culminating in a rigorous empirical evaluation of the model’s performance. Results demonstrate the model’s diagnostic accuracy and robustness, supported by a series of visualizations that illustrate the decision-making process and comparative effectiveness. The discussion interprets the findings within the IC fault diagnosis context, evaluating the model’s efficacy and suggesting avenues for improvement. The paper concludes with a summary of contributions and prospects for future research, emphasizing the potential of the Random Forest model in advancing fault diagnosis capabilities.",Yes,"논문 초록에서 모델의 성능을 평가하기 위해 ""diagnostic accuracy""와 ""robustness""를 언급하며, 실험적 평가와 시각화를 통해 정량적 평가를 실시했음을 보여줍니다. 이러한 내용은 정량적 평가가 수행되었음을 명확히 나타냅니다."
A Review of YOLO Models for Soccer-Based Object Detection,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10756443,"The application of AI-driven computer vision techniques to sports footage for the purpose of automatic insight generation is a growing area of research and development. The ability to detect players of various teams along with other entities is a foundational component of such activities. This paper describes the machine learning-based detection of soccer players, balls, goalkeepers, referees, assistant referees, and other attendees from multiple teams which form the initial steps for soccer analytics. This study performs an empirical analysis of various versions of the computer vision model YOLO (You Only Look Once) using the open source soccer dataset named SoccerNet. The images contained within are trained on YOLO V3, V5, V8 and V9 with epoch configurations 1, 5, 10, 25, and 50 to facilitate a broad review of the capabilities of YOLO models. The results are evaluated using mAP50 and mAP50-95 (Mean Average Precision) metrics. YOLOv9-(9c, 9e) weights exhibited a similar level of performance to those of YOLOv8(8l, 8x), which both outperformed versions V3 and V5. However, YOLOv9 resulted in a higher true positive rate than YOLOv8, which suggests that a multi-metric analysis is pertinent for model ranking. The results of each model variant utilised are reported and visualized for reproducibility and to form a benchmark supporting future studies. The implementation was performed using the Python-based Ultralytics library.",Yes,논문은 다양한 YOLO 모델의 성능을 평가하기 위해 mAP50 및 mAP50-95와 같은 정량적 지표를 사용하여 실험적 분석을 수행하고 있다. 이러한 평가 지표를 통해 모델의 성능을 수치적으로 비교하고 있기 때문에 정량적 평가를 실시하고 있다고 볼 수 있다.
The Use of Blockchain to Support Distributed AI Implementation in IoT Systems,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9372311,"This article presents a distributed and decentralized architecture for the implementation of distributed artificial intelligence (DAI) using hardware platforms provided by the Internet of Things (IoT). A trained DAI system has been implemented over IoT, where each IoT device acts as one or more of the neurons within the DAI layers. This is accomplished by the utilization of decentralized, self-managed blockchain technologies that allow trusted interactions and information to be exchanged between distributed neurons. The platform was built and customized to be used within the IoT system, and it is capable of handling DAI-related tasks. A new consensus mechanism based on Proof of Authority (PoA) and Proof of Work (PoW) has been designed and implemented, along with bespoke block and transaction formats. The proposed architecture was analyzed, implemented, and tested using a dedicated testbed with low-cost IoT devices. A quantitative measurement and performance evaluation of the system based on a real-world IoT application was conducted. The implemented DAI is found to have an accuracy of 92%–98%, with an energy cost of 0.12 joules (J) when utilizing a Raspberry Pi to run one neuron. The measured hash per joule (h/J) when using a Raspberry Pi for mining is 13.8 Kh/J compared to 54 Kh/J using an ESP32. The results showed that it is feasible to implement a DAI system utilizing the IoT hardware platform while maintaining the system’s accuracy. The integration of the blockchain has added an element of security and trust to the data and the interaction between system components.",Yes,"논문 초록에서 시스템의 성능 평가를 위해 정량적 측정과 성능 평가가 수행되었음을 명확히 언급하고 있습니다. 구체적인 정확도, 에너지 비용, 해시율 등의 수치 데이터를 통해 정량적 평가를 실시한 것으로 보입니다."
An Unobtrusive Stress Recognition System for the Smart Office,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8856597,"This paper presents a novel approach to monitor office workers' behavioral patterns and heart rate variability. We integrated an EMFi sensor into a chair to measure the pressure changes caused by a user's body movements and heartbeat. Then, we employed machine learning methods to develop a classification model through which different work behaviors (body moving, typing, talking and browsing) could be recognized from the sensor data. Subsequently, we developed a BCG processing method to process the data recognized as `browsing' and further calculate heart rate variability. The results show that the developed model achieved classification accuracies of up to 91% and the HRV could be calculated effectively with an average error of 5.77ms. By combining these behavioral and physiological measures, the proposed approach portrays work-related stress in a more comprehensive manner and could contribute an unobtrusive early stress detection system for future smart offices.",Yes,"논문은 머신러닝을 활용하여 행동 인식의 분류 정확도를 평가하는 등 정량적 평가를 실시하고 있습니다. 또한, 심박수 변동성(HRV)의 계산 오차를 수치로 제시하여 정량적 성능 평가를 수행하고 있습니다."
Text Filtering Insignificant Word (TFIW) Readability Framework Model to Explain NLP in Sentiment Analysis Using Reinforcement Machine Learning,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10894597,Reading of a text in a given sentence have lot of parameters to consider for expressing an opinion on a given text to conclude nature of the text. The data which need to be formed in the form of data sets based on specific constrains. The Natural Language Processing (NLP) will always presume that Text readability made as the considerable measure for better round spread of any newspaper. The data related to these documents must be collected and store them in data sets. During this process of measuring text readability at the granular level of the text reading is a cumbersome task. This will always implicate a problem of machine readability of the text and explainability of the text taken from the documents mentioned above. In this context human readability will act an important role in predicting the text reading at granular level where the text-based sentiment analysis have been predicted through a machine learning model. The text reading has been evaluated in order to improve the readability through explainable system. The explainable systems will capture and explain the predictions of text reading. In this technical work an explainable system Text Filtering Insignificant Word (TFIW) is introduced where it improves the textual reading at the granule level based on sentiments by prediction the words which need to be filtered. This will improve the explainability of text and text reading and improve the fast text and explainability of the document.,Yes,"논문 초록에서 텍스트 읽기와 관련된 평가를 개선하기 위해 TFIW 시스템을 도입하는 내용을 언급하며, 텍스트의 가독성 향상과 관련된 평가를 수행하는 것으로 보입니다. 또한, 텍스트의 이해와 설명 가능성을 높이기 위해 특정 단어를 필터링하는 방법을 제시하고 있어, 정량적 평가가 실시되고 있음을 시사합니다."
Cathode Position Detection in a Transferred Arc Plasma Using Artificial Neural Network,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9998184,"In a transferred arc plasma system, the position of the cathode is difficult to detect during the smelting process as it remains inside the cylindrical anode. Real-time and accurate cathode position detection leads to efficient smelting operation with optimal use of electrical energy. In this article, a machine learning technique is proposed to accurately detect the position of the cathode in a direct current (DC) transferred arc plasma system. The measured voltage signal sampled at 20 kHz is processed using a tunable Q-factor wavelet transform (TQWT) followed by statistical features extraction and a machine learning algorithm to provide accurate cathode position information. Two different machine learning algorithms are used in this work, namely, single hidden layer neural network (SHLNN) and single-layer extreme learning machine (SELM). The output of these machine learning algorithms provides accurate position information and is also compared to the traditional voltage-related position information. The experimental signal of a 30-kW DC plasma system and cathode position detection results is shown.",Yes,"논문 초록에서 두 가지 머신러닝 알고리즘(SHLNN과 SELM)을 사용하여 정량적 평가를 수행했다고 명시되어 있습니다. 또한, 실험 신호와 검증 결과를 통해 정확한 위치 정보를 제공하는 것으로 언급되어 있어 정량적 평가가 실시된 것으로 판단됩니다."
GitHub Bug Classification Using Pipeline Approach in Machine Learning,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10452560,"GitHub bug classification refers to the process of automatically categorizing bug reports or issues on GitHub into predefined categories based on their text content. This process helps to improve the efficiency of software development teams by reducing the time spent on manual issue triage. By using machine learning techniques such as Naive Bayes, Decision Trees, and Logistic Regression, a model can be trained on a dataset of past issues and then used to classify new issues as they are submitted. This study aims to build a machine-learning model for GitHub bug classification using a pipeline approach and evaluate its accuracy, precision, and recall performance.The study also includes a comprehensive literature review of bug tracking and classification techniques, existing systems and approaches, and evaluation metrics for performance measures. The research design and strategy, data collection and sources, and ethical considerations are also discussed in detail.The practice of automatically classifying bug reports or issues on GitHub into specified categories based on their text content is called GitHub bug categorization. By cutting down on the time needed for manual problem triage, this technique increases the effectiveness of software development teams.",Yes,"초록에서 연구가 모델의 정확도, 정밀도, 재현율 등의 성능 평가를 포함한다고 명시되어 있어, 정량적 평가를 실시하고 있음을 알 수 있습니다. 이러한 평가는 일반적으로 수치 데이터를 기반으로 하는 정량적 방법입니다."
Convolutional Neural Network in Combination with Multiple Machine Learning Models to Recognize the Spoken Digits,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10859457,"The classification of audio signals plays a crucial role in various applications including speech recognition, analysis of environmental audio, and music classification. Digit recognition, as a subset of audio classification, plays an essential role in domains comprising automated systems, telecommunications, transport systems, and security. A review of recent research papers in the field of audio classification, focusing on the use of Artificial Intelligence such as Neural Networks, and ML - Machine Learning, along with its hybrid models, has been conducted. The objective is to enhance training accuracy using the Mel Spectrogram in CNN - Convolutional Neural Networks and improve prediction accuracy with ML models. Various hybrid approaches, including CNN combined with Logistic Regression, K-Nearest Neighbor, Random Forest, Decision Tree, Naive Bayes, Support Vector Machine, Gaussian Mixture Model, and Linear Discriminant Analysis, have been evaluated. The proposed method, CNN combined with Logistic Regression, establishes the highest accuracy compared to the other models. Experimentation was conducted using the Audio MNIST dataset, which includes 10 distinct classes of digits. Numerical results reveal that the CNN + Logistic Regression accomplished the highest Accuracy value of about 99%, and CNN + K-Nearest Neighbor achieved 98%, making CNN + Logistic Regression the most effective model for digit recognition within the audio classification field.",Yes,"논문 초록에서 다양한 모델의 성능을 정량적으로 평가한 결과를 제시하고 있으며, 특히 정확도(Accuracy)와 같은 수치적 지표를 통해 모델의 성능을 비교하고 있습니다. 이러한 내용은 정량적 평가를 실시하고 있음을 명확히 보여줍니다."
A Deep Learning-Based Approach to Strawberry Grasping Using a Telescopic-Link Differential Drive Mobile Robot in ROS-Gazebo for Greenhouse Digital Twin Environments,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10807213,"The primary goal of this research is to develop a deep learning-powered robotic solution to address labor shortages and optimize harvesting processes in strawberry greenhouse farms. By incorporating this system into the development process, the aim is to provide continuous, 24/7 operational efficiency for strawberry harvesting in greenhouse environments. This study is grounded in a comprehensive literature review of simulated environments, such as ROS-Gazebo, deep learning detection models, and mobile robot platforms, with a focus on developing innovative robotic solutions for strawberry detection and grasping in a simulated digital twin greenhouse environment. The YOLOv9-GLEAN deep learning model, with super-resolution capabilities, is introduced to enhance strawberry detection accuracy by generating high-resolution image features. We developed a digital twin model of the SILAL strawberry greenhouse farm in Abu Dhabi, UAE, within the ROS-Gazebo environment, to validate our algorithm and test the MARTA (Mobile Autonomous Robot with Telescopic Arm) robot. The dataset used to improve model performance includes both real strawberry images from greenhouse farm and synthetic CAD-generated images. ROS-MoveIt was employed to implement visual servoing, allowing the robot to generate precise motion trajectories to approach and grasp identified strawberries, with visual feedback enhancing accuracy. Empirical results show that our proposed detection model outperforms other existing models, achieving a precision of 0.996 and a recall of 0.991. The model’s adaptability to varied datasets, including real and synthetic images, is notable, and it performs exceptionally well in the simulated digital twin model of the greenhouse farm. The model is uniquely trained on both real and synthetic strawberry images to ensure robust detection performance. It is compared to state-of-the-art models and deployed on a telescopic arm-based robotic platform, which is simpler to control than an articulated arm for strawberry harvesting and grasping tasks.",Yes,"논문 초록에서 딥러닝 모델의 성능 평가를 위해 정밀도(0.996)와 재현율(0.991)과 같은 정량적 지표를 사용하여 평가한 내용을 명확히 언급하고 있습니다. 또한, 모델의 성능 비교와 검증을 위해 실험적 수치를 제시하고 있어 정량적 평가를 실시하고 있음을 알 수 있습니다."
Design Amharic Text Sentiment Analysis Model Using Machine Learning Techniques. In Case of Restaurant Reviews,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10302239,"Sentiment analysis is a type of natural language processing for tracking the attitude of the public about a particular product, service or topic. It is also highly challenging as natural language processing research topic, and covers many novel sub-problems. Now business organizations and academics are putting forward their efforts to find the best system for sentiment analysis. The focus of this study was an Amharic unstructured restaurant review on the web. The objective of the paper was to design Amharic text sentiment analysis model using supervised machine learning techniques and evaluate the performance of classifiers. This paper explored the supervised machine learning classification approaches (naive Bayes, support vector machine and k-nearest neighbor) with different feature selection schemes to obtain a sentiment analysis model for domain specific restaurant review dataset at sentence level. The proposed model has the following components: Data preparation, preprocessing such as tokenization, normalization, filter stop words, feature extraction and selection to prepare feature vector, polarity classification. Performance analysis carried out on classifiers, based on n-grams proposed. From the results of the experimental studies, all algorithms are known to be highly effective classifiers, and are able to achieve good accuracy in this experiment. The experiments show that Term frequency (TF) and the TF -IDF scheme gives maximum accuracy 80.43 % and 79.49 % respectively for SVM in bigram features. Term frequency and term occurrence also give maximum accuracy 78.37 % and 78.00 % respectively for Naive Bayes classifier at bigram features. TF-IDF also give maximum accuracy 78.00% for KNN at 4-gram. The challenge was opinion holders sometimes give objective text to express their opinion, but the classifier did not identify those facts from opinions. These kinds of complexities of natural languages make sentiment mining systems more challenging and to resolving this challenge subjectivity and objectivity classification is needed.",Yes,"논문 초록에서 여러 분류기(나이브 베이즈, 서포트 벡터 머신, K-최근접 이웃)를 사용하여 성능 평가를 실시했다고 명시되어 있습니다. 또한, 정확도(accuracy)와 같은 정량적 지표를 통해 성능을 평가하는 내용이 포함되어 있어 정량적 평가를 수행하고 있음을 알 수 있습니다."
Rapid Wildfire Hotspot Detection Using Self-Supervised Learning on Temporal Remote Sensing Data,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10641631,"Rapid detection and well-timed intervention are essential to mitigate the impacts of wildfires. Leveraging remote sensed data from satellite networks and advanced AI models to automatically detect hotspots (i.e., thermal anomalies caused by active fires) is an effective way to build wildfire monitoring systems. In this work, we propose a novel dataset containing time series of remotely sensed data related to European fire events and a Self-Supervised Learning (SSL)-based model able to analyse multi-temporal data and identify hotspots in potentially near real time. We train and evaluate the performance of our model using our dataset and Thraws, a dataset of thermal anomalies including several fire events, obtaining an F1 score of 63.58.",Yes,논문은 모델의 성능을 평가하기 위해 F1 점수라는 정량적 지표를 사용하여 평가를 실시하고 있습니다. 이는 정량적 평가를 수행하고 있음을 보여줍니다.
Using Echocardiography and AI to Predict Cardiac Biological Age,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10633303,"Biological age is a personalized measure of the health status of an organism, organ, or system, as opposed to simply accounting for chronological age. To date, there have been known attempts to create estimators of biological age based on various biomedical data. In this work, we focused on developing an approach for assessing heart biological age using echocardiographic data. The current study included echocardiographic data from more than 5,000 different cases. As a result, indicators such as EA (E/A ratio of maximum flow rates in the first and second phases), IVS (thickness of the interventricular septum), LVPW (thickness of the posterior left ventricular wall), LVCO (cardiac output), and RWT (relative wall thickness) showed the greatest predictive potential. Based on these parameters, we created and trained neural network models to determine heart biological age, with a Mean Absolute Error (MAE) of approximately 3.5 years, an R-squared (R2) value of around 0.87, and a Spearman's rank correlation coefficient (rho) greater than 0.9 in men. In women, the MAE was approximately 3.4 years, with an R2 value of around 0.89 and a rho greater than 0.9. In addition, we have applied an AI explanation algorithm to improve understanding of how the model performs an assessment. Furthermore, the EchoAGE model was tested on echo cardiographic data from patients with age-related diseases, patients with multimorbidity, children with progeria syndrome, and diachronic data series.",Yes,"논문은 심장 생물학적 나이를 예측하기 위해 신경망 모델을 개발하고 훈련시켰으며, MAE, R-squared, Spearman's rho와 같은 정량적 평가 지표를 사용하여 모델의 성능을 평가하고 있습니다. 이러한 평가 지표들은 정량적 평가를 실시하고 있음을 보여줍니다."
Classification of OLTC defects based on AE signals measured by two different transducers,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8778140,"The subject of the article is related to diagnosis of on-load tap-changer (OLTC) based on acoustic emission (AE) signals measured by two different transducers. The main advantage of the AE method is the possibility of its application during normal operation without having to turn off the device under investigation. Based on chosen parameters of the AE signal various defects of the OLTC may be recognized. A number of signals, gathered from laboratory tests, in which four types of typical OLTC defects were simulated, was applied for classification studies with the use of artificial intelligence methods. In particular seventeen different supervised learning algorithms were investigated, while their effectiveness was compared by using common measures. Based on the performed studies the best algorithm for each of the two applied transducers was determined. Results of the works in form of the chosen algorithm may be applied in an expert system for diagnosis of OLTC devices when using different AE measuring sensors.",Yes,"논문 초록에서 다양한 인공 지능 방법을 이용한 분류 연구를 수행하였으며, 여러 알고리즘의 성능을 비교하는 과정이 포함되어 있어 정량적 평가가 실시된 것으로 보입니다. 따라서, 논문은 정량적 평가를 수행하고 있다고 판단됩니다."
Unsupervised classification of online community input to advance transportation services,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8301704,"The traditional approach taken by transit agencies to assess their performance is through regular rider surveys. The performance metrics include safety, timeliness, efficiency, and cleanliness. However, with the increased use of online social media by the public, including users of public transit, it has become possible to automatically summarize the riders' opinions on the services provided by transit agencies by statistical analysis of the words used in the social media messages. This work describes a system based on machine learning to summarize text messages regarding transportation in California on online social media platforms. This tool is intended to reveal factors important to transportation users that may not be evident to transit agencies and hence will not be collected by rider surveys. The system uses an unsupervised statistical topic modeling algorithm (latent Dirichlet allocation) to cluster public messages related to transportation on the Twitter social media platform into distinct “topics.” Sentiment analysis was then utilized to assign a polarity (positive, negative, or neutral) to each message and then the sentiment is aggregated by topic. The system is thus able to summarize the sentiment towards each automatically identified topic. The approach was applied to a set of 10,400 tweets containing words related to transportation; these messages were downloaded over a period of three weeks in 2016. The proposed system was evaluated by varying topic modeling algorithm parameters and studying the effect of parameters on the interpretability of results. It was found that the quality of topic identification depends on the size of the dataset, the number of topics that has to be specified to the topic modeling algorithm, and the positive/negative thresholds for the sentiment analysis algorithm.",Yes,"논문은 머신러닝 기반의 시스템을 사용하여 온라인 소셜 미디어 메시지의 텍스트를 분석하고, 주제별 감성 분석을 수행하는 등 정량적 평가 방법을 적용하고 있습니다. 이러한 분석은 통계적 기법과 알고리즘의 파라미터 조정을 통해 결과의 품질을 평가하는 과정을 포함하고 있어 정량적 평가를 실시한다고 볼 수 있습니다."
An Efficient Hybrid Quantum Variational Classifier With Matrix Product State,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10888238,"Matrix Product States have been extensively explored as a powerful tool for simulating quantum states in image classification task. However, most research has focused on classical simulations or computations involving high-dimensional unitaries, and significant challenges still exist in the practical preparation of Matrix Product States on quantum computers. This paper proposes a novel and practically feasible quantum variational algorithm based on Matrix Product States for image classification task. We design a hardware-efficient quantum circuit with several adjustable entangling operators to prepare the local tensors in Matrix Product States and integrate minimal residuals to ensure computational stability. We demonstrate that our algorithm can reduce the parameter complexity from growing exponentially with the system size to a linear scale. To validate the effectiveness of this quantum variational algorithm, we conducted experiments on the MNIST dataset, achieving accuracies of 99.95% and 95.96% for binary and ten-class classification tasks, which outperforms other related quantum algorithms. This work advances the practical application of quantum machine learning in resource-constrained environments of quantum computing.",Yes,논문 초록에서 실험을 통해 MNIST 데이터셋에 대한 분류 정확도를 측정하는 등 정량적 평가를 수행했음을 명확히 언급하고 있습니다. 이는 연구의 성과를 수치로 평가하는 정량적 평가의 실시를 보여줍니다.
Forecasting Students Academic Achievement Using Machine Learning Techniques,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10531560,"In today’s competitive world, investigating students learning performance is the major component for accessing any educational systems, Predicting the students’ performance in academics is a difficult task. In order to address this, researchers use the EDM (Educational Data Mining) technique to examine data from educational settings and enhance the educational system based on the collected data. This allows for a more accurate and comprehensive understanding of students' performance and helps them achieve better educational outcomes. Prediction of student performance in academics helps to analyze students community in better understandable and communicable with the wide range of socio demographic(age, gender, family, size, obesity, marital status of parents, occupation,),learning practices(school level), student related(stress and lifestyle) variables Numerous methods are employed to assess students' academic performance; however, the primary goal of this work is to build a prediction model through the application of machine learning techniques, such as logistic regression, K-Nearest Neighbor algorithm (KNN), and Support Vector Machine (SVM).Multiple approaches are used here to measure the performance of academics of students along with good prediction method based on accuracy. The predictive models offer valuable insights into the factors influencing academic success, allowing for the allocation of resources through social media and interventions more effectively. The prediction is a variable that helps to predict how many hours they spend on internet in some activities based on data collected. The result is a predictor variable that aids in forecasting academic achievement on the final exam of the semester (CGPA). The study identifies the lagged part of the studies and how it affect the education history in future. The results as the prediction have been increased which helps the institution and others in encouraging and help the students in different ways. The health-conscious lifestyle positively helps to improve the performance in academics. However, gender is not significant predictor to predict performance and classify their talents based on their skills helps to enhance their performance",Yes,"논문 초록에서 여러 머신러닝 기법(로지스틱 회귀, KNN, SVM)을 사용하여 학생들의 학업 성취도를 예측하는 모델을 구축하고, 그 성능을 평가하는 방법이 언급되어 있습니다. 이는 정량적 평가를 실시하고 있음을 보여주는 명확한 증거입니다."
Machine Learning for Data Trust Evaluations in Blockchain-Enabled IoT Systems,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10634433,"Recently, there has been a surge of interest surrounding the integration of blockchain with the Internet of Things (IoT), aiming to address IoT’s inherent issues like single points of failure and concerns related to data integrity. However, although blockchain provides decentralization and transparency, it does not guarantee the accuracy and reliability of IoT-generated data. Therefore, additional measures are needed to assess and verify the reliability of IoT data stored on blockchains. In this demonstration, we present a novel approach that employs support vector machine (SVM) models in edge servers and multiple machine learning (ML) models executed by validators for data trust evaluations in blockchain-enabled IoT systems. Our approach introduces a composite trust metric that combines past device reputation on the blockchain with real-time data assessment enabled by SVM models. This composite measure provides a dynamic method for determining the trustworthiness of data at the point of submission. The multiple different ML models used by validators work as a distributed ensemble, leading to improved classification accuracy. This novel approach helps to calculate reputation scores more accurately, increasing the system’s reliability. We illustrate the feasibility of our approach through a description of our prototype implementation.",Yes,"논문 초록에서 Support Vector Machine (SVM)과 여러 머신러닝(ML) 모델을 활용하여 데이터 신뢰도를 평가하는 방식을 제시하고 있으며, 이를 통해 정량적 평가가 수행되고 있음을 알 수 있습니다. 또한, 신뢰도 계산과 분류 정확도 향상을 위해 구체적인 머신러닝 기법들이 사용되고 있음을 명확히 언급하고 있습니다."
Coupling Machine Learning Models with Innovative Technology-based Screening Tool for Identifying Psychological Distress among Aboriginal Perinatal Mothers,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10340563,"Aboriginal perinatal mothers are at a significant risk of experiencing mental health problems, which can have profound negative impacts, despite their overall resilience. This work aimed to build prediction models for identifying high psychological distress among Aboriginal perinatal mothers by coupling machine learning models with an innovative and culturally-safe screening tool. The original dataset of 179 Aboriginal mothers with 337 variables was obtained from twelve perinatal health settings at Perth metropolitan and regional centers in Western Australia between July and September 2022, using a specifically designed web-based rubric for the perinatal mental health assessment. After data preprocessing and feature selection, 23 variables related to emotional manifestations, the problematic partner, worries about daily living, and the need for follow-up wraparound support were identified as significant predictors for the high risk of psychological distress measured by the Kessler 5 plus adaptation. The selected predictors were used to train prediction models, and most of the chosen machine learning models achieved satisfactory results, with Random Forest and Support Vector Machine yielding the highest AUC of over 0.95, accuracy over 0.86, and F1 score above 0.87. This study demonstrates the potential of using machine learning-based models in clinical decision-making to facilitate healthcare and social and emotional well-being for Aboriginal families.",Yes,"논문은 머신러닝 모델을 사용하여 예측 성능을 평가하고 있으며, AUC, 정확도, F1 점수와 같은 정량적 지표를 제시하여 정량적 평가를 실시하고 있음을 보여줍니다. 이러한 지표들은 모델의 성능을 수치로 측정하는 정량적 평가의 대표적인 예입니다."
Generalization vs Personalization: A Trade-off for better Data Heterogeneity impact Mitigation in FL,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10901830,"Federated learning (FL) was introduced recently as a new machine learning (ML) paradigm. It is a distributed network of client nodes that train ML and deep learning (DL) models on their local data without sharing them to preserve data privacy (DP). However, these data are heterogeneous by nature as they are collected in different contexts using various sources such as IoT devices. Consequently, data heterogeneity (DH) in FL has brought new performance-related challenges. Few of these challenges have been addressed in the literature; moreover, context heterogeneity and balance rate were not explored at all. In this paper, we introduce an FL approach in which a trade-off between personalization and generalization is achieved to mitigate the impact of DH and obtain better performance. We focus on three DH challenges: context, non-independent and identically distributed (non-IID) data, and balance rate. For the implementation, fall detection (FD) data is used to demonstrate the potential of our approach in improving the FL system’s performance. FD is an important subject and is particularly prevalent for the safety of elderly people. Hence, we collected fall data from two sensors: accelerometer (ACC) and heart rate (HR), then, we used two ML models to evaluate our approach. We utilized XGBoost (XGB) for balanced and unbalanced clients and One-Class Support Vector Machine (OC-SVM) for one-label clients. Our approach achieved an average F1-score of 88%. A comparative study was also conducted with previous works on FD. Our results showed a performance improvement which exceeded 94.30% on average.",Yes,"논문 초록에서 다양한 평가 지표인 F1-score와 성능 향상률(94.30%)을 언급하며, 실험을 통해 정량적 평가를 실시했음을 명확히 보여줍니다. 이는 연구의 성과를 수치로 측정하고 검증하는 정량적 평가가 수행되었음을 의미합니다."
Automation of Bug-Report Allocation to Developer using a Deep Learning Algorithm,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9493515,"Software bug maintenance is an important aspect of all software projects. The assignment of bug reports is essential in order to resolve bugs efficiently. In the case of open-source software developments and large projects, where many developers are engaged on different aspects of software development, it can be difficult to assign bug removal tasks to an appropriate developer. An increase in reported bugs, coupled with an increase in the number of software developers, will complicate the bug triage process. In these situations, bug triaging might be slow and may increase the Bug Tossing Length (BTL). An automated system to triage bug reports could potentially reduce BTL, as manual assignment of bug reports is tiresome, costly, and very time-consuming. The assignment of bug reporting to an irrelevant developer who does not possess sufficient experience to deal with the bug will adversely impact BTL and customer satisfaction. Text-based classification methods have the potential to make a strong contribution to automating the bug triaging process. In this research, different types of Information Retrieval and Machine Learning algorithms are used to determine the appropriate developer/s to rectify the reported bugs. This study used deep learning algorithms, such as the Bidirectional Long Short-Term Memory Network, to automate the bug triaging process. Bug reports contain textual data related to the bug information. In this research, the pretrained GloVe model is employed for word-to-vector representation of bug reports’ textual information. In this framework, developers’ activities are monitored based on their working history. To test the proposed approach, three large datasets, Net-Beans, Eclipse, and Mozilla, are used. It was observed that the proposed technique produced better results in terms of accuracy, recall, precision and f-measure compared to traditional Machine Learning algorithms for bug report recommendation.",Yes,"논문 초록에서 딥러닝 알고리즘과 텍스트 분류 방법을 사용하여 버그 보고서의 적절한 개발자를 정량적으로 평가하는 실험을 수행했다고 언급하고 있습니다. 또한, 제안된 기법이 정확도, 재현율, 정밀도, F-측정값 등 다양한 성능 지표를 통해 평가되었다고 명시되어 있어 정량적 평가가 실시되고 있음을 알 수 있습니다."
"Review on Scheduling, Clustering, and Forecasting Strategies for Controlling Electric Vehicle Charging: Challenges and Recommendations",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8825773,"The usage and adoption of electric vehicles (EVs) have increased rapidly in the 21st century due to the shifting of the global energy demand away from fossil fuels. The market penetration of EVs brings new challenges to the usual operations of the power system. Uncontrolled EV charging impacts the local distribution grid in terms of its voltage profile, power loss, grid unbalance, and reduction of transformer life, as well as harmonic distortion. Multiple research studies have addressed these problems by proposing various EV charging control methods. This manuscript comprehensively reviews EV control charging strategies using real-world data. This review classifies the EV control charging strategies into scheduling, clustering, and forecasting strategies. The models of EV control charging strategies are highlighted to compare and evaluate the techniques used in EV charging, enabling the identification of the advantages and disadvantages of the different methods applied. A summary of the methods and techniques for these EV charging strategies is presented based on machine learning and probabilities approaches. This research paper indicates many factors and challenges in the development of EV charging control in next-generation smart grid applications and provides potential recommendations. A report on the guidelines for future studies on this research topic is provided to enhance the comparability of the various results and findings. Accordingly, all the highlighted insights of this paper serve to further the increasing effort towards the development of advanced EV charging methods and demand-side management (DSM) for future smart grid applications.",Yes,"초록에서 EV 충전 제어 전략을 평가하기 위해 다양한 모델과 기법들을 비교하고 평가하는 내용이 언급되어 있습니다. 특히, 실세계 데이터를 활용한 정량적 평가와 기법들의 장단점을 분석하는 부분이 포함되어 있어 정량적 평가가 수행되고 있음을 알 수 있습니다."
Towards A Machine Learning Framework for Suicide Ideation Detection in Twitter,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9918782,"A worldwide rise of number of individuals had been observed to commit suicide at young age since 2019. With emergence of digital technologies, more suicides attempts were seen to have been pre-communicated through social media posts before the attempts. As such, much initiatives had been conducted to detect communication of distress on social media which imply risks of suicide attempts or any related forms of self-harm. Such initiatives aim to predict the possibility of suicide attempts for prevention measures. This work proposes a framework for machine learning of suicide ideation detection in social media which will contribute to the prediction of possibility of suicide attempt in a social media post. The framework includes data acquisition, data annotation, data pre-processing, feature extraction, classification and performance evaluation of the machine learning model. Acquisition of social media post samples from Twitter is proposed for training and testing datasets through representational state transfer application programming interface. Manual annotation is conducted on the training datasets with different formulated suicide risks. Data pre-processing is done through natural language toolkit and performance evaluation through valence aware dictionary for sentiment reasoning. This work will be further extended with a web-based application for implementation and evaluation of the trained machine learning model.",Yes,"논문 초록에서 데이터 수집, 데이터 전처리, 특징 추출, 분류, 성능 평가 등 다양한 단계에서 정량적 평가가 수행되고 있음을 언급하고 있습니다. 특히, 성능 평가를 위한 구체적인 방법이 포함되어 있어 정량적 평가를 실시하는 것으로 판단됩니다."
Extraction-Based Text Summarization and Sentiment Analysis of Online Reviews Using Hybrid Classification Method,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8995164,"The field of sentiment mining and text summarization has evoked the interest of many scientists and researchers over the last few years, as the textual data has become useful for many real-world applications and challenges. Sentiment Analysis and Opinion Mining is the most popular field for analyzing and discovering insights from text data from various sources, such as Facebook, Twitter and Amazon, Zomato, etc. It involves a computational study of an individual’s behavior in terms of buying interest and then extracting his opinions on the business entity of the company. This entity can be viewed as an event, individual, blog post or product experience. Scholars in the fields of natural language processing, data mining, machine learning and others have tested a variety of methods for automating sentiment analysis. These reviews are increasing on a daily basis, as a result of which the summarization of the reviews plays a role where the text is summarized as needed, which provides useful information from a large number of reviews. It is very difficult for a human being to extract and interpret useful data from a very large file. In the text analysis, the value of sentences is decided on the basis of the linguistic characteristics of sentences. This paper provides a comprehensive review of current and past work on sentiment analysis and text description. In this research work, a new hybrid classification system is proposed based on coupling classification methods using arcing classifiers and their quality is evaluated within terms of accuracy. The Classifier Collection was constructed using Naïve Bayes (NB), Support Vector Machine (SVM) and Genetic Algorithm (GA). The proposed work consists of a comparative study of the efficacy of the ensemble technique for sentiment classification. The feasibility and benefits of the proposed approaches are demonstrated by a restaurant review that is widely used in the field of sentiment classification. A wide range of comparative studies is performed and, ultimately, some in-depth analysis is addressed and conclusions are drawn on the efficacy of the ensemble technique for sentiment classification.",Yes,"논문 초록에서 정량적 평가를 위해 Naïve Bayes, Support Vector Machine, Genetic Algorithm 등 다양한 분류 기법을 사용하여 성능을 평가했다고 명시되어 있습니다. 또한, 분류 방법의 효율성을 비교하는 연구를 수행하여 정량적 평가를 실시하고 있음을 알 수 있습니다."
Handwriting Styles: Benchmarks and Evaluation Metrics,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8554834,"Extracting styles of handwriting is a challenging problem, since the style themselves are not well defined. It is a key component to develop systems with more personalized experiences for humans. In this paper, we propose baseline benchmarks, in order to set anchors to estimate the relative quality of different handwriting style methods. This will be done using deep learning techniques, which have shown remarkable results in different machine learning tasks, learning classification, regression, and most relevant to our work, generating temporal sequences. We discuss the challenges associated with evaluating our methods, which is related to evaluation of generative models in general. We then propose evaluation metrics, which we find relevant to this problem, and we discuss how we evaluate the performance metrics. In this study, we use IRON-OFF dataset [1]. To the best of our knowledge, no existing benchmarks or evaluation metrics for this task exit yet, and this dataset has not been used before in the context of handwriting synthesis.",Yes,"논문은 다양한 평가 지표를 제안하고, 이를 통해 손글씨 스타일 생성 방법의 성능을 평가하는 방법을 논의하고 있습니다. 또한, 벤치마크와 평가 지표를 설정하여 정량적 평가를 실시하는 방식을 명확히 제시하고 있습니다."
A Learning-Based NLOS Mitigation Method for Single-Anchor SLAM,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9769439,"Location-awareness has playing an increasingly important role in wireless networks. Indoor radio frequency-based simultaneous localization and mapping (SLAM) can be enabled through ultra-wide bandwidth systems due to its ability to provide accurate channel information. In this paper, we provide a deep learning approach to improve the localization accuracy of users and reflection points based on a single-anchor ultra-wide bandwidth system in indoor complex environments. In the proposed approach, we propose a deep generative model to mitigate the distance and the angle-of-arrival estimation errors introduced by non-line-of-sight propagation. Instead of manually extracting features, we make full use of the amplitude and phase information in the channel impulse response to obtain more location-related information. Our work is validated by an indoor sufficient measurement campaign with self-built FCC-compliant ultra-wide bandwidth transceivers, and the results show that our approach outperforms conventional machine learning approaches in practical scenarios.",Yes,"논문 초록에서 제안하는 딥러닝 기반 방법의 성능 검증을 위해 실내 측정 캠페인을 수행했다고 언급되어 있으며, 결과가 기존 방법보다 우수하다고 평가하고 있습니다. 이는 정량적 평가가 이루어졌음을 시사합니다."
Affective Lexicon for Intelligent Tutoring Systems,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10261000,"Affective Tutoring Systems (ATS) is a next-generation Intelligent Tutoring System (ITS) that can detect learners' affective states and provide affective interventions to encourage learners and improve their motivation to learn using artificial intelligence techniques. However, little research has been done on creating an educational affective lexicon in English that those systems can use for providing affective intervention. There needs to be more evidence as to which phrases learners may like to receive from an ATS. This study investigates popular congratulating and encouraging phrases to build a comprehensive affective educational lexicon in English for ATS. Firstly, we examined and collected phrases by reviewing existing learning support systems from the literature that provide affective feedback to learners for constructing an affective lexicon. Secondly, 84 students from various qualifications and backgrounds evaluated the collected phrases by choosing the most popular ones in the congratulating and encouraging dimensions. The lexicon currently consists of 43 encouraging and 32 congratulating phrases categorised by popularity. The findings from this study will augment the ATS to provide better affective tutoring support for students by choosing more constructive and popular affective phrases.",Yes,"논문 초록에서 84명의 학생들이 구체적인 구절들을 평가하는 과정을 언급하며, 이를 통해 정량적 평가가 수행되었음을 알 수 있습니다. 또한, 인기 있는 구절들을 선정하여 어휘집을 구축하는 과정이 포함되어 있어 정량적 평가의 실시를 보여줍니다."
Classifying El Niño-Southern Oscillation Combining Network Science and Machine Learning,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9042254,"Machine learning and complex network theory have emerged as crucial tools to extract meaningful information from big data, especially those related to complex systems. In this work, we aim to combine them to analyze El Niño Southern Oscillation (ENSO) phases. This non-linear phenomenon consists of anomalous (de)increase of temperature at the tropical Pacific Ocean, which has irregular occurrence and causes climatic variability worldwide. We construct temporal Climate Networks from the Surface Air Temperature time-series and calculate network metrics to characterize the warm and cold ENSO episodes. The metrics are used as topological features for classification. We employ ten classifiers and achieved 80% AUC ROC when predicting the intensity of Strong/ Weak El Niño and Strong/Weak La Niña for the next season. The complex network represents the relationship among different regions of the planet and machine learning creates models to classify the different classes of ENSO. This work opens new paths of research by integrating network science and machine learning to analyze complex data like global climate systems.",Yes,"논문 초록에서 네트워크 지표를 계산하여 정량적 평가를 수행하고 있으며, 이를 이용해 ENSO 강도 예측의 성능을 평가하는 내용이 포함되어 있습니다. 따라서, 정량적 평가를 실시하고 있다고 판단됩니다."
Power Quality Improvement in Grid Connected PV System using Fuzzy Logic Controller based Maximum Power Point Tracing(MPPT),https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9837635,"The expansion of the spread of solar photovoltaic power generation systems is fraught with challenges related to the low efficiency and performance of these systems in light of the change in the surrounding weather conditions and the disturbances associated with the loads, which weakens the electrical energy productivity of these photovoltaic systems due to energy loss. To overcome and reduce these challenges as much as possible, it is considered the use of controllers that track the maximum power point of photovoltaic systems is the ideal solution to increase their efficiency and improve the quality of their electrical power, in order to obtain the maximum productive capacity from these systems, and this will be reflected in achieving an optimum benefit from the available solar energy and thus reducing the loss of unused energy in the absence of the control system.This paper presents a study, analysis and simulation of the actual behaviour of the grid-connected solar photovoltaic system model by means of the (MATLAB/Simulink_R2018a) program. The performance of Fuzzy Logic Controller is then evaluated to track the path of the maximum power point, and its work is based on tracking techniques that use the direct control method to control the operating cycle of the DC commutator, which in turn performs by feeding the inverter with the maximum output power from the solar photovoltaic system.A tracking technology was selected that relies on the method of artificial intelligence, which is the technique (fuzzy logic controller), and a fuzzy logic controller of the type (Mamdani) was used. The most suitable for tracking the maximum power point at the steady state of the Grid and under constant and changing weather conditions, as well as choosing the most appropriate controller when transient disturbances occur in the Grid under constant weather conditions only. The results proved the effectiveness of the fuzzy logic controller, and it had good performance in tracking the maximum power point in terms of achieving more stability, reducing error and settling time.",Yes,"논문 초록에서 성능 평가를 위해 시뮬레이션을 수행하고, 퍼포먼스 지표(안정성, 오차, 정착 시간 등)를 분석했다고 명시되어 있습니다. 이는 정량적 평가가 실시되고 있음을 보여줍니다."
Explainable Unsupervised Machine Learning for Cyber-Physical Systems,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9536751,"Cyber-Physical Systems (CPSs) play a critical role in our modern infrastructure due to their capability to connect computing resources with physical systems. As such, topics such as reliability, performance, and security of CPSs continue to receive increased attention from the research community. CPSs produce massive amounts of data, creating opportunities to use predictive Machine Learning (ML) models for performance monitoring and optimization, preventive maintenance, and threat detection. However, the ‘‘black-box’’ nature of complex ML models is a drawback when used in safety-critical systems such as CPSs. While explainable ML has been an active research area in recent years, much of the work has been focused on supervised learning. As CPSs rapidly produce massive amounts of unlabeled data, relying on supervised learning alone is not sufficient for data-driven decision making in CPSs. Therefore, if we are to maximize the use of ML in CPSs, it is necessary to have explainable unsupervised ML models. In this paper, we outline how unsupervised explainable ML could be used within CPSs. We review the existing work in unsupervised ML, present initial desiderata of explainable unsupervised ML for CPS, and present a Self-Organizing Maps based explainable clustering methodology which generates global and local explanations. We evaluate the fidelity of the generated explanations using feature perturbation techniques. The results show that the proposed method identifies the most important features responsible for the decision-making process of Self-organizing Maps. Further, we demonstrated that explainable Self-Organizing Maps are a strong candidate for explainable unsupervised machine learning by comparing its model capabilities and limitations with current explainable unsupervised methods.",Yes,"논문 초록에서 제안된 방법의 설명 가능성을 평가하기 위해 피처 교란 기법을 사용하여 설명의 충실도를 검증하는 등 정량적 평가를 실시한 내용을 언급하고 있습니다. 또한, 제안된 Self-Organizing Maps 기반 클러스터링 방법의 성능과 설명 가능성을 비교 분석하는 과정이 포함되어 있어 정량적 평가가 수행되고 있음을 알 수 있습니다."
ECG Based Stress Detection Using Machine Learning,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9807877,"Today, the endeavour of accomplishment and performance has increased the efficiency immensely, yet it comes with its own price. There has been a drastic increase in the diseases related to stress, especially in the past couple of decades. The plethora of diseases and disorders related to long-term effects of stress vary from muscle related disorders to nervous system related diseases. Stress can be defined as unrest in the normal homeostasis. Since this state of unrest is usually triggered by the sympathetic nervous system as a physiological response, stress can be captured by physiological signals. Though a variety of approaches such as the use of questionnaires, biochemical measures and physiological techniques are available to diagnose stress; physiological signals are the most reliable method. Therefore, we have analysed stress using Electrocardiogram which is a physiological signal to increase the accuracy rate by using machine learning algorithms. Here we propose a simple algorithm for the classification of ECG signal as stress or normal by the automatic detection of heart rate variability from R peaks through DWT method. Works includes ECG raw data extraction, wavelet de-noising, R peak detection and classification. Machine learning algorithm uses various parameters obtained from classification for finding the accuracy of the results. Short term ECG is needed for stress detection, which produces a reliable classification with high accuracy.",Yes,"논문 초록에서 머신러닝 알고리즘을 사용하여 ECG 신호를 분류하는 방법을 제시하며, 다양한 파라미터를 이용한 정량적 평가를 수행한다고 언급하고 있습니다. 이는 정량적 평가가 실시되고 있음을 의미합니다."
Enhancing QoE of WebRTC-based Video Conferencing using Deep Reinforcement Learning,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10258222,"The proportion of video traffic within the total internet traffic is steadily increasing and then video traffic already accounts for over half of the internet traffic. The increase in video traffic is due to the growing number of users for video-related services such as video streaming, live streaming, and video telephony. With the increasing users on video-related services, the importance of the quality of experience (QoE) for these services will become even more crucial in the future. Numerous studies to enhance the experience quality of video streaming have been conducted using adaptive bitrate (ABR) algorithms and artificial intelligence (AI). However, this work focuses on a more complex problem: improving the experience quality in multi-party, bi-directional communication scenarios such as video conferences. We propose a system that applies deep reinforcement learning (DRL) to the media server of a webRTC-based video conferencing system to allocate a bitrate’s video stream that suits the network conditions for users. The proposed method was implemented and evaluated, demonstrating great improvements. When the network conditions changed dynamically, the proposed approach achieved approximately 56.2% higher video bitrate compared to existing methods, resulting in a 24.7% enhancement in user experience quality.",Yes,"논문 초록에서 제안된 시스템이 실험을 통해 평가되었으며, 네트워크 조건 변화에 따른 비디오 비트레이트 향상과 사용자 경험 품질 개선이 정량적으로 측정된 것으로 보입니다. 따라서, 정량적 평가가 실시된 것으로 판단됩니다."
Deep Learning and Multivariate Time Series for Cheat Detection in Video Games,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9564219,"Online video games drive a multi-billion dollar industry dedicated to maintaining a competitive and enjoyable experience for players. Traditional cheat detection systems struggle when facing new exploits or sophisticated fraudsters. More advanced solutions based on machine learning are more adaptive but rely heavily on in-game data, which means that each game has to develop its own cheat detection system. In this work, we propose a novel approach to cheat detection that doesn't require in-game data. Firstly, we treat the multimodal interactions between the player and the platform as multivariate time series. We then use convolutional neural networks to classify these time series as corresponding to legitimate or fraudulent gameplay. Our models achieve an average accuracy of respectively 99.2% and 98.9% in triggerbot and aimbot (two widespread cheats), in an experiment to validate the system's ability to detect cheating in players never seen before. Because this approach is based solely on player behavior, it can be applied to any game or input method, and even various tasks related to modeling human activity.",Yes,"논문 초록에서 convolutional neural networks를 사용하여 다변량 시계열 데이터를 분류하는 정량적 평가를 수행했다고 명시되어 있습니다. 또한, 모델의 정확도(99.2% 및 98.9%)라는 구체적인 수치로 성능을 평가하고 있어 정량적 평가가 이루어지고 있음을 알 수 있습니다."
Multiple Disease Prediction System using Machine Learning and Streamlit,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10060903,"There are many existing machine learning models related to health care which mainly focuses on detecting only one disease. Therefore, this study has developed a system to forecast several diseases by using a single user interface. The proposed model can predict multiple diseases such as diabetes, heart disease, chronic kidney disease and cancer. If left untreated, these diseases pose a risk to humanity. As a result, many lives can be saved by early detection and diagnosis of these disorders. This research work attempts to implement various classification algorithms (K-Nearest Neighbor, Support Vector Machine, Decision Tree, Random Forest, and Logistic Regression, Gaussian naive bayes.) to perform disease prediction. The accuracy of each algorithm is validated and compared with each other to find the best one for prediction. Furthermore, multiple datasets (for each disease each dataset) are used to achieve utmost accuracy in the predicted results. The main goal is to create a web application capable of forecasting several diseases by using machine learning, including diabetes, heart disease, chronic kidney disease, and cancer.",Yes,"논문 초록에서 여러 분류 알고리즘의 정확도를 검증하고 비교하는 과정을 언급하고 있어, 정량적 평가가 실시되고 있음을 알 수 있습니다. 이를 통해 모델의 성능을 수치로 평가하는 연구임을 확인할 수 있습니다."
Emerging Results on Automated Support for Searching and Selecting Evidence for Systematic Literature Review Updates,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10707620,"Context: The constant growth of primary evidence and Systematic Literature Reviews (SLRs) publications in the Software Engineering (SE) field leads to the need for SLR Updates. However, searching and selecting evidence for SLR updates demands significant effort from SE researchers. Objective: We present emerging results on an automated approach to support searching and selecting studies for SLR updates in SE. Method: We developed an automated tool prototype to perform the snowballing search technique and to support the selection of relevant studies for SLR updates using Machine Learning (ML) algorithms. We evaluated our automation proposition through a small-scale evaluation with a reliable dataset from an SLR replication and its update. Results: Effectively automating snowballing-based search strategies showed feasibility with minor losses, specifically related to papers without Digital Object Identifier (DOI). The ML algorithm giving the highest performance to select studies for SLR updates was Linear Support Vector Machine with approximately 74% recall and 15% precision. The use of such algorithms with conservative thresholds to minimize the risk of missing papers can already significantly reduce evidence selection efforts. Conclusion: The preliminary results of our evaluation point in promising directions, indicating the potential of automating snowballing search efforts and of reducing the number of papers to be manually analyzed by about 2.5 times when selecting evidence for updating SLRs in SE.",Yes,"논문은 ML 알고리즘의 성능 평가와 같은 정량적 평가를 수행했음을 명확히 언급하고 있습니다. 또한, 실험 결과로서 재현율과 정밀도와 같은 수치적 지표를 제시하여 정량적 평가를 실시했음을 보여줍니다."
Maritime Human Drone Teaming For Search and Rescue Operations,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10531426,"Drowning detection is a critical safety measure aimed at identifying and preventing drowning incidents in various environments, such as swimming pools, beaches, rivers, and other bodies of water. Drowning is a leading cause of accidental death worldwide, and early detection is essential for saving lives and ensuring water-related activities remain safe. The goal of drowning detection systems is to promptly identify when a person is in distress or submerged in the water, triggering an immediate response to prevent potential drowning incidents. In this proposed work, a monitoring system using UAV (drones) to detect a drowning person is proposed. The system includes an operator, camera gear, Raspberry Pi3, and rescue UAV. The real-time image is assisted by the drowning detection algorithm, and judges whether there are targets to be rescued, so the performance of detection algorithm used in this process is very important. The drowning activity detection is identified using deep learning algorithm. After comparison with other models/methods, the deep learning model chosen for drowning detection is Convolutional Neural Networks (CNN). Conv2dLstm is the convolution layer used for developing the model, since the proposed work deals with 3D input data instead of 1D vector. Deep learning model is successfully built using CNN architecture which has an accuracy of 0.9341. The processing time taken for the model to detect the drowning activity is 5 seconds where the rescue operation can be done immediately to save the person. Real time implementation of the proposed system has been achieved using Raspberry Pi 3. For the rescue operation, human-drone communication is established. The controller is mounted on a carrier device and is tested in real time environment. The drowning detection system has successfully identified a person drowning in a swimming pool.",Yes,"논문은 딥러닝 알고리즘(Convolutional Neural Networks)을 사용하여 익사 활동을 감지하는 시스템의 성능을 평가하기 위해 정확도(0.9341)와 처리 시간(5초)을 제시하며, 정량적 평가를 실시하고 있음을 보여줍니다. 이러한 수치는 시스템의 성능을 수치로 측정하고 평가하는 정량적 평가의 예입니다."
Enhancing Autism Spectrum Disorder Recognition in EEG Data through Filtering-Driven CNN Approach,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10444503,"Wearable Electroencephalogram (EEG) devices hold immense potential for optimizing health monitoring processes. This paper introduces an innovative approach that seamlessly integrates deep learning techniques into EEG-based recognition, bridging the gap between traditional feature-based methods and Convolutional Neural Networks (CNNs). The methodology revolves around crafting CNNs to emulate the information extraction principles of feature-based techniques, resulting in a streamlined yet robust architecture tailored for EEG-based classification.To validate this approach, two comprehensive experiments were conducted, involving EEG data collection and subsequent evaluation within health monitoring scenarios. Specifically, the focus was on the diagnosis of Autism Spectrum Disorder (ASD), necessitating precise identification and characterization of EEG signals. Deep learning, embedded within a neural network framework, emerges as a powerful tool for the identification and classification of ASD.The proposed deep CNN structure employs separated temporal and spatial filters, selecting raw EEG signals from electrode pairs over the motor cortex region as hybrid samples without preprocessing or artificial feature extraction operations. This 5-layer CNN is augmented by a 4-layer max pooling mechanism to reduce dimensionality, and a fully-connected (FC) layer for classification. Dropout and batch normalization techniques are incorporated to mitigate overfitting risks.In the experimental phase, 20m EEG data from 5, 10, 20, and 50 subjects sourced from the Physionet database, utilizing a 14 Channel Emotiv EPOC EEG headset, were employed. States of focus, unfocused, and drowsed were considered. Results indicate a remarkable global averaged accuracy of 92.31% in group-level classification, an outstanding area under the receiver operating characteristic (ROC) curve at 0.981, and, notably, the electrode pair FC3-FC4 achieved the highest accuracy of 99.61% on a 10-subject dataset.This work contributes to the evolving landscape of EEG-based health monitoring, showcasing the potential of a deep CNN architecture in accurately classifying states related to ASD, and thereby advancing the precision and efficacy of neurodevelopmental disorder diagnoses.",Yes,"논문 초록에서는 실험을 통해 EEG 데이터를 수집하고, 그 데이터를 이용하여 ASD 상태를 분류하는 평가를 수행했다고 명시되어 있습니다. 또한, 정확도, ROC 곡선 아래 면적 등 정량적 평가 지표를 제시하여 정량적 평가를 실시했음을 알 수 있습니다."
Language Identification Models for Short Medical Texts,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9991579,"In the context of SARS-CoV-2 transmission prevention, the short texts on the social networks are full of abbreviations, technical medical terms, slang words that are outside the native languages or pejorative jargon. In other words, the language identification issues are not trivial. In fact, always this task remained a challenge for short texts originating from social media, which abounds in hard-to-understand sequences of letters. Moreover, when the whole world is facing a “medical crisis”, the situation must somehow be controlled in order for the panic to not degenerate even more. As a result, we need enhanced tools that can help us speed up the process of detection of linguistic aspects of the online content. This paper presents a new method intended to identify the language of a Twitter collection related to COVID-19 subject, based on AI algorithms. The aim of this work is to optimally determine the main language in which a text is written, with the constrains given by the diversity of the short text language found in tweets. Therefore, to find an optimal solution for language detection, we evaluated the impact of several language detection algorithms for short texts. Moreover, the results of this analysis were used for the implementation of a new language detection model, focused primarily on the detection of the Romanian language of the gathered tweets. The results suggest that a hybrid approach which combines classic techniques looks like a realistic direction of research.",Yes,"초록에서 여러 언어 감지 알고리즘의 영향을 평가했다고 명시되어 있으며, 이를 바탕으로 새로운 언어 감지 모델을 구현했다고 언급되어 있습니다. 이는 정량적 평가가 수행되었음을 시사합니다."
"Analysis and simulation of social behavior during the COVID-19 pandemic in Argentina, using intelligent agents",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9782344,"The present work is an innovative educational strategy that uses a Final Integrative Work (FIW) as a method of evaluation of subjects of the Computer Engineering degree where students learn different subjects such as Artificial Intelligence and Databases, through real world problems related to COVID-19. The evaluation process through the FIW is based on several skills acquisition and by measuring the way in which students apply concepts of Databases and intelligent agents by means of numerical simulations that involves social behavior in times of the COVID-19 pandemic in the province of Tucumán, in the northwest of Argentina. The students carried out simulations of a multiagent system through the tool Netlogo, applying rules with a high impact factor for tackling a decision making problem. The results observed suggest that a paradigm shift in the degree evaluation processes is possible and necessary.",Yes,"논문 초록에서 학생들이 수치적 시뮬레이션을 통해 사회적 행동을 평가하는 과정을 언급하고 있으며, 이를 통해 정량적 평가가 실시되고 있음을 알 수 있습니다. 시뮬레이션 도구인 Netlogo를 활용하여 규칙을 적용하고 결과를 분석하는 과정이 포함되어 있습니다."
Multi-task Learning Based Ocular Disease Discrimination and FAZ Segmentation Utilizing OCTA Images,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9631043,"In this paper, we proposed and validated a multi-task based deep learning method for simultaneously segmenting the foveal avascular zone (FAZ) and classifying three ocular disease related states (normal, diabetic, and myopia) utilizing optical coherence tomography angiography (OCTA) images. The essential motivation of this work is that reliable predictions on disease states may be made based on features extracted from a segmentation network, by sharing a same encoder between the classification network and the segmentation network. In this study, a cotraining network structure was designed for simultaneous ocular disease discrimination and FAZ segmentation. Specifically, we made use of a classification head following a segmentation network’s encoder, so that the classification branch used the feature information extracted in the segmentation branch to improve the classification results. The performance of our proposed network structure has been tested and validated on the FAZID dataset, with the best Dice and Jaccard being 0.9031±0.0772 and 0.8302 ±0.0990 for FAZ segmentation, and the best Accuracy and Kappa being 0.7533 and 0.6282 for classifying three ocular disease related states.Clinical Relevance— This work provides a useful tool for segmenting FAZ and discriminating three ocular disease related states utilizing OCTA images, which has a great clinical potential in ocular disease screening and biomarker delivering.",Yes,"논문 초록에서 Dice, Jaccard, Accuracy, Kappa와 같은 정량적 평가 지표를 사용하여 제안된 네트워크 구조의 성능을 검증했다고 명시되어 있습니다. 이는 정량적 평가가 실시되고 있음을 보여줍니다."
PSARE: A RL-Based Online Participant Selection Scheme Incorporating Area Coverage Ratio and Degree in Mobile Crowdsensing,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9797859,"Mobile crowdsensing (MCS) is a cost-effective paradigm for gathering real-time and location-related urban sensing data. To complete MCS tasks, MCS platform needs to exploit the trajectory of participants (vehicles or individuals, etc.) for effectively choosing participants. On one hand, the existing works usually assume that platform has possessed the abundant historical movement trajectory for participant selection, or can accurately predict the movement of participant before selection, but this assumption is impractical for many MCS applications, for some candidates have just arrived without sufficient mobility profiles, so-called trajectory from-scratch, or cold-trajectory issue. On the other hand, most of works only considers the coverage ratio of the sensing area, while some hotspots should be sensed frequently, so-called coverage degree of hotspots. To solve the issue, this paper proposes a reinforcement learning (RL) based, i.e., an improved Q-learning based online participant selection scheme to incorporate both coverage ratio and degree, PSARE. First, to solve the explosion of state-value table in traditional tabular Q-learning, an improved two-level Q-learning method is proposed to select participants in online way so as to achieve high long-term return. Specifically, in each selection round, PSARE dynamically compresses all the real participants (RPs) into several virtual participants (VPs) using the available historical trajectories of RPs, and the VP-based state-value table is constructed and constantly updated (i.e., the first level). Then, after selecting the VP through looking up the table, PARSE chooses the RP with the largest expected reward in this VP using epsilon-greedy way to balance the effect of exploration and exploitation (i.e., the second level). Moreover, the reward function is designed to measure the MCS coverage quality, including both coverage degree of hotspots and coverage ratio of target area. Thorough experiments on real-world mobility data set demonstrate that PSARE outperforms than other RL based online participant selection schemes (including deep Q-learning network) and traditional offline selection methods.",Yes,"논문 초록에서 강화학습(RL)을 기반으로 한 온라인 참여자 선택 방식을 제안하며, 이를 위해 Q-러닝과 딥 Q-러닝 네트워크를 포함한 다양한 RL 기법을 활용하고 있음을 명시하고 있습니다. 또한, 보상 함수를 설계하여 성능 평가를 수행하는 내용이 언급되어 있어 정량적 평가가 실시되고 있음을 알 수 있습니다."
Machine Learning-Based Joint Vital Signs and Occupancy Detection With IR-UWB Sensor,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10054563,"This article proposes the machine learning (ML)-based joint vital signs (VSs) and occupancy detection (OD) with an impulse radio ultra-wideband (IR-UWB) sensor. Works that have been done on VS or OD development using an IR-UWB are related to how VS works. In the related experiments performed, the OD and state of individuals were not sufficiently verified, and the methods were computationally complex. Issues related to the use of ML for joint VS and OD (VSOD) have also not been studied in the literature. Extensive experimental scenarios involving the application of an ML-based classifier for human OD and VS classification, which we extended toward three sub-scenarios, were evaluated. We formulated a solution for VS estimation, which was aligned, so that each network input sequence received signal corresponding to respective VS over different scenarios. The performance of the proposal was evaluated with other competing ML-based classification algorithms. Compared with other techniques, our proposed deep neural network (DNN)-based classifier achieved the best results, and it also offers benefits over other algorithms, such as not needing to extract features from the data.",Yes,"논문 초록에서 다양한 실험 시나리오를 통해 ML 기반 분류 알고리즘의 성능을 평가했다고 명시되어 있으며, 특히 제안된 딥 뉴럴 네트워크(DNN) 분류기가 다른 기법보다 우수한 성과를 보였다고 언급하고 있습니다. 이는 정량적 평가가 수행되었음을 의미합니다."
Performance Evaluation of Transmission Mode Selection in D2D communication,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9432648,"Device to Device (D2D) Communication is expected to be a one of the major contributing factors of the realisation of 5G and Beyond Mobile communication networks as it promises improvements in energy efficiency, spectral efficiency, overall system capacity, and higher data rates with the use of the same frequencies for different D2D transmissions in short communication distances within the Cell. However, in order to achieve optimum results, it is important, among others, to select wisely the Transmission Mode of the D2D Device. Towards this end, our previous work proposed an intelligent Transmission mode selection approach in a framework that is utilizing Artificial Intelligence (AI) BDIx agents to collectively satisfy the D2D challenges in a Distributed Artificial Intelligent (DAI) manner and act autonomously and independently. In this paper, as a first step, a literature review focused on related Transmission mode approaches is performed. Then, our investigated Transmission mode selection approach is further explained with formulas, evaluated based on different threshold values and investigated how these can affect the overall spectral efficiency and power usage of the network in order to achieve the maximum performance. The investigated thresholds on utilized values (i.e., D2D Device Weighted Data Rate (WDR), D2D Device Battery Power Level) and metrics (i.e., WDR) are also further analyzed and formulated. In addition, the effect the transmission power of the D2D links has on the total spectral efficiency and total power consumption of the network, is also examined. The evaluation results revealed some interesting findings that can contribute in other approaches that utilized similar or same thresholds. Also, the results obtained demonstrate that with the right tuning of the thresholds and transmission power, one can achieve a significant improvement in the network power usage and total spectral efficiency.",Yes,"초록에서 제안된 전송 모드 선택 방법이 다양한 임계값과 지표를 기반으로 평가되고 있으며, 그 결과를 통해 네트워크의 성능 향상에 대한 정량적 분석이 수행되었음을 알 수 있습니다. 또한, 평가 결과와 관련된 수식과 실험적 검증이 언급되어 있어 정량적 평가가 실시된 것으로 판단됩니다."
Semantic Segmentation of Histopathological Images with Fully and Dilated Convolutional Networks,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9632856,"Nowadays, the segmentation of different components in medical images is a major subject of study, and parallel to this, numerous image segmentation methods are still being developed. This study aimed to assess image segmentation methodologies utilizing deep learning models, due to the success of deep learning models in image processing applications. Firstly, starting from the introduction, a literature review on semantic segmentation and medical image segmentation is introduced in this study. In addition, pre-processing steps and techniques, models used, evaluation criteria, and the reasons for their preference are also explained. In the methods section, SegNet, U-Net, and DeepLabV3+ model architectures are introduced, and the architectures of these models are visualized at a basic level. The application results section includes all evaluation results with the metrics used in measuring accuracy. The comparison of the evaluation results and the evaluations on these results are included in the results and discussion section. In addition to these, visualized prediction results are also presented under the application results section.",Yes,"초록에서 ""evaluation criteria""와 ""metrics used in measuring accuracy""라는 표현이 등장하여, 논문이 정량적 평가를 실시하고 있음을 명확히 보여줍니다. 또한, 평가 결과와 관련된 비교와 분석이 포함되어 있어 정량적 평가가 수행되고 있음을 알 수 있습니다."
ResCovNet: A Deep Learning-Based Architecture For COVID-19 Detection From Chest CT Scan Images,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9293887,"Automatic disease detection using machine learning-based techniques from X-ray and computed tomography (CT) can play a major role in the frontline to assist medical professionals during the current outbreak of COVID-19. Fast diagnosis of the disease is the key to reduce the uncontrollable spread of this life-threatening disease, where machine learning-based applications can contribute greatly by predicting the situation of patients so that professionals can decide accordingly. The major drawbacks of detecting COVID-19 are its similarities with different types of pneumonia, and the absence of properly labeled data. Considering the ResNet152V2 as a backbone network, an efficient architecture, namely ResCovNet is proposed to detect COVID-19 accurately from chest CT scan images by separating it from three types of pneumonia and normal cases. Otsu's thresholding is applied in the pre-processing step to strengthen the features for the classification network. With the use of proposed architecture, a very satisfactory classification accuracy of 88.1% is achieved to separate COVID-19 from all other four classes. Evaluating the performance of this study by 3-fold cross-validation, and comparison with related works prove that this adroit algorithm provides an effective way to be implemented as a diagnostic tool in the COVID-19 screening.",Yes,"논문 초록에서 ""classification accuracy""와 ""3-fold cross-validation""과 같은 정량적 평가 지표를 언급하고 있어, 정량적 평가를 실시하고 있음을 알 수 있습니다. 이러한 지표들은 모델의 성능을 수치로 평가하는 방법입니다."
Evaluation of Multi-layer Perceptron Neural Networks in Predicting Ankle Dorsiflexion in Healthy Adults using Movement-related Cortical Potentials for BCI-Neurofeedback Applications,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9896584,"Brain computer interface (BCI) systems were initially developed to replace lost function; however, they are being increasingly utilized in rehabilitation to restore motor functioning after brain injury. In such BCI-mediated neurofeedback training (BCI-NFT), the brain-state associated with movement attempt or intention is used to activate an external device which assists the movement while providing sensory feedback to enhance neuroplasticity. A critical element in the success of BCI-NFT is accurate timing of the feedback within the active period of the brain state. The overarching goal of this work was to develop a reliable deep learning model that can predict motion before its onset, and thereby deliver the sensory stimuli in a timely manner for BCI-NFT applications. To this end, the main objective of the current study was to design and evaluate a Multi-layer Perceptron Neural Network (MLP-NN). Movement-related cortical potentials (MRCP) during planning and execution of ankle dorsiflexion was used to train the model to classify dorsiflexion planning vs. rest. The accuracy and reliability of the model was evaluated offline using data from eight healthy individuals (age: 26.3 ± 7.6 years). First, we evaluated three different epoching strategies for defining our 2 classes, to identify the one which best discriminated rest from dorsiflexion. The best model accuracy for predicting ankle dorsiflexion from EEG before movement execution was 84.7%. Second, the effect of various spatial filters on the model accuracy was evaluated, demonstrating that the spatial filtering had minimal effect on model accuracy and reliability.",Yes,"논문 초록에서 Multi-layer Perceptron Neural Network (MLP-NN)를 설계하고 평가하는 과정이 언급되어 있으며, 그 성능을 평가하기 위해 정확도와 신뢰도를 측정하는 정량적 평가가 수행된 것으로 보입니다. 따라서, 이 논문은 정량적 평가를 실시하고 있다고 판단됩니다."
Comparing the Design Quality and Efficiency between Design Intelligence and Intermediate Designers,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9903240,"Design intelligence is to adapt and introduce artificial intelligence methods to design tasks. SmartPaint is a typical design intelligence system to generate paintings, and its improved version further considers the causal relation between objects in a scene and is trained with a larger dataset with over one million artwork samples. In this paper, we compare the improved SmartPaint with 12 intermediate designers on a controlled painting task. The intermediate designers have been working in the design and related industries for over two years. The comparison is about design quality and efficiency, evaluated by 20 volunteers. Empirically we find over 50% of the paintings generated by SmartPaint are more preferred than those drawn by human designers along creativity, artistic quality and color scheme. Besides, SmartPaint takes only less than 1% of the time spended by human designers.",Yes,"논문 초록에서 디자인 품질과 효율성을 평가하기 위해 20명의 자원봉사자를 통한 비교 실험이 수행되었으며, 이를 통해 정량적 평가가 이루어졌음을 알 수 있습니다. 또한, 시간 소요와 선호도와 같은 수치 데이터를 활용하여 평가가 진행된 것으로 보입니다."
DES-KNORA Model: Developing an Intelligent System for Automatic Power Mode Adjustment in Electric Bicycles,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10725483,"Electric bicycles (e-bikes) have gained considerable popularity due to their environmentally friendly nature and suitability as a mode of transportation. However, they face challenges related to manual switches for power mode changes. A potential solution to this issue could be the application of machine learning to improve their performance and safety. Previous research has explored the use of machine learning for gear shifting in bicycles, but there remains a gap in the specific application of ML for automating power mode changes in electric bikes. In order to address this gap, the study proposes the design and evaluation of an intelligent system based on machine learning that can automatically adjust electric bike power modes for users. The research team utilized a Hero Lectro C7+ electric bike and designed and tested a novel ensemble model, the dynamic ensemble selection approach model (DES-KNORA), against several machine learning techniques to predict the need for power mode changes. The DES-KNORA ensemble model fit the measured data the best, with an F1-score of 0.9995 and an accuracy of 99.95%. The study’s results show that the suggested method works in real life, making the ride smoother and less annoying for riders.",Yes,논문은 DES-KNORA 모델의 성능 평가를 위해 F1-score와 정확도(accuracy)와 같은 정량적 지표를 사용하여 평가하였음을 명확히 제시하고 있습니다. 이는 정량적 평가를 실시하고 있음을 보여주는 중요한 근거입니다.
SmartDet: Context-Aware Dynamic Control of Edge Task Offloading for Mobile Object Detection,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9842816,"Mobile devices such as drones and autonomous vehicles increasingly rely on object detection (OD) through deep neural networks (DNNs) to perform critical tasks such as navigation, target-tracking and surveillance, just to name a few. Due to their high complexity, the execution of these DNNs requires excessive time and energy. Low-complexity object tracking (OT) is thus used along with OD, where the latter is periodically applied to generate ""fresh"" references for tracking. However, the frames processed with OD incur large delays, which does not comply with real-time applications requirements. Offloading OD to edge servers can mitigate this issue, but existing work focuses on the optimization of the offloading process in systems where the wireless channel has a very large capacity. Herein, we consider systems with constrained and erratic channel capacity, and establish parallel OT (at the mobile device) and OD (at the edge server) processes that are resilient to large OD latency. We propose Katch-Up, a novel tracking mechanism that improves the system resilience to excessive OD delay. We show that this technique greatly improves the quality of the reference available to tracking, and boosts performance up to 33%. However, while Katch-Up significantly improves performance, it also increases the computing load of the mobile device. Hence, we design SmartDet, a low-complexity controller based on deep reinforcement learning (DRL) that learns to achieve the right trade-off between resource utilization and OD performance. SmartDet takes as input highly-heterogeneous context-related information related to the current video content and the current network conditions to optimize frequency and type of OD offloading, as well as Katch-Up utilization. We extensively evaluate SmartDet on a real-world testbed composed by a JetSon Nano as mobile device and a GTX 980 Ti as edge server, connected through a Wi-Fi link, to collect several network-related traces, as well as energy measurements. We consider a state-of-the-art video dataset (ILSVRC 2015 - VID) and state-of-the-art OD models (EfficientDet 0, 2 and 4). Experimental results show that SmartDet achieves an optimal balance between tracking performance – mean Average Recall (mAR) and resource usage. With respect to a baseline with full Katch-Up usage and maximum channel usage, we still increase mAR by 4% while using 50% less of the channel and 30% power resources associated with Katch-Up. With respect to a fixed strategy using minimal resources, we increase mAR by 20% while using Katch-Up on 1/3 of the frames.",Yes,"논문 초록에서 ""SmartDet""이 딥 강화학습(DRL)을 기반으로 하는 제어기를 설계하여 자원 활용과 객체 검출 성능 간의 균형을 최적화하는 방식을 제시하고 있으며, 이를 위해 다양한 정량적 평가 지표(예: mAR, 채널 사용량, 전력 소비 등)를 사용하여 성능을 평가하고 있습니다. 따라서, 정량적 평가를 실시하고 있다고 판단됩니다."
Mental Task Classification using Machine Learning,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10150533,"Brain-computer interface (BCI) applications are an exciting area of research that has the potential to drastically alter the way we engage with technology. By translating brainwaves into an operational signal, it offers its users an additional means of controlling their environment. There are various techniques available to record brain activity including EEG (Electroencephalogram), fNIRS (functional near-infrared spectroscopy), and DTI (diffusion tensor imaging). Because of the low cost of acquisition devices and the lack of any known clinical risks associated with EEG, it has been widely used in the construction of brain-computer interface systems. In this work, an EEG data is recorded from 5 subjects, in three different sessions following motor imagery, motor movement, and resting state protocols. Using this dataset, we have trained different machine learning models to perform binary class classification of mental tasks into task and non-task related ones. For taskrelated data, we have used Motor Imagery (MI) data while the non-task related involves the Resting state (eyes open) recording of data. We have evaluated the performances of four machine learning algorithms: Decision Tree, KNN, Ensembles, and SVM, out of which SVM performed the best with the training and test accuracy of 87.9 and 72.7% respectively.",Yes,논문 초록에서 여러 머신러닝 알고리즘의 성능 평가를 위해 정확도(accuracy)를 측정하는 등 정량적 평가를 실시했음을 명확히 언급하고 있습니다. 이는 정량적 평가가 수행되었음을 보여줍니다.
Effect of robot's title in human-robot interaction,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7057515,"The collaboration between humans and intelligent agents keeps increasing as the technology advances. In this sense, each can rely on the other's strengths to achieve the best overall performance. But as intelligent agents play an increasingly escalating role as a partner rather than mere tools, it is imperative that we understand how humans are influenced by such agents. This is so as to achieve a certain level of persuasiveness to ensure human compliance with intelligent agents in times of need, and also prevent over-reliance on such agents, which may make humans susceptible to manipulation. Reviewing the literature from human-computer interaction, persuasion, and decision-making processes, this study examined the effect of labelling source expertise (i.e., title) on the human decision-making process, when there is not an agreement between human and robot partners. Specifically, we conducted an experiment (n = 88) to investigate how perceived expertise of a robot resulted in the attractiveness, intelligence and credibility of the robot, and how these perceptions influence the level of cooperation and compliance in a desert survival game. The results showed that participants evaluated the robot as more credible when labelled as expert, compared to when labelled as novice. The results of a mediation analysis also showed that perceived credibility successfully mediated the effect of title on cooperation and compliance when there was a conflict in the ranking order of items between each participant and the robot. Implications for future development of artificial intelligence and future research directions are discussed.",Yes,"논문 초록에서 실험(n = 88)을 통해 인간과 로봇 간의 상호작용에 대한 정량적 데이터를 수집하고 분석한 내용을 언급하고 있습니다. 또한, 매개 분석(mediation analysis)과 같은 통계적 방법을 사용하여 연구 결과를 정량적으로 평가했음을 알 수 있습니다."
Machine Learning Driven Analysis of Mental Health Indicators in Social Media Posts,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10689856,"Mental stress has been a major issue among all age groups today. This is more like a stigma in the society where people don't even want to talk about it openly leading to severe health issues. Nowadays, people are deeply engaged with social media platforms for connection and self-expression of their emotions. They express all these through posts, photos, and comments. Thus, social media platforms can help in predicting the mental state and well-being of an individual. Prediction of a person's mental health can help to undertake some preventive measures. Various researchers have worked around this topic but there is no evidence of utilizing the most active web of people for obtaining the most accurate results. Machine Learning (ML) algorithms are used in this research study to identify whether a person is mentally stressed or not based on the social media data obtained from the user's post or by using a text input of around hundred words from users related to their day-to-day activities. This research study has used a decision tree, random forest, and Bidirectional Encoder Representations from Transformers (referred as BERT onwards) model classifier to train models. This study has used a dataset of Reddit (a social media platform) posts text data for training the models. The primary objective is to compare the efficacy of various machine learning models in predicting mental health based on social media data.",Yes,"논문 초록에서 여러 머신러닝 알고리즘(의사결정 트리, 랜덤 포레스트, BERT)을 사용하여 모델을 훈련시키고, 그 성능을 비교하는 내용을 언급하고 있어 정량적 평가를 실시하고 있음을 알 수 있습니다."
Early Prediction of Diabetes Mellitus Using Machine Learning,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9197832,"Diabetes mellitus is one of the noxious disease which causes abnormalities of blood glucose due to the resistance of producing insulin hormone in the body. It affects various organs in the body such as the kidney, nerves, and eyes if it is not an early diagnosis. With the advancement in technological growth, people attract to personalized healthcare. Machine learning is a very growing field in the predictive analysis and often used in healthcare applications where the prediction of diseases and their symptoms is identified in an early stage. The main objective of this work is to build a model for early prediction of diabetes by using machine learning classification algorithms under consideration of significant features related to diabetes. The proposed model gives the closest results comparing to clinical outcomes and also helps in the personalized diagnosis of patients. There are four machine learning algorithms these are Linear Discriminant Analysis (LDA), K-nearest neighbor (KNN), Support Vector Machine (SVM), and Random Forest (RF) are used in the predictive analysis of early-stage diabetes. Pima Indian Diabetes Database (PIDD) is used for experimental analysis which is taken from the UCI machine learning repository from the University of California, Irvine. The performance measures of these classification algorithms are done on various statistical measures such as sensitivity (recall), precision, specificity, F-score, and accuracy. Accuracy is the measurements of classifying correctly and incorrectly instances. The experimental results show that Random Forest (RF) gives the maximum accuracy of 87.66 % and outperformed in other classification algorithms.",Yes,"논문 초록에서 여러 머신러닝 분류 알고리즘의 성능 평가를 위해 정확도, 민감도(재현율), 정밀도, 특이도, F-점수 등 다양한 통계적 성과 지표를 사용하여 정량적 평가를 실시했음을 명확히 언급하고 있습니다. 이는 정량적 평가가 수행되었음을 보여줍니다."
Is the Future Cold or Tall? Design Space Exploration of Cryogenic and 3D Embedded Cache Memory,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10158184,"Memory latency, density, and power efficiency are key bottlenecks in a variety of computing systems, and the need for efficient and dense memory solutions is exacerbated by the continued importance of data-intensive applications such as machine learning, graph processing, and scientific computing. A myriad of emerging technologies and approaches aim to address the limitations of current systems. For example, 3D integration can enable highly dense memory structures, and multiple alternative device technologies such as STT and PCM have emerged as compelling solutions to improve memory system density and efficiency. Additionally, cryogenic operation of computing systems (i.e., ultra-low temperature cooling) is becoming a compelling solution as thermal hotspots have become a primary roadblock to conventional transistor scaling. This work probes, evaluates, and compares the potential capabilities of 3D integration, embedded non-volatile memories (eNVMs), and cryogenic operation towards improving future memory systems by presenting the first design space exploration of cryogenic operation and 3D integration applied towards the largest on-chip memory structure, the last level cache, as well as presenting and providing open-source tools for future, related design studies. This work specffically evaluates the applicationlevel benefits or limitations of such proposals by leveraging a cross-computing-stack simulation approach. Our studies reveal that the most compelling solution varies depending on the expected memory traffic patterns and workloads of interest, which in turn exposes several opportunities for future optimization and customization. For example, due to potentially high costs of cooling to cryogenic operation, we find that SRAM or 3T-eDRAM operating at 77K is sub-optimal compared to room-temperature SRAM and eNVM solutions, but exhibits advantages for relatively low-traffic workloads.",Yes,"논문 초록에서 다양한 기술과 설계 공간 탐색을 통해 평가를 수행했음을 보여주는 내용이 포함되어 있습니다. 특히, cryogenic operation과 3D 통합 기술의 잠재력을 평가하고 비교하는 정량적 분석과 시뮬레이션 연구를 수행했다고 명시되어 있습니다."
Deep Learning Models for Time Series Forecasting: A Review,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10583885,"Time series forecasting involves justifying assertions scientifically regarding potential states or predicting future trends of an event based on historical data recorded at various time intervals. The field of time series forecasting, supported by diverse deep learning models, has made significant advancements, rendering it a prominent research area. The broad spectra of available time series datasets serve as valuable resources for conducting extensive studies in time series analysis with varied objectives. However, the complexity and scale of time series data present challenges in constructing reliable prediction models. In this paper, our objectives are to introduce and review methodologies for modeling time series data, outline the commonly used time series forecasting datasets and different evaluation metrics. We delve into the essential architectures for trending an input dataset and offer a comprehensive assessment of the recently developed deep learning prediction models. In general, different models likely serve different design goals. We boldly examine the performance of these models under the same time series input dataset with an identical hardware computing system. The measured performance may reflect the design flexibility among all the ranked models. And through our experiments, the SCINet model performs the best in accuracy with the ETT energy input dataset. The results we obtain could give a glimpse in understanding the model design and performance relationship. Upon concluding the paper, we shall provide further discussion on future deep learning research directions in the realm of time series forecasting.",Yes,"초록에서 ""different evaluation metrics""와 ""performance""를 언급하며, 여러 모델의 성능 평가를 위해 정량적 평가를 실시했음을 시사합니다. 또한, 실험을 통해 모델의 정확도를 비교하는 내용이 포함되어 있어 정량적 평가가 수행된 것으로 판단됩니다."
Empowering Robo-Advisors: Data-Driven Mutual Fund and Stock Market Price Prediction with Deep Learning Techniques,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10718557,"In the contemporary financial landscape, the integration of deep learning techniques has revolutionized the capabilities of robo-advisors in providing data-driven insights for mutual fund and stock market price prediction. This study explores the application of deep learning methods, specifically Long Short-Term Memory (LSTM) and Gated Recurrent Unit (GRU) networks, in empowering robo-advisors to offer personalized investment recommendations and enhance decision-making processes for investors. Leveraging vast amounts of historical financial data, including market trends, asset prices, and economic indicators, LSTM and GRU networks are adept at capturing complex temporal patterns and dependencies within sequential data, enabling more accurate predictions of future stock prices and market trends. By employing these deep learning techniques, robo-advisors can analyze market dynamics in real-time, adapt investment strategies to changing conditions, and provide tailored recommendations aligned with individual investor preferences and risk profiles. Through a comprehensive review of existing literature and empirical studies, this paper evaluates the performance and effectiveness of LSTM and GRU networks in mutual fund and stock market price prediction tasks. The findings suggest that LSTM and GRU networks offer significant advantages over traditional forecasting methods, such as autoregressive models and technical analysis, by effectively capturing long-term dependencies and nonlinear relationships within financial time series data. Moreover, the integration of additional data sources, such as news sentiment analysis and social media trends, further enhances the predictive accuracy and robustness of the models. Overall, the application of deep learning techniques in empowering robo-advisors holds immense potential for revolutionizing investment management practices, democratizing access to financial markets, and empowering investors with actionable insights for informed decision-making. The proposed method is implemented in Python and has an accuracy of about 99.12%.",Yes,"논문 초록에서 딥러닝 기법(LSTM, GRU)을 활용하여 금융 데이터의 예측 성능을 평가하는 실험과 성과를 언급하고 있습니다. 이는 정량적 평가를 실시하고 있음을 시사하며, 모델의 정확도와 성능 비교도 포함되어 있습니다."
Improvement of Min-Entropy Evaluation Based on Pruning and Quantized Deep Neural Network,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10032186,"In the field of information security, the unpredictability of random numbers plays determinant role according to the security of cryptographic systems. However, limited by the capability of pattern recognition and data mining, statistical-based methods for random number security assessment can only detect whether there are obvious statistical flaws in random sequences. In recent years, some machine learning-based techniques such as deep neural networks and prediction-based methods applied to random number security have exhibited superior performance. Concurrently, the proposed deep learning models bring out issues of large number of parameters, high storage space occupation and complex computation. In this paper, for the challenge of random number security analysis: building high-performance predictive models, we propose an effective analysis method based on pruning and quantized deep neural network. Firstly, we train a temporal pattern attention-based long short-term memory (TPA-LSTM) model with complex structure and good prediction performance. Secondly, through pruning and quantization operations, the complexity and storage space occupation of the TPA-LSTM model were reduced. Finally, we retrain the network to find the best model and evaluate the effectiveness of this method using various simulated data sets with known min-entropy values. By comparing with related work, the TPA-LSTM model provides more accurate estimates: the relative error is less than 0.43%. In addition, the model weight parameters are reduced by more than 98% and quantized to 2 bits (compression over 175x) without accuracy loss.",Yes,"논문 초록에서 다양한 데이터 세트에 대해 최소 엔트로피 값을 평가하는 방법을 사용했다고 명시되어 있으며, 이를 통해 평가의 정량적 측정을 수행하고 있음을 알 수 있습니다. 또한, 모델의 정확도와 오차율을 구체적으로 제시하여 정량적 평가를 실시하고 있음을 보여줍니다."
A study of the Dream Net model robustness across continual learning scenarios,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10031093,"Continual learning is one of the major challenges of deep learning. For decades, many studies have proposed efficient models overcoming catastrophic forgetting when learning new data. However, as they were focused on providing the best reduce-forgetting performance, studies have moved away from real-life applications where algorithms need to adapt to changing environments and perform, no matter the type of data arrival. Therefore, there is a growing need to define new scenarios to assess the robustness of existing methods with those challenges in mind. The issue of data availability during training is another essential point in the development of solid continual learning algorithms. Depending on the streaming formulation, the model needs in the more extreme scenarios to be able to adapt to new data as soon as it arrives and without the possibility to review it afterwards. In this study, we propose a review of existing continual learning scenarios and their associated terms. Those existing terms and definitions are synthesized in an atlas in order to provide a better overview. Based on two of the main categories defined in the atlas, “Class-IL.” and “Domain-IL”, we define eight different scenarios with data streams of varying complexity that allow to test the models robustness in changing data arrival scenarios. We choose to evaluate Dream Net - Data Free, a privacy-preserving continual learning algorithm, in each proposed scenario and demonstrate that this model is robust enough to succeed in every proposed scenario, regardless of how the data is presented. We also show that it is competitive with other continual learning literature algorithms that are not privacy preserving which is a clear advantage for real-life human-centered applications.",Yes,"논문 초록에서 Dream Net 모델을 다양한 시나리오에서 평가하는 실험이 언급되어 있으며, 이를 통해 모델의 강건성을 정량적으로 검증하는 평가가 이루어지고 있음을 알 수 있습니다. 따라서, 정량적 평가를 실시하고 있다고 판단됩니다."
Detection And Tracking of Multiple Pedestrians Using Deep Learning,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10307543,"Recent advancements in deep learning and computer vision have benefitted security systems. Recent object tracking algorithms, in example, have incorporated deep learning in a variety of methods to enhance tracking performance. Object tracking and security systems continue to provide a number of difficulties. This work will first identify the several challenges related to the object tracking for an autonomous system and further the object tracker system will be evaluated in a simulated environment for multiple objects like pedestrian, moving or stationary object. This research paper is all about designing the tracking algorithm for multiple pedestrians. This research employed YOLO V3 with a Deep Sort architecture. In order to get heightened accuracy different kind of scenario is used for preparing the test data. As a result, precision is 93 %, Recall is 98% and accuracy is 96%.",Yes,"논문 초록에서 정밀도(precision), 재현율(recall), 정확도(accuracy)와 같은 정량적 평가 지표를 제시하고 있어, 정량적 평가를 실시하고 있음을 알 수 있습니다. 이러한 지표들은 성능을 수치로 평가하는 정량적 분석의 예입니다."
Augmenting Dementia Cognitive Assessment With Instruction-Less Eye-Tracking Tests,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9124654,"Eye-tracking technology is an innovative tool that holds promise for enhancing dementia screening. In this work, we introduce a novel way of extracting salient features directly from the raw eye-tracking data of a mixed sample of dementia patients during a novel instruction-less cognitive test. Our approach is based on self-supervised representation learning where, by training initially a deep neural network to solve a pretext task using well-defined available labels (e.g. recognising distinct cognitive activities in healthy individuals), the network encodes high-level semantic information which is useful for solving other problems of interest (e.g. dementia classification). Inspired by previous work in explainable AI, we use the Layer-wise Relevance Propagation (LRP) technique to describe our network's decisions in differentiating between the distinct cognitive activities. The extent to which eye-tracking features of dementia patients deviate from healthy behaviour is then explored, followed by a comparison between self-supervised and handcrafted representations on discriminating between participants with and without dementia. Our findings not only reveal novel self-supervised learning features that are more sensitive than handcrafted features in detecting performance differences between participants with and without dementia across a variety of tasks, but also validate that instruction-less eye-tracking tests can detect oculomotor biomarkers of dementia-related cognitive dysfunction. This work highlights the contribution of self-supervised representation learning techniques in biomedical applications where the small number of patients, the non-homogenous presentations of the disease and the complexity of the setting can be a challenge using state-of-the-art feature extraction methods.",Yes,"논문은 딥 뉴럴 네트워크를 활용한 정량적 특징 추출과 성능 평가를 수행하고 있으며, self-supervised 학습과 비교 실험을 통해 성능 차이를 정량적으로 분석하고 있습니다. 이러한 내용은 정량적 평가가 이루어지고 있음을 보여줍니다."
Early Prediction of Neonatal Sepsis From Synthetic Clinical Data Using Machine Learning,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10341082,"Neonatal sepsis is one of the most serious complications in neonatal intensive care units. Due to the often immature immune system, sepsis-related comorbidities are the major contributors to increased neonatal mortality. The rapid progression of the disease makes early treatment critical for patient survival. However, early diagnosis of sepsis remains difficult due to its non-specific symptoms. In recent years, Machine Learning-based techniques have been used in various medical applications to predict diseases using clinical data. In this work, we optimized and evaluated four prediction models with different architectural concepts. Two public datasets containing clinical data from adults and neonates were used for training. The adult data were collected to pre-train the models. Since neonatal data with sepsis diagnosis are very limited, we propose an augmentation method to generate synthetic clinical data. For the final evaluation, the real data of neonatal patients were defined as a test set. An AUROC of 0.91 and an AUPRC of 0.38 were obtained. These results are promising for early prediction of neonatal sepsis using artificial data for augmentation.Clinical relevance— This work demonstrates the potential of Machine Learning-based prediction models for the detection of sepsis to improve the early diagnosis of life-threatening conditions in neonatal intensive care units.",Yes,"논문 초록에서 네 가지 예측 모델을 최적화하고 평가했다고 명시되어 있으며, AUROC와 AUPRC와 같은 정량적 지표를 통해 성능을 평가했다고 언급되어 있습니다. 이는 정량적 평가가 실시되었음을 보여줍니다."
Sentiment Analysis for Informal Malay Text in Social Commerce,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9574436,"Sentiment Analysis (SA) is opinion mining which often defines as the study of emotions, opinions, or feedback that relates to the usage of computational linguistics, text analytics, and natural language processing. With the rise of social media posts, it is becoming more challenging to evaluate brief, casual, and non-structured texts to optimize consumer feedback and spot patterns. Meanwhile, social commerce involves social media for social interaction in assisting customers and merchants to do business transactions. From a social media perspective, the informal Malay Text is less explored by the researchers. Thus, it will directly yield difficulties in conducting and preparing the SA processes. Cross-Industry Standard Process for Data Mining (CRISP-DM) was adapted as a reference model for the methodology of this work with machine learning approaches in classifying the informal Malay textual data based on sentiment. The dataset was extracted from the Facebook platform of Pos Laju Malaysia pages. The comparison of the classification technique performances was analyzed in identifying the most accurate classifier for SA, within three different machine learning classifiers was experimented by using 1200 instances from an informal Malay textual dataset. The results of Decision Tree (J48), Support Vector Machine (SVM), and Naïve Bayes (NB) were analyzed and discussed. The result of the highest accuracy of Ten-Fold Cross-Validation is 69.7% and meanwhile, for the Percentage Split method, the highest accuracy result is 70.9%. It shows that Support Vector Machine (SVM) is the best classifier compared to other classifiers of text classification based on sentiment.",Yes,"논문 초록에서 세 가지 머신러닝 분류기(SVM, Naïve Bayes, Decision Tree)의 성능을 정량적으로 평가한 결과를 제시하고 있으며, 정확도 수치를 통해 평가를 수행하고 있음을 보여줍니다. 이는 명확한 정량적 평가가 이루어지고 있음을 의미합니다."
Modeling Flow Boiling Utilizing Machine Learning Vision Data,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10709607,"Flow boiling is a very efficient configuration for meeting the high heat dissipation demands of thermal management systems. However, the lack of a clear understanding of physics affecting two-phase flow has limited its wide implementation across thermal systems. Recently, novel machine learning vision tools have been developed to capture physical feature information during subcooled flow boiling in a rectangular channel with single-sided heating. These features include local and averaged, as well as transient and steady-state statistical data on void fraction, vapor-liquid voids, interfacial behaviors, and liquidsolid wall wetting front areas. In this study, this data is used to model performance parameters in flow boiling. The statistical information relating to void fraction, bubble behaviors, interfacial waviness, and wetting fronts is analyzed and correlated with heat transfer coefficients, and critical heat flux. The data is used in combination with traditional control-volume-based theoretical modeling techniques to capture the relationship between the parameter of interest and the input parameters. The data on channel void fraction and wetting front areas are used to improve theoretical models predicting heat transfer coefficient. The data on interfacial behaviors and wetting front areas is to improve mechanistic model predicting critical heat flux. With this work, a new approach to utilizing machine vision data is proposed and validated.",Yes,"논문 초록에서 다양한 통계적 데이터와 물리적 특성들을 분석하고 상관관계를 파악하는 과정이 언급되어 있으며, 이를 통해 성능 매개변수와 이론적 모델을 정량적으로 평가하는 방법이 사용되고 있음을 알 수 있습니다. 따라서, 정량적 평가를 실시하고 있다고 판단됩니다."
Differentially Private Multi-Site Treatment Effect Estimation,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10516620,"Patient privacy is a major barrier to healthcare AI. For confidentiality reasons, most patient data remains in silo in separate hospitals, preventing the design of data-driven healthcare AI systems that need large volumes of patient data to make effective decisions. A solution to this is collective learning across multiple sites through federated learning with differential privacy. However, literature in this space typically focuses on differentially private statistical estimation and machine learning, which is different from the causal inference-related problems that arise in healthcare. In this work, we take a fresh look at federated learning with a focus on causal inference; specifically, we look at estimating the average treatment effect (ATE), an important task in causal inference for healthcare applications, and provide a federated analytics approach to enable ATE estimation across multiple sites along with differential privacy (DP) guarantees at each site. The main challenge comes from site heterogeneity—different sites have different sample sizes and privacy budgets. We address this through a class of per-site estimation algorithms that reports the ATE estimate and its variance as a quality measure, and an aggregation algorithm on the server side that minimizes the overall variance of the final ATE estimate. Our experiments on real and synthetic data show that our method reliably aggregates private statistics across sites and provides better privacy-utility tradeoff under site heterogeneity than baselines.",Yes,"논문 초록에서 ATE(평균 치료 효과)를 추정하는 정량적 평가를 수행한다고 명확히 언급하고 있으며, 각 사이트의 ATE 추정치와 분산을 보고하는 알고리즘을 제시하여 정량적 평가를 실시하고 있음을 보여줍니다. 또한, 실험을 통해 방법의 성능을 수치적으로 평가하는 내용이 포함되어 있습니다."
Comparative Analysis of Deep Convolution Neural Networks on Medical Image-Based COVID-19 Detection,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10670901,"The COVID-19 pandemic has spurred a dire need for efficient and accurate diagnostic tools to combat the spread of the virus. Medical imaging, particularly chest X-rays and computed tomography (CT) scans, has emerged as a vital component in the diagnosis and monitoring of COVID-19-related lung abnormalities. An effective method is presented in this paper for identifying COVID-19 and distinguishing it from normal X-rays and viral pneumonia cases using Deep Convolutional Neural Networks (CNN). An assessment of three CNN models (EfcientNetB0, VGG16, and InceptionV3) is performed using transfer learning methods. The most common deep learning algorithms used in this study are convolutional neural networks (CNNs). Performance measures (accuracy, recall, specificity, precision, and F1 scores) and deep learning approaches are used in this work. With an overall accuracy of 96.27% and a sensitivity of 95.63% for COVID-19, the findings demonstrate that the suggested technique generated a high-quality model. Effective detection and screening procedures may be facilitated by implementing computer vision design, as demonstrated by the study.",Yes,"논문 초록에서 정확도, 재현율, 특이도, 정밀도, F1 점수 등 다양한 성능 지표를 사용하여 모델의 성능을 정량적으로 평가했다고 명시되어 있습니다. 이러한 지표들은 정량적 평가의 대표적인 예로, 연구에서 평가 방법이 포함되어 있음을 보여줍니다."
A Comprehensive Experiment to Enhance Multidisciplinary Engineering Ability via UAVs Visual Navigation,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9273977,"This Research to Practice WIP presents a UAVs visual navigation based comprehensive experiment to enhance multidisciplinary engineering ability in Aerospace engineering education. In traditional courses, aerospace-related disciplines are independently distributed in different courses, and there is rarely a hands-on platform which includes signal processing, control theory, and artificial intelligence into Aerospace engineering. Facing this problem, this paper designs a multidisciplinary comprehensive experiment, aiming to provide a hand-on platform and flexible project-based program to students of aerospace engineering professions. First of all, in order to let the students understand actual aerospace problems, a multidisciplinary simulation platform containing UAVs and remote objects scenarios is constructed for them to explore in the experiments. Second, the content of the experiment is designed into three stages including data acquisition and processing, conceptual design and simulation, in-flight validation, during which the multidisciplinary engineering ability runs through the whole process of the activities. Finally, Project Oriented Design Based Learning is also introduced here to combine engineering design education with innovation and creativity. Through the project demonstration and presentation at the end of the experiment, the multidisciplinary engineering ability of each student can be effectively evaluated. The UVN comprehensive experiment enables students to work on real-world aerospace engineering problems through a hardware-software integration framework, which may greatly stimulate their curiosity and interest in autonomously learning. It also provides students unprecedented opportunities to immerse themselves in projects that cross disciplinary boundaries, improve their professional ability and enhance their exploration competence in aerospace areas.",No,"논문 초록에서는 실험이 설계되고 수행되었음을 언급하지만, 구체적인 정량적 평가 방법이나 수치 데이터 분석에 대한 내용이 포함되어 있지 않습니다. 따라서 정량적 평가를 실시하고 있다고 보기 어렵습니다."
Feature importance calculation and protein quality assessment on the decoy discrimination problem,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7965862,"The function of each protein in the body is determined by its 3D structure, which can be predicted by computational methods. These methods generate an exceptional quantity of candidate models (decoys). similarity and machine learning methods are used to assess their quality. When measuring the distance from the decoy to its native structure (RMSD, TM-Score, Z-Score), similarity methods may be applied. On the other hand, machine learning methods use a subset of structural and physicochemical features to assess the quality of these candidate models. In the preprocessing step, a subset of these features is selected by hand to be used in the machine learning process. The model proposed in this work considers different sets of features simultaneously, and automatically selects, via an evolutionary model, the optimal subset to be used in the machine learning method. The proposed model also provides the relative feature importance related to the quality of the decoy model. The new model, named Score Wrapper to Feature Importance Calculation (SWtoFIC), also calculates the quality of the decoy model. These characteristics make this model an important tool to assess the decoy quality and to better understand the influence of different types of features in the decoy quality determination.",Yes,"논문 초록에서 제안된 모델은 다양한 특징의 중요도를 계산하는 기능을 포함하고 있으며, 이를 통해 정량적 평가를 수행하고 있음을 명확히 언급하고 있습니다. 또한, decoy 모델의 품질을 평가하는 데 사용되는 수치적 지표와 방법들이 언급되어 있어 정량적 평가가 실시되고 있음을 알 수 있습니다."
Real-time fuzzy logic speed tracking controller for a DC motor using Arduino Due,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7069560,"Designing and developing AI controllers on separately dedicated chips have many advantages. This paper reviews the development of a real-time fuzzy logic controller for speed control of a dc motor using Arduino Due board. The proposed fuzzy logic controller is based on Mamdani approach and has been tested on the aforementioned high performance microcontroller board and using MATLAB. During the real-time operation the dc motor behavior and the fuzzy controller's response were plotted and the data were stored in MATLAB without interrupting the fuzzy logic controller. Based on these observed information, the system settling time and the rise time reduction were calculated for each input wave patent trajectories while increasing the wave frequency. It was noted that the system overshoot is negligible. Utilizing the aforementioned parameters the Arduino Due board performance was analyzed with the fuzzy logic speed control approaches of dc motors made by past researchers as mentioned above. The system response shows a satisfactory performance for this particular dc motor application when the input signal (desired output signal) frequency is less than 2 Hz, but further research is needed when identifying the optimum performance of the Arduino Due board for different fuzzy logic algorithms while increasing the desired input signal frequency.",Yes,"논문 초록에서 시스템의 응답 시간과 상승 시간, 오버슈트 등을 정량적으로 계산하고 분석하는 내용을 포함하고 있어, 정량적 평가를 실시하고 있음을 알 수 있습니다."
Evaluating ML Algorithm precision over indoor thermal comfort through comparison of popular metrics,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10187456,"Predicting the temperature in indoor spaces is essential for upholding cozy living and working conditions as well as for assuring the security and preservation of delicate tools and materials. This parameter's forecast beforehand can aid in reducing hazards, enhancing operations, and improving energy efficiency. In this paper, data retrieved from sensors, positioned within a particular building, has been simulated through three machine learning ML models. Machine Learnings (ML) become a potent tool for temperature prediction based on historical data, weather patterns, and other related elements in recent years. We evaluated the performance of three machine learning (ML) models using a train and test dataset. This paper focuses on identifying the best model selection comparing the three chosen models.",Yes,"초록에서 ""We evaluated the performance of three machine learning (ML) models using a train and test dataset""라는 문장을 통해 정량적 평가가 수행되었음을 알 수 있습니다. 이는 여러 모델의 성능을 비교하기 위해 수치적 지표를 활용했음을 시사합니다."
Analysis of Movie Recommendation Systems,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10308144,"This research paper presents a comprehensive literature review of various movie recommendation systems, including techniques such as sentiment analysis of comments, movie trailer data, facial expressions, browsing history, and view percentage. The paper also compares various recommenders based on deep learning and swarm algorithms. Furthermore, this paper provides a novel approach for movie recommender system that uses a hybrid model combining content-based and collaborative filtering approaches. Specifically, the proposed approach involves creating a matrix factorization-based model and providing certain custom-designed features, such as averages of all movies and users, top similar movies, and top similar users, to produce the final model. The proposed approach is evaluated on the MovieLens dataset and achieves a mean absolute percentage error (MAPE) of 19.868316 and a root mean squared error (RMSE) of 0.672788. These outcomes illustrate the potency of the suggested strategy and its potential to enhance movie recommendation systems.",Yes,논문 초록에서 제안된 영화 추천 시스템의 성능 평가를 위해 평균 절대 백분율 오차(MAPE)와 루트 평균 제곱 오차(RMSE)를 사용하여 정량적 평가를 실시했다고 명시되어 있습니다. 이러한 지표들은 추천 시스템의 정확도를 수치로 측정하는 정량적 평가 방법입니다.
Neural Currency Guard using Generative Adversarial Networks,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10537784,"Counterfeit currency detection remains an ongoing challenge worldwide, as counterfeiters continuously enhance their techniques. This paper provides a comprehensive review of recent advancements in counterfeit currency detection systems, with a specific focus on innovative approaches using Generative Adversarial Networks (GANs). We implement GANs to generate realistic synthetic currency images for training robust counterfeit detectors. By thoroughly analyzing current research, we gain valuable perspectives into GAN-based methodologies for producing diversified fake currency data. Our study also examines the utilization of image processing, machine learning, and spectroscopic techniques in existing counterfeit recognition systems. Additionally, we detail a practical implementation of GANs for generating counterfeit currency images in Indian context, as well as evaluate its effectiveness. This research aims to deliver vital insights into cutting-edge counterfeit currency detection, presenting fresh perspectives on harnessing GANs. It also intends to aid future research by highlighting potential areas for improvement.",Yes,"The abstract mentions that the study evaluates the effectiveness of the GAN-based approach for generating counterfeit currency images, indicating that some form of quantitative assessment or evaluation is conducted. This suggests that the paper includes quantitative evaluation methods to measure the system's performance."
User interest acquisition by adding home and work related contexts on mobile big data analysis,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7562072,"User interest acquisition facilitates customized service by figuring out user preferences in various areas, such as recommendation system and intelligence city. Mobile Internet enriches traditional user behaviors (such as who (user), when (time) and what (content)) by introducing where (mobility) into the analysis of user interest acquisition. However, user mobility is highly predictable, and user interests are constrained in a small scope. In the era of mobile big data, although several association rules and Bayesian model based approaches have been proposed to identify user interests, the impact of home and work related contexts in users' daily lives on user interest has not been fully investigated. In fact, home and work locations are anchors in user mobility and provide abundant behavior contexts to know a person. So this article proposes a framework using home and work related contexts to identify user interests. The proposed framework consists of home-work related contexts awareness based on greedy strategy, dimensionality reduction based on principle components analysis, and modeling based on various state-of-the-art machine learning algorithms. Then the proposed framework is validated on a real dataset covering 6,800 residents with more than 3.2 million records in 23 days. Results show that the proposed framework is effective, and the precision can reach more than 82% with only 7 principle components.",Yes,"논문 초록에서 다양한 기계 학습 알고리즘을 활용한 모델링과 정량적 평가 결과(정확도 82% 이상)를 제시하고 있어, 정량적 평가를 실시하고 있음을 알 수 있습니다."
A Deep Learning Approach for Semantic Similarity Prediction Between Question Pairs Using Siamese Network and Word Embedding Techniques,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10585920,"Question-answering platforms, such as Quora, Red-dit, and StackOverflow, have become immensely popular in the virtual community. Among these platforms, Quora stands out as a widely utilized and resourceful repository with over 300 million monthly visitors. However, the prevalence of similar questions with paraphrased content poses challenges for users in finding relevant answers. This paper proposes a deep learning approach for predicting the semantic similarity of question pairs to address the issue of duplicate questions. The proposed model employs a Siamese network-based Long Short-Term Memory (LSTM) architecture, utilizing word embedding vectors from various algorithms such as Glo Ve, Word2Vec, and FastText. Previous research on duplicate question identification is reviewed, with our approach overcoming drawbacks such as low-level semantic connections and text type incompatibility. After pre-processing the Siamese LSTM network compares the embeddings using L1 distance to determine question pair similarity. The model is trained and evaluated on the Quora Question Pair Classification dataset, and outperformed other state-of-the-art methods with an accuracy of 84.77% with the FastText word embedding.",Yes,"논문 초록에서 정량적 평가를 위해 모델의 정확도(84.77%)를 제시하며, 실험을 통해 성능을 평가하고 있음을 보여줍니다. 이는 정량적 평가를 실시하고 있음을 의미합니다."
Binarized Neural Network for Edge Intelligence of Sensor-Based Human Activity Recognition,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9529002,"A wide diversity of sensors has been applied in human activity recognition. These sensors generate enormous amounts of data during human activity monitoring. Server-based computing and cloud computing require to upload all sensor data to servers/clouds for data processing and analysis. The long-distance data traveling between sensors and servers increases the costs of bandwidth and latency. However, human activity recognition has a high demand for real-time processing. Recently, edge computing is surging to solve this problem by moving computation and data storage closer to the sensors, rather than relying on a central server/cloud. Most human activity recognition is conducted by artificial intelligence, which requires intensive computation and high power consumption. Edge servers are usually designed for low power, low cost, and low computation. They do not support computation-intensive deep learning algorithms or result in high latency. Fortunately, the development of binarized neural networks enables edge intelligence, which supports AI running at the network edge for real-time applications. In this paper, we implement a binarized neural network (BinaryDilatedDenseNet) to enable low-latency and low-memory human activity recognition at the network edge. We applied the BinaryDilatedDenseNet on three sensor-based human activity recognition datasets and evaluated it with four metrics. In comparison, the BinaryDilatedDenseNet outperforms the related work and other three binarized neural networks in overall and saves 10× memory and 4.5×–8× inference time compared to the FPDilatedDenseNet(the full-precision version of the BinaryDilatedDenseNet).",Yes,"논문 초록에서 ""evaluated it with four metrics""라는 표현을 통해 정량적 평가를 실시했음을 명확히 언급하고 있습니다. 또한, BinaryDilatedDenseNet의 성능을 기존 방법과 비교하는 구체적인 수치(메모리 절감, 추론 시간 향상)를 제시하여 정량적 평가가 이루어졌음을 알 수 있습니다."
Noise and performance analysis on fundus images with CNN and transformer models,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10455148,"Fundus imaging is a valuable diagnostic tool in ophthalmology, providing clinicians with detailed visualizations of the retina and aiding in the detection and monitoring of various eye diseases, including age-related macular degeneration (AMD), glaucoma, diabetic retinopathy (DR), and cataract. However, the quality of fundus images can be significantly affected by noise, mainly additive white Gaussian noise (AWGN), which is inherent in many imaging systems. The presence of noise in real-world data poses significant challenges for computer vision tasks. In the field of medical image classification, a wrong diagnoisis has heavy consequences. Understanding the impact of AWGN on fundus images is crucial for developing practical denoising algorithms and improving diagnostic accuracy. This work presents an analysis of AWGN noise in fundus images aims to characterize its effects on image quality and assess its impact on diagnostic tasks. The work also analyzes the performance of six models (3 each) of two popular deep learning architectures, Convolutional Neural Networks (CNN) and Vision Transformers (ViT) in the presence of AWGN. AWGN is first introduced to the clean image datasets to conduct the analysis. The CNN and ViT models are trained on the noisy datasets to evaluate the performance of the image classification task. The work also involves six denoising algorithms and a popular image enhancement algorithm- Contrast Limited Adaptive Histogram Equalization (CLAHE).",Yes,"논문 초록에서 CNN과 Transformer 모델의 성능 평가를 위해 노이즈가 포함된 데이터셋을 사용하여 실험을 수행했다고 명시되어 있습니다. 또한, 다양한 노이즈 제거 알고리즘과 성능 평가를 통해 정량적 분석이 이루어졌음을 알 수 있습니다."
Meta Mimetic: Few-Shot Classification of Mobile-App Encrypted Traffic via Multimodal Meta-Learning,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10555634,"Despite its proven effectiveness in classifying encrypted network traffic, deep learning requires large amounts of labeled data to feed typical data-hungry training processes. Few-shot learning provides means to overcome these limitations, supporting classification tasks related to traffic with few labeled data available. Its extensive investigation in other domains notwithstanding (e.g., computer vision), it has been only preliminarily adopted for classifying encrypted traffic.In this work, we design and evaluate Meta Mimetic a novel multimodal few-shot learning solution for classifying mobile-app encrypted traffic. The proposal is based on the meta-learning paradigm and introduces enhancements via the adoption of a multimodal feature extractor trained via a novel ad-hoc meta-learning procedure. Since Meta Mimetic is orthogonal to the specific few-shot learning approach, in our experimentation, we adapt it to a number of different meta-learning approaches (namely MatchingNet, ProtoNet, RelationNet, MetaOptNet, foMAML, and ANIL). We provide an empirical assessment of these approaches, considering the Mirage-2019 dataset as a test bench. Results show that Meta Mimetic represents the best trade-off in terms of performance and complexity in mobile-app traffic classification (up to 91% F1-score) when compared to state-of-the-art solutions. The in-depth analysis of the performance of its components allows us to shed light on the multimodal internal mechanisms and further improve classification performance. Finally, we demonstrate the robustness of our proposal (only ≈ 2% F1-score drop) against the next variations introduced by the TLS 1.3 encryption that may impair the information exploitable by payload-based traffic classifiers.",Yes,"논문 초록에서 다양한 메타러닝 접근법을 적용하여 실험을 수행하고, 성능 평가를 통해 결과를 제시하는 등 정량적 평가를 실시했음을 명확히 언급하고 있습니다. 또한, F1-score와 같은 구체적인 성능 지표를 제시하여 평가의 정량성을 보여줍니다."
Enhancing Electricity Consumption Forecasting with Artificial Intelligence on Small Datasets: A Comparative Study,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10821571,"Accurate electricity consumption forecasting is essential for efficient resource allocation and grid management, particularly with limited data. The present paper investigates how artificial intelligence techniques can enhance forecasting in small datasets and addresses data quality concerns in the educational sector. It reviews challenges in traditional forecasting, explores artificial intelligence methods such as support vector machines, autoregressive integrated moving average, and long short-term memory networks, and evaluates their performance using real-world data from four educational buildings belonging to the Technical University of Cluj-Napoca. By combining theoretical insights with empirical results, the present study advances artificial intelligence-driven forecasting for electricity consumption in small datasets, offering insights for future research and industry applications in energy management and policy formulation.",Yes,"논문 초록에서 여러 인공지능 기법들의 성능을 평가하기 위해 실험적 데이터를 활용하여 비교 분석하는 내용을 언급하고 있습니다. 이는 정량적 평가를 실시하고 있음을 시사하며, 실세계 데이터를 이용한 성과 평가가 포함되어 있음을 알 수 있습니다."
Machine Learning Based Battery Aging Management Strategy for Electric Vehicles,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9533026,"Electric vehicles are becoming the front runners for both urban and rural mobility challenges on account of less pollution, rising fuel cost, better performance and environmental impacts. However, the aging and replacement cost of battery packs, resulting from dynamic and nonlinear behavior of the battery degradation is still an unresolved problem in electric automobile applications. The goal of this work is to introduce a novel machine learning based battery degradation control strategy to avert the rapid capacity loss of battery packs bearing in mind of vehicle performance. Battery currents and depth of discharge are chosen as the battery aging control parameters and performance validation is achieved by doing simulation on degrading battery pack in the electric vehicle model using various charging and discharging profiles. The proposed closed-loop control strategy is developed by evaluating different regression models using generated dataset, based on work related to data-driven power management strategy and controlling battery current limit values. From the comparison, it is observed that Gaussian process regression shows better precision over other regression models. The simulation outputs prove the ability of the proposed strategy to extend the electric vehicle battery life by 2.03% over 200,000km. This work can be extended by using deep learning based models and more charge and discharge profiles.",Yes,"논문 초록에서 배터리 성능을 평가하기 위해 다양한 회귀 모델을 사용하여 시뮬레이션을 수행하고, 그 결과를 비교 분석하는 정량적 평가를 실시하고 있음을 명확히 언급하고 있습니다. 이를 통해 배터리 수명 연장 효과를 수치로 제시하는 등 정량적 평가가 이루어지고 있음을 알 수 있습니다."
Implementation of a Customized Named Entity Recognition (NER) Model in Document Categorization,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10841691,"In institutions, one of the problems that arise is related to accumulating a large amount of documentation about their processes and other important information; a recurring task to manage these documents occurs when classifying them. In addition to this, in current times, with the exploitation of applications using Artificial Intelligence (AI) and Natural Language Processing (NLP), they are allowing to provide solutions at a technological level. In this work, we propose a methodology for the development of a customized Named Entity Recognition (NER) model and implement it, for the task of classifying documents and determining and verifying if the classification performed corresponds to a manual classification. To evaluate the performance of the classifier, an automatic classification of 1049 documents from the corpus for knowledge management of an institution was used, using a customized NER model. The results allow us to determine that the presented model achieves 95% positive classifications; the methodology is developed with the purpose of being replicated and scaled, according to the different needs of organizations.",Yes,"논문 초록에서 제안된 NER 모델의 성능을 평가하기 위해 1049개의 문서에 대한 자동 분류 결과를 제시하며, 95%의 긍정적 분류율을 보고하고 있습니다. 이는 정량적 평가를 실시했음을 보여주는 명확한 지표입니다."
Rendering 3D City for Smart City Digital Twin,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9821113,"The field of 3D city modelling has attracted a growing interest for representing the city digital twin, providing interactive visualizations of building infrastructures integrated with a wide range of data typically produced in a Smart City environment. This paper presents a method for producing a 3D city model with photorealistic rooftop textures extracted from aerial images, as well as the integration of the 3D city model into an open-source Smart City framework. The proposed solution provides a smart visualization of 3D city entities integrated with a large variety of Smart City data (coming, for instance, from IoT Devices which generate time-series data, heatmaps, geometries and shapes related to traffic flows, bus routes, cycling paths etc.). The proposed method for rooftop detection and alignment follows a deep learning approach based on U-Net architecture, and it has been validated against a manually created ground-truth of 50 buildings scattered uniformly on the covered area. The solution is implemented in the open-source Snap4City Smart City platform. DEMO: The solution will be demonstrated and the readers and conference attendees will be capable to interact and work with the tools by using the links provided.",Yes,"논문은 3D 도시 모델의 제작과 검증을 위해 U-Net 기반 딥러닝 방법을 사용하여 정량적 평가를 수행했음을 언급하고 있습니다. 특히, 50개 건물에 대한 수작업 검증 데이터와의 비교를 통해 검증 과정을 포함하고 있어 정량적 평가가 실시되고 있음을 알 수 있습니다."
Undergraduate In-class Research Experience for Computer Architecture Students,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9799265,"This study presents a hands-on research experience for undergraduate senior-level computer architecture course students. The students have investigated scientific research process, literature review approaches, technical writing as well as blind-review principles, and conducted hands-on research on three different computer systems, namely, a supercomputer, an office desktop, and an autonomous vehicle artificial intelligence computer systems, for a budget-constrained final computer configuration of an office desktop computer.The final student team outcomes, relevant feedback, and the corresponding surveys, evaluated by the project administrators, strongly imply the success of the project for an effective research component inclusion in an undergraduate course.",No,"논문 초록에서는 학생들이 다양한 연구 활동을 수행했음을 언급하지만, 정량적 평가 방법이나 구체적인 평가 지표에 대한 언급이 없습니다. 따라서 정량적 평가를 실시했다고 보기 어렵습니다."
Statistical Minimax Lower Bounds for Transfer Learning in Linear Binary Classification,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9834760,"Modern machine learning models require a large amount of labeled data for training to perform well. A recently emerging paradigm for reducing the reliance of large model training on massive labeled data is to take advantage of abundantly available labeled data from a related source task to boost the performance of the model in a desired target task where there may not be a lot of data available. This approach, which is called transfer learning, has been applied successfully in many application domains. However, despite the fact that many transfer learning algorithms have been developed, the fundamental understanding of ""when"" and ""to what extent"" transfer learning can reduce sample complexity is still limited. In this work, we take a step towards foundational understanding of transfer learning by focusing on binary classification with linear models and Gaussian features and develop statistical minimax lower bounds in terms of the number of source and target samples and an appropriate notion of similarity between source and target tasks. To derive this bound, we reduce the transfer learning problem to hypothesis testing via constructing a packing set of source and target parameters by exploiting Gilbert-Varshamov bound, which in turn leads to a lower bound on sample complexity. We also evaluate our theoretical results by experiments on real data sets.",Yes,"논문 초록에서 ""develop statistical minimax lower bounds""라는 표현을 통해 정량적 평가를 위한 수학적 또는 통계적 기준을 제시하고 있음을 알 수 있습니다. 또한, 샘플 복잡도에 대한 하한을 도출하는 과정이 포함되어 있어 정량적 평가를 실시하고 있음을 보여줍니다."
Mental Effort Estimation by Passive BCI: A Cross-Subject Analysis,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9630613,"Despite the technological advancements, the employment of passive brain computer interface (BCI) out of the laboratory context is still challenging. This is largely due to methodological reasons. On the one hand, machine learning methods have shown their potential in maximizing performance for user mental states classification. On the other hand, the issues related to the necessary and frequent calibration of algorithms and to the temporal resolution of the measurement (i.e. how long it takes to have a reliable state measure) are still unsolved. This work explores the performances of a passive BCI system for mental effort monitoring consisting of three frontal electroencephalographic (EEG) channels. In particular, three calibration approaches have been tested: an intra-subject approach, a cross-subject approach, and a free-calibration procedure based on the simple average of theta activity over the three employed channels. A Random Forest model has been employed in the first two cases. The results obtained during multi-tasking have shown that the cross-subject approach allows the classification of low and high mental effort with an AUC higher than 0.9, with a related time resolution of 45 seconds. Moreover, these performances are not significantly different from the intra-subject approach although they are significantly higher than the calibration-free approach. In conclusion, these results suggest that a light (three EEG channels) passive BCI system based on a Random Forest algorithm and cross-subject calibration could be a simple and reliable tool for out-of-the-lab employment.",Yes,"논문은 머신러닝 기법인 Random Forest를 사용하여 정신적 노력 수준을 정량적으로 평가하는 실험을 수행하였으며, 성능 지표인 AUC 값을 제시하여 정량적 평가를 실시하고 있음을 보여줍니다. 따라서, 정량적 평가를 수행하는 것으로 판단됩니다."
Systematic Comprehension for Developer Reply in Mobile System Forum,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8668016,"Review-based software development has become increasingly prevalent in recent years. Existing efforts aiming at either informative evaluation or sentiment analysis are mainly from the perspective of the reviewers, while neglecting the attitude and behavior of the developers. Such efforts inevitably suffer from recommendation bias in practice, and thus benefit little for the improvement of user reviews.In this paper, we attempt to bridge the gap between user review and developer reply, and conduct a systematic study for review reply in development forums, especially in Chinese mobile system forums. To this end, we concentrate on three research questions: 1) should a targeted review be replied; 2) how long time it should be replied; 3) does traditional review analysis help to pursue a reply for certain review? To answer such questions, given certain review datasets, we perform a systematical study including the following three stages: 1) a binary classification for reply behavior prediction, 2) a regression for prediction of reply time, 3) a systematic factor study for the relationship between traditional review analysis and reply performance. To enhance the accuracy of prediction and analysis, we proposed a CNN-based weak-supervision analysis framework, which exploits manifold techniques from NLP and deep learning. We validate our approach via extensive comparison experiments. The results show that our analysis framework is effective. More importantly, we have uncovered several interesting findings, which provide valuable guidance for further review improvement and recommendation.",Yes,"논문 초록에서 답변 행동 예측, 답변 시간 예측, 전통적 리뷰 분석과 답변 성과 간의 관계를 평가하는 등 정량적 평가를 수행하는 구체적인 방법들이 언급되어 있습니다. 또한, CNN 기반의 약지도 학습 프레임워크를 활용하여 실험을 통해 검증하는 과정을 포함하고 있어 정량적 평가가 실시되고 있음을 알 수 있습니다."
Fine-Grained Sentiment Analysis for Enhanced Financial Distress Prediction,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10485942,"Sentiment analysis aims to identify the sentiment polarity of specific aspects within given sentences or comments, and aspect-based sentiment analysis is considered a fundamental task in sentiment analysis. With practical applications in areas such as product reviews, food delivery evaluations, and public opinion monitoring, sentiment analysis plays a crucial role. This paper focuses on the application of fine-grained sentiment analysis in financial distress prediction (FDP) to enhance early warnings of the management status of companies. In previous studies, there has been a narrow emphasis on using document-level sentiment analysis to extract overall sentiment from text, overlooking the semantic nuances conveyed by sentiments. Therefore, this paper aims to extract fine-grained sentiments from the Management Discussion & Analysis (MD&A) of Chinese listed companies. The proposed model is based on a two-step framework, consisting of an unsupervised aspect-level financial sentiment extraction phase and a model validation phase. Specifically, the former is built on a deep learning model with an attention mechanism, conducting unsupervised aspect extraction, aspect identification, and aspect-level sentiment classification in a sequential manner to obtain fine-grained sentiments. The latter is responsible for evaluating the effectiveness of the newly acquired features on benchmark machine learning models, including SVM, DT, LR, CNN, and DNN. Experimental results reveal that MD&A predominantly covers eight types of aspects, including ownership, business scope, development, capital, sales, management, prizes, and probability. Additionally, it has been observed that fine-grained sentiment features can enhance the performance of FDP. This study represents a significant innovation in existing literature, being the first to introduce aspect-level financial sentiment analysis into the realm of FDP.",Yes,"논문은 딥러닝 모델과 여러 머신러닝 기법(SVM, DT, LR, CNN, DNN)을 활용하여 정량적 평가를 수행하고 있음을 명시하고 있습니다. 실험 결과를 통해 제안된 방법의 성능을 평가하는 과정이 포함되어 있어 정량적 평가가 실시되고 있음을 알 수 있습니다."
Performance enhancement of cooperative learning algorithms by improved decision making for context based application,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7877588,"Cooperation in learning (CL) can be understood in a multiagent system. In this the agents are capable of learning from both their own experiments and other agents' knowledge and expertise. Implementation of CL is a complicated task in the real world. In distributed systems several agents cooperate to achieve a common goal or accomplish a shared task. In particular, if there are different people or organizations with different goals and information, then a multiagent system (MAS) is needed to handle their interactions. In this paper, various issues related with cooperative machine learning are studied and implemented. A new set of improved cooperative learning algorithms is proposed in the paper. Expertness measuring criteria which were used in earlier work is further enhanced in proposed method. Six methods for measuring the agents' expertness are used i.e. Normal (Nrm), Absolute (Abs), Positive (P), Negative (N), Certainty (Cer) and Entropy (Ent). The novelty of this approach lies in the implementation of Weighted Strategy Sharing with expertness measuring criteria by means of Q-learning, Sarsa learning, Q(λ) and Sarsa(λ) learning algorithms. The paper shows implementation results and performance comparison of all these algorithms.",Yes,"논문 초록에서 여러 평가 방법(여섯 가지 측정 기준)과 다양한 학습 알고리즘(Q-learning, Sarsa 등)을 사용하여 성능을 비교하는 실험을 수행했다고 명시되어 있어 정량적 평가를 실시하고 있음을 알 수 있습니다."
Understanding Security Issues based on App Comment Analysis,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9914435,"Mobile Applications (App) security issues occur in sync with the progress of information technology. User comments serve as a valuable source of information for evaluating a mobile app, for both new users and developers. However, previous works rarely rely on existing comments to provide a detailed summarization of the app's security issues. We present a novel comment summarization framework, SBR-Miner(Security Bug Related-Comment Miner). It first extracts the security-related sentences from the comment sentences using a classification model, then extracts the aspect, opinion, misbehavior of the sentences using a deep learning model, and assigns security issues categories to the triads, and finally visualizes the comment summaries using a radar plot. Our evaluation of the manually labeled dataset shows that SBR-Miner can provide a clearer and more comprehensive aspect than the state-of-the-art, with an average F1 score of 0.92, higher than AR-Miner (0.80) and SUR-Miner (0.81). 92% of developers agree that the SBR-Miner summaries are beneficial, according to feedback from relevant practitioners.",Yes,논문 초록에서 SBR-Miner 프레임워크의 성능 평가를 위해 F1 점수와 비교 대상 모델과의 성능 차이를 제시하며 정량적 평가를 실시했음을 명확히 언급하고 있습니다. 이는 정량적 평가가 수행되었음을 보여줍니다.
Development of Novel Big Data Analytics Framework for Smart Clothing,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9162027,"Recent advances in micro electro-mechanical systems (MEMS) have produced wide variety of wearable sensors. Owing to their low cost, small size and interfacability, those MEMS based devices have become increasingly commonplace and part of daily life for many people. Large amount of data from heart and breath rates to electrocardiograph (ECG) signals, which contain a wealth of health-related information, can be measured. Hence, there is a timely need for novel interrogation and analysis methods for extracting health related features from such a Big Data. In this paper, the prospects from smart clothing such as wearable devices in generating Big Data are critically analyzed with a focus on applications related to healthcare, sports and fashion. The work also covers state-of-the-art data analytics methods and frameworks for health monitoring purposes. Subsequently, a novel data analytics framework that can provide accurate decision in both normal and emergency health situations is proposed. The proposed novel framework identifies and discusses sources of Big Data from the human body, data collection, communication, data storage, data analytics and decision making using artificial intelligence (AI) algorithms. The paper concludes by identifying challenges facing the integration of Big Data analytics with smart clothing. Recommendation for further development opportunities and directions for future work are also suggested.",Yes,"논문 초록에서 ""a novel data analytics framework""를 제안하고 있으며, ""state-of-the-art data analytics methods""에 대해 언급하고 있습니다. 이는 정량적 평가와 분석 방법을 포함하는 연구임을 시사합니다."
Melanoma Risk Prediction with respect to Modifiable Lifestyle Factors by Meta-Analysis Aided Machine Learning Technique,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9231223,"Melanoma is a highly prevalent dermatological disease and a life-threatening form of skin cancer. Lifestyle factors have been observed to influence melanoma risk. The relationship between increased BMI and melanoma incidence has been investigated using epidemiological, in our previous studies. In order to study relationships between melanoma and other modifiable lifestyle factors such as alcohol consumption, smoking, sunscreen application, and use of tanning devices, a meta-analysis aided by machine learning technique was carried out. PubMed database was searched carefully to sort out literature pertaining to the associations of these lifestyle factors with melanoma risk. Meta-analyses were carried out using a software called Review Manager 5.3. It gave risk ratios and 95% confidence intervals as results. Analysis of these data revealed weak positive relationship between alcohol consumption (OR=1.46; 95% CI=1.32−1.62) and use of tanning devices (OR=1.36; 95% CI=1.20−1.53). Negative associations were found between smoking (OR=0.78; 95% CI=0.67−0.92) and sunscreen application (OR=0.5; 95% CI=0.44−0.57). These results were matched, and association trends were confirmed with the rule induction results obtained by applying Naïve Bayes model to the data of each lifestyle factor. All the data from the five factors were pooled in together to create a master datasheet, and machine learning was performed on it to generate a predictive model for melanoma risk. The results were validated through a test split (ratio 0.7:0.3) and cross-validation as well. The accuracy was observed to be 70.23% and 70.35% + 0.79%. The functioning of the model was tested on an unlabeled dataset.",Yes,"논문은 다양한 라이프스타일 요인에 대한 정량적 분석을 위해 메타분석과 머신러닝 기법을 사용하여 위험 예측 모델을 개발하고 검증하는 과정을 포함하고 있습니다. 이를 통해 위험 비율, 신뢰구간, 정확도 등 정량적 평가 지표를 제시하고 있어 정량적 평가를 실시하고 있다고 판단됩니다."
GuiltyTargets: Prioritization of Novel Therapeutic Targets With Network Representation Learning,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9121705,"The majority of clinical trials fail due to low efficacy of investigated drugs, often resulting from a poor choice of target protein. Existing computational approaches aim to support target selection either via genetic evidence or by putting potential targets into the context of a disease specific network reconstruction. The purpose of this work was to investigate whether network representation learning techniques could be used to allow for a machine learning based prioritization of putative targets. We propose a novel target prioritization approach, GuiltyTargets, which relies on attributed network representation learning of a genome-wide protein-protein interaction network annotated with disease-specific differential gene expression and uses positive-unlabeled (PU) machine learning for candidate ranking. We evaluated our approach on 12 datasets from six diseases of different type (cancer, metabolic, neurodegenerative) within a 10 times repeated 5-fold stratified cross-validation and achieved AUROC values between 0.92 - 0.97, significantly outperforming previous approaches that relied on manually engineered topological features. Moreover, we showed that GuiltyTargets allows for target repositioning across related disease areas. An application of GuiltyTargets to Alzheimer’s disease resulted in a number of highly ranked candidates that are currently discussed as targets in the literature. Interestingly, one (COMT) is also the target of an approved drug (Tolcapone) for Parkinson’s disease, highlighting the potential for target repositioning with our method. The GuiltyTargets Python package is available on PyPI and all code used for analysis can be found under the MIT License at https://github.com/GuiltyTargets. Attributed network representation learning techniques provide an interesting approach to effectively leverage the existing knowledge about the molecular mechanisms in different diseases. In this work, the combination with positiveunlabeled learning for target prioritization demonstrated a clear superiority compared to classical feature engineering approaches. Our work highlights the potential of attributed network representation learning for target prioritization. Given the overarching relevance of networks in computational biology we believe that attributed network representation learning techniques could have a broader impact in the future.",Yes,"논문은 네트워크 표현 학습과 기계 학습을 활용하여 후보 타겟의 우선순위를 정하는 정량적 평가를 수행하고 있음을 명확히 언급하고 있습니다. 또한, 12개 데이터셋에 대한 교차 검증을 통해 AUROC 값을 측정하여 성능을 정량적으로 평가하였음을 보여줍니다."
The Risk Classification of Ergonomic Musculoskeletal Disorders in Work-related Repetitive Manual Handling Operations with Deep Learning Approaches,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9302701,"The injury resulted from the repetitive and load-bearing works is the most frequent work-related musculoskeletal disorders (WMSD) or cumulative trauma disorders (CTD). It comes from the overload of repetitive load-bearing actions, which resulting in fatigue, inflammation, even injuries of musculoskeletal system. According to the annular report of Labor Insurance Bureau in Taiwan, WMSD is up to 85-88% payment. Thus, the aim of this study is to evaluate the risk of WMSD during work by using the simple, quick, and correct methods by using the deep learning algorithms. In the proposed research method, after collection the videos of hand repeated movements, the ergonomic injuries are evaluated by using the 2D human pose estimation method, which is based on the Key Indicator Method - Manual Handling Operations (KIM-MHO). Then, a model of predefined classifications through deep learning approaches for manual handling operating tasks is built. The analysis results show that the classification accuracy is more than 80%, compared with the doctor's judgment. The goal of this study is to get the accuracy up to 90%, so as to achieve fast and accurate assistance for deciding the risk of ergonomics, and immediately give proper feedback.",Yes,"논문은 딥러닝 알고리즘을 활용하여 위험 분류를 수행하는 모델을 구축하고 있으며, 그 성능 평가를 위해 분류 정확도를 제시하고 있습니다. 이는 정량적 평가를 실시하고 있음을 보여줍니다."
Lung Cancer Classification Based on Ensembling EfficientNet Using Histopathology Images,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10913233,"Lung cancer is a leading cause of cancer-related deaths, and accurate, early diagnosis is critical for effective treatment. Histopathological analysis is a standard diagnostic approach but requires significant expertise and time. This study aims to improve lung cancer classification through an ensemble of EfficientNetV2 models (B0-B3) applied to histopathological images. EfficientNetV2 was chosen for its scalability and strong performance in image classification tasks. Data augmentation was used to enhance robustness, simulating variability in histopathological slides, while transfer learning from ImageNet pre-trained models enabled faster convergence with limited data. The models were trained on the LC25000 dataset, containing augmented images, and evaluated individually and in ensemble configurations. Grad-CAM provided interpretability, generating heatmaps that highlight model focus, aiding in understanding decision-making. Results showed that individual EfficientNetV2 models achieved near-perfect accuracy, with the ensemble approach further improving performance. Ensemble models, particularly those using hard voting, achieved up to 100% accuracy, precision, and recall, underscoring the effectiveness of combined predictions. However, the high accuracy may be partially due to the dataset's limited unique images, as repeated patterns in augmented data might inflate performance. Future work will test the ensemble on larger, more diverse datasets to validate generalizability. These findings demonstrate the potential of EfficientNetV2 ensembles in lung cancer diagnostics, paving the way for reliable, interpretable AI-based pathology tools in clinical settings.",Yes,"논문 초록에서 모델의 성능 평가를 위해 정확도, 정밀도, 재현율 등 정량적 지표를 사용했다고 명시되어 있습니다. 또한, 여러 모델과 앙상블 방법의 성과를 수치로 제시하여 정량적 평가를 실시했음을 알 수 있습니다."
Will Fault Localization Work for These Failures? An Automated Approach to Predict Effectiveness of Fault Localization Tools,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6676902,"Debugging is a crucial yet expensive activity to improve the reliability of software systems. To reduce debugging cost, various fault localization tools have been proposed. A spectrum-based fault localization tool often outputs an ordered list of program elements sorted based on their likelihood to be the root cause of a set of failures (i.e., their suspiciousness scores). Despite the many studies on fault localization, unfortunately, however, for many bugs, the root causes are often low in the ordered list. This potentially causes developers to distrust fault localization tools. Recently, Parnin and Orso highlight in their user study that many debuggers do not find fault localization useful if they do not find the root cause early in the list. To alleviate the above issue, we build an oracle that could predict whether the output of a fault localization tool can be trusted or not. If the output is not likely to be trusted, developers do not need to spend time going through the list of most suspicious program elements one by one. Rather, other conventional means of debugging could be performed. To construct the oracle, we extract the values of a number of features that are potentially related to the effectiveness of fault localization. Building upon advances in machine learning, we process these feature values to learn a discriminative model that is able to predict the effectiveness of a fault localization tool output. In this preliminary work, we consider an output of a fault localization tool to be effective if the root cause appears in the top 10 most suspicious program elements. We have experimented our proposed oracle on 200 faulty programs from Space, NanoXML, XML-Security, and the 7 programs in Siemens test suite. Our experiments demonstrate that we could predict the effectiveness of fault localization tool with a precision, recall, and F-measure (harmonic mean of precision and recall) of 54.36%, 95.29%, and 69.23%. The numbers indicate that many ineffective fault localization instances are identified correctly, while only very few effective ones are identified wrongly.",Yes,"논문 초록에서 머신러닝 기반의 정량적 평가 방법을 사용하여 결함 위치 추적 도구의 효과성을 예측하는 모델을 개발했다고 명확히 언급하고 있습니다. 또한, 실험 결과를 통해 정량적 평가 지표(정밀도, 재현율, F-측정치)를 제시하여 평가를 수행했음을 보여줍니다."
An Occlusion Compensation Learning Framework for Improving the Rendering Quality of Light Field,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9241065,"Occlusions are common phenomena in light field rendering (LFR) technology applications. The 3-D spatial structures of some features may be missing or incorrect when capturing some samples due to occlusion discontinuities. Most prior works on LFR, however, have neglected occlusions from other objects in 3-D scenes that do not participate in the capturing and rendering of the light field. To improve rendering quality, this report proposes an occlusion probability learning framework (OPLF) based on a deep Boltzmann machine (DBM) to compensate for the occluded information. In the OPLF, an occlusion probability density model is applied to calculate the visibility scores, which are modeled as hidden variables. Additionally, the probability of occlusion is related to the visibility, the camera configuration (i.e., position and direction), and the relationship between the occlusion object and occluded object. Furthermore, a deep probability model based on the OPLF is used for learning the occlusion relationship between the camera and object in multiple layers. The proposed OPLF can optimize the LFR quality. Finally, to verify the claimed performance, we also compare the OPLF with the most advanced occlusion theory and light field reconstruction algorithms. The experimental results show that the proposed OPLF outperforms other known occlusion quantization schemes.",Yes,"논문 초록에서 ""experimental results""를 통해 제안된 방법의 성능을 검증하고 있으며, ""compare""라는 표현으로 정량적 평가를 실시했음을 시사합니다. 또한, ""outperforms""라는 표현은 비교 평가를 통한 정량적 성과 측정을 의미합니다."
A Comparative Machine Learning Approaches for Patient Flow Forecasting in an Emergency Department during the COVID-19,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9938025,"The Corona Virus Disease 2019 (COVID-19) has impacted numerous areas of the health system. In fact, it made the world work remotely during several months and created an assorted uncertainty for medical service recipients. Thus, anticipating novel everyday patient income in relation to the COVID-19 has become pivotal for clinical, political, and different authorities who handle on a daily basis, COVID-19 related planned operations. Current machine learning draws near, in an attempt to get dynamic results. This work intends to demonstrate the wayan Emergency Department (ED) is able to use machine-learning approaches during the daily patient flow forecasting for better management in an emergency department. Thus, it is essential to test five different supervised machine-learning approaches by evaluating their coefficient of determination (R2) to figure the everyday patient flow income for better management.",Yes,논문 초록에서 다섯 가지 머신러닝 방법을 평가하기 위해 결정 계수(R2)를 사용하여 정량적 평가를 실시했다고 명시되어 있습니다. 이는 구체적인 수치 기반 평가를 수행했음을 의미합니다.
A Hybrid Deep Random Neural Network for Cyberattack Detection in the Industrial Internet of Things,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9399085,"The Industrial Internet of Things (IIoT) refers to the use of traditional Internet of Things (IoT) concepts in industrial sectors and applications. IIoT has several applications in smart homes, smart cities, smart grids, connected cars, and supply chain management. However, these systems are being more frequently targeted by cybercriminals. Deep learning and big data analytics have great potential in designing and developing robust security mechanisms for IIoT networks. In this paper, a novel hybrid deep random neural network (HDRaNN) for cyberattack detection in the IIoT is presented. The HDRaNN combines a deep random neural network and a multilayer perceptron with dropout regularization. The proposed technique is evaluated using two IIoT security-related datasets: (i) DS2OS and (ii) UNSW-NB15. The performance of the proposed scheme is analyzed through a number of performance metrics such as accuracy, precision, recall, F1 score, log loss, Region of Convergence (ROC), and Area Under the Curve (AUC). The HDRaNN classified 16 different types of cyberattacks using with higher accuracy of 98% and 99% for DS2OS and UNSW-NB15, respectively. To measure the effectiveness of the proposed scheme, the performance metrics are also compared with several state-of-the-art attack detection algorithms. The findings of HDRaNN proved its superior performance over other DL-based schemes. The deployment perspective of the proposed work is also highlighted in this work.",Yes,"논문 초록에서 다양한 성능 평가 지표(정확도, 정밀도, 재현율, F1 점수, 로그 손실, ROC, AUC)를 사용하여 제안된 방법의 성능을 정량적으로 평가했다고 명시되어 있습니다. 이러한 지표들은 정량적 평가의 실시를 보여줍니다."
Remaining Useful Life Prediction of Turbofan Engines with Fuzzy Systems,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10814888,"Since the beginning of the 21st century, predictive maintenance (PdM) has gained increasing prominence in the industry, providing the capability to predict the Remaining Useful Life (RUL) of equipment and mitigate accidents and financial losses. In this context, Machine Learning (ML) models are widely employed. This study proposes the prediction of Turbofan engine RUL through a machine learning model trained with historical data from this equipment. Two distinct models were evaluated: the Fuzzy System and the Neuro-Fuzzy System. To enable training, it was necessary to select the best features using a genetic algorithm, aiming to reduce complexity and enhance the performance of the Fuzzy System. The model with the best performance was the Fuzzy System with 5 selected features and 11 Fuzzy sets. Despite not yielding the lowest RMSE metric compared to related works, this interpretable model demonstrated reasonable performance in comparison to the model by Babu et al. [8]. This suggests that, for the dataset in question, the Fuzzy system is recommended to ensure better interpretability, while neural networks used in previous studies are better suited for precise predictions.",Yes,"논문 초록에서 RMSE와 같은 성능 평가 지표를 사용하여 모델의 예측 성능을 정량적으로 평가하고 있음을 명확히 언급하고 있습니다. 따라서, 정량적 평가를 실시하고 있다고 판단됩니다."
Time Machine: Generative Real-Time Model for Failure (and Lead Time) Prediction in HPC Systems,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10202658,"High Performance Computing (HPC) systems generate a large amount of unstructured/alphanumeric log messages that capture the health state of their components. Due to their design complexity, HPC systems often undergo failures that halt applications (e.g., weather prediction, aerodynamics simulation) execution. However, existing failure prediction methods, which typically seek to extract some information theoretic features, fail to scale both in terms of accuracy and prediction speed, limiting their adoption in real-time production systems. In this paper, differently from existing work and inspired by current transformer-based neural networks which have revolutionized the sequential learning in the natural language processing (NLP) tasks, we propose a novel scalable log-based, self-supervised model (i.e., no need for manual labels), called Time Machine 11A Time Machine allows us to travel into the future to observe the health state of HPC system and report back. Here, we travel into the log extension to report an upcoming failure., that predicts (i) forthcoming log events (ii) the upcoming failure and its location and (iii) the expected lead time to failure. Time Machine is designed by combining two stacks of transformer-decoders, each employing the self-attention mechanism. The first stack addresses the failure location by predicting the sequence of log events and then identifying if a failure event is part of that sequence. The lead time to predicted failure is addressed by the second stack. We evaluate Time Machine on four real-world HPC log datasets and compare it against three state-of-the-art failure prediction approaches. Results show that Time Machine significantly outperforms the related works on Bleu, Rouge, MCC, and F1-score in predicting forthcoming events, failure location, failure lead-time, with higher prediction speed.",Yes,"논문 초록에서 Time Machine이 실패와 리드 타임 예측을 위해 정량적 평가 지표(예: Bleu, Rouge, MCC, F1-score)를 사용하여 성능을 평가했다고 명시되어 있습니다. 이는 정량적 평가를 실시하고 있음을 보여줍니다."
Exploring machine learning techniques on Yeast dataset classification,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10235819,"Generating information from different datasets using machine learning technologies is one of the crucial and pivotal jobs in the area of data mining. In the recent years, application of these data mining is seen in healthcare, academics and different organizations. A massive application is identified in the area of healthcare. An inseparable part of healthcare organizations is pharmacological industry-i.e. industry related to producing, discovering drugs, their composition and their reaction to human body. Yeast is considered one of the major components in producing drugs for human, for its similarity in cell structure with human cell. In this proposed work, a thorough study of application of machine learning algorithms along with different validation and ensemble techniques have been explored on Yeast dataset. The models are evaluated with mean accuracy. Several other performance measures f-score, Recall, RMSE etc. also has been considered to decide the best model for the said dataset. Results show that ensemble method bagged decision tree works best with a mean accuracy of 61%.The performance of Bagged extra tree is also best with respect to other performance metrics like f1-score, precision etc.",Yes,"논문 초록에서 여러 성능 지표(accuracy, f-score, Recall, RMSE 등)를 사용하여 모델의 성능을 정량적으로 평가했다고 명시되어 있습니다. 이는 정량적 평가를 실시하고 있음을 보여줍니다."
Predictive Traffic Control and Differentiation on Smart Grid Neighborhood Area Networks,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9274318,"Smart Grid (SG) networks include an associated data network for the transmission and reception of control data related to the electric power supply service. A subset of this data network is the SG Neighborhood Area Network (SG NAN), whose objective is to interconnect the subscribers’ homes with the supplier control center. The data flows transmitted through these SG NANs belong to different applications, giving rise to the need for different quality of service requirements. Additionally, other subscriber appliances could use this network to communicate over the Internet. To avoid network congestion, as well as to differentiate the quality of service (QoS) received by the different data flows, a congestion control mechanism with traffic differentiation capabilities is required. The main contribution of this work is the proposal of a new congestion control mechanism based on machine learning techniques to try to guarantee the different QoS requirements to the different data flows. A main problem when applying machine learning techniques is the need for datasets to be used in the training steps. In this sense, a second contribution of this article is the proposal of a method to generate such datasets by means of simulation techniques. The proposed mechanism is then evaluated in the context of a wireless SG NAN. The nodes of this network are the subscriber’s smart meters, which in turn perform the function of concentrating the data traffic sent and received by the rest of the home appliances. Besides, different machine learning classification methods are taken into account. The evaluation carried out shows significant improvements in terms of network throughput, transit time, and quality of service differentiation. Finally, the computational cost of the algorithms used in this proposal has also been evaluated, using real low-cost IoT hardware platforms.",Yes,"논문은 기계 학습 기법을 활용한 혼잡 제어 메커니즘을 제안하며, 이를 평가하기 위해 시뮬레이션을 통한 데이터셋 생성과 성능 평가를 수행하고 있다. 이러한 평가 과정은 정량적 지표를 사용하여 네트워크 성능 향상과 QoS 차별화의 효과를 수치로 보여주고 있어 정량적 평가를 실시하고 있다고 판단된다."
Impact of Switching Variability of 65nm CMOS Integrated Hafnium Dioxide-based ReRAM Devices on Distinct Level Operations,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9312855,"Limitations related to the von Neumann bottleneck have resulted in novel circuits and architectures, including designs that utilize Resistive Random Access Memory (ReRAM) as nonvolatile memory (NVM) devices. ReRAM implemented with hafnium oxide (HfO2) is a strong candidate for such applications. The non-volatility of these devices and their amenability to compute in memory functionality makes them ideal for neuromorphic applications, deep learning, and mathematical accelerator circuits (e.g. Vector Matrix Multiplication - VMM). However, these devices suffer from stochastic switching variability that currently limits their usage and performance. To realize the full potential of these devices, reliability analysis is required. In this work, a reliability study was performed using previously developed a 65 nm CMOS/Memristor process on a 300 mm wafer platform. To address the influence of switching compliance current on the variability of Low Resistance State (LRS) and High Resistance State (HRS), a total of 23 different compliance current values were implemented. The effects of temperature on device performance was also measured.",Yes,논문 초록에서 다양한 실험 조건(23가지의 compliance current 값과 온도 변화)에 대해 실험을 수행하여 데이터를 수집하고 분석하는 정량적 평가를 실시했음을 시사합니다. 이러한 실험적 접근은 정량적 평가의 핵심 요소입니다.
Speech Recognition Applications in Enhancing Safety for Women in Built Environment,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10482912,"This research delves into the potential of speech recognition technology to enhance the safety of women in urban environments. Given the increasing concerns about safety for women in cities, technology presents viable solutions. Among these innovations, speech recognition stands out as a powerful security tool. The study introduces speech recognition and explores its various applications in addressing women's safety issues while identifying vulnerabilities. Additionally, it evaluates how speech recognition can enhance security measures, encompassing personal safety devices, emergency response systems, and smart city integration through case studies. Ethical considerations related to privacy and user empowerment are also discussed. The paper suggests integrating speech technology with other tools, further research initiatives, and policies to foster safer environments. In today's technological landscape, speech recognition empowers women by providing discreet emergency access and real-time monitoring capabilities in public spaces. AI-driven voice recognition algorithms continually improve accuracy and personalization based on comprehensive data sets, thus enabling safer navigation within urban areas. This review offers insights for academia, practitioners, and policymakers, advocating for collaboration to foster secure public spaces for women.",Yes,"The abstract mentions that the study evaluates how speech recognition can enhance security measures, including case studies and AI-driven algorithms, which implies the use of quantitative assessments. Therefore, the research appears to include some form of quantitative evaluation."
Gated Stacked Target-Related Autoencoder: A Novel Deep Feature Extraction and Layerwise Ensemble Method for Industrial Soft Sensor Application,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9174659,"These days, data-driven soft sensors have been widely applied to estimate the difficult-to-measure quality variables in the industrial process. How to extract effective feature representations from complex process data is still the difficult and hot spot in the soft sensing application field. Deep learning (DL), which has made great progresses in many fields recently, has been used for process monitoring and quality prediction purposes for its outstanding nonlinear modeling and feature extraction abilities. In this work, deep stacked autoencoder (SAE) is introduced to construct a soft sensor model. Nevertheless, conventional SAE-based methods do not take information related to target values in the pretraining stage and just use the feature representations in the last hidden layer for final prediction. To this end, a novel gated stacked target-related autoencoder (GSTAE) is proposed for improving modeling performance in view of the above two issues. By adding prediction errors of target values into the loss function when executing a layerwise pretraining procedure, the target-related information is used to guide the feature learning process. Besides, gated neurons are utilized to control the information flow from different layers to the final output neuron that take full advantage of different levels of abstraction representations and quantify their contributions. Finally, the effectiveness and feasibility of the proposed approach are verified in two real industrial cases.",Yes,논문 초록에서 제안하는 GSTAE는 손실 함수에 예측 오차를 포함하는 방식을 통해 정량적 평가를 수행하고 있음을 명확히 언급하고 있습니다. 이는 모델의 성능을 수치적으로 평가하는 정량적 평가 방법을 사용하고 있음을 시사합니다.
TCP-Net: Test Case Prioritization using End-to-End Deep Neural Networks,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9787970,"Regression testing is facing a bottleneck due to the growing number of test cases and the wide adoption of continuous integration (CI) in software projects, which increases the frequency of running software builds, making it challenging to run all the regression test cases. Machine learning (ML) techniques can be used to save time and hardware resources without compromising quality. In this work, we introduce a novel end-to-end, self-configurable, and incremental learning deep neural network (DNN) tool for test case prioritization (TCP-Net). TCP-Net is fed with source code-related features, test case metadata, test case coverage information, and test case failure history, to learn a high dimensional correlation between source files and test cases. We experimentally show that TCP-Net can be efficiently used for test case prioritization by evaluating it on three different real-life industrial software packages.",Yes,"논문 초록에서 TCP-Net이 다양한 데이터를 활용하여 테스트 케이스 우선순위화를 수행하는 것을 언급하며, 실험을 통해 그 효율성을 평가했다고 명시되어 있습니다. 이는 정량적 평가가 이루어지고 있음을 시사합니다."
Prioritization of Mobile IoT Data Transmission Based on Data Importance Extracted From Machine Learning Model,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8759870,"Predicting real-time spatial information from data collected by the mobile Internet of Things (IoT) devices is one solution to the social problems related to road traffic. The mobile IoT devices for real-time spatial information prediction generate an extremely high volume of data, making it impossible to collect all of it through mobile networks. Although some previous works have reduced the volume of transmitted data, the prediction accuracy of real-time spatial information is still not ensured. Therefore, this paper proposes an IoT device control system that reduces the amount of transmitted data used as input for real-time prediction while maintaining the prediction accuracy. The main contribution of this paper is that the proposed system controls data transmission from the mobile IoT devices based on the importance of data extracted from the machine learning model used for the prediction. Feature selection has been widely used for extracting the importance of data from the machine learning model. Feature selection methods were also used to reduce communication overhead in distributed learning. Unlike the conventional usage of feature selection methods, the proposed system uses them to control the data transmission of the mobile IoT devices with priority. In this paper, the proposed system is evaluated with a real-world vehicle mobility dataset in two practical scenarios using the random forest model, which is an extensively used machine learning model. The evaluation results show that the proposed system reduces the amount of transmitted input data for real-time prediction while achieving the same level of prediction accuracy as benchmark methods.",Yes,"논문은 제안된 시스템의 성능을 평가하기 위해 실험을 수행하며, 그 과정에서 전송 데이터 양과 예측 정확도를 정량적으로 측정하고 비교하는 것으로 보입니다. 따라서, 정량적 평가가 실시되고 있다고 판단됩니다."
Investigating barriers and facilitators to wearable adherence in fine-grained eating detection,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7917597,"Energy balance is one component of weight management, but passive objective measures of caloric intake are non-existent. Given the recent success of actigraphy as a passive objective measure of the physical activity construct that relieves participants of the burden of biased self-report, computer scientists and engineers are aiming to find a passive objective measure of caloric intake. Passive sensing food intake systems have failed to go beyond the lab and into behavioral research in part due to low adherence to wearing passive monitoring systems. While system accuracy and battery lifetime are sine qua non to a successfully deployed technology, they come second to adherence, since a system does nothing if it remains unused. This paper focuses on adherence as affected by: 1) perceived data privacy; 2) stigma of wearing devices; 3) comfort. These factors highlight new challenges surrounding participant informed consent and Institutional Review Board (IRB) risk assessment. The wearables examined include neck- and wrist-worn sensors, and video camera-based systems. Findings support the potential for adherence using wrist- and shoulder-based video cameras, and personalized style-conscious neck-worn sensors. The feasibility of detecting fine-grained eating gestures to validate the machine learning models is shown, improving the potential of translation of this technology.",Yes,"논문 초록에서 ""Feasibility of detecting fine-grained eating gestures""와 관련된 내용을 다루며, 머신러닝 모델의 검증을 위해 정량적 평가가 이루어졌음을 시사합니다. 또한, 시스템의 정확성 및 잠재적 성능 평가에 대한 언급이 있어 정량적 평가가 실시된 것으로 판단됩니다."
Programmable Switches for in-Networking Classification,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9488840,"Deploying accurate machine learning algorithms into a high-throughput networking environment is a challenging task. On the one hand, machine learning has proved itself useful for traffic classification in many contexts (e.g., intrusion detection, application classification, and early heavy hitter identification). On the other hand, most of the work in the area is related to post-processing (i.e., training and testing are performed offline on previously collected samples) or to scenarios where the traffic has to leave the data plane to be classified (i.e., high latency). In this work, we tackle the problem of creating simple and reasonably accurate machine learning models that can be deployed into the data plane in a way that performance degradation is acceptable. To that purpose, we introduce a framework and discuss issues related to the translation of simple models, for handling individual packets or flows, into the P4 language. We validate our framework with an intrusion detection use case and by deploying a single decision tree into a Netronome SmartNIC (Agilio CX 2x10GbE). Our results show that high-accuracy is achievable (above 95%) with minor performance degradation, even for a large number of flows.",Yes,"논문 초록에서 ""high-accuracy is achievable (above 95%)""라는 표현을 통해 정량적 평가를 실시했음을 알 수 있습니다. 또한, 실험 결과를 통해 성능과 정확도를 수치로 제시하고 있어 정량적 평가가 수행된 것으로 판단됩니다."
Automatic Voice Disorder Detection Using Self-Supervised Representations,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10041907,"Many speech features and models, including Deep Neural Networks (DNN), are used for classification tasks between healthy and pathological speech with the Saarbruecken Voice Database (SVD). However, accuracy values of 80.71% for phrases or 82.8% for vowels /aiu/ are the highest reported for audio samples in SVD when the evaluation includes the wide amount of pathologies in the database, instead of a selection of some pathologies. This paper targets this top performance in the state-of-the-art Automatic Voice Disorder Detection (AVDD) systems. In the framework of a DNN-based AVDD system we study the capability of Self-Supervised (SS) representation learning for describing discriminative cues between healthy and pathological speech. The system processes the SS temporal sequence of features with a single feed-forward layer and Class-Token (CT) Transformer for obtaining the classification between healthy and pathological speech. Furthermore, there is evaluated a suitable data extension of the training set with out-of-domain data is also evaluated to deal with the low availability of data for using DNN-based models in voice pathology detection. Experimental results using audio samples corresponding to phrases in the SVD dataset, including all pathologies available, show classification accuracy values until 93.36%. This means that the proposed AVDD system achieved accuracy improvements of 4.1% without the training data extension, and 15.62% after the training data extension compared to the baseline system. Beyond the novelty of using SS representations for AVDD, the fact of obtaining accuracies over 90% in these conditions and using the whole set of pathologies in the SVD is a milestone for voice disorder-related research. Furthermore, the study on the amount of in-domain data in the training set related to the system performance show guidance for the data preparation stage. Lessons learned in this work suggest guidelines for taking advantage of DNN, to boost the performance in developing automatic systems for diagnosis, treatment, and monitoring of voice pathologies.",Yes,"논문은 Self-Supervised representations를 이용한 음성 장애 분류의 성능 평가를 위해 실험을 수행하였으며, 정확도와 같은 정량적 지표를 제시하고 있습니다. 또한, 다양한 실험 조건에서의 성능 향상 수치를 구체적으로 제시하여 정량적 평가를 실시하고 있음을 보여줍니다."
Advanced Traffic Violation Detection with Tesseract OCR and Computer Vision,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10616606,"The paper introduces an intelligent system that utilizes machine learning to effectively detect traffic infractions. It incorporates adaptive stop line detection, robust licence plate extraction, and real-time traffic light monitoring. The system’s machine learning component accurately recognizes traffic signal colors, facilitating better traffic flow management. Adaptive stop line detection adjusts to various traffic situations, enhancing system flexibility. Licence plates are accurately extracted using Optical Character Recognition (OCR), which is powered by image processing and Haar Cascade classifiers. The system’s effectiveness in identifying traffic violations, especially during red lights, is demonstrated through video data testing. Additionally, the integration of a MySQL database enables comprehensive logging and tracking of penalized licence plates, providing a detailed overview of traffic infractions and keeping track of all the violating vehicles. This technological integration promises significant improvements in traffic enforcement and road safety. The combination of adaptive stop line detection, real-time traffic light analysis, and licence plate identification makes this system an invaluable tool for traffic control authorities. By improving enforcement and monitoring, the system has the potential to revolutionize traffic management and enhance safety measures. This proposed work suggests that such an intelligent system can be a sophisticated asset in addressing traffic-related challenges and ensuring safer road conditions.",Yes,"논문 초록에서 OCR과 영상 데이터 테스트를 통해 교통 위반을 식별하는 시스템의 성능을 평가하고 있음을 언급하고 있어 정량적 평가를 실시하고 있음을 알 수 있습니다. 또한, 시스템의 효과를 검증하기 위해 구체적인 데이터와 테스트 결과를 활용하는 것으로 보입니다."
A Performance Evaluation of Machine Learning-Based Streaming Spam Tweets Detection,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7400989,"The popularity of Twitter attracts more and more spammers. Spammers send unwanted tweets to Twitter users to promote websites or services, which are harmful to normal users. In order to stop spammers, researchers have proposed a number of mechanisms. The focus of recent works is on the application of machine learning techniques into Twitter spam detection. However, tweets are retrieved in a streaming way, and Twitter provides the Streaming API for developers and researchers to access public tweets in real time. There lacks a performance evaluation of existing machine learning-based streaming spam detection methods. In this paper, we bridged the gap by carrying out a performance evaluation, which was from three different aspects of data, feature, and model. A big ground-truth of over 600 million public tweets was created by using a commercial URL-based security tool. For real-time spam detection, we further extracted 12 lightweight features for tweet representation. Spam detection was then transformed to a binary classification problem in the feature space and can be solved by conventional machine learning algorithms. We evaluated the impact of different factors to the spam detection performance, which included spam to nonspam ratio, feature discretization, training data size, data sampling, time-related data, and machine learning algorithms. The results show the streaming spam tweet detection is still a big challenge and a robust detection technique should take into account the three aspects of data, feature, and model.",Yes,"논문 초록에서 다양한 측면(데이터, 특징, 모델)에 대한 성능 평가를 수행했다고 명확히 언급하고 있습니다. 또한, 여러 실험 조건과 영향을 분석하여 정량적 평가를 실시했음을 알 수 있습니다."
Sentiment Analysis from Depression-Related User-Generated Contents from Social Media,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9467214,"In this paper, we try to detect the sentiment levels such as positive, negative and neutral sentiments from depression related posts and comments generated in social media platforms. Social media platforms such as Facebook, Twitter are not only used for communication or building networks among connections, but also are getting useful for supporting needy peoples who are on special need or care in terms of mental support. In Facebook, there are several depression support groups, which are very much effective to provide mental support to the victims. In this paper, we try to formalize the depression-related posts and comments into a concise lexicon database and detect the sentiment levels form each instance. We have segmented the total work into two parts: sentiment detection and applying machine learning algorithms to analyze the ability to detect sentiment from such special category of texts. We have utilized python textblob package to detect the sentiment levels and applied traditional machine learning algorithms such as Naïve Bayes (NB), Decision Tree (DT), Random Forest (RF), Support Vector Machine (SVM), Sequential Minimal Optimization (SMO), Logistic Regression (LR), Adaboost (AB), Bagging (Bg), Stacking (St) and Multilayer Perceptron (MP) on the linguistic features. We have determined the precision, recall, F-measure, accuracy, ROC values for each of the classifiers. Among the classifiers Random Forest has outperformed others showing 60.54% correctly classified instance. We believe such sentiment analysis on special category of texts may lead to further investigation in natural language understandings.",Yes,"논문 초록에서 다양한 머신러닝 알고리즘을 적용하여 정밀도, 재현율, F-측정, 정확도, ROC 값 등 여러 정량적 평가 지표를 사용하여 성능을 평가했다고 명시되어 있습니다. 이는 정량적 평가를 실시하고 있음을 보여줍니다."
Predictive Modeling for Smart Traffic Systems: Harnessing IoT Data Insights,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10453841,"The paper discusses the development of an IoT-based smart traffic system that utilizes real-time data and machine learning algorithms to enhance traffic safety, reduce congestion, and improve emergency response times. The exponential growth of vehicles on roads has increased traffic congestion, accidents, and environmental pollution, necessitating a smarter traffic management system. The paper reviews several studies demonstrating the potential of IoT-based traffic management solutions in improving traffic flow, enhancing safety, and reducing environmental impact. Furthermore, creating a sustainable and efficient urban environment is possible by integrating IoT-based smart traffic systems with other smart city solutions, such as smart energy and waste management. Chi-squared tests and regression models were employed to extensively analyze various variables in this study, including accident severity, weather conditions, and sunrise/sunset times. The findings rejected the null hypothesis, indicating strong associations among these factors. Furthermore, the residual frequency graph and regression analysis demonstrated the model's data fit and ability to capture predictor-response relationships. This research offers valuable insights into traffic accident causes and underscores the potential for real-time implementation to enhance traffic management and safety measures in smart cities.",Yes,"논문 초록에서 Chi-squared tests와 회귀 모델을 사용하여 다양한 변수들을 정량적으로 분석했다고 명확히 언급하고 있습니다. 이러한 통계적 방법들은 정량적 평가의 일환으로 볼 수 있으므로, 본 연구는 정량적 평가를 실시하고 있다고 판단됩니다."
Training AI to Recognize Objects of Interest to the Blind and Low Vision Community,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10340454,"Recent object detection models show promising advances in their architecture and performance, expanding potential applications for the benefit of persons with blindness or low vision (pBLV). However, object detection models are usually trained on generic data rather than datasets that focus on the needs of pBLV. Hence, for applications that locate objects of interest to pBLV, object detection models need to be trained specifically for this purpose. Informed by prior interviews, questionnaires, and Microsoft’s ORBIT research, we identified thirty-five objects pertinent to pBLV. We employed this user-centric feedback to gather images of these objects from the Google Open Images V6 dataset. We subsequently trained a YOLOv5x model with this dataset to recognize these objects of interest. We demonstrate that the model can identify objects that previous generic models could not, such as those related to tasks of daily functioning – e.g., coffee mug, knife, fork, and glass. Crucially, we show that careful pruning of a dataset with severe class imbalances leads to a rapid, noticeable improvement in the overall performance of the model by two-fold, as measured using the mean average precision at the intersection over union thresholds from 0.5 to 0.95 (mAP50-95). Specifically, mAP50-95 improved from 0.14 to 0.36 on the seven least prevalent classes in the training dataset. Overall, we show that careful curation of training data can improve training speed and object detection outcomes. We show clear directions on effectively customizing training data to create models that focus on the desires and needs of pBLV.Clinical Relevance— This work demonstrated the benefits of developing assistive AI technology customized to individual users or the wider BLV community.",Yes,"논문은 YOLOv5x 모델을 사용하여 특정 객체를 인식하도록 훈련시키는 과정을 상세히 설명하며, 이를 위해 데이터셋을 정제하고 성능 평가를 수행하였음을 보여줍니다. 특히, mAP50-95와 같은 정량적 지표를 활용하여 모델의 성능 향상을 평가하고 있어 정량적 평가를 실시하고 있음을 알 수 있습니다."
On the effectiveness of machine and deep learning for cyber security,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8405026,"Machine learning is adopted in a wide range of domains where it shows its superiority over traditional rule-based algorithms. These methods are being integrated in cyber detection systems with the goal of supporting or even replacing the first level of security analysts. Although the complete automation of detection and analysis is an enticing goal, the efficacy of machine learning in cyber security must be evaluated with the due diligence. We present an analysis, addressed to security specialists, of machine learning techniques applied to the detection of intrusion, malware, and spam. The goal is twofold: to assess the current maturity of these solutions and to identify their main limitations that prevent an immediate adoption of machine learning cyber detection schemes. Our conclusions are based on an extensive review of the literature as well as on experiments performed on real enterprise systems and network traffic.",Yes,"논문 초록에서 ""Our conclusions are based on an extensive review of the literature as well as on experiments performed on real enterprise systems and network traffic""라고 언급되어 있어, 정량적 평가와 실험이 수행되었음을 알 수 있습니다. 이는 논문이 정량적 평가를 실시하고 있음을 시사합니다."
"Case studies in computing education: Presentation, evaluation and assessment of four case study-based course design and delivery models",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7044194,"Case studies have been used in different fields of university-level education already for decades. More recently, the advantages of using case studies have been realised by university-level computing educators, too. New approaches have been introduced in computing education - such as project-based learning, problem-based learning, situated learning or inquiry-based learning. Many of those approaches successfully use case studies. Despite the increasing popularity of this teaching methodology there seems to be a deep lack in any research papers or practice reports which would attempt to describe, evaluate and assess possible approaches or models in using case studies in computing education. This conference contribution reports on selected best practices of course design and delivery implemented in one of the core courses of the Bachelor of Science (Information Systems Management) degree program (BSc (ISM)) offered by the School of Information Systems (SIS) at the Singapore Management University (SMU). The paper presents, evaluates, compares and assesses four different course design and delivery models which are largely based on case studies and are extensively using this teaching methodology throughout the entire course lifecycle (starting with the course design process, delivery of face-to-face teaching sessions, student assessment process and post-mortem course review process).",Yes,"초록에서 논문이 네 가지 다른 강좌 설계 및 전달 모델을 평가하고 비교하며, 이 과정에서 다양한 평가 및 평가 방법을 사용했다고 언급하고 있습니다. 이는 정량적 평가를 실시했음을 시사합니다."
Adeptness Evaluation of Memory Based Classifiers for Credit Risk Analysis,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6965029,"Banking industry is an important source of finance in any country. Credit Risk analysis is a critical and decisive task in banking sector. Loan sanction procedure can be followed based on the credit risk analysis of any customer. Automation of decision making in financial applications using best algorithms and classifiers is much useful. This work evaluates the adeptness of different Memory based classifiers on credit risk analysis. The German credit data have been taken for adeptness evaluation and is done using open source machine learning tool. The performances of different memory based classifier are analyzed and a practical guideline for selecting exceptional and well suited algorithm for credit analysis is presented. Apart from that, some discreet criteria for relating and evaluating the best classifiers are discussed.",Yes,"논문 초록에서 여러 메모리 기반 분류기를 평가하는 연구임을 명확히 언급하고 있으며, 성능 평가와 적합성 가이드라인 제시를 통해 정량적 평가를 실시하고 있음을 알 수 있습니다."
Automate surgical tasks for a flexible Serpentine Manipulator via learning actuation space trajectory from demonstration,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7487640,"Surgical robotic systems with miniaturized flexible Tendon-driven Serpentine Manipulators (TSM) have enjoyed increasing popularities among surgeons and researchers for their advantages of working in constrained and torturous human lumen such as oral cavity and upper GI tract. However, they suffer from sufficient nonlinearities and model uncertainties due to friction, tension varying, tendon slacking, etc. Model based control is insufficient to overcome such uncertainties and automate challenging surgical related tasks. The objective of this work is to automate certain clinical tasks to alleviate surgeon fatigue and promote task efficiency in kinematics free and sensor free circumstances. We present a data-driven approach based on Learning from Demonstration (LfD), which utilizes statistical machine learning models to encode system underlying dynamics and generalize smooth motor trajectories by direct actuation space learning. Motion segmentation is enabled with soft margin Support Vector Machine (soft-SVM) in complicated tasks. We also make attempts to retrieve task-specific properties by Locally Weighted Regression (LWR). We evaluated the approach on two surgical related tasks: compliant insertion and simplified Endoscopic Submucosal Dissection (ESD). The flexible TSM successfully reproduced both tasks and demonstrated superior trajectory performance. A video is available at: https://youtu.be/rLQo6xKtyMI.",Yes,"논문 초록에서 시스템의 동적 특성을 학습하고 일반화하는 데 사용된 통계적 기계학습 모델들을 언급하며, 정량적 평가를 통해 두 가지 수술 관련 작업에서 성공적으로 수행되었음을 보여줍니다. 이는 정량적 평가가 실시되었음을 시사합니다."
Real-Time Position Falsification Attack Detection System for Internet of Vehicles,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9613271,"Ensuring secured and reliable dissemination of information for a mission-critical system such as the Internet of Vehicle (IoV) in real-time is of utmost importance. In this work, a False Location Detection System (FLDS) based on an optimized Ensemble Random Forest (Ens.RF) was proposed. The performance of the Ens.RF was compared with four other Machine Learning (ML) algorithms, using the Veremi dataset where five (5) different location falsification categories and one benign category were modeled. To validate the idea in this work, a performance comparison with recent work was presented. The result shows that the proposed Ens.RF outperformed other algorithms modeled in this work as well as related works with an accuracy of 99.92%",Yes,"논문 초록에서 Ens.RF의 성능을 비교하는 실험 결과를 제시하며 정확도(99.92%)와 같은 정량적 평가 지표를 사용하여 평가를 실시했다고 명시하고 있습니다. 따라서, 이 논문은 정량적 평가를 수행하고 있다고 판단됩니다."
Sentiments Detection for Amazon Product Review,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9402414,"In this paper, we evaluated the sentiments in the present technological age over the reviews of online products, online products are used by the majority of people. They provide their feedback and then products are recommended for purchase and sale on that factor too. The large e-commerce platforms such as Flipkart, Myntra, Amazon, and many others enable their users to review the Products. To buy a commodity, the consumer will examine to have a better-quality understanding of the product and product work. The interpretation will be a really simple product polarized into positive, neutral, and negative Product checks. We may use machine learning methods to perform this experiment. Sentiment Analysis is research in which consumers are conscious of a product reaction. A Kaggle of amazon product reviews gathers the data collection used. We use various Logistic Regression, Naive Bayes, and Random Forest methodology for classifying feedback and achieving the best of precision. Among all the algorithms used we find that the Random forest machine-learning algorithm to be the most accurate.",Yes,"논문 초록에서 여러 머신러닝 방법을 사용하여 감성 분석의 성능을 평가하고 있으며, 특히 정확도를 비교하는 내용이 포함되어 있어 정량적 평가를 실시하고 있음을 알 수 있습니다."
Review of Using Various Deep Learning Techniques and Cycle-GANs with Transformer for Disease Detection and Classification in Plant Leaves,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10603311,"In the upcoming years, agricultural yields should rise by 50–60 % to assure food security and feed the world's rapidly expanding population. Considering the importance of agriculture, it is imperative to look at methods that can enhance planting practices, track agricultural conditions, identify plant illnesses, and streamline harvesting procedures. The significance of these fundamental elements has prompted in-depth investigation and the creation of numerous studies that offer solutions to these problems. To improve productivity, identifying and preventing plant diseases is crucial. For increased agricultural yields, cost savings, and decreased crop losses, early disease diagnosis is essential. Deep learning and other computer vision-based technologies can help diagnose diseases early. However, the commonality of illness traits in images and interference from the external environment pose hurdles to existing machine vision approaches. Most of the previous work on image classification used plant leaf images captured in controlled environment, having similar background, which produced good results on the same data-set but failed to generalise on the images captured in real conditions. To solve this problem real background images ere used to train the classifiers which increased the generalisation significantly on same data-set but still performed poor on cross data-set generalisation. Attempts are done to solve the problem of data having no background diversity (Background, lighting, camera setting, distance and angle of capture), by data augmentation using GANs, Specifically by using unpaired image to image translation to translate healthy images into diseased images. Earlier models were based on CycleGAN and could not increase the accuracy significantly as CycleGAN translated the latent features also with the disease region. No study within our knowledge has employed Swin transformers in the generator network to augment the CycleGAN model's ability to capture the distribution of the diseased dataset. Furthermore, the use of a transformer-based Image-to-Image translation model reveals issues related to the generation of artifacts, particularly in areas with excessively high or low pixel values. This phenomenon was noted in the present study when applying existing models to plant leaf data augmentation. Thus, by evaluating good fid, psnr, and ssim values using the Swin transformer cycle-GAN, good quality images are obtained and the background diversity issue is resolved. Therefore, classification accuracy is increased by using both actual and produced images to aid in the process. To offer farmers effective solutions for safeguarding their crops and future applications, this paper assesses various methods, delineating their advantages and disadvantages. It proposes the utilization of a hybrid deep learning architecture along with diverse strategies for the detection and classification of plant leaf diseases.",Yes,"논문 초록에서 Cycle-GAN과 Swin Transformer를 활용한 이미지 생성 품질 평가를 위해 fid, psnr, ssim과 같은 정량적 지표를 사용했다고 언급하고 있습니다. 또한, 이러한 평가를 통해 생성된 이미지의 품질을 검증하고, 분류 정확도를 향상시키기 위한 목적으로 정량적 평가를 실시한 것으로 보입니다."
Practices for Engineering Trustworthy Machine Learning Applications,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9474373,"Following the recent surge in adoption of machine learning (ML), the negative impact that improper use of ML can have on users and society is now also widely recognised. To address this issue, policy makers and other stakeholders, such as the European Commission or NIST, have proposed high-level guidelines aiming to promote trustworthy ML (i.e., lawful, ethical and robust). However, these guidelines do not specify actions to be taken by those involved in building ML systems. In this paper, we argue that guidelines related to the development of trustworthy ML can be translated to operational practices, and should become part of the ML development life cycle. Towards this goal, we ran a multi-vocal literature review, and mined operational practices from white and grey literature. Moreover, we launched a global survey to measure practice adoption and the effects of these practices. In total, we identified 14 new practices, and used them to complement an existing catalogue of ML engineering practices. Initial analysis of the survey results reveals that so far, practice adoption for trustworthy ML is relatively low. In particular, practices related to assuring security of ML components have very low adoption. Other practices enjoy slightly larger adoption, such as providing explanations to users. Our extended practice catalogue can be used by ML development teams to bridge the gap between high-level guidelines and actual development of trustworthy ML systems; it is open for review and contributions.",Yes,"논문 초록에서 ""global survey to measure practice adoption""과 ""initial analysis of the survey results""라는 표현을 통해 정량적 평가가 실시되고 있음을 알 수 있습니다. 또한, 실천 사례의 채택률을 분석하는 내용이 포함되어 있어 정량적 평가가 수행되고 있음을 확인할 수 있습니다."
Validation of a simulation tool for ship traffic noise,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7271489,"There is a rising concern about the environmental status of the seas of our planet. Such concern regards several kinds of anthropogenic activities and their impact on the marine ecosystems. Part of the adverse effects are recognised to be due to various forms of acoustic emissions generated by human activities related to the exploitation of sea resources and to shipping. The main regulatory bodies at international level, in the last decade, have started to look into the problem with the aim of monitoring the environmental status of marine waters, (in particular the acoustical aspects) identify the situations where the anthropogenic impact is most intrusive and study and promote future actions for its control and reduction. The present work reports about the development and validation of a simulation tool able to predict the noise field generated by a set of ships sailing in a specific area. The simulation is based on real traffic data derived from the Automatic Identification System (AIS) normally used to monitor shipping traffic and on specific data characterising the environment of the zone of interest. The tool is meant to provide the Regulator with a means to study the present situation (with on-line AIS data) and/or study the effectiveness of possible measures devoted to reduce the acoustical impact of shipping by design and/or operative requirements. Motivation, bases and characteristics of the developed procedure are described in the paper, where a first validation of the tool is presented on the basis of data regarding a sea area off Barcelona (Spain). Data include AIS records, environmental parameters and underwater sound levels surveyed by an hydrophone placed in the area. The work has been developed in the framework of the collaborative project AQUO (Achieve QUieter Oceans by shipping noise footprint reduction), funded by the European Commission within a call of the 7th Framework Programme dedicated to the assessment and mitigation of noise impacts of the maritime transport on the marine environment, coordinated topic “The Ocean of Tomorrow”.",Yes,"논문 초록에서 개발된 시뮬레이션 도구의 검증(Validation)에 관한 내용을 언급하고 있으며, 이를 위해 실제 환경 데이터와 수중 음향 수준 데이터를 활용한 검증 과정을 수행했다고 명시되어 있습니다. 따라서, 정량적 평가가 실시되고 있음을 알 수 있습니다."
How to Support ML End-User Programmers through a Conversational Agent,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548214,"Machine Learning (ML) is increasingly gaining significance for enduser programmer (EUP) applications. However, machine learning end-user programmers (ML-EUPs) without the right background face a daunting learning curve and a heightened risk of mistakes and flaws in their models. In this work, we designed a conversational agent named “Newton” as an expert to support ML-EUPs. Newton's design was shaped by a comprehensive review of existing literature, from which we identified six primary challenges faced by ML-EUPs and five strategies to assist them. To evaluate the efficacy of Newton's design, we conducted a Wizard of Oz within-subjects study with 12 ML-EUPs. Our findings indicate that Newton effectively assisted ML-EUPs, addressing the challenges highlighted in the literature. We also proposed six design guidelines for future conversational agents, which can help other EUP applications and software engineering activities.",No,"논문 초록에서는 Newton이라는 대화형 에이전트의 설계와 그 효과를 평가하는 사용자 연구를 수행했음을 언급하지만, 구체적인 정량적 평가 방법이나 수치 데이터에 대한 언급은 없습니다. 따라서 정량적 평가를 실시했다고 보기 어렵습니다."
Celebrity: Creation of A Database Towards an Automatic Beauty Evaluation System,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10147452,"In recent days, facial beauty analysis has attracted various beauty-related fields like plastic surgery, the cosmetic industry, photo retouching applications, etc., The facial beauty analysis framework depends on an aesthetic scoring mechanism and needs high quality large-scale facial image database for facial beauty prediction. Beauty analysis can be extended to the ranking of beauty pageants in beauty pageant competitions. Most of the beauty scoring systems have focused on feature fusion and selection mechanisms through hand-crafted features with limited low-quality databases which are inadequate to analyze facial beauty and lead to infancy in the research of facial beauty. This work presents a machinebased automatic evaluation system for beauty by creating and compiling a database that includes beauty pageant images of winners and runners-up of beauty pageants competition using a deep learning algorithm. To evaluate the created database, pre-trained deep-learning models are used where deep-learned facial features are extracted for learning latent representations of beauty from facial images. From experiments performed on the created dataset, the classification accuracy achieved is 76.15%, using a pre-trained CNN model, ResNet 50.",Yes,"논문 초록에서 ""classification accuracy""라는 정량적 평가 지표를 제시하며, 실험을 통해 성능을 평가했다고 명시하고 있습니다. 또한, 딥러닝 모델을 활용한 평가 결과를 수치로 제시하여 정량적 평가를 실시했음을 알 수 있습니다."
Temperature Compensation Schemes for In-Memory Computing using Phase-Change Memory,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9074003,"The explosive growth in data-centric artificial intelligence related applications necessitates exploration of non-von Neumann computing paradigms such as in-memory computing. The ability to perform certain computational tasks within the memory unit will reduce dramatically the time and energy that is spent into shuttling the data from the memory to the processing unit. However, the nanoscale resistive memory devices that are useful for these technologies suffer from non-ideal characteristics. In this work we deal with the computational precision loss due to the strong and inhomogeneous temperature dependence of resistive devices and in particular phase-change memory. We describe a temperature compensation method that applies to resistive crossbar arrays and its realization as a peripheral circuit. We derive array-level temperature compensation functions that are remarkably effective for projected phase-change memory devices. We simulate the system and experimentally validate its efficacy in the task of matrix-vector multiplications. The computational precision is found to be equivalent to an 8-bit multiplier at elevated temperatures.",Yes,"논문 초록에서 시스템을 시뮬레이션하고 실험을 통해 온도 보상 방법의 효과를 검증했다고 명시되어 있으며, 특히 계산 정밀도를 정량적으로 평가한 것으로 보입니다. 이는 정량적 평가가 수행되었음을 의미합니다."
Machine learning-based multi-channel evaluation pooling strategy for image quality assessment,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6738088,"Multi-channel peculiarity is one of the most widely accepted human visual system (HVS) models for perceptual image quality assessment (IQA). Otherwise than extensive studies of channel decomposition and intra-channel distortion measure, relatively scant research effort has been devoted to develop efficient multichannel evaluation pooling strategies. In this paper, we review and address the limitations of the conventional pooling models based on HVS sensitivities-weighted average. Instead, we explore the utilization of machine learning for this pooling problem, since machine learning can establish an optimal and generalized mapping that models the highly complex relationship between the multi-channel distortion evaluations and the perceived image quality. Experiments based on available subjective IQA databases demonstrate the rationality, reliability and robustness of our proposed scheme.",Yes,"논문 초록에서 머신러닝을 활용하여 다중 채널 평가 풀링 전략을 개발했다고 명시되어 있으며, 실험을 통해 제안한 방법의 신뢰성과 강건성을 검증했다고 언급하고 있습니다. 이는 정량적 평가를 수행하는 연구임을 시사합니다."
Subject-aware PET Denoising with Contrastive Adversarial Domain Generalization,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10656150,"Recent advances in deep learning (DL) have greatly improved the performance of positron emission tomography (PET) denoising performance. However, DL model performance can vary a lot across subjects, due to the large variability of the count levels and spatial distributions. A generalizable DL model that mitigates the subject-wise variations is highly expected toward a reliable and trustworthy system for clinical application. In this work, we propose a contrastive adversarial learning framework for subject-wise domain generalization (DG). Specifically, we configure a contrastive discriminator in addition to the UNet-based denoising module to check the subject-related information in the bottleneck feature, while the denoising module is adversarially trained to enforce the extraction of subject-invariant features. The sampled low-count realizations from the list-mode data are used as anchor-positive pairs to be close to each other, while the other subjects are used as negative samples to be distributed far away. We evaluated on 9718 F-MK6240 tau PET studies, each having 20 noise realizations with 25% fractions of events. Training, validation, and testing were implemented using 1400, 120, and 420 pairs of 3D image volumes in a subject-independent manner. The proposed contrastive adversarial DG demonstrated superior denoising performance than conventional UNet without subject-wise DG and cross-entropy-based adversarial DG.",Yes,"논문 초록에서 제안하는 방법이 정량적 평가를 통해 성능을 검증했다고 명시되어 있으며, 9718개의 PET 연구 데이터를 사용하여 실험을 수행했다고 언급되어 있습니다. 이는 정량적 평가가 실시되었음을 시사합니다."
ThermAI: Exploring Temperature Analysis Through Diverse Machine Learning Models,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10593875,"Meteorological forecasting is crucial in multiple industries, including agriculture, aviation, and daily routines. The objective of this inquiry is to improve temperature predictions by examining and comparing several machine learning methods, such as linear regression, decision trees, and random forests. This work aims to fill the gap in assessing machine learning models for temperature forecasting on a broader scale by utilising the comprehensive Indian meteorological dataset, which covers a wide range of geographical regions. The research utilises a thorough technique that includes gathering data, selecting relevant features, choosing appropriate models, and evaluating the results using R-squared and Mean Square Error metrics. The findings demonstrate that the Random Forest model surpasses both multiple linear regression and decision trees in terms of performance, displaying superior accuracy and reduced prediction errors. This study enhances proactive weather management and decision-making processes by offering valuable insights and tools to stakeholders in various industries. The work is organised into distinct sections that encompass a literature review, methodology, results, and conclusions, providing a comprehensive viewpoint on developments in temperature forecasting.",Yes,논문 초록에서 R-squared와 Mean Square Error와 같은 정량적 평가 지표를 사용하여 모델의 성능을 평가했다고 명시되어 있습니다. 이러한 지표들은 모델의 예측 정확도를 수치적으로 측정하는 정량적 평가 방법입니다.
An inference mechanism using Bayes-based classifiers in pregnancy care,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7749475,"Significant advances on smart decision support systems (DSSs) development have influenced important results on pregnancy care. Nevertheless, even considering the efforts to reduce the number of women deaths due to problems related to pregnancy, this decrease presented less impact than other areas of human development. Hypertensive disorders in pregnancy, particularly pre-eclampsia and eclampsia, account for significant proportion of perinatal morbidity and maternal mortality. In this context, this paper proposes an inference model that uses data mining (DM) techniques capable for operating in a data set to extract patterns and assist in knowledge discovery. Identifying hypertensive crises that complicate pregnancy, it can impact in a meaningful reduction the incidence of sequelae and death of pregnant women. Comparison between two Bayesian classifiers is performed in this work to better classify the hypertensive disorders severity. Results showed that Naïve Bayes classifier had an excellent performance, presenting better precision and F-measure, compared to the other experimented classifiers. Even finding a good performance to predict hypertensive disorders, other Bayesian methods need to be evaluated, as well as other DM techniques such as those based on artificial intelligence (AI) and tree-based methods.",Yes,"논문 초록에서 두 Bayesian 분류기를 비교하는 실험을 통해 성능 평가를 수행했다고 명시되어 있습니다. 또한, Naïve Bayes 분류기의 정밀도와 F-측정값을 언급하며 정량적 평가가 이루어졌음을 보여줍니다."
Cheetah: An Accurate Assessment Mechanism and a High-Throughput Acceleration Architecture Oriented Toward Resource Efficiency,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9146930,"Convolutional neural network (CNN) is widely used in artificial intelligence for its excellent recognition accuracy. With its scale increasing rapidly and architecture becoming complicated, it is much difficult to implement CNN in hardware platform efficiently. Many FPGA-based CNN accelerators are proposed in previous work. However, when evaluating resource efficiency, their assessment methods are: 1) device related; 2) frequency related; or 3) they confuse resource efficiency with resource occupancy. There is an insistent demand for intuitive and fair assessment criteria. When implementing CNNs, they still have improvement room in computing resource efficiency, especially for layers with large feature size and few feature maps. In this work, we propose Rscore and Cscore , which compose a comprehensive and accurate resource efficiency assessment mechanism for evaluation and design guidance, respectively. Under the guidance, we introduce Cheetah, an FPGA-based high-throughput acceleration architecture. Its computing part can optimize the use of available resources in both time and space aspects, resulting in better throughput improvement. An auxiliary storage system and a pipeline stage compression method are designed for less storage overhead and shorter inference latency. We implement AlexNet and ResNet18 on KCU1500 at 230 and 240 MHz, respectively, with a throughput of 2411.01GOP/s and 2435.05GOP/s for 16-bit quantification. Cheetah achieves an excellent average Rscore of (0.9441, 0.9456) on different FPGA devices, while the others’ mainly distribute between 0.3 and 0.8. Finally, Cheetah has 6.78X speed improvement and 1.87X power-efficiency improvement than that of Nvidia Jetson TX2, which is the fastest, most power-efficient embedded AI computing device.",Yes,"논문 초록에서 Rscore와 Cscore라는 정량적 평가 지표를 제안하고 있으며, 이를 통해 자원 효율성을 정량적으로 평가하는 방법을 사용하고 있음을 명확히 언급하고 있습니다. 또한, FPGA 기반 성능 평가와 비교를 위한 수치적 결과도 포함되어 있어 정량적 평가를 실시하고 있음을 알 수 있습니다."
Predicting Object Trajectories from High-Speed Streaming Data,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7345501,"Huge amounts of loosely structured and high velocity data are now being generated by ubiquitous mobile sensing devices, aerial sensory systems, cameras and radiofrequency identification readers, which are generating key knowledge into social media behaviors, intelligent transport patterns, military operational environments and space monitoring, safety systems etc. Machine learning models and data mining techniques can be employed to produce actionable intelligence, based on predictive and prescriptive analytics. However, more data is not leading to better predictions as the accuracy of the implicated learning models hugely varies in accordance to the complexity of the given space and related data. Especially in the case of open-ended data streams of massive scale, their efficiency is put to the challenge. In this work, we employ a variety of machine learning methods and apply them to geospatial time-series surveillance data, in an attempt to determine their capacity to learn a vessels behavioral pattern. We evaluate their effectiveness against metrics of accuracy, time and resource usage. The main concept of this study is to determine the most appropriate machine-learning model capable of learning a vessels behavior and performing predictions into a future point in time. Our aim is to document the prediction accuracy of a set of traditional forecasting models and then compare this to the prediction accuracy of streaming algorithms.",Yes,"논문 초록에서 다양한 머신러닝 방법을 적용하여 예측 정확도, 시간, 자원 사용량 등을 평가한다고 명시되어 있습니다. 이는 정량적 평가를 실시하고 있음을 보여주는 명확한 근거입니다."
Deep U-Net Based Dental Caries Detection and Classification in Panoramic X-Ray Images,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10859665,"Dental caries, identified as a frequent oral health issue, demands timely detection and classification for effective treatment planning and prevention of further complications. This work focuses on developing a robust automated system to detect and classify dental caries using radiology images of panoramic X-ray. The proposed automated classification system aims to accurately identify the required region of interest and categorize regions of dental caries within images of X-ray using deep convolutional learning methods. The workflow begins with acquisition of raw input images of panoramic X-ray images, containing various stages and types of dental caries followed by finetuning them. Subsequently, a custom-designed CNN architecture (U-Net) is trained on the selected dataset using appropriate loss functions and optimization techniques. Testing image sets are used to evaluate the model, and performance is assessed by accuracy, sensitivity, specificity, and other relevant metrics. A maximum of 94% of diagnostic accuracy is reported with appropriate sensitivity and specificity using U-Net based segmented images. The effectiveness related to the developed system is measured in automated finding the regions of dental caries, by minimizing the errors of manual examination by dental professionals. This automated approach holds significant potential for improving diagnostic efficiency, enhancing treatment procedures, and ultimately contributing to better oral healthcare outcomes.",Yes,"논문 초록에서 모델의 성능 평가를 위해 정확도, 민감도, 특이도 등 정량적 지표를 사용했다고 명시되어 있습니다. 이러한 지표들은 정량적 평가의 대표적인 예로, 연구에서 정량적 평가를 실시하고 있음을 보여줍니다."
Towards clinically relevant automatic assessment of upper-limb motor function impairment,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7455856,"This paper is to develop an automated assessment system of upper-limb motor function impairment for clinical environment. Although we had proposed the system in our previous work, there are some rooms to be improved. Using glove sensor was difficult due to stroke patient's hand contracture. Moreover, it was based on machine learning, and thus required huge effort to collect reference data to increase classification accuracy. To address those issues, three tests of Fugl-Meyer Assessment which were closely related the issues were chosen as target tests. Since Kinect v2 and force-sensing resister can provide hand-related information, the tests were automated without glove sensor. Fuzzy-logic classification table that is based on traditional FMA guidelines was implemented to rate the FMA score without machine learning. With a healthy subject, simple experiments were conducted to evaluate the proposed system with novel classification scheme. The results show a feasibility for more convenient automated assessment of upper-limb motor function impairment.",Yes,"논문은 Fugl-Meyer Assessment를 기반으로 한 자동 평가 시스템을 개발하며, 이를 위해 실험을 통해 평가 결과를 정량적으로 측정하고 있습니다. 또한, 퍼지-논리 분류 표를 활용하여 FMA 점수를 평가하는 방식을 도입하여 정량적 평가를 실시하고 있음을 보여줍니다."
A Deep Reinforcement Learning Approach for Improving Age of Information in Mission-Critical IoT,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9692982,"The emerging mission-critical Internet of Things (IoT) play a vital role in remote healthcare, haptic interaction, and industrial automation, where timely delivery of status updates is crucial. The Age of Information (AoI) is an effective metric to capture and evaluate information freshness at the destination. A system design based solely on the optimization of the average AoI might not be adequate to capture the requirements of mission-critical applications, since averaging eliminates the effects of extreme events. In this paper, we introduce a Deep Reinforcement Learning (DRL)-based algorithm to improve AoI in mission-critical IoT applications. The objective is to minimize an AoI-based metric consisting of the weighted sum of the average AoI and the probability of exceeding an AoI threshold. We utilize the actor-critic method to train the algorithm to achieve optimized scheduling policy to solve the formulated problem. The performance of our proposed method is evaluated in a simulated setup and the results show a significant improvement in terms of the average AoI and the AoI violation probability compared to the related-work.",Yes,"논문 초록에서 제안된 딥 강화학습 알고리즘의 성능을 평가하기 위해 시뮬레이션을 통한 정량적 평가가 수행되었음을 언급하고 있습니다. 또한, 평균 AoI와 AoI 위반 확률과 같은 구체적인 지표를 사용하여 성능 향상을 보여주고 있어 정량적 평가를 실시하고 있음을 알 수 있습니다."
Predicting Seizures from Electroencephalography Recordings: A Knowledge Transfer Strategy,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7776343,"Epilepsy, a brain disorder afflicts nearly 1% of the world's population, is characterized by the occurrence of spontaneous seizures. For most epilepsy patients, the drugs are either not effective or produce severe side-effects. Seizure forecasting systems have the potential to help patients with epilepsy lead more normal lives. Recently multi-center clinical studies showed evidence of premonitory symptoms in 6.2% of 500 patients with epilepsy, and some interviews of epilepsy patients also found that a certain amount of patients felt ""auras"". All these are promising signs suggesting that seizure might be predictable. In this paper, we will study the application of deep learning techniques for seizure prediction with EEG signals. Deep learning methods have been shown to be very effective on exploring the latent structures from continuous signals and they have achieved state-of-the-art performance on speech analysis. One potential requirement for deep learning algorithms to work is a huge training set, which could be difficult for a specific medical problem. Therefore we specifically investigated a transfer learning strategy: we performed the major seizure prediction task on the data from American Epilepsy Society Seizure Prediction Challenge1, and we adopted another 6 publicly available EEG datasets2, which are not directly related to seizure prediction, as auxiliary information to pre-train the deep neural network for getting a good initial point. Our results show that with those auxiliary information, the prediction performance can be boosted. This observation is validated with different predictive models, which opens another gate for effective integration and utilization of medical data resources.",Yes,"논문 초록에서 딥러닝 기법을 활용하여 EEG 신호를 기반으로 발작 예측을 수행하고 있으며, 이를 위해 다양한 데이터셋을 이용한 정량적 학습 전략을 적용하고 있음을 보여줍니다. 또한, 예측 성능 향상을 위해 실험적 평가와 성과 검증이 이루어졌음을 시사하므로 정량적 평가를 실시하고 있다고 판단됩니다."
Assessing Application Portfolios of IT Services through Maturity Levels of IT Governance,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8874902,"Managing application portfolios of Information Technology (IT) services are not limited to information services. There should be guarantee and integration of synchronization and interoperability of information services. Availability of information services can create risks of IT investment and hinder the effectiveness of organizational performance. The aim of this research was to find out to what extent the use of application portfolios of IT services could support IT processes of Acquire and Implement (AI) and Monitor and Evaluate (ME) Domains. This survey research applied the combination method and a convergent triangulation model through a follow-up explanatory design. Quantitative analysis was performed after online questionnaires were filled out by respondents working at 65 credit unions. These respondents have used application portfolios of IT services in West Kalimantan, Indonesia. COBIT (Control Objectives for Information and Related Technology) 4.1 Framework was in use to measure maturity levels of IT governance. Maturity values of IT governance indicate that IT processes are at the scale interval of 2.51 to 3.50. So far, the use of application portfolios of IT services has been restricted to procedure standardization and documentation system. Also, the conduct has not involved appropriateness of obvious synchronization as well as consistency of procedures and IT service implementation.",Yes,"논문 초록에서 COBIT 4.1 프레임워크를 사용하여 IT 거버넌스의 성숙도 수준을 측정하는 정량적 평가를 실시했다고 명확히 언급하고 있습니다. 또한, 성숙도 값이 구체적인 수치 범위(2.51에서 3.50)로 제시되어 있어 정량적 분석이 수행되었음을 알 수 있습니다."
A Fault Diagnosis Model for Wind Turbine Blade Using a Deep Learning Method,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10353888,"A wind turbine plays a pivot role in the field of energy supply. A stable working state of the wind turbine is highlighted in power generation. For this reason, it is thus of great interest to develop a fault diagnosis method for status identification of wind turbine. In this work, the imbalance of turbine blade is investigated on the task of fault diagnosis. Vibration sensors are attached to the blade to detect vibration signals. A deep learning based method using gated convolution neural network and long short term memory unit, together with the attention mechanism, is established. The application of the proposed model is capable of capturing the most-related features that characterize the working states. The working performance of the proposed model is validated on the samples from various working conditions. The experimental results set solid evidence of a high accuracy.",Yes,"논문 초록에서 딥러닝 기반의 모델을 사용하여 풍력 터빈 블레이드의 결함 진단을 수행한다고 명시되어 있습니다. 또한, 실험을 통해 높은 정확도를 검증하는 정량적 평가가 이루어졌음을 시사하므로, 정량적 평가를 실시하고 있다고 판단됩니다."
EXTRA: An Experience-driven Control Framework for Distributed Stream Data Processing with a Variable Number of Threads,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9521325,"In this paper, we present design, implementation and evaluation of a control framework, EXTRA (Experience-driven conTRol frAmework), for scheduling in general-purpose Distributed Stream Data Processing Systems (DSDPSs). Our design is novel due to the following reasons. First, EXTRA enables a DSDPS to dynamically change the number of threads on the fly according to system states and demands. Most existing methods, however, use a fixed number of threads to carry workload (for each processing unit of an application), which is specified by a user in advance and does not change during runtime. So our design introduces a whole new dimension for control in DSDPSs, which has a great potential to significantly improve system flexibility and efficiency, but makes the scheduling problem much harder. Second, EXTRA leverages an experience/data driven model-free approach for dynamic control using the emerging Deep Reinforcement Learning (DRL), which enables a DSDPS to learn the best way to control itself from its own experience just as a human learns a skill (such as driving and swimming) without any accurate and mathematically solvable model. We implemented it based on a widely-used DSDPS, Apache Storm, and evaluated its performance with three representative Stream Data Processing (SDP) applications: continuous queries, word count (stream version) and log stream processing. Particularly, we performed experiments under realistic settings (where multiple application instances are mixed up together), rather than a simplified setting (where experiments are conducted only on a single application instance) used in most related works. Extensive experimental results show: 1) Compared to Storm’s default scheduler and the state-of-the-art model-based method, EXTRA substantially reduces average end-to-end tuple processing time by 39.6% and 21.6% respectively on average. 2) EXTRA does lead to more flexible and efficient stream data processing by enabling the use of a variable number of threads. 3) EXTRA is robust in a highly dynamic environment with significant workload change.",Yes,"논문 초록에서 실험과 평가를 통해 성능을 정량적으로 측정했다고 명시되어 있으며, ""extensive experimental results""라는 표현을 통해 다양한 실험 데이터를 기반으로 평가했음을 알 수 있습니다. 따라서, 정량적 평가를 실시하고 있다고 판단됩니다."
The Supermarket Model With Known and Predicted Service Times,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9695323,"queues at random and join the one with the fewest customers. This model demonstrates the power of even small amounts of choice, as compared to simply joining a queue chosen uniformly at random, for load balancing systems. In this work we perform simulation-based studies to consider variations where service times for a customer are predicted, as might be done in modern settings using machine learning techniques or related mechanisms. Our primary takeaway is that using even seemingly weak predictions of service times can yield significant benefits over blind First In First Out queueing in this context. However, some care must be taken when using predicted service time information to both choose a queue and order elements for service within a queue; while in many cases using the information for both choosing and ordering is beneficial, in many of our simulation settings we find that simply using the number of jobs to choose a queue is better when using predicted service times to order jobs in a queue. In our simulations, we evaluate both synthetic and real-world workloads–in the latter, service times are predicted by machine learning. Our results provide practical guidance for the design of real-world systems; moreover, we leave many natural theoretical open questions for future work, validating their relevance to real-world situations.",Yes,"논문 초록에서 시뮬레이션 기반 연구를 통해 서비스 시간 예측의 효과를 평가하고 있으며, 이를 정량적으로 분석하는 방법을 사용하고 있음을 시사합니다. 따라서, 정량적 평가를 실시하고 있다고 판단됩니다."
"Precision Biometrics Based on PPG Measured From an IoT Device With OPDs, Real-Time Quality Check Through PSD, DC Drift, and Deep Learning",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10670010,"A high-accuracy biometric identification system based on photoplethysmography (PPG) is proposed in this study. Equipped with continuous quality assessment on PPG in real-time by calculated power spectral density (PSD) and large-area organic photodetectors (OPDs) in the PPG sensor offering low-noise PPG, the deep learning model built herein is able to acquire delicate PPG features varying clearly from subject to subject, and then achieves high accuracy for biometric applications. It is known that PPG is a technology capable of measuring blood volume changes by emitting optical power into skin, reaching blood vessels and collects the reflected optical power back and out of skin, suitable for ensuring live body biometrics while many other biometrics are unable to. The raw PPG measured by the PPG device is first preprocessed by a bandpass filter, and then those with low PSD of PPG versus noise or large direct current drifts are screened out in real time to ensure the signal quality of PPG prior to biometrics. This preprocessing step is crucial to disregard all the unqualified PPG that may lead to wrongful result of biometrics later. The biometrics is next conducted by a built deep-learning (DL) model of a convolutional neural network (CNN) and long short-term memory (LSTM) layers. The DL model is trained by the PPG data collected from 42 subjects. Experimental results show an accuracy of 99.64% for binary while 98.8% for multiclass classification, outperforming other related works using PPG.",Yes,"논문 초록에서 PPG 신호의 품질 평가를 위해 PSD와 DC 드리프트를 실시간으로 계산하는 과정을 언급하며, 이를 통해 정량적 평가가 이루어지고 있음을 알 수 있습니다. 또한, 신호 품질이 낮은 데이터를 선별하는 과정이 포함되어 있어 정량적 평가가 중요한 역할을 하고 있음을 보여줍니다."
Performance Analysis of Regression and Artificial Neural Network Schemes for Dynamic Model Reduction of Power Systems,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9633912,"The performance of regression and artificial neural network schemes is evaluated for dynamic model reduction of power systems. The evaluation criterion is based on the goodness of fit in each reduced model with respect to the original model. Multiple linear regression, polynomial regression, and support vector are used as regression models while a Feedforward Artificial Neural Network with different activation functions is used for comparison with regression models. All simulations are based on a simplified Australian 14 Generator model. Datasets for training and test sets are obtained by measuring boundary bus properties and power flowing through tie lines. The simulation results show that the artificial neural network outperforms the regression models in making a reduced model of the power system, but only related to the system responses corresponding to the contingencies that were used for training. However, they perform poorly for unknown contingencies. Research work is being continued by the authors to create better models by combining classical models with machine learning techniques.",Yes,"논문 초록에서 ""evaluation criterion""과 ""goodness of fit""를 기반으로 성능 평가를 실시했다고 명시되어 있으며, 다양한 모델의 성능을 정량적으로 비교하는 실험이 수행된 것으로 보입니다. 따라서, 정량적 평가가 이루어지고 있다고 판단됩니다."
A Machine Learning Based Approach To Detect Fake News In Social Media,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10541688,"The News available on online resources such as social media applications like facebook, twitter etc. are propagating fast that too in a uncontrolled way and is a matter of high concern in its capability to endure a lot of social and national damage. This damage can prove to be destructive. A lot of researchers are working on detecting this unreliable and falsified information. In this paper, we will be making a short analysis on research related work done till now on fake news detection, using supervised ML algorithms which can catgorize news as true or false by utilising python modules such as sci-kit learn and NLP module for literal analysis. This paper is more focused towards NLP rather than the machine learning domain. This textual analysis process will include processes like feature extraction and vectorization which will be performed using python sci-kit module to carry out feature extraction and pre-processing of text from the dataset, as this library deliver helpful tools like implementation of vectorizer for feature extraction process. Then we will evaluate the performance of different ML algorithms based on several performance factors like accuracy, F1 score, precision and recall. Also, we will work on selecting the best features for the machine learning model to give high precision in detecting fake news. Today the majority of the people have a phone with them and are connected to people around the world through the means of social networking sites. These sites gave everyone the power to keep their opinions but today people are using this power to spread mis-information. This is causing mistrust among people and society. Today fake news is the major reason for the communal riots, government distrust, and a lot more.",Yes,"논문 초록에서 여러 머신러닝 알고리즘의 성능 평가를 위해 정확도, F1 점수, 정밀도, 재현율과 같은 정량적 지표를 사용한다고 명시되어 있습니다. 따라서 정량적 평가를 실시하고 있다고 판단됩니다."
A hybrid convolutional neural networks with extreme learning machine for WCE image classification,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7419037,"Wireless Capsule Endoscopy (WCE) is considered as a promising technology for non-invasive gastrointestinal disease examination. This paper studies the classification problem of the digestive organs for wireless capsule endoscopy (WCE) images aiming at saving the review time of doctors. Our previous study has proved the Convolutional Neural Networks (CNN)-based WCE classification system is able to achieve 95% classification accuracy in average, but it is difficult to further improve the classification accuracy owing to the variations of individuals and the complex digestive tract circumstance. Research shows that there are two possible approaches to improve classification accuracy: to extract more discriminative image features and to employ a more powerful classifier. In this paper, we propose to design a WCE classification system by a hybrid CNN with Extreme Learning Machine (ELM). In our approach, we construct the CNN as a data-driven feature extractor and the cascaded ELM as a strong classifier instead of the conventional used full-connection classifier in deep CNN classification system. Moreover, to improve the convergence and classification capability of ELM under supervision manner, a new initialization is employed. Our developed WCE image classification system is named as HCNN-NELM. With about 1 million real WCE images (25 examinations), intensive experiments are conducted to evaluate its performance. Results illustrate its superior performance compared to traditional classification methods and conventional CNN-based method, where about 97.25% classification accuracy can be achieved in average.",Yes,논문 초록에서 제안하는 시스템의 성능 평가를 위해 실험을 통해 정확도(97.25%)를 측정하는 정량적 평가를 실시했다고 명시되어 있습니다. 이는 구체적인 수치와 실험 결과를 통해 성능을 평가하는 정량적 평가의 수행을 보여줍니다.
Machine Learning-Driven Optimization of Inverter Drive Parameters for Enhanced Electric Vehicle Efficiency: An In-Depth Analysis and Application,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10235206,"Inverter drives play a crucial role in various industrial applications, where optimizing their parameters is essential for enhancing efficiency and performance. This work presents an advanced technique to optimize the DC Link Voltage (u_dc_k) parameter in inverter drives using machine learning techniques. Traditional methods of parameter optimization have faced challenges in terms of complexity and adaptability. This work proposes a data-driven approach that leverages machine learning models, including linear regression, decision tree, and random forest, to predict the optimized u_dc_k values. The dataset, comprising multiple features related to inverter drives, undergoes pre-processing to handle missing data and scale features. The performance of the machine learning models is evaluated using the root mean squared error (RMSE) metric, and k-fold cross-validation is employed for model comparison. Our results demonstrate the effectiveness of machine learning techniques in predicting optimized u_dc_k values, with the best-performing model yielding improved performance compared to traditional methods.",Yes,논문 초록에서 RMSE와 k-fold 교차 검증과 같은 정량적 평가 지표를 사용하여 머신러닝 모델의 성능을 평가했다고 명시되어 있습니다. 이는 정량적 평가를 실시하고 있음을 보여줍니다.
Empowering First Responders through Automated Multimodal Content Moderation,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8457689,"Social media enables users to spread information and opinions, including in times of crisis events such as riots, protests or uprisings. Sensitive event-related content can lead to repercussions in the real world. Therefore it is crucial for first responders, such as law enforcement agencies, to have ready access, and the ability to monitor the propagation of such content. Obstacles to easy access include a lack of automatic moderation tools targeted for first responders. Efforts are further complicated by the multimodal nature of content which may have either textual and pictorial aspects. In this work, as a means of providing intelligence to first responders, we investigate automatic moderation of sensitive event-related content across the two modalities by exploiting recent advances in Deep Neural Networks (DNN). We use a combination of image classification with Convolutional Neural Networks (CNN) and text classification with Recurrent Neural Networks (RNN). Our multilevel content classifier is obtained by fusing the image classifier and the text classifier. We utilize feature engineering for preprocessing but bypass it during classification due to our use of DNNs while achieving coverage by leveraging community guidelines. Our approach maintains a low false positive rate and high precision by learning from a weakly labeled dataset and then, by learning from an expert annotated dataset. We evaluate our system both quantitatively and qualitatively to gain a deeper understanding of its functioning. Finally, we benchmark our technique with current approaches to combating sensitive content and find that our system outperforms by 16% in accuracy.",Yes,"논문 초록에서 ""We evaluate our system both quantitatively and qualitatively""라고 명시되어 있어, 정량적 평가를 실시하고 있음을 확인할 수 있습니다. 또한, 시스템의 성능을 벤치마킹하는 내용도 포함되어 있어 정량적 평가의 수행이 명확히 드러납니다."
A kinect-based workplace postural analysis system using deep residual networks,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8088272,"Human behavior understanding is a well-known area of interest for computer vision researchers. This discipline aims at evaluating several aspects of interactions among humans and system components to ensure long term human well-being. The robust human posture analysis is a crucial step towards achieving this target. In this paper, the deep representation learning paradigm is used to analyze the articulated human posture and assess the risk of having work-related musculoskeletal discomfort in manufacturing industries. Particularly, we train a deep residual convolutional neural network model to predict body joint angles from a single depth image. Estimated joint angles are essential for ergonomists to evaluate ergonomic assessment metrics. The proposed method applies the deep residual learning framework that has demonstrated impressive convergence speed and generalization capabilities in addressing different vision tasks such as object recognition, localization and detection. Moreover, we extend the state-of-the-art data generation pipeline to synthesize a dataset that features simulations of manual tasks performed by different workers. An inverse kinematics stage is proposed to generate the corresponding ground truth joint angles. Experimental results demonstrate the generalization performance of the proposed method.",Yes,"논문은 딥러닝 모델을 사용하여 신체 관절 각도를 예측하는 정량적 평가를 수행하고 있습니다. 예측된 관절 각도는 인체 자세 평가와 관련된 정량적 지표로 활용되며, 실험 결과를 통해 모델의 성능을 평가하고 있습니다."
Machine Learning for Detecting Subtle Signs of EyeDisease,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10612587,"Eye disorders can have serious repercussions, such as blindness or visual impairment, if they are not identified or addressed, Treatment that works and preventing permanent harm depend on early diagnosis and prediction. Using cutting-edge clinical observations, this method looks for diseases such diabetic retinopathy, cataracts, myopia, glaucoma, age-related eye illnesses, and hypertension-related eye disorders. This study presents an innovative method for early detection of eye health disorders: The Eye Health Station. It uses machine learning algorithm, by leveraging EfficientNet's superior performance in image classification tasks, our system analyzes ocular images, such as retinal scans, to identify potential indicators of eye disorders at an early stage., The proposed system seeks to discover possible markers of eye problems by evaluating several factors taken from ocular pictures and patient data, including retinal scans and medical history. The system is able to learn from various datasets and gradually increase its accuracy since machine learning techniques are included into the system.",Yes,"논문 초록에서 머신러닝 알고리즘을 활용하여 눈 질환의 조기 진단을 위해 다양한 데이터를 평가하는 방법을 제시하고 있으며, 이를 통해 정량적 평가가 수행되고 있음을 알 수 있습니다. 따라서, 이 연구는 정량적 평가를 실시하는 것으로 판단됩니다."
Scalable Analytics Platform for Machine Learning in Smart Production Systems,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8869075,"Manufacturing industry is facing major challenges to meet customer requirements, which are constantly changing. Therefore, products have to be manufactured with efficient processes, minimal interruptions, and low resource consumptions. To achieve this goal, huge amounts of data generated by industrial equipment needs to be managed and analyzed by modern technologies. Since the big data era in manufacturing industry is still at an early stage, there is a need for a reference architecture that incorporates big data and machine learning technologies and aligns with the Industrie 4.0 standards and requirements. In this paper, requirements for designing a scalable analytics platform for industrial data are derived from Industrie 4.0 standards and literature. Based on these requirements, a reference big data architecture for industrial machine learning applications is proposed and compared to related works. Finally, the proposed architecture has been implemented in the Lab Big Data at the SmartFactoryOWL and its scalability and performance have been evaluated on parallel computation of an industrial PCA model. The results show that the proposed architecture is linearly scalable and adaptable to machine learning use cases and will help to improve the industrial automation processes in production systems.",Yes,"논문 초록에서 산업용 PCA 모델의 병렬 계산을 통해 성능과 확장성을 평가했다고 명시되어 있어, 정량적 평가가 실시되고 있음을 알 수 있습니다. 이러한 평가를 통해 제안된 아키텍처의 성능을 수치로 검증하는 과정이 포함되어 있습니다."
Classification Of a bank data set on various data mining platforms,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8391441,"The process of extracting meaningful rules from big and complex data is called data mining. Data mining has an increasing popularity in every field today. Data units are established in customer-oriented industries such as marketing, finance and telecommunication to work on the customer churn and acquisition, in particular. Among the data mining methods, classification algorithms are used in studies conducted for customer acquisition to predict the potential customers of the company in question in the related industry. In this study, bank marketing data set in UCI Machine Learning Data Set was used by creating models with the same classification algorithms in different data mining programs. Accuracy, precision and f- measure criteria were used to test performances of the classification models. When creating the classification models, the test and training data sets were randomly divided by the holdout method to evaluate the performance of the data set. The data set was divided into training and test data sets with the 60-40%, 75-25% and 80-20% separation ratios. Data mining programs used for these processes are the R, Knime, RapidMiner and WEKA. And, classification algorithms commonly used in these platforms are the k-nearest neighbor (k-nn), Naive Bayes, and C4.5 decision tree.",Yes,"논문 초록에서 정확도, 정밀도, F-측정값 등 정량적 평가 지표를 사용하여 분류 모델의 성능을 평가했다고 명확히 언급하고 있습니다. 따라서 정량적 평가를 실시하고 있다고 판단됩니다."
Multi-Label Classification of Lung Diseases Using Deep Learning,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10664582,"Assistance for doctors in disease detection can be very useful in environments with scarce resources and personnel. Historically, many patients could have been cured with early detection of the disease. The application of deep learning techniques in the fields of medical imaging, on large datasets, has allowed computer algorithms to produce as effective results as medical professionals. To assist doctors, it is essential to have a versatile system that can timely detect multiple diseases in the lungs with high accuracy. Over time, although many classifiers and algorithms have been implemented, however, deep learning models (i.e., CNN, Deep-CNN, and R-CNN) are known to offer better results. After a thorough literature review of the state-of-the-art techniques, this work applies various models such as MobileNet, DenseNet, VGG-16, EfficientNet, Xception, and InceptionV3 to the selected large dataset. The goal is to enhance the accuracy of these algorithms by experimenting with parameter optimizations. We observe that MobileNet produces better results as compared to other models. We implement a deep convolutional GAN to produce synthetic X-ray images containing various pathologies already included in the chosen imbalanced dataset namely NIH Chest X-ray containing 14 classes. The synthetic dataset contains 1193 samples belonging to five classes. We test the suggested model using evaluation measures like recall, precision, and F1-score, along with binary accuracy. The suggested deep learning model produces recall as high as 57%, binary accuracy as 93.4%, F1-Score as 0.553, and AUC as 81. After the inclusion of generated synthetic samples, the value of the F1-score becomes 0.582 resulting in a 5% increase. Though, Generative Adversarial Network (GAN) shows lower performance, however, we encourage further research and experiments to find the versatility of GANs in the field of medical imaging.",Yes,"논문 초록에서 다양한 평가 지표인 recall, precision, F1-score, binary accuracy, 그리고 AUC를 사용하여 정량적 평가를 실시하고 있음을 명확히 언급하고 있습니다. 이는 논문이 정량적 평가를 수행하고 있음을 보여줍니다."
Fake Profile Detection Using Machine Learning,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10459570,"Nowadays, Social Media Platforms on behalf of entities or individuals, can harm (SMPs) are being utilized by an enormous number their reputations and reduce the number of likes of users to get connected with their friends and and followers they receive. Additionally, they family. There are sites like Facebook, Instagram, experience unnecessary confusion with other Twitter where people spend a significant amount of time to get updated about the world. The data uploaded on social media contains their personal information, thoughts on certain topics, news, etc. The social media platforms verify the authenticity of the registered user. However, some of the users hide their identities and these people are threats to the security of other users’ data. These bot accounts are used to scam, or purposefully cause harm to people. There is a need for detection techniques to find and eradicate these bots as quickly as possible. In this work, we have proposed a Machine learning based model that can identify fake or bot created accounts accurately. This paper is divided into multiple parts: Introduction, Literature Review, Methodology, Results and Discussion, Conclusion. To validate the authenticity of our work, we have experimented over the publicly available dataset TwiBot-20 and achieved accuracy of 87%.",Yes,"논문 초록에서 머신러닝 기반 모델을 사용하여 가짜 또는 봇 계정을 정확하게 식별하는 정량적 평가를 수행했다고 명시되어 있습니다. 또한, 실험을 통해 87%의 정확도를 달성했다고 언급하여 정량적 평가가 이루어졌음을 알 수 있습니다."
Seat Belt And Helmet Detection Using Deep Learning,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9725574,"The proposed system relates the current situation of multitudinous problems in traffic rules and regulations in different countries. Further, examines how any accident or causality can be averted using enhance methods of natural language processing. Mainly in highways, people just focus on speed and overtaking the other vehicles, rather than following traffic rules and taking basic safety measures. And due to these highways, police barricading is also not possible. Therefore, it is highly requisite to adopt an automatic seat belt and helmet detection system which captures the image of rule brakers, so that necessary legal action should be taken against them. The system works on real time detection and used for continuous surveillance for safety purposes. In the paper we solve the issue of manually checking the safety measures while driving a vehicle to avoid any accidents and deaths due to fast moving vehicles without wearing proper safety measures. The elucidated process in the paper is based on real-time surveillance system and obligate everyone to wear seat belts and helmets to increase the safety of individuals by the help of OpenCV (Open-Source Computer Vision Library) and deep learning algorithm which is embedded in Raspberry Pi. Addition to this, all the pictures and videos are saved in a database which is only accessed by higher government officials for future security purpose and expediate the tackling process of traffic rules violation due to the negligence and irresponsibility of law enforcement officials as well as common citizens.",Yes,"논문은 딥러닝 알고리즘을 활용하여 안전벨트와 헬멧을 실시간으로 감지하는 시스템을 제안하며, 이를 위해 데이터베이스에 이미지와 비디오를 저장하는 등 정량적 평가를 수행할 수 있는 구조를 갖추고 있다. 따라서, 정량적 평가를 실시하고 있다고 판단된다."
Drone net architecture for UAS traffic management multi-modal sensor networking experiments,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8396716,"Drone Net is a conceptual architecture to integrate passive sensor nodes in a local sensor network along with traditional active sensing methods for small Unmanned Aerial System (sUAS) traffic management. The goal of the proposed research architecture is to evaluate the feasibility of the use of multiple passive sensor nodes integrating Electro-Optical/Infrared (EO/IR) and acoustic arrays networked around a UAS Traffic Management (UTM) operating region (Class G uncontrolled airspace for general aviation). The Drone Net approach will be further developed based on the feasibility analysis provided here, to compare to and/or be used in addition to RADAR (Radio Detection and Ranging) and Automatic Dependent Surveillance-Broadcast (ADS-B) tracking and identification in future experiments. We hypothesize that this hybrid passive plus active sensing approach can better manage non-compliant small UAS (without ADS-B transceivers) along with compliant UAS and general aviation in sensitive airspace, urban locations, and geofenced regions. Numerous commercial interests are developing UTM instrumentation for compliant and non-compliant drone detection and counter measures, but performance in terms of ability to detect, track, classify (bird, bug, drone, general aviation), identify, and localize aerial objects has not been standardized or well developed to compare multi-sensor solutions. The proposed Drone Net open system reference architecture is designed for passive nodes organized in a network, which can be integrated with RADAR and ADS-B. Here we present preliminary proof of concept results for two primary methods of truth comparison for generation of performance in terms of true and false positives and negatives for detection, classification, and identification. The first ground truth method designed and evaluated uses sUAS Micro Air Vehicle Link (MAVLink) ADS-B data along with EO/IR range detection experiments. The second ground truth method requires human review of triggered detection image capture and allows for truth performance assessment for non-compliant sUAS and other aerial objects (birds and bugs). The networked passive sensors have been designed to meet Class G and geo-fence UTM goals as well as assist with urban UTM operations. The approach can greatly complement NASA UTM collaboration and testing goals for 2020 and the “last fifty foot challenge” for package delivery UAS operations. The EO/IR system has been tested with basic motion detection for general aviation and sUAS in prior work, which is now being extended to include more sensing modalities and more advanced machine vision and machine learning development via the networking of the nodes and ground computing. The paper will detail the hardware, firmware and software architecture, and preliminary efficacy of the two ground truth methods used to compute standard performance metrics.",Yes,"논문 초록에서는 성능 평가를 위해 두 가지 방법의 진실성 검증(ground truth methods)을 사용하여 탐지, 분류, 식별의 성능 지표를 계산하는 등 정량적 평가를 실시하고 있음을 명확히 언급하고 있습니다. 또한, 성능 지표를 산출하기 위한 실험과 검증 절차를 포함하고 있어 정량적 평가가 수행되고 있음을 알 수 있습니다."
System abnormality detection in stock market complex trading systems using machine learning techniques,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8285660,"Stock market trading systems are real time systems that process thousands of data per minute and are considered to be critical as well as complex. It incorporates the features of complex business processing and sophisticated in-memory processing techniques for speed and throughput. These systems are distributed in nature, and they use a large number of processing nodes incorporating fault tolerance mechanisms. Complex systems also have a large effective number of strongly interdependent variables. Hence detecting faults and failures in stock market systems is a complex and cumbersome task. The study explores machine learning techniques to detect anomalous behavior to provide warnings before a system results in a fault or failure state. The study extensively utilizes a supervised learning approach with machine learning algorithms such as C4.5, Naïve Bayes, and ensemble techniques; bagging and Random Forest. The system statistics captured from log files are preprocessed and transformed to eliminate system environment dependencies. For each of the three components the initial feature selection is carried out manually using domain knowledge and expertise. Initial feature selection based on domain expertise was required as the number of features per component is large and does not closely relate to the system state. Feature selection methods (Info Gain algorithm with Ranker search) have been successfully employed to filter out unrelated attributes and to reduce computational complexity. A comparative evaluation is performed under each component status prediction. This study also utilizes oversampling techniques to overcome limitations caused by the class imbalance phenomena. A range of evaluators are used to analyze the results and effectiveness of the models. The highest accuracy and Receiver Operating Characteristic (ROC) values are achieved when C4.5 decision tree is applied to the oversampled feature set and when the Random Forest algorithm is applied to the oversampled feature set. However, precision, recall and F-measure values vary. Root cause detection for anomalies and numeric values for system health predictions are future work in the research.",Yes,"논문은 다양한 머신러닝 알고리즘을 사용하여 시스템 이상 탐지의 성능을 평가하고 있으며, 정확도, ROC 값, 정밀도, 재현율, F-측정값 등 정량적 지표를 활용하여 모델의 성능을 평가하고 있습니다. 따라서 정량적 평가를 실시하고 있다고 판단됩니다."
Driver identification using histogram and neural network from acceleration data,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8359893,"Sensor technology has continuously improved in term of size and cost. It encourages car companies to embed various types of sensors in their cars. The most common sensors that can be found are location sensor and acceleration sensor. The sensors generate a lot of useful data which could be applied for many future applications such as car tracking or emergency warning. One of the most interesting applications among others is analyzing the driver behavior. There are some previous works using this information to define types of drivers that are related to levels of accident risk. However, the driver behavior not only can separate the type of drivers but also can identify driving characteristic of an individual driver. The driver identification benefits a security application and it can eliminate the global car theft issue. Because the driver behavior cannot be repeated or copied like other anti-theft systems so this is an essential solution to stop increasing the number of stolen cars every year. In this paper, we propose a methodology to identify each driver and classify group of drivers using only accelerating behavior with machine learning technique. In order to identify an individual driver, the acceleration data have been transformed to a histogram in order to represent the accelerating behavior then we utilize a neural network model. We evaluate our methodology with data that have been collected from the acceleration sensors installed on 13 shuttle buses in our campus for more than 10 months. The results show the accuracy of the proposed methodology up to 88.3% for driver identification and up to 92% for driver classification.",Yes,"논문 초록에서 머신러닝 기법을 사용하여 운전자 식별 및 분류를 수행하며, 그 성능을 평가하기 위해 정량적 지표인 정확도(88.3% 및 92%)를 제시하고 있습니다. 이는 명확한 정량적 평가를 실시하고 있음을 보여줍니다."
Integration of multimodal technologies for a rowing platform,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4957238,"This paper presents the integration of multimodal technologies to measure and transmit different variables and stimuli involved in the human motion analysis, both for the training and for the transfer of users skills achieved by means of a mechatronic rowing platform. Although the mechanical design is the core of this project, this paper describes the integration and interaction of two multimodal systems (the human being and the rowing platform). These systems works together using different sensors and methodologies directly integrated to the human body to obtain detailed information related to the synchronization and correlation among the trajectories, proximal distance coupling, velocities, muscular activation and muscular force, transversal force in the oars and head position acquired through digital image processing and machine learning techniques. This information is evaluated and used in the rendering section through audio-tactile stimuli for the acceleration learning process.",Yes,"논문 초록에서 다양한 센서와 방법론을 활용하여 인간 운동 분석에 관련된 여러 변수와 자극을 측정하고 있으며, 이 데이터를 평가하는 과정이 언급되어 있습니다. 따라서 정량적 평가가 수행되고 있음을 알 수 있습니다."
Feature-Level Attention-Guided Multitask CNN for Fault Diagnosis and Working Conditions Identification of Rolling Bearing,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9372133,"Accurate and real-time fault diagnosis (FD) and working conditions identification (WCI) are the key to ensuring the safe operation of mechanical systems. We observe that there is a close correlation between the fault condition and the working condition in the vibration signal. Most of the intelligent FD methods only learn some features from the vibration signals and then use them to identify fault categories. They ignore the impact of working conditions on the bearing system, and such a single-task learning method cannot learn the complementary information contained in multiple related tasks. Therefore, this article is devoted to mining richer and complementary globally shared features from vibration signals to complete the FD and WCI of rolling bearings at the same time. To this end, we propose a novel multitask attention convolutional neural network (MTA-CNN) that can automatically give feature-level attention to specific tasks. The MTA-CNN consists of a global feature shared network (GFS-network) for learning globally shared features and K task-specific networks with feature-level attention module (FLA-module). This architecture allows the FLA-module to automatically learn the features of specific tasks from globally shared features, thereby sharing information among different tasks. We evaluated our method on the wheelset bearing data set and motor bearing data set. The results show that our method has a better performance than the state-of-the-art deep learning methods and strongly prove that our multitask learning mechanism can improve the results of each task.",Yes,"논문 초록에서 제안하는 방법은 성능 평가를 위해 실험을 수행하고 있으며, 여러 데이터셋에서의 성과를 비교하는 내용이 포함되어 있습니다. 이는 정량적 평가가 이루어지고 있음을 시사합니다."
Towards the Use of Language Models in Scientific Paper Recommender Systems,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10578590,"Within the educational and research community, Research Paper Recommender Systems debuted in the late 1990s and today, they constitute a specific research area. In this work, it is explored how the use of neural networks together with the incorporation of Natural Language Processing techniques, such as word embeddings and language models, affect the recom-mendation process of scientific papers. Three Deep Learning-based recommenders are explored: a neural collaborative filtering recommender, a recommender that uses word embeddings, and a recommender that incorporates language models. In addition, the results obtained are evaluated on two different datasets to see the effect of each of them on the recommendation process. While the first dataset only includes papers that have interested the user, the second one also includes papers that have not interested the user. The collaborative Deep Learning-based recommender constitutes the baseline against which to compare the rest of the developed recommenders. To evaluate the recommenders, each model is used to recommend 10 research papers for each user. The recommendations are evaluated and considered appropriate if they are related to the research field the user is interested in. The results confirm that the use of NLP techniques improves the performance of pure collaborative recommenders.",Yes,"논문 초록에서 여러 추천 시스템의 성능을 평가하기 위해 추천 결과의 적합성을 측정하는 방법이 언급되어 있으며, 이를 통해 추천 시스템의 성능을 정량적으로 평가하고 있음을 알 수 있습니다. 따라서, 정량적 평가를 실시하고 있다고 판단됩니다."
Recognizing User Preferences Based on Layered Activity Recognition and First-Order Logic,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6735312,"Only few cognitive architectures have been proposed that cover the complete range from recognizers working on the direct sensor input, to logical inference mechanisms of classical artificial intelligence (AI). Logical systems operate on abstract predicates, which are often related to an action-like state transition, especially when compared to the classes recognized by pattern recognition approaches. On the other hand, pattern recognition is often limited to static patterns, and temporal and multi-modal aspects of a class are often not regarded, e.g. by testing only on pre-segmented data. Recent trends in AI aim at developing applications and methods that are motivated by data-driven real world scenarios, while the field of pattern recognition attempts to push forward the boundary of pattern complexity. We propose a new generic architecture to close the gap between AI and pattern recognition approaches. In order to detect abstract complex patterns, we process sequential data in layers. On each layer, a set of elementary classes is recognized and the outcome of the classification is passed to the successive layer such that the time granularity increases. Layers can combine modalities, additional symbolic information or make use of reasoning algorithms. We evaluated our approach in an on-line scenario of activity recognition using three layers. The obtained results show that the combination of concepts from pattern recognition and high-level symbolic information leads to a prosperous and powerful symbiosis.",Yes,"논문 초록에서 ""We evaluated our approach""라는 표현을 통해 정량적 평가를 수행했음을 명확히 언급하고 있습니다. 또한, 활동 인식 시나리오에서 실험을 통해 결과를 분석하는 과정을 포함하고 있어 정량적 평가가 이루어지고 있음을 알 수 있습니다."
Big Data Visualisation in the Maritime Industry,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10794236,"VesselAI aims to develop, validate and demonstrate a unique framework to unlock the potential of extreme-scale data and advanced HPC, AI and Digital Twin technologies in the maritime industry. With the growth of data and the digitalization of the sector comes the need to process and visualise this information as the maritime industry generates and consumes huge amounts of different types of data every day. This paper presents literature review focusing on two aspects: (1) an examination of visualization tools available, and (2) an investigation into existing works and studies within the domain of Big Data visualization. This study addresses specific visualization requirements pertinent to the Maritime domain, including the necessity for intricate spatial-temporal visualizations encompassing diverse datasets such as weather patterns, vessel trajectories, and Automatic Identification System (AIS) data. VesselAI intends to build the VesselAI Visualisation and Reporting Engine to empower maritime users and stakeholders to make informed decisions and gather knowledge from data. To this end a platform based on Apache Superset was applied and tested in response to challenges faced by maritime stakeholders and the findings indicate that Apache Superset's robust capabilities, including a vast number of visualisation types supported, out-of-the-box data connectors, customization options, and security features, effectively met the requirements identified in the literature and by pilot users.",No,"논문 초록은 주로 빅데이터 시각화 도구와 요구사항에 대한 문헌 검토와 플랫폼 테스트에 대해 언급하고 있으며, 구체적인 정량적 평가 방법이나 결과를 제시하지 않습니다. 따라서 정량적 평가를 실시했다고 보기 어렵습니다."
Advancing Age Estimation from Facial Images Using Deep Learning Approaches and Ethical Considerations,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10912143,"Estimation of age from facial images is an important application in various fields, like biometrics, forensics, and personalized healthcare. The proposed work investigated the use of a machine learning approach to predict human age from facial features only, obtained from images. Our method used Convolutional Neural Networks (CNNs) in feature extraction and then combined regression models for age estimation. The used dataset is images of faces from different demographic groups, which makes the model robust and generalizable. All critical challenges related to variations in lighting, facial expression, and age distribution are adequately covered. The preprocessing steps, which include normalization and data augmentation, were properly applied to improve the performance of the models and reduce overfitting. Measures to report on prediction accuracy are also reported by using metrics such as Mean Absolute Deviation (MAD) and Root Mean Square Deviation (RMSD). The approach CNN-based shows a higher accuracy and computation rate compared to the baseline methods. Additionally, it presents practical applications of the models in missing people cases or for age-sensitive services. Ethical concerns such as privacy and control of bias are also of high concern and thus point to the need for clear and equitable use of such technology. This research seriously tests deep learning and shows its effectiveness in improving the estimation of age from facial images, providing important insights in relation to biometric solutions and more.",Yes,논문 초록에서 평균 절대 편차(MAD)와 제곱 평균근 오차(RMSD)와 같은 정량적 평가 지표를 사용하여 모델의 예측 정확도를 측정했다고 명시되어 있습니다. 이는 정량적 평가를 실시하고 있음을 보여줍니다.
A flexible machine learning based framework for state of charge evaluation,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9855050,"Batteries State-of-Charge (SoC) must be accurately monitored for safe battery operations, and to extend battery life. Machine Learning (ML) algorithms allow to perform the SoC estimation on a data-based approach, avoiding the need for a physical model for each different battery. In this work, a new ML-based framework for the SoC evaluation is proposed, exploiting constant current discharges for model training, rather than the commonly exploited standard drive cycle profiles. This allows avoiding the conversion processes from the drive cycles vehicle acceleration set-point into a current profile, which lead to vehicle-dependent data and the need for a conversion tool. Currents, voltages and temperatures related to different current discharge rates were measured for a Panasonic 18650 Lithium-Ion battery cell. These data were used to train and optimize a Support Vector Regression (SVR) model in the MATLAB environment. Subsequently, different data were combined together to emulate a real vehicle discharge process and were used for evaluating the model. A Root Mean Square Error (RMSE) of 0.564% was obtained, proving that the SVR model trained with constant current discharges data has been capable to estimate the SoC of the tested drive cycles operations.",Yes,논문 초록에서 Support Vector Regression (SVR) 모델의 성능 평가를 위해 Root Mean Square Error (RMSE)를 사용하여 정량적 평가를 실시했음을 명확히 언급하고 있습니다. 이는 모델의 예측 정확도를 수치로 측정하는 정량적 평가의 예시입니다.
Evaluation of activity monitors to estimate energy expenditure in manual wheelchair users,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5333626,"In an effort to make activity monitors usable by manual wheelchair users with spinal cord injury (SCI), our study examines the validity of SenseWearreg Armband (SenseWear) and RT3 in assessing energy expenditure (EE) during wheelchair related activities. This paper presents the data obtained from six subjects (n=6) with SCI performing three activities, including wheelchair propulsion, armergometer exercise and deskwork. The analysis presented here compares the EE estimated from the SenseWear and the RT3 with respect to the EE measured from a portable metabolic cart. It was found that the SenseWear overestimated EE for resting (+5.78%), wheelchair propulsion (+88.20%, +46.20%, and +138.21% for the three trials at different intensities, respectively), arm-ergometer exercise (+55.05%, +26.91%, and +39.17% for the three trials at different intensities, respectively) and deskwork (+13.11%). The results also indicate that RT3 underestimated EE for resting (-3.06%), wheelchair propulsion (-24.23%, -19.42%, and -9.98% for the three trials at different intensities, respectively), arm-ergometer exercise (-49.06%, -53.69% and -52.08 for the three trials at different intensities, respectively) and measured EE relatively accurate for deskwork. Good and moderate Intraclass correlations were found between EE measured by metabolic cart and EE estimated by SenseWear (0.787, p<0.0001) and RT3 (0.705, p<0.0001). Weka, machine learning software, was used to select attributes and model EE equations for the SenseWear and the RT3. Excellent and good Intraclass correlations were found between the EE measured by the metabolic cart and the estimated EE based on the models for SenseWear (0.944, p<0.0001) and RT3 (0.821, p<0.0001). Future work will test more subjects to refine the model and provide manual wheelchair users with a valid tool to gauge their daily physical activity and EE.",Yes,"논문 초록에서 SenseWear와 RT3 활동 모니터의 에너지 소비 추정값을 휴대용 대사 측정기와 비교하는 정량적 평가를 수행했음을 명확히 언급하고 있습니다. 또한, Intraclass correlation과 같은 통계적 지표를 활용하여 평가의 정밀도를 제시하고 있어 정량적 평가가 실시된 것으로 판단됩니다."
EchoWrite 2.0: A Lightweight Zero-Shot Text-Entry System Based on Acoustics,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793596,"Limited by size, shape, and other factors, it is rather inconvenient to interact with new smart devices by traditional methods. Acoustic-based methods following a machine learning approach have been put forward to resolve this problem in previous works. But they possess limitations of heavy training overhead, low performance for unseen users, and intensive computation cost. Following our previous work in this area, we further overcome shortcomings of existing work and propose a lightweight and zero-shot text-entry system for unseen users based on acoustic sensing. The key novelty of this work is proposing a new model training strategy including dataset construction and augmentation methods to effectively enhance generalization ability of a simple learning model with as few training data as possible, based on our insight into the problem. We design and implement a real-time Android application system called EchoWrite 2.0 to validate our idea with extensive experiments. Results show that EchoWrite 2.0 can recognize digits, English letters, and words with an accuracy of 85.3%, 73.2%, and 96.9%, respectively, for unseen users without providing any data to the learning model. The comparison with related work in different aspects shows overall superiority of EchoWrite 2.0.",Yes,"논문 초록에서 실험 결과를 통해 인식 정확도를 제시하며, 다양한 평가 지표를 사용하여 시스템의 성능을 정량적으로 평가했음을 보여줍니다. 또한, ""extensive experiments""라는 표현이 실험을 통한 정량적 평가를 수행했음을 시사합니다."
Analysis of the State of High-Voltage Current Transformers Based on Gradient Boosting on Decision Trees,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9186646,"This paper addresses the problem of instrument current transformers technical state assessment based on machine learning methods. The introductory parts of the paper provide a detailed analysis of modern methods and approaches for technical state assessment of high-voltage power equipment of power plants and substations as well as a review of modern software tools and the latest trends in the given field of study. Justification of the relevance of the presented research aimed at instrument current transformers technical state assessment is provided along with the motivation for machine learning methods application for improvement of the accuracy and quality of high-voltage equipment state classification. Within the framework of the study, a comparative analysis of gradient boosting on decision trees and random forest algorithms was carried out for a given mathematical problem formulation. The main stages of processing the initial dataset are proposed as a step-by-step procedure, including feature extraction, feature transformation, feature interactions, etc. The outperforming efficiency of gradient boosting on decision trees algorithm was validated for real power equipment fleet. The resulting classification quality metrics of current transformers technical state assessment, Precision and Recall, are estimated to be 87.1% and 83.7%, correspondingly.",Yes,"논문은 기계 학습 방법을 활용하여 정량적 평가를 수행하고 있으며, 특히 성능 지표인 Precision과 Recall을 통해 평가 결과를 제시하고 있다. 이러한 지표들은 정량적 평가의 대표적인 예로, 논문이 정량적 평가를 실시하고 있음을 보여준다."
Examining digital forensics in the context of Shamoan attack behavior within fog computing and exploring threat intelligence for Incident Response,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10482310,"Cybercrime is on the rise in modern society. Thus, the investigation of cybercrimes has used digital forensics. Numerous studies that analyze malware types, cyber-attacks, and other related topics have been conducted. Studies and analyses of APTs, particularly the Shamoon attack, as a basis for research. The purpose of this study was to evaluate the efficacy of supervised machine learning classifiers in the context of intrusion detection, with a focus on Support Vector Machine, Random Forest, Logistic Regression, and Gaussian Naive Bayes. The NSL-KDD dataset was used for the evaluation, and each classifier’s efficacy was assessed by contrasting its results based on accuracy, precision, recall, and F1-Score.With an accuracy of 99%, it can be inferred from the observed results that the Random Forest classifier performs better than the other classifiers for the specified dataset and parameters. To build on this work, future studies may examine how well these classifiers operate in scenarios involving several classes and think about adding only the most necessary characteristics for more focused intrusion detection.The FPSO mechanism puts the TSP’s operational process into practice. The FPSO mechanism carries out insertion and swap operations. After evaluating the fitness function, the nearest neighbour’s algorithm is used to determine the best shortest path. After evaluation, the best local and best global solutions are discovered. The appropriate positions and speeds are lastly updated. The generated optimal path can be used to assess the distribution of movement for Shamoon attacks. The suggested system’s efficacy has been evaluated by evaluating the fitness value and optimal cost. Distribution of the Shamoon data attack has been observed. Lastly, a threat intelligence plan is proposed to investigate and examine the behavior and spread of Shamoon attacks in the margins of fog computing.",Yes,"논문 초록에서 Support Vector Machine, Random Forest, Logistic Regression, Gaussian Naive Bayes와 같은 정량적 평가 지표(accuracy, precision, recall, F1-Score)를 사용하여 분류기 성능을 평가했다고 명시되어 있습니다. 또한, 평가 결과를 기반으로 성능 비교와 분석이 이루어지고 있어 정량적 평가를 실시하고 있음을 알 수 있습니다."
Sentimental Analysis of airline tweets using Machine Learning Algorithm and Regular Expression,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10602480,"Sentiment analysis is a technique that uses natural language processing techniques to analyze the feelings and usage of textual content evaluation.Sentiment analysis makes use of information identified and taken from a variety of sources. It looks at a variety of factors to try and ascertain a customer’s attitude. It is extensively used throughout the world for sentiment analysis and opinion extraction, enabling business organizations to understand user preferences. This paper presents a thorough yet user-friendly method for evaluating sentiment, which primarily displays aggregate ratings based on both positive and negative words. Based on the ratings, the tweets are then classified as Positive, Negative, or Neutral. Over the past ten years, there has been a notable increase in the application of opinion mining and sentiment evaluation techniques. Many studies in this field seek to determine people’s attitudes, beliefs, and feelings about a particular topic or individual. The evaluation’s primary objective is to use a machine learning model to ascertain the sentiment of the reviews, and then to compare the outcome with a manual review of the data. This could help scientists represent and analyze assessments across domains and impartially support data evaluation. For review evaluation, a hybrid approach combining a supervised machine learning algorithm with natural language processing methods is suggested. Finding the first-class version is the aim of this mission in order to gauge the sentiment of airline tweets. Throughout the process of conducting research and considering various approaches and factors to consider, we noticed that approaches such as naive bayes and logistic regression have not been thoroughly investigated since along with data imbalancing was also not look into consideration.So We will assess a more practical method in this mission that makes use of regular expression, oversampling and ml models and look into data balancing.",Yes,"논문 초록에서 머신러닝 알고리즘과 자연어 처리 기법을 활용하여 감성 평가를 수행하는 방법을 제시하고 있으며, 평가를 위해 머신러닝 모델을 사용하여 감성을 정량적으로 분류하는 과정을 언급하고 있습니다. 또한, 데이터 균형 조정과 정량적 평가 방법에 대한 언급도 포함되어 있어 정량적 평가를 실시하고 있음을 알 수 있습니다."
"StackGenVis: Alignment of Data, Algorithms, and Models for Stacking Ensemble Learning Using Performance Metrics",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9222343,"In machine learning (ML), ensemble methods-such as bagging, boosting, and stacking-are widely-established approaches that regularly achieve top-notch predictive performance. Stacking (also called “stacked generalization”) is an ensemble method that combines heterogeneous base models, arranged in at least one layer, and then employs another metamodel to summarize the predictions of those models. Although it may be a highly-effective approach for increasing the predictive performance of ML, generating a stack of models from scratch can be a cumbersome trial-and-error process. This challenge stems from the enormous space of available solutions, with different sets of data instances and features that could be used for training, several algorithms to choose from, and instantiations of these algorithms using diverse parameters (i.e., models) that perform differently according to various metrics. In this work, we present a knowledge generation model, which supports ensemble learning with the use of visualization, and a visual analytics system for stacked generalization. Our system, StackGenVis, assists users in dynamically adapting performance metrics, managing data instances, selecting the most important features for a given data set, choosing a set of top-performant and diverse algorithms, and measuring the predictive performance. In consequence, our proposed tool helps users to decide between distinct models and to reduce the complexity of the resulting stack by removing overpromising and underperforming models. The applicability and effectiveness of StackGenVis are demonstrated with two use cases: a real-world healthcare data set and a collection of data related to sentiment/stance detection in texts. Finally, the tool has been evaluated through interviews with three ML experts.",Yes,"논문 초록에서 성능 지표(performance metrics)를 활용하여 모델의 성능을 평가하는 과정을 지원하는 시스템을 제시하고 있으며, 이를 통해 정량적 평가가 수행되고 있음을 알 수 있습니다. 따라서, 논문은 정량적 평가를 실시하고 있다고 판단됩니다."
Feature Analysis for Fake Review Detection through Supervised Classification,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8259828,"Nowadays, review sites are more and more confronted with the spread of misinformation, i.e., opinion spam, which aims at promoting or damaging some target businesses, by misleading either human readers, or automated opinion mining and sentiment analysis systems. For this reason, in the last years, several data-driven approaches have been proposed to assess the credibility of user-generated content diffused through social media in the form of on-line reviews. Distinct approaches often consider different subsets of characteristics, i.e., features, connected to both reviews and reviewers, as well as to the network structure linking distinct entities on the review-site in exam. This article aims at providing an analysis of the main review- and reviewer-centric features that have been proposed up to now in the literature to detect fake reviews, in particular from those approaches that employ supervised machine learning techniques. These solutions provide in general better results with respect to purely unsupervised approaches, which are often based on graph-based methods that consider relational ties in review sites. Furthermore, this work proposes and evaluates some additional new features that can be suitable to classify genuine and fake reviews. For this purpose, a supervised classifier based on Random Forests have been implemented, by considering both well-known and new features, and a large-scale labeled dataset from which all these features have been extracted. The good results obtained show the effectiveness of new features to detect in particular singleton fake reviews, and in general the utility of this study.",Yes,"논문은 supervised classification 기법을 사용하여 가짜 리뷰를 분류하는 데 초점을 맞추고 있으며, 이를 위해 다양한 특징들을 추출하고 평가하는 정량적 실험을 수행하고 있습니다. 또한, Random Forests와 같은 기계 학습 모델을 활용하여 성능을 평가하는 과정이 포함되어 있어 정량적 평가가 실시되고 있음을 알 수 있습니다."
Affective Computing: A Topic-Based SER Approach on Collaborative Discussions in Academic Setting,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10342963,"One of the biggest concerns in the modern day especially in the educational domain centers on the student's mental health. High rates of anxiety and depression have especially brought the attention of researchers in engineering education to apply affective computing to help with students' academic performance. It is known that a person's emotional states cause physiological and physical changes in the body. Emotions may impact facial expression, tone of speech, blood pressure, pulse, etc. Since visual and auditory signals are two variables that can be measured without the need to attach any physical device to the individuals, they are most studied in this field. Speech in particular has been known as a means that transfers much information about the mental and emotional states of the person. Speech Emotion Recognition (SER) is a growing field that has been applied in several domains including engineering education. Recent advancements in AI, Natural Language Understanding (NLU), and Large Language Models (LLM) have significantly streamlined this line of research. In this work which is a continuation of our prior work, we propose a speech analysis model that extracts both the emotions and topics from verbal discussions in a computer science classroom to understand if the expressed emotions were mostly about the course related topics or not. The goal of this research is to develop a tool that helps educators gain insights into the students' emotional states in teamwork and also understand the context of their conversations. We further analyze if the expressed emotions in the verbal class discussions are mostly about the course content or other subjects outside class setting. To expand the emotion analysis module we added a new layer to our developed pipeline by passing the speech data into the ChatGPT API to generate summarized scripts and extract additional classes of emotion. The preliminary results from this study are promising, indicating the potential value of this research direction and its prospects for further development. Application of this model in the educational domain can greatly benefit both educators and students and allows the instructors to make necessary interventions needed to maximize students' positive experiences in team settings while considering their emotional states.",Yes,"논문 초록에서 제안된 연구는 감정 인식 및 주제 추출을 위한 모델을 개발하고, 이를 평가하기 위해 실험적 결과를 분석하는 것으로 보입니다. 이러한 평가 과정은 정량적 평가를 포함할 가능성이 높으며, 연구의 유효성을 검증하는 데 중요한 역할을 합니다."
Prediction of difficulties in Intubation using an Expert system,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9007952,"Expert anesthesiologist inserts a tube into the respiratory passage of the patient who is undergoing surgery in Intensive Care Unit or Operation Theater. The patient is unable to breath on their own during the surgery. This process helps in providing artificial assistance in breathing and prevents suffocation. Any interruption in oxygen supply or difficulties in intubation may result in acute internal body damages or may lead to death of the patient. Authors have carried out a literature review and field study to identify list of risk parameters leading to difficulty in intubation. Only 1 to 5 percentage of patients who are undergoing intubation suffer from difficult intubation. There is an acute shortage of expert anesthesiologist in hospital and employing an expert anesthesiologist will be very expensive. In US anesthesiologist have to perform at least 150 successful intubations in first pass to consider him as an expert. The author's main aim for designing an expert system using machine learning algorithms was to predict the difficulties in securing airway and also create an allocation system which allocates an expert anesthesiologist for difficult cases based on the results produced by the system. This paper discusses the procedure to carry out Intubation to emulate the high cognitive process of an expert anesthesiologist. The outcomes of the prediction process divides intubation into easy, difficult and impossible. The authors have designed framework of data sets, risk parameters, rules and algorithms. The expert system gives the prediction results of difficulty in intubation which will be validated by expert anesthesiologist.",Yes,"논문 초록에서 머신러닝 알고리즘을 사용하여 어려움 예측을 수행하는 시스템을 설계했다고 명시되어 있으며, 정량적 평가를 통해 예측 결과를 분류하는 과정이 포함되어 있을 것으로 보입니다. 따라서, 정량적 평가가 실시되고 있다고 판단됩니다."
A Mobile Telematics Pattern Recognition Framework for Driving Behavior Extraction,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8986619,"Mobile telematics is a relatively new innovation that involves collecting data on driving behavior using the internal sensors in a smartphone rather than from an in-vehicle data recorder. However, telematics data are usually not labeled, which makes extracting driving patterns from them very difficult. Therefore, unsupervised learning algorithms play an important role in this field. In addition, most current research is based on datasets developed in a laboratory or from site investigations and questionnaires, which are very different from real-world driving behaviors. To advance unsupervised learning techniques in this field, and to fill the gap in findings based on real-world data, we have developed an unsupervised pattern recognition framework for mobile telematics data. The framework comprises three main components: a self-organizing map, a nine-layers deep auto-encoder, and partitive clustering algorithms. The SOM algorithm reduces the complexity of the data, the deep auto-encoder extracts the features, and the clustering algorithm groups driving events with similar patterns into behaviors. Further, given clustering with mobile telematics data is an under-researched area, we undertook an empirical comparison of five well-known clustering algorithms to determine the strengths and weaknesses of each method and which is best suited to categorizing driving styles. The study was conducted with a real-world insurance dataset containing 500,000 journeys by 2500 drivers, and the results were evaluated against three measures- Davis Boulding, Calinski Harabasz, and execution time. Overall, we find that k-means clustering and a self-organizing map were able to extract more accurate patterns than others. A statistical analysis of the 29 clusters produced by SOM and k-means, revealed 29 unique driving styles, all of which can be found in the transportation literature. The results from the study, with support from the corresponding literature review, demonstrate the efficacy of the presented framework in unsupervised settings. Additionally, the results provide a basis for developing a future risk analysis and automatic decision support system for usage-based insurance companies.",Yes,"논문 초록에서 여러 평가 지표( Davis Boulding, Calinski Harabasz, execution time)를 사용하여 클러스터링 성능을 정량적으로 평가했다고 명시되어 있습니다. 이는 정량적 평가를 실시하고 있음을 보여줍니다."
Impact on Celebrity Endorsement Essentials on Brand Awareness and Purchase Intention in Men's Wear Industry in Sri Lanka,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10857789,"In fashion marketing, companies use various strategies to attract consumers and boost brand visibility. Celebrity endorsements are a key method that significantly impacts consumer behavior and brand promotion. This study explores how celebrity credibility and attractiveness affect brand awareness and purchase intention through Structural Equation Modeling (SEM), focusing the Sri Lanka's branded men's wear industry. Serving such industry, this study has discovered, explained, and evaluated how celebrity endorsement affects the customers' perception on brand image and purchase intention on men's wear, through a quantitative research approach. The literature review first identified a conceptual model and then investigates the validity of such model to the men's wear industry where the celebrity endorsement is needed. The data were analyzed using confirmatory factor analysis, SEM and cluster analysis techniques, to capture relations and impacts among key variables of celebrity endorsement essentials by means of observed variables. As key findings, while presenting individual correlations among the key factors, a SEM model is also presented to describe the true relationships and their deviations when all celebrity endorsement essentials act together. Further, using the consumer data, the effective clusters that advertisers should target when they have a plan to endorse celebrities' features, is presented to provide useful insights to the advertisers. Additionally, study has practical implications for the creation of a data-driven tool that aids fashion businesses in developing AI-based celebrity endorsement applications.",Yes,"논문 초록에서 구조방정식모델(SEM)을 사용하여 변수 간의 관계와 영향을 정량적으로 평가하는 연구를 수행했다고 명시되어 있습니다. 또한, 확인적 요인 분석과 클러스터 분석 등 다양한 정량적 분석 기법을 활용하여 데이터를 분석했다고 언급되어 있어 정량적 평가를 실시하고 있음을 알 수 있습니다."
Mapping a Navigation System for Confined Space using CNN,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9544781,"In today's world, a GPS based navigation system is inevitable. Though GPS provides a better navigation system, it compromises one's location privacy. Unintentional broadcast of one's location may open the gateway for malicious 3rd party applications that may not operate on a legal basis. To overcome privacy related issues, this paper proposes a method of navigation without the use of GPS. This can be achieved by combining Convolutional Neural Network(CNN) along with Dijkstra's Algorithm. In this work, initially the starting point of the user is identified by capturing the image of the nearest building, thereafter using the CNN model to process the image and identify the location. The dataset of more than 6,000 images was built considering various circumstances for training and testing of models. This dataset was fed to different deep learning models and CNN performed the best. The shortest path between the locations is calculated using a modified Dijkstra's algorithm. It uses priority queue to reduce the time complexity of traditional Dijkstra's algorithm. This paper will help to navigate through different college campuses/universities and other big premises without using GPS.",Yes,"논문 초록에서 CNN과 Dijkstra's Algorithm을 이용하여 위치를 식별하고 최단 경로를 계산하는 과정을 설명하며, 이를 위해 6,000개 이상의 이미지 데이터셋을 활용하여 모델의 성능을 평가하는 내용이 포함되어 있다. 이는 정량적 평가를 실시하고 있음을 보여주는 명확한 증거이다."
Machine Learning and IoT for Predicting the Productivity of MRI Equipment,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10650835,"The rapid evolution and widespread accessibility of non-invasive medical imaging technologies, exemplified by Magnetic Resonance Imaging (MRI) and Computerized Tomography (CT), are fundamentally reshaping medical decisionmaking paradigms. These sophisticated imaging modalities, capable of extracting high-definition medical images, have emerged as integral components of modern healthcare, facilitating precise diagnostics and treatment planning. The escalating adoption of such technologies, however, has accentuated the need for a nuanced understanding and optimization of the performance and productivity of both medical equipment and the teams operating them, mainly due to the high costs and risks caused by their misuse. This work proposes using univariate analytical models to estimate the number of exams performed per day with machine learning algorithms. For such, different energy-related sensors monitoring 25 magnetic resonance equipment from three different brands were considered. The results of the research reveal a compelling validation of the proposed approach. A notably high Pearson correlation coefficient is observed between the predictions generated by the evaluated models and the real measurements obtained through the Radiology Information System (RIS). This robust correlation emphasizes the accuracy and reliability of the estimation models, validating their potential applicability in real-world healthcare scenarios. Furthermore, the study unveils an intriguing trend that distinguishes the performance of electric current sensors. Thirteen out of the 25 evaluated MRI machines demonstrate superior results when equipped with electric current sensors compared to other sensor types. This nuanced insight not only substantiates the critical role of energy-related sensors in predicting equipment performance but also underscores the importance of tailoring monitoring strategies to the unique characteristics of each machine.",Yes,"논문은 univariate analytical models과 머신러닝 알고리즘을 사용하여 MRI 장비의 생산성을 예측하는 정량적 평가를 수행하고 있습니다. 또한, 예측 모델의 성능을 평가하기 위해 피어슨 상관계수와 같은 통계적 지표를 활용하여 정량적 검증을 실시하고 있습니다."
Classification of art paintings by genre,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5967323,"This paper offers an approach to automatic art genre classification of paintings. Development of machine learning algorithms and increase of overall computing power improved speed and efficiency of feature extraction from digital images and with it opened a whole new set of possibilities in classification of visual data such as paintings and other visual art. Automatic classification is useful in large database processing (e.g. museums) and could be used as a commercial application on mobile platforms. Six genres are classified in the paper: realism, impressionism, cubism, fauvism, pointilism and naïve art. Some of the genres have now been tested for the first time. Used features are described as well as a measure of their usefulness. Rate of success for different classifiers is given. Accomplished results are similar to related work results.",Yes,"논문 초록에서 여러 분류기(classifiers)의 성공률(success rate)을 제시하는 등 정량적 평가가 수행되었음을 명확히 언급하고 있습니다. 또한, 특징(feature)의 유용성 평가와 성과 비교도 포함되어 있어 정량적 평가가 이루어졌다고 판단됩니다."
Utilizing the U-Net Network for Segmenting the Left Ventricle from Cine-MRI Scans,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10841228,"In this research, we studied the U-Net segmentation model for identifying and demonstrating addresses related to cardiac left ventricle contour in cine-MRI images. Efficacy of the model is evaluated across different stages such as preprocessing, training, validation and robustness testing along with comparisons to conventional methods and other deep learning architectures. But the preprocessing includes standardized pixel intensities, and by data augmentation using rotation, flip method or scaling techniques. The training and validation stages clearly show the robust consolidation of our model with little overfitting, guaranteeing decent performance on different datasets. The developed model is robust by passing the test against noise/ artifacts, and providing a very good segmentation in extreme situations so that there are no accuracy outliers represented. Comparative analyses show better sensitivity-specificity trade-offs and precision-recall characteristics versus other methods. In general, a U-Net model developed here works well for cardiac MRI analysis and can be used as an effective tool to help automatic LV segmentation accurate and efficient in clinical applications which will improve diagnosis of heart diseases from imaging points.",Yes,논문 초록에서 모델의 성능을 평가하는 다양한 지표와 비교 분석이 언급되어 있어 정량적 평가가 실시되고 있음을 알 수 있습니다. 구체적인 성능 평가 방법과 결과를 통해 모델의 효과성을 수치로 검증하는 내용이 포함되어 있습니다.
Cost-Sensitive Bootstrapped Weighted Random Forest for DoS attack Detection in Wireless Sensor Networks,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9707254,"Security of Wireless Sensor Networks is vital as this class of networks is increasingly being used for mission-critical applications, surveillance, military and disaster management monitoring. Machine learning algorithms are used nowadays in Intrusion Detection Systems that form the first line of defense against security attacks. This work proposes a cost-sensitive machine learning-based classifier trained on the WSN-DS dataset [13] comprising flooding, TDMA/Scheduling, Black-hole, and Grey-hole attack samples. Our proposed algorithm handles the imbalanced nature of the dataset efficiently without relying on resampling techniques. Other techniques for handling imbalance can induce extra computational processing that is unsuitable for battery-powered and resource-constrained sensor networks. Given this, we propose Cost-Sensitive Bootstrapped Weighted Random Forest (CSBW-Random Forest), which demonstrated superior performance over existing works. Our method gives the accuracy, precision, recall, and F1-score of 0.997, and per-class performance scores are also in the range of 0.95 to 0.99, which is significantly better than existing literature. The analysis also indicates that the proposed work is giving a better true positive rate (0.979), false-positive rate (0.003), false-negative rate (0.020) than related works. Experimentation with proportionately increasing data samples also validates the higher performance of our model.",Yes,"논문 초록에서 정확도, 정밀도, 재현율, F1-score 등 정량적 평가 지표를 제시하며, 모델의 성능을 수치로 평가하고 있음을 명확히 언급하고 있습니다. 따라서 정량적 평가를 실시하고 있다고 판단됩니다."
A Novel Deeper One-Dimensional CNN With Residual Learning for Fault Diagnosis of Wheelset Bearings in High-Speed Trains,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8584445,"The health condition of a wheelset bearing, the key component of a railway bogie, has a considerable impact on the safety of a train. Traditional bearing fault diagnosis techniques generally extract signals manually and then diagnose the bearing health conditions through the classifier. However, high-speed trains (HSTs) are usually faced with variable loads, variable speeds, and strong environmental noise, which pose a huge challenge to the application of the traditional bearing fault diagnosis methods in wheelset bearing fault diagnosis. Therefore, this paper proposes a 1D residual block, and based on the block, a novel deeper 1D convolutional neural network (Der-1DCNN) is proposed. The framework includes the idea of residual learning and can effectively learn high-level and abstract features while effectively alleviating the problem of training difficulty and the performance degradation of a deeper network. Additionally, for the first time, we fully use the wide convolution kernel and dropout technology to improve the model's ability to learn low-frequency signal features related to the fault components and to enhance the network's generalization performance. By constructing a deep residual learning network, Der-1DCNN can adaptively learn the deep fault features of the original vibration signal. This method not only achieves very high diagnostic accuracy for the fault diagnosis task of wheelset bearings in HSTs under strong noise environment, but also its performance is quite superior when the train's working load changes without any domain adaptation algorithm processing. The proposed Der-1DCNN is evaluated on the dataset of the multi-operating conditions of the wheelset bearings of HSTs. Experiments show that this method shows a better diagnostic performance compared with the state-of-the-art deep learning methods of bearing fault diagnosis, which proves the method's effectiveness and superiority.",Yes,"논문 초록에서 제안된 딥러닝 모델의 성능 평가를 위해 실험을 수행했음을 언급하며, 다양한 조건에서의 진단 성능을 비교하는 실험 결과를 제시하고 있습니다. 이는 정량적 평가가 이루어졌음을 의미합니다."
Leveraging ML Power for Crowdfunding Success Evaluation and Security Enforcement,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10581049,"Numerous online portals have been developed over time, to host large-scale and global crowdfunding campaigns[1] in order to fulfill the funding goals of the listed projects. Therefore it becomes essential to be able to assess the probability of success of these campaigns based on the provided parameters. In this dynamic landscape of Online crowdfunding, ensuring the security[2] and integrity[3]of such a model to safeguard the interests of the investors is imperative to develop a high degree of credibility of the platform. This research introduces a sophisticated Machine Learning (ML) model[4]which is tailored according to a specifically extracted dataset which works upon a comprehensive range of features like number of images, campaign timeline, textual description, security score, associated industry and other related attributes. A distinctive feature of this study includes engineering textual features[5]from the campaign description to analyze its impact on the accuracy of the predictive model. One of the key components of this research initiative lies in discerning the scam or fraudulent campaigns listed upon the platform. The model was evaluated under several metrics to ensure its thoroughness. Notably, the Logistic Regression (LR) model was the best performer, showing a favorable ROC curve and a high accuracy of 0.899, which indicated that our predictive model was successful in its objective. Furthermore, by emphasizing the identification and suspension of fraudulent campaigns, our study fills a significant research gap and safeguards investor interests while promoting platform confidence. Our study increases investor trust in online crowdfunding ecosystems and by offering a strong foundation for well-informed decision-making. Our research offers a novel and thorough method for using machine learning to improve the effectiveness, security, and legitimacy of crowdfunding platforms.",Yes,"논문 초록에서 여러 평가 지표(ROC 곡선, 정확도 0.899 등)를 사용하여 머신러닝 모델의 성능을 정량적으로 평가했다고 명시하고 있습니다. 이는 정량적 평가를 실시하고 있음을 보여줍니다."
Developing machine learning tools for long-lead heavy precipitation prediction with multi-sensor data,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7116011,"A large number of extreme floods were closely related to heavy precipitation which lasted for several days or weeks. Long-lead prediction of extreme precipitation, i.e., prediction of 6-15 days ahead of time, is important for understanding the prognostic forecasting potential of many natural disasters, such as floods. Yet, long-lead flood forecasting is a challenging task due to the cascaded uncertainty with prediction errors from measurements to modeling, which makes the current physics-based numerical simulation models extremely complex and inaccurate. In this paper, we formulate the modeling work as a machine learning problem and introduce a complementary data mining framework for heavy precipitation prediction. Heavy precipitation that may lead to extreme floods is a rare event. Long-lead prediction requires the corresponding feature space to be sampled from extremely high spatio-temporal dimensions. Such a complexity makes long-lead heavy precipitation prediction a high dimensional and imbalanced machine learning problem. In this work, we firstly define the extreme precipitation and non-extreme precipitation clusters and then design the Nearest-Sample Choosing method to handle the imbalanced data sets. We introduce streaming feature selection and subspace learning to extract the most relevant features from high dimensional data. We evaluate the machine learning tools using historical flood data collected in the State of Iowa, the United States and associated hydrometeorological variables from 1948 to 2010.",Yes,"논문 초록에서 다양한 머신러닝 기법(예: 데이터 마이닝, 특징 선택, 서브스페이스 학습)을 도입하고, 이를 평가하기 위해 역사적 홍수 데이터와 수문기상 변수들을 활용하여 정량적 평가를 수행했음을 언급하고 있습니다. 따라서, 정량적 평가를 실시하고 있다고 판단됩니다."
DenGue CarB: Mosquito Identification and Classification using Machine Learning,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9357133,"This research paper discusses a web-based application that assists Public Health Officers in the dengue identification process. The mosquito classification is done using image processing and machine learning techniques. The training models are developed using Convolutional Neural Networks Algorithm, Support Vector Machine Algorithm, and K-Nearest Neighbors Algorithm to validate the results to determine the most accurate and suitable algorithm. this paper discusses the previous related research work on its significance and drawbacks while highlighting design, methods, and implementation in the solution. We conclude that the CNN algorithm provides the highest accuracy among the machine learning techniques used.",Yes,"논문 초록에서 여러 머신러닝 알고리즘의 성능을 비교하여 가장 정확한 알고리즘을 선정하는 과정을 언급하고 있으며, 이는 정량적 평가를 실시했음을 의미합니다. 따라서, 본 연구는 정량적 평가를 수행하고 있다고 판단됩니다."
Leveraging Industry 4.0 in Education for Remote Implementation in a Team-Based Computer Engineering Capstone Project,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10892929,"This Innovative Practice Category Full Paper presents the remote implementation of an embedded systems capstone project for computer engineering students. A capstone project is a feature of most undergraduate programs in computer engineering. Such a project is usually meant to expose students to the development of a large system from conceptualization to its final implementation, involving substantial design and development of hardware and software components. In our university, students were given the opportunity to work on a cutting-edge problem focused on healthcare - “Designing a wearable device that automatically detects human activities”. It is an area where a large amount of research is ongoing, and hundreds of scientific papers are published every year. In addition, students had to evaluate and adopt techniques from existing literature and adapt them to meet the problem requirements. Students equipped themselves with state-of-the-art hardware, Bio-signal processing, machine learning, power optimization and secure communications to design the wearable. Thus, the project reinforced their knowledge of fundamentals, while exposing them to a problem with no obvious solution. Through the capstone project, students are able to better appreciate the relevance of the various components in the computer engineering curriculum to large-scale computer engineering projects. Students are organized into teams of six to execute the project. The COVID-19 pandemic resulted in the university migrating the teaching online for all courses. This was particularly challenging to implement for the capstone project as one of the key requirements is for the members to work together and subsystems to interact with each other. A course refresh resulted in a credits update and this provided a unique opportunity for the teaching team to re-design the project with core Industry 4.0 technologies such as hardware acceleration, remote processing, networking, remote analytics, and secure protocols. This work presents a framework for its implementation, reviews the challenges encountered and the processes put in place to ensure data security and smooth running of the project in the event of future disruptions. Quantitative and qualitative results from the course feedback surveys are analyzed to gauge student response to the implementation and compared to the previous version.",Yes,"논문 초록에서 ""Quantitative and qualitative results from the course feedback surveys are analyzed""라고 명시되어 있어, 정량적 평가가 실시되고 있음을 알 수 있습니다. 따라서 이 연구는 정량적 평가를 수행하고 있다고 판단됩니다."
Leveraging Tactile Sensors for Low Latency Embedded Smart Hands for Prosthetic and Robotic Applications,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9751605,"Tactile sensing is a crucial perception mode for robots and human amputees in need of controlling a prosthetic device. Today, robotic and prosthetic systems are still missing the important feature of accurate tactile sensing. This lack is mainly due to the fact that the existing tactile technologies have limited spatial and temporal resolution and are either expensive or not scalable. In this article, we present the design and implementation of a hardware–software embedded system called SmartHand. It is specifically designed to enable the acquisition and real-time processing of high-resolution tactile information from a hand-shaped multisensor array for prosthetic and robotic applications. During data collection, our system can deliver a high throughput of 100 frames per second, which is 13.7× higher than previous related work. This has allowed the collection of a new tactile dataset consisting of 340 000 frames while interacting with 16 objects from everyday life during five different sessions. Together with the empty hand, the dataset presents a total of 17 classes. We propose a compact yet accurate convolutional neural network that requires one order of magnitude less memory and 15.6× fewer computations compared with related work without degrading classification accuracy. The top-1 and top-3 cross-validation accuracies on the collected dataset are, respectively, 98.86% and 99.83%. We further analyze the intersession variability and obtain the best top-3 leave-one-out-validation accuracy of 77.84%. We deploy the trained model on a high-performance ARM Cortex-M7 microcontroller achieving an inference time of only 100 ms minimizing the response latency. The overall measured power consumption is 505 mW. Finally, we fabricate a new control sensor and perform additional experiments to provide analyses on sensor degradation and slip detection. This work is a step forward in giving robotic and prosthetic devices a sense of touch by demonstrating the practicality of a smart embedded system that uses a scalable tactile sensor with embedded tiny machine learning.",Yes,"논문은 고해상도 촉각 정보를 실시간으로 처리하는 시스템을 설계하고 구현했으며, 제안된 딥러닝 모델의 성능 평가와 정확도 측정을 포함하고 있습니다. 또한, 모델의 추론 시간과 성능을 정량적으로 평가하여 정량적 평가를 실시하고 있음을 보여줍니다."
Enhancing Thyroid Disease Diagnosis Through Machine Learning: A Classification-Based Approach,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10864062,"Thyroid disease has recently adopted the related classification which has been worthy in the contemporary system of healthcare delivery because of the advances in diagnostics. This work proposes an automated diagnostic system for thyroid disease using machine learning approach to improve the diagnostic accuracy of the disease. The presented model also uses the features selection and classifiers like SVM and Random Forest for the classification of different thyroid disorders including hypothyroidism, hyperthyroidism, and euthyroidism. Missing values in the dataset are treated to provide actual worth in the results while imbalance is also dealt with. The process involves feeding its input a well-constructed data set after which it is checked for its performance through a validation process. The performance of the model is evaluated based on thyroid disease related parameters and the findings show a better performance compared to conventional diagnosis techniques. In this study, the authors also present their future work on how to possibly incorporate this machine learning framework into clinical practice although the study shows how this framework will help the healthcare workers to make better decisions in relation to thyroid diseases.",Yes,"논문 초록에서 모델의 성능을 평가하기 위해 다양한 파라미터를 사용하여 성과를 검증하는 과정을 언급하고 있으며, 이를 통해 정량적 평가가 실시되고 있음을 알 수 있습니다. 따라서, 이 연구는 정량적 평가를 수행하고 있다고 판단됩니다."
Achievable Rate Approximation of Large Intelligent Surface Based on Deep Learning,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10540586,"In order to enhance the achievable rate of large intelligent surfaces (LIS) afflicted by hardware impairment (HWI), existing LIS systems have adopted a distributed deployment scheme that takes into consideration the impact of HWI. This study aims to investigate the optimization problem of matrix design for distributed LIS in the presence of HWI, as well as to reduce the required number of channel samples and computational complexity for calculating the HWI equivalent noise density and utility. A deep learning-based approach is proposed in this work, which not only learns environment-related information between LISs aiming for maximizing the achievable rate of LIS systems with HWI, but also uses small training samples so to ease the system complexity.",Yes,"논문 초록에서 ""achievable rate""를 최대화하는 것을 목표로 하며, 이를 위해 최적화 문제를 다루고 있다고 명시되어 있습니다. 또한, 딥러닝 기반 접근법을 통해 환경 관련 정보를 학습하는 과정이 포함되어 있어 정량적 평가가 수행되고 있음을 시사합니다."
A case study on machine learning model for code review expert system in software engineering,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8104731,"Code review is a key tool for quality assurance in software development. It is intended to find coding mistakes overlooked during development phase and lower risk of bugs in final product. In large and complex projects accurate code review is a challenging task. As code review depends on individual reviewer predisposition there is certain margin of source code changes that is not checked as it should. In this paper we propose machine learning approach for pointing project artifacts that are significantly at risk of failure. Planning and adjusting quality assurance (QA) activities could strongly benefit from accurate estimation of software areas endangered by defects. Extended code review could be directed there. The proposed approach has been evaluated for feasibility on large medical software project. Significant work was done to extract features from heterogeneous production data, leading to good predictive model. Our preliminary research results were considered worthy of implementation in the company where the research has been conducted, thus opening the opportunities for the continuation of the studies.",Yes,"논문 초록에서 머신러닝 접근법을 사용하여 소프트웨어 프로젝트의 위험 영역을 예측하는 모델을 개발하고 평가했다고 명시되어 있습니다. 이는 정량적 평가를 수행했음을 시사하며, 모델의 예측 가능성과 유효성을 검증하는 과정이 포함되어 있음을 보여줍니다."
Benchmark and Design Support for Demand-Oriented Cloud-Communication Architectures of Cyber-Physical Production Systems,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10312564,"The usage of cloud applications in industrial automation domain is boosted by the desire to apply computational-intensive machine-learning (ML) models and access production data from all over the world. Accomplished by the demand for powerful hardware platforms for ML and centralized data storage, the connectivity performance also increases and allows high data transmission rates. Nevertheless, requirements for data transmission, like safety, security, and real-time must be considered in line with the production use case. Finding a suitable infrastructure with communication protocols for data transmission to transform legacy production plants into cyber-physical production systems (CPPS) is overwhelming due to the many available communication methods. Design support for CPPS would increase the acceptance of cloud-based solutions by engineers of automated production systems that are not specifically familiar with high-level information technology systems. This paper introduces an investigation and design recommendations for application-layer communication protocols usually used in industrial applications. The overall goal is to support the engineering for the different automation levels on field-, edge-, and cloud-level. In this paper, design measures are firstly derived from related work. Secondly, an analysis of the timing behavior and the CPU resources are carried out. Finally, the findings are collected in a summarizing rating table that briefly suggests adjusting the performance and the impact on the overall system design by selecting suitable communication protocols.",Yes,"논문 초록에서 타이밍 행동과 CPU 자원에 대한 분석이 수행되었음을 언급하며, 이를 바탕으로 평가 표를 통해 성능과 시스템 설계에 미치는 영향을 정량적으로 평가하는 내용을 포함하고 있다. 따라서 정량적 평가가 실시되고 있다고 판단됩니다."
ECG multi-class classification using neural network as machine learning model,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8379901,"The main objective of this paper is to prepare a Clinical Decision Support System (CDSS) for a multi-class classification of ElectroCardioGram (ECG) signals into certain cardiac diseases. This CDSS is based on Artificial Neural Network (ANN) as a machine learning classifier and uses time scale input features. Fourty eight (48) ECG signals were selected from MIT-BIH arrhythmia database, of one minute recording. Unfortunately, among several types of learning algorithms for the ANN classifier, finding the appropriate one demands a comparative study. So, in this study, we have evaluated the impact of two learning algorithms, which are the Levenberg-Marquardt (trainlm) and the Bayesian-Regularization (trainbr) on the proposed ANN performance. Consequently, we have achieved that trainbr reaches the most accurate result (93.8%), while trainlm generates the highest classification speed (0.582s). Subsequently, in order to assess the efficiency of this work, a second comparative study with related works, is done. Therefore, despite not being in the same working conditions, the obtained accuracy (93.8%) is considered acceptable.",Yes,논문 초록에서 ANN의 성능 평가를 위해 두 가지 학습 알고리즘(Levenberg-Marquardt와 Bayesian-Regularization)을 비교하여 정확도와 속도를 정량적으로 평가하였음을 확인할 수 있습니다. 이는 정량적 평가를 실시하고 있음을 보여줍니다.
Dysarthric Speech Detection Using Hybrid Models,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10308386,"Dysarthria is a speech disorder caused by weak or poorly coordinated speech-related muscles. Dysarthria can be caused by various factors such as stroke, multiple sclerosis, or cerebral palsy, as well as brain injury or certain medications. The ultimate goal of our paper is to make a suitable and accurate tool for detecting dysarthric speech that can be used in clinical settings for early diagnosis, treatment planning for dysarthric individuals. In this work, the machine learning models namely CNN (Convolutional Neural Network), and hybrid models, such as CNN, combined with LSTM (Long Short-Term Memory), and CNN combined with GRU (Gated Recurrent Unit) are trained on TORGO dataset, to classify the dysarthric speech from non-dysarthric speech. The model's performance is evaluated on the testing data and all of these models produce more than 95% accuracy rate. From this study, we understood that this methodology can be used in developing Automatic Speech Recognition(ASR) for people with dysarthria, which would become an essential technology for many applications.",Yes,논문 초록에서 모델의 성능 평가를 위해 테스트 데이터에서 정확도(accuracy)를 측정했다고 명시되어 있습니다. 이는 정량적 평가를 실시했음을 보여주는 명확한 증거입니다.
Efficient autism spectrum disorder prediction with eye movement: A machine learning framework,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7344638,"We propose an autism spectrum disorder (ASD) prediction system based on machine learning techniques. Our work features the novel development and application of machine learning methods over traditional ASD evaluation protocols. Specifically, we are interested in discovering the latent patterns that possibly indicate the symptom of ASD underneath the observations of eye movement. A group of subjects (either ASD or non-ASD) are shown with a set of aligned human face images, with eye gaze locations on each image recorded sequentially. An image-level feature is then extracted from the recorded eye gaze locations on each face image. Such feature extraction process is expected to capture discriminative eye movement patterns related to ASD. In this work, we propose a variety of feature extraction methods, seeking to evaluate their prediction performance comprehensively. We further propose an ASD prediction framework in which the prediction model is learned on the labeled features. At testing stage, a test subject is also asked to view the face images with eye gaze locations recorded. The learned model predicts the image-level labels and a threshold is set to determine whether the test subject potentially has ASD or not. Despite the inherent difficulty of ASD prediction, experimental results indicates statistical significance of the predicted results, showing promising perspective of this framework.",Yes,"논문은 다양한 특징 추출 방법을 평가하고, 학습된 모델을 통해 ASD 여부를 예측하는 과정을 포함하고 있어 정량적 평가를 실시하고 있음을 보여줍니다. 또한, 실험 결과의 통계적 유의성을 언급하여 정량적 평가의 수행을 명확히 하고 있습니다."
A Theoretical Comparison of Federated Learning with Differential Privacy and Blockchain for Security and Privacy in IoMT,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10857505,"The advancement of decentralized, real-time data collection through the Internet of Medical Things is transforming the healthcare industry. However, this innovation brings forth significant privacy, security, and scalability challenges. Federated Learning offers a reliable solution by enabling distributed machine learning while preserving data localization. This paper introduces two frameworks-Federated Learning combined with Differential Privacy and Blockchain-enhanced Federated Learning-to enhance robustness in IoMT systems. We compare these frameworks theoretically, evaluating their effectiveness in mitigating risks related to data confidentiality, adversarial resilience, scalability, and computational efficiency. FL-DP provides formal privacy guarantees through differential privacy techniques but is limited by the need to manage the privacy budget (E), especially in large-scale deployments. Alternatively, Blockchain-based FL maintains data integrity and decentralized trust using consensus mechanisms such as Proof of Work and Proof of Stake, but it encounters challenges related to scalability and computational efficiency. Our findings suggest that the choice between FL-DP and Blockchain-based FL depends on the specific security and privacy requirements of the IoMT application. FL-DP is better suited for privacy-critical applications where strict data confidentiality is paramount, while Blockchain-based FL is more appropriate when data integrity and trust are the primary concerns.",Yes,"논문 초록에서 두 프레임워크의 효과를 평가하기 위해 이론적 비교를 수행한다고 명시되어 있으며, 이를 통해 각각의 방법이 갖는 장단점과 성능을 정량적으로 평가하는 것으로 보입니다. 따라서, 정량적 평가를 실시하고 있다고 판단됩니다."
Machine Learning Techniques for Analysis of Mars Weather Data,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10194233,"The exploration of Mars has provided vast amounts of weather data that present unique challenges for analysis and prediction. To address these challenges, this research paper focuses on the application of machine learning techniques for the analysis of Mars weather data. The objective is to develop models that can effectively extract patterns, uncover hidden relationships, and enable accurate predictions in the Martian weather system. The research begins with a comprehensive review of the available Mars weather data. The dataset, consisting of historical records, serves as the foundation for training and evaluating machine learning models. The analysis of the Mars weather dataset reveals the planet's icy and harsh climate, with average maximum temperatures of around -21°C and average minimum temperatures of -80°C. The temperature variations show that the minimum temperature fluctuates within a narrower range of 20-30°C over the course of Mars sols from 0 to 2000, while the maximum temperature experiences larger variations of about 40-50°C. During this time, the atmospheric pressure on Mars fluctuates between 720 Pa and 950 Pa. In addition, using the elbow method revealed that 3 clusters were the ideal number for identifying distinct patterns in the weather data. The linear regression model also attained an accuracy of 85%, demonstrating its efficacy in forecasting weather patterns on Mars.",Yes,"논문은 기계 학습 기법을 활용하여 화성 기상 데이터를 분석하고 있으며, 특히 선형 회귀 모델의 정확도를 언급하여 정량적 평가를 실시했음을 보여줍니다. 또한, 클러스터링을 위한 엘보우 방법과 모델 성능 평가가 포함되어 있어 정량적 평가가 수행되고 있음을 알 수 있습니다."
Interpretable Anomaly Detection for Knowledge Discovery in Semiconductor Manufacturing,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9384026,"Machine Learning-based Anomaly Detection approaches are efficient tools to monitor complex processes. One of the advantages of such approaches is that they provide a unique anomaly indicator, a quantitative index that captures the degree of ’outlierness’ of the process at hand considering possibly hundreds or more variables at the same time, the typical scenario in semiconductor manufacturing. One of the drawbacks of such approaches is that Root Cause Analysis is not guided by the system itself. In this work, we show the effectiveness of a method, called DIFFI, to equip Isolation Forest, one of the most popular Anomaly Detection algorithms, with interpretability traits that can help corrective actions and knowledge understanding. Such approach is validated on real world semiconductor manufacturing data related to a Chemical Vapor Deposition process.",Yes,"논문 초록에서 ""a quantitative index that captures the degree of ’outlierness’""와 같은 정량적 평가 지표를 언급하고 있으며, 이를 통해 정량적 평가를 실시하고 있음을 알 수 있습니다. 또한, 제안된 방법의 유효성을 실세계 데이터를 통해 검증하는 과정이 포함되어 있어 정량적 평가가 수행되고 있음을 시사합니다."
HEND-FL: Accurate Federated Learning Using Homomorphic Encryption and a New Distributed Protocol,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9928012,"Federated learning (FL) is the latest development of distributed machine learning(ML), in which data is acquired and processed locally on the client, and then updated ML parameters are transmitted to a central server for aggregation. However, FL also brings some challenges, since it may reveal private information by analyzing upload parameters (such as weights trained in deep neural networks) from the client. To tackle the problem, this paper introduces a decentralized system, HEND-FL, which relies on a group of computing nodes to achieve aggregate calculations of parameters. In order to ensure the data confidentiality and the privacy of the data provider, this proposed system combines an interactive protocol and homomorphic encryption, and uses the Chinese Remainder Theorem to optimize the speed of decryption. Based on the discrete logarithm problem of elliptic curves, the scheme can be proved to be secure under the defined threat model. We evaluate the effectiveness of our plan and compare it with existing related work on the MNIST dataset. The results show that our scheme has almost the same accuracy in the plaintext and encrypted state. Compared with other encryption schemes, due to our smaller ciphertext size and the assistance of multiple computing nodes, the burden on the central server is significantly reduced.",Yes,"논문 초록에서 ""evaluate the effectiveness of our plan""라는 표현과 함께 MNIST 데이터셋을 이용한 성능 비교 결과를 언급하고 있어, 정량적 평가가 실시되었음을 알 수 있습니다. 이는 실험을 통해 제안된 방법의 성능을 수치적으로 평가했음을 의미합니다."
Smart Patient Monitoring and Recommendation (SPMR) Using Cloud Analytics and Deep Learning,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10496106,"The escalating global prevalence of chronic and lifestyle-related illnesses presents substantial societal and economic challenges. This work delves into an extensive review of healthcare monitoring systems tailored for chronic and lifestyle disorders. Subsequently, we propose a pioneering Smart Patient Monitoring and Recommendation (SPMR) framework, leveraging Deep Learning (DL) and cloud-based analytics. SPMR ensures continuous monitoring and predictive insights into a patient’s authentic health status using data from vital signs and contextual activities collected via Ambient Assisted Living devices. Within the predictive DL component of the LIP module, we employ Categorical Cross Entropy (CCE) Optimization to forecast real-world health conditions using unbalanced datasets derived from Chronic Blood Pressure Disorder case studies. Significantly, SPMR’s capability to deliver real-time preventive measures and treatments persists even without Internet or cloud connectivity. This circumvents the need to replicate Machine Learning (ML) models and associated procedures in local setups, thus streamlining operations. Comparative analysis against analogous models showcases the considerable effectiveness of our proposed model, notably enhancing accuracy by up to 8 to 18 percent. Moreover, both the overall F-score and the emergency class F-score exhibit marked improvements of 17% and 36%, respectively. These outcomes underscore SPMR’s pivotal role, especially during crises, emphasizing its significance in healthcare monitoring systems.",Yes,"논문 초록에서 정량적 평가를 위해 Categorical Cross Entropy (CCE) 최적화, 정확도 향상, F-score 개선 등 구체적인 수치와 성능 지표를 제시하고 있습니다. 이러한 내용은 정량적 평가를 실시했음을 명확히 보여줍니다."
Quality Assessment for Natural and Screen Content Images,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8977791,"Quality assessment (QA) of screen content images (SCIs) has gained more and more popularity. SCIs are very different from natural images (NIs) which have been dealing with by most researchers in the literature. QA methods specifically designed for NIs also can be used to evaluate the quality of SCIs. Yet, their performances are unsatisfactory. This may due to the statistical differences of SCIs and NIs. In this paper, SCIs and NIs QA methods in the literature are being compared and studied for both SCIs and NIs benchmarked databases. It is found out that methods that incorporate gradient features work well for both SCIs and NIs. This points out a possible way to utilize gradient features to come out with a QA method that works for both SCIs and NIs simultaneously. Hence, application related to SCIs and NIs such as deep learning and multitasking for person tracking system can be improved with the QA method.",Yes,"초록에서 여러 QA 방법들을 비교하고 연구하는 과정이 언급되어 있으며, 특히 성능 평가를 위해 다양한 방법들이 검증되고 있음을 시사합니다. 이는 정량적 평가를 실시하는 연구임을 나타내며, 구체적인 평가 방법이나 실험 결과를 통해 평가가 이루어지고 있음을 알 수 있습니다."
A Generative Deep Learning Framework Across Time Series to Optimize the Energy Consumption of Air Conditioning Systems,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9676657,"Working towards active buildings that fully integrate efficient demand management with renewable energy sources and storage, energy efficiency is an important step, as building inefficiencies cause energy wastage and increase energy-related expenses. Currently, static thermal setpoints are typically used to maintain the inside temperature of a building at a comfortable level irrespective of its occupancy. This paper introduces a deep learning framework that trains across time series to forecast the temperatures of a future period directly where a particular room is unoccupied and optimises the setpoints of the room. To the best of our knowledge, this is the first study to use a state-of-the-art deep learning method trained across series to accurately predict temperatures for the subsequent optimal control of room setpoints. In contrast to traditional forecasting approaches that build isolated models to predict each series, our framework uses global recurrent neural network models that are trained with a set of relatively short temperature series, allowing the models to learn cross-series information. The predicted temperatures were then used to define the optimal thermal setpoints to be used inside the room during the unoccupied periods. We evaluate the prediction accuracy of our deep learning framework against a set of state-of-the-art forecasting models and can outperform those by a large margin. Furthermore, we analyse the usage of our deep learning framework to optimise the energy consumption of an air conditioning system in a real-world scenario using temperature data from a university lecture theatre. Based on simulations, we show that our proposed framework can lead to savings of approximately 20% and 15%, respectively, compared to the traditional temperature control model that does not use optimisation techniques and a programmable thermostat.",Yes,"논문은 딥러닝 프레임워크를 사용하여 온도 예측의 정확도를 평가하고 있으며, 예측 성능을 기존 모델과 비교하는 정량적 평가를 수행하고 있습니다. 또한, 시뮬레이션을 통해 에너지 절감 효과를 수치로 제시하여 정량적 평가를 실시하고 있음을 보여줍니다."
CFD Investigation of Dispersion of Airborne Particulate Contaminants in a Raised Floor Data Center,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9142865,"Modern data center facilities administrators are finding it increasingly difficult to lower the costs incurred in mechanical cooling of their IT equipment. This is especially true for high computing applications like Artificial Intelligence, Bitcoin Mining, Deep Learning, etc. Airside Economization/free air cooling reduces the mechanical cooling costs by using outside air to cool IT equipment under favorable ambient conditions. In this process, administrators risk their equipment to the exposure of fine particulate/gaseous contaminants that might enter the data center facility with the cooling airflow. Literature suggests that the nature of failures caused by particulate contamination is very intermittent which makes the failures tough to predict. While the recommended filters can remove PM10-2.5, it's the fine and ultra-fine particulates like DPM (Diesel Particulate Matter), corrosive salts of high ionic content like sulfates and nitrates with low DRH (Deliquescent Relative Humidity) values that are the cause of concern. The present investigation utilizes a 3 - D CFD modeling of particle-laden flow in a rectangular flow domain, imitating the flow through floor tiles as in a raised floor data center. Literature was reviewed to study various numerical models that have been used for simulating particle dispersion and particle deposition in ventilated rooms, air ducts and particle behavior across physical obstructions of various geometries. A Discrete Phase Modeling approach was chosen using ANSYS FLUENT to calculate trajectories of the dispersed contaminants. 6SigmaRoom was used to predict accurate boundary and flow conditions of the fluid flow leaving the floor tiles.",Yes,"논문 초록에서 3D CFD 모델링을 활용하여 입자 분산을 시뮬레이션하고 있으며, Discrete Phase Modeling을 통해 오염물의 궤적을 계산하는 등 정량적 평가를 수행하는 구체적인 방법이 언급되어 있습니다. 이는 명확히 정량적 평가를 실시하고 있음을 보여줍니다."
Effective Features Selection and Machine Learning Classifiers for Improved Wireless Intrusion Detection,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8530969,"Machine learning algorithms are effective means applied to wireless intrusion detection systems (WIDS) in an attempt to protect computing resources against unauthorized access. A key aspect for an improved WIDS based on machine learning classification is features selection. This paper considers multiclass classification that utilizes four effective features sets of 32, 10, 7 and 5 features, respectively. The classes represent 15 types of 802.11 MAC layer attacks, and the features represent 802.11 frame fields information. The experimental results utilized the Aegean Wi-Fi Intrusion Dataset (AWID) to evaluate the performance of seven well-known machine learning classifiers, namely, AdaBoost, Random Forest, Random Tree, J48, logit Boost, Multi-Layer Perceptron, and ZeroR with respect to the selected features set. The presented work outperforms previous related work in terms of number of classes, features and accuracy. The proposed system using the Random Forest algorithm and 32 features achieves a maximum accuracy of 99.64%. By using logit Boost with five features, we achieved a maximum accuracy of 99.53%.",Yes,"논문 초록에서 다양한 특징 세트와 머신러닝 분류기들을 이용하여 성능 평가를 수행했다고 명시되어 있으며, 실험 결과를 통해 정확도를 정량적으로 제시하고 있기 때문에 정량적 평가를 실시하고 있다고 판단됩니다."
Decoding of finger movement using kinematic model classification and regression model switching,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7836126,"Brain Computer Interface (BCI) is one of the clinical applications that may help to restore communication to people with motor disabilities. Electrocorticography (ECoG) is a semi invasive record to brain signals from electrode grids on the cortex surface. ECoG signal makes possible localization of the source of neural signals due to its high spatial resolution. This study is a step towards exploring the usability of ECoG signal as BCI input technique and a multidimensional BCI control. The objective of this deterministic approach is to predict individual finger movement from ECoG signal by combining both classification and regression problems in machine learning of signal responses (regression via classification), on the other hand addressing the signal responses variability within a single subject. The dataset used in this work is the one presented in the fourth dataset from BCI competition IV. The difficulty is that; there is no simple and direct relation between ECoG signals and finger movements. This research work starts in two directions. The first direction is related to the decoding of the finger position signal to obtain a finger movement state signal. The second direction is related to the ECoG recorded signal, in order to obtain the corresponding brain signal of each finger movement. The work consists of five main phases (decoding finger state, pre-processing, features acquisition, classification, and regression). This approach suggests kinematic finger model which is applied on the finger muscle signal to generate the finger kinematic state signal. For feature extraction we used shift invariant wavelet decomposition and multi-taper frequency spectrum, followed by Gram-Schmidt test for selection. Linear support vector machine (SVM) is used for classification. Regression models are established by using the finger position training signal and the acquired ECoG features. To predict the finger movement signal under test; switching between these regression models is made. Finally the predicted finger movement signal is correlated with the measured one for evaluation. Results show that the average correlation measure between real and predicted movement is 0.82. This result is higher than the one obtained by the competition winner (0.46).",Yes,"논문은 다양한 기계학습 기법을 활용하여 손가락 움직임을 정량적으로 예측하는 과정을 포함하고 있으며, 예측된 신호와 실제 신호 간의 상관 계수로 평가하는 정량적 평가를 실시하고 있습니다. 이러한 평가 방법은 정량적 평가의 명확한 예시입니다."
Non-Invasive Skin Disease Diagnostic System Using Deep Learning,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10840609,"Human skin is an important part of the body that needs attention. Skin diseases are quite common in a country like India with varied climate and high pollution levels. The usual diagnosis of skin diseases is based on visual examination and certain tests performed by a dermatologist. But this is a time-consuming process and can also end up in the wrong diagnosis. Skin disease diagnosis has undergone a revolution because of the significant development in the field of machine learning, notably convolutional neural networks (CNN). CNNs have the potential to completely change the way skin illnesses are diagnosed, tracked, and treated. This study investigates the application of various machine learning techniques in skin problem identification. By using CNN analysis of skin disease images, identification of patterns and making accurate predictions can be done with an unprecedented accuracy and consistency. In addition to diagnosis, machine learning models can treat different skins individually according to their type, thus simplifying the doctor's role. This study aims to use CNN to improve dermatology practices by introducing efficiency and accuracy. This study includes a comprehensive literature review examining existing CNN models and performance metrics. Goals include collecting health data, using CNN's predefined models, comparing their performance, recommending the best models for diagnosing skin diseases, and improving the user interface. It presents a benchmark-based neural network model that may contribute to advances in dermatology in identifying skin diseases through machine learning using data from HAM10000 and DERMNET. The effectiveness of the model is determined by comparing it with other existing models by evaluating quality indicators such as accuracy, precision, and F1 score.",Yes,"논문 초록에서 CNN 모델의 성능 평가를 위해 정확도, 정밀도, F1 점수와 같은 정량적 지표를 사용했다고 명시되어 있습니다. 이러한 지표들은 정량적 평가의 대표적인 예로, 논문이 정량적 평가를 실시하고 있음을 보여줍니다."
"Predicting Events in MOBA Games: Prediction, Attribution, and Evaluation",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9736637,"The multiplayer online battle arena (MOBA) games have become increasingly popular in recent years. Consequently, many efforts have been devoted to providing pregame or in-game predictions for them. These predictions can be used in many MOBA esports-related applications, such as artificial intelligence commentator systems, in-game data analysis, and game-assistant bots. However, these works are limited in the following two aspects: the lack of sufficient in-game features and the absence of interpretability in the prediction results. These two limitations greatly restrict the practical performance and industrial application of the current works. In this work, we collect a large-scale dataset containing rich in-game features for the popular MOBA game Honor of Kings. We then propose to predict four types of prediction tasks in an interpretable way by attributing the predictions to the input features using two gradient-based attribution methods: Integrated Gradients and SmoothGrad. To evaluate the explanatory power of different models and attribution methods, a fidelity-based evaluation metric is further proposed. Finally, we evaluate the accuracy and fidelity of several competitive methods to assess how well machines predict events in MOBA games.",Yes,"논문 초록에서 여러 예측 작업의 정확도와 신뢰도를 평가하기 위해 ""accuracy""와 ""fidelity""라는 정량적 평가 지표를 사용했다고 명시되어 있습니다. 또한, 다양한 방법의 성능을 비교 평가하는 과정이 포함되어 있어 정량적 평가가 실시되고 있음을 알 수 있습니다."
Cross validating hyperspectral with Ultrasound-based skin thickness estimation,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8077565,"Our work is focused on the development of non-invasive methods to estimate skin constitutive elements. Such methods can play an important clinical and scientific role in detecting the early onset of skin tumors. Given current statistics by the American Academy of Dermatology suggesting that more than 10 people die each hour worldwide due to skin related conditions, this has potentially high impact on the delivery of skin cancer diagnostics, and patient mortality and morbidity. It can also serve as a valuable tool for research in cosmetology and pharmaceuticals in general. We combine a physics-based model of human skin with machine learning and hyperspectral imaging to non-invasively estimate physiological skin parameters, including melanosomes, collagen, oxygen saturation, blood volume, and skin thickness. While some prior work has been done in this regard, no validation against ground truth has occurred whatsoever. In this specific study we develop a protocol to validate our methodology for estimating one of these skin parameters, skin thickness, using a dataset of 48 hyperspectral signatures obtained in vivo, and cross-validate our depth estimates with a gold standard obtained via Ultrasound. Relative to this gold standard, we find promising mean absolute errors of less than 0.1 mm for skin thickness estimation.",Yes,"논문은 피부 두께 추정을 위해 정량적 평가를 실시하고 있으며, 초음파를 통한 골드 표준과의 교차 검증을 통해 평균 절대 오차를 측정하는 등 구체적인 수치로 성능을 평가하고 있다. 이러한 평가 방법은 정량적 평가의 핵심 요소를 충족한다."
Tremor Class Scaling for Parkinson Disease Patients Using an Array X-Band Microwave Doppler-Based Upper Limb Movement Quantizer,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9509550,"Consensus criteria for tremor classification in Parkinson’s disease (PD) patients are clinically important for automatically evaluating the PD rating scale. Wearable sensing tools with direct contact measurements can obtain physiological signals to monitor tremor symptoms. Then, machine learning algorithms (MLAs) can train the frequency-based parameters and motion features to accurately measure PD-related tremors. Noncontact measurement with customized computer information devices can also digitalize the digitized handwritten patterns with the bespoke movements that a hand makes for identifying tremor classes. However, wearable sensors need a set of multiple electrodes to be placed on a patient’s body to acquire biosignals, and the setup does not allow continuous measurement and limits the patient’s motion range. The handwritten patterns of noncontact-based methods need frequency-domain and linearization transformations. In addition, feature extraction methods and MLAs are limited in complex computations and adaptive applications. Hence, in this work, a noncontact measurement with an array X-band microwave (10 GHz) Doppler-based linear quantizer is designed to continuously measure upper limb movements for tremor class scaling. To overcome the complex computations, time-domain parametric features, including zero crossing (ZC), Willison amplitude (WAMP), and waveform length (WL) indexes, are used to extract the physical changes in the oscillation frequencies, amplitudes, and directions of tremor signals for scaling upper limb tremor (ULT) levels. In the experiments involving 10 subjects, the proposed noncontact bioradar sensor could quantify asymmetrical and irregular oscillations with a positive correlation (mean R2 > 0.85) between the three indexes (ZC, WAMP, WL) and various oscillation frequencies. The linear relationship quantizer could predict the ULT levels from 0 Hz to 8 Hz for PD patients (typical tremor frequency: 4–6 Hz). It could also map the three indexes into colored visual representation for computerized visual analysis.",Yes,"논문은 시간 도메인 파라미터(Zero Crossing, Willison Amplitude, Waveform Length)를 사용하여 떨림 신호의 물리적 변화를 정량적으로 평가하고 있으며, 이들 지표를 기반으로 상지 떨림 수준을 예측하는 선형 관계를 구축하는 정량적 평가 방법을 실시하고 있습니다. 따라서, 논문은 정량적 평가를 수행하고 있다고 볼 수 있습니다."
Modeling Human Innate Immune Response Using Graph Neural Networks,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9641838,"Since the rapid outbreak of Covid-19, profound research interest has emerged to understand the innate immune response to viruses to enable appropriate vaccination. This understanding can help to inhibit virus replication, prolong adaptive immune response, accelerated virus clearance, and tissue recovery, a key milestone to combat coronaviruses (CoVs), e.g., Covid-19. An innate immune system triggers inflammatory responses against CoVs upon recognition of viruses. An appropriate defense against various coronavirus strains requires a deep understanding of the innate immune response system. Current deep learning approaches focus more on Covid-19 detection and pay no attention to understand the immune response once a virus invades. In this work, we propose a graph neural network-based (GNN) model that exploits the interactions between pattern recognition receptors (PRRs)to understand the human immune response system. PRRs are germline-encoded proteins that identify molecules related to pathogens and initiate a defense mechanism against the related pathogens, thereby aiding the innate immune response system. An understanding of PRR interactions can help to recognize pathogen-associated molecular patterns (PAMPs) to predict the activation requirements of each PRR. The immune response information of each PRR is derived from combining its historical PAMPs activation coupled with the modeled effect on the same from PRRs in its neighborhood. On one hand, this work can help to understand how long Covid-19 can confer immunity for a strong immune response. On the other hand, this GNN-based understanding can also abode well for appropriate vaccine development efforts against CoVs. Our proposal has been evaluated using CoVs immune response dataset, with results showing an average IFNs activation prediction accuracy of 90%, compared to 85% using feed-forward neural networks.",Yes,논문 초록에서 제안하는 그래프 신경망(GNN) 모델의 성능 평가를 위해 CoVs 면역 반응 데이터셋을 사용하여 IFNs 활성화 예측 정확도를 측정하는 정량적 평가를 실시했다고 명시되어 있습니다. 이는 연구에서 정량적 평가가 수행되고 있음을 보여줍니다.
An efficient approach for spammer detection on Twitter and their behavior analysis,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9774154,"Twitter is the 4th most popular social networking site and almost 353 million are using Twitter worldwide. The main problems faced by Twitter users are spam, malicious automation, and platform manipulation. Twitter’s developer API is exposed to make it easy to interact. So, the anti-spam system on Twitter is known by spammers. Here, we are using some features that are related to account details of Twitter users with two different data sets having one lakh data for each. We propose a method to classify spam and non-spam users using five machine learning classifiers. We evaluated the performance using accuracy, precision, and recall. Then we are proposing a fuzzy-based approach for user behavior analysis, inspired by the Five-factor model of behavior theory. Only a few works are discussing the behavior of the spammer, and we found that there exists a relationship between the traits of a person and spamming.",Yes,"논문 초록에서 정확도, 정밀도, 재현율과 같은 정량적 평가 지표를 사용하여 성능을 평가했다고 명시되어 있습니다. 또한, 머신러닝 분류기와 퍼지 기반 접근법의 성과를 수치적으로 분석하는 내용이 포함되어 있어 정량적 평가를 실시하고 있음을 알 수 있습니다."
Transferring Age and Gender Attributes for Dimensional Emotion Prediction from Big Speech Data Using Hierarchical Deep Learning,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8552276,"The continuous speech emotion prediction is a challenging task. This research has many important applications in real-life, especially on human-computer interaction and its applications are expected to become increasingly wider and deeper. Previous studies have show that three dimensional attributes of emotion such as arousal, valence and dominance are related each other. Moreover, age and gender of speaker affect the recognition of speech emotion. Based on these observation, we propose a new dimensional attributes prediction model using multi-task learning, aiming to improve the emotion recognition performance and generalization capabilities. The present methods utilize the big speech data to train the age and gender submodel, which will be transferred to the main modelłła hierarchical deep learning model, using age and gender as the high level attributes of the emotion. The publicly available databases IEMOCAP and aGender have been conducted to evaluate the performance and the accuracy of the proposed work. Experiment results of within-corpus evaluation show that the proposed approach has superior performance compared to state of the art result.",Yes,"논문 초록에서 ""Experiment results""와 ""accuracy""라는 용어를 사용하여 성능 평가를 수행했음을 언급하고 있습니다. 이는 정량적 평가가 이루어지고 있음을 시사하며, 실험을 통해 제안된 방법의 성능을 수치적으로 검증했음을 알 수 있습니다."
Towards a Geometric Understanding of Spatiotemporal Graph Convolution Networks,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10518107,"Spatiotemporal graph convolutional networks (STGCNs) have emerged as a desirable model for skeleton-based human action recognition. Despite achieving state-of-the-art performance, there is a limited understanding of the representations learned by these models, which hinders their application in critical and real-world settings. While layerwise analysis of CNN models has been studied in the literature, to the best of our knowledge, there exists no study on the layerwise explainability of the embeddings learned on spatiotemporal data using STGCNs. In this paper, we first propose to use a local Dataset Graph (DS-Graph) obtained from the feature representation of input data at each layer to develop an understanding of the layer-wise embedding geometry of the STGCN. To do so, we develop a window-based dynamic time warping (DTW) method to compute the distance between data sequences with varying temporal lengths. To validate our findings, we have developed a layer-specific Spatiotemporal Graph Gradient-weighted Class Activation Mapping (L-STG-GradCAM) technique tailored for spatiotemporal data. This approach enables us to visually analyze and interpret each layer within the STGCN network. We characterize the functions learned by each layer of the STGCN using the label smoothness of the representation and visualize them using our L-STG-GradCAM approach. Our proposed method is generic and can yield valuable insights for STGCN architectures in different applications. However, this paper focuses on the human activity recognition task as a representative application. Our experiments show that STGCN models learn representations that capture general human motion in their initial layers while discriminating different actions only in later layers. This justifies experimental observations showing that fine-tuning deeper layers works well for transfer between related tasks. We provide experimental evidence for different human activity datasets and advanced spatiotemporal graph networks to validate that the proposed method is general enough to analyze any STGCN model and can be useful for drawing insight into networks in various scenarios. We also show that noise at the input has a limited effect on label smoothness, which can help justify the robustness of STGCNs to noise.",Yes,"논문은 다양한 실험을 통해 제안된 방법의 유효성을 검증하고 있으며, 특히 실험적 증거를 제공하여 정량적 평가를 실시하고 있음을 보여줍니다. 또한, 여러 데이터셋과 모델을 대상으로 한 분석이 포함되어 있어 정량적 평가의 수행이 명확하게 드러납니다."
Restaurant Recommendation System for User Preference and Services Based on Rating and Amenities,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8862048,"Recommendation systems are being enforced to offer personalized set of services to the users. They are basically build to produce recommendations or suggestions (like restaurants, places...) that comply with user's concern and that can be applied to multiple fields. To enhance the quality and service of Recommendation systems and to resolve any issues related to it, various effective techniques linked to data management can be made use of. The current paper proposes a machine learning algorithms to resolve the issue of personalized Restaurant selection relying upon tripadvisor.com search data. The facilities provided by the hotel along with user's comments are being utilized. The NLP - Natural Language Processing is imbibed for examining and tagging all the previous user's comments (whether positive or negative) for every hotel, thereafter computing the overall % of the comments and storing the output. In the process of Restaurant recommendation, first the user chooses the hotel's features according to his interest and centered on this, the corresponding hotels are fetched and the user comments are examined to identify the hotel with the highest ranking. Eventually, the highest rated hotel is being recommended to the user by the restaurant recommended system. The proposed sentimental score measure NLP algorithm is used for finding the aspect and sentiments of the user comments. Natural language processing (NLP) is one of the machines learning technique to analyze, understand, and derive meaning from human language in a smart and useful way. The evaluation results reveal that the proposed NLP algorithm improves the performance when compared to existing algorithms. The focus of the research work is to offer list of recommended restaurants that is more precise and accessible. The conclusion and results reveal that the suggested approach yields high accuracy.",Yes,"논문 초록에서 제안된 방법이 추천 시스템의 성능을 평가하기 위해 정량적 평가 지표를 사용했음을 시사하는 문구가 포함되어 있습니다. 특히, ""평가 결과""와 ""높은 정확도""라는 표현이 있어 정량적 평가가 실시되었음을 알 수 있습니다."
Analysis and Simulation of Humanoid Gait,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7402132,"The development of mobile robots is related to multidisciplinary areas of mechanics, electronics, computing and biology. Current research have made possible the development of robots that assist in exploration, rescue and rehabilitation, using artificial intelligence techniques, optimization and dynamic analysis of multibody systems. This work aims the synthesis of a humanoid robot and presents the theoretic robot kinematic model allowing define its movement in order to maintain dynamic balance and evaluate the torques applied on their actuators using CAD-CAE simulation. From the 3D computational model and using numerical simulation of multibody systems, it was possible to obtain the dynamic torques in the structure of the robot and the position of its center of mass and legs along the defined path. With this study was evaluated a methodology for multibody simulation mechanisms applied in projects of humanoid robots.",Yes,논문 초록에서 CAD-CAE 시뮬레이션을 통해 토크와 구조의 동적 특성을 평가하는 정량적 분석이 수행되었음을 언급하고 있습니다. 이러한 시뮬레이션은 수치적 데이터를 기반으로 한 정량적 평가의 일환으로 볼 수 있습니다.
Critical Factors Affecting Fast-Track Construction Management for Infrastructure Projects: Validated Scale Development and K-Means Clustering Algorithms Insights,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10550696,"The fast-track project concept has become crucial in today’s competitive business landscape, driven by escalating market demands. This research aims to pinpoint success-determining factors in such projects, a quest initiated through an extensive literature review and further explored via structured interviews and questionnaires. This study unfolds in multiple phases, beginning with interviews of five experts with over 25 years of experience validating 10 critical factors: planning, scheduling, customer commitment, communication, risk management, technology adoption, project skills, material management, activity breakdown, and leadership. Subsequent phases involve quantitative approaches, including a survey with 125 respondents, predominantly Filipino professionals with substantial construction experience, and a follow-up phase with 200 Filipino respondents. These phases leverage principal component and confirmatory factor analysis, alongside machine learning techniques like K-means clustering, to analyze each success factor’s significance and perception variations. The analysis found high component loadings above 0.6 for critical success factors, confirmed by Cronbach’s Alpha values within the acceptable range of 0.6 to 0.8, but faced challenges in model fit, indicated by mixed results in Confirmatory Factor Analysis with communalities below 0.4 and inconsistent appropriate indices. The paper also looks into the application of the K-means clustering algorithm. Finally, it lays the groundwork for future research, emphasizing the need for diverse, experienced perspectives in understanding fast-track project dynamics.",Yes,"논문 초록에서 설문조사, 주성분 분석, 확인적 요인 분석 등 정량적 평가 방법을 사용했다고 명확히 언급하고 있으며, K-means 클러스터링 알고리즘도 활용하여 데이터를 분석하는 것으로 나타납니다. 이러한 내용들은 정량적 평가를 실시하고 있음을 보여줍니다."
On Applicability of Imagery-Based CNN to Computational Offloading Location Selection,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9999423,"The progress in computational offloading is heavily pushing the development of the modern Information and Communications Technology domain. The growth in resource-constrained Internet of Things devices demands the development of new computational offloading strategies to be sustainably integrated in beyond 5G networks. One of the solutions to said demand is enabling Mobile Edge Computing (MEC) powered by advanced methods of Machine Learning (ML). This paper proposes the application of ML-powered computational offloading strategy in a wireless cellular network by applying the traditional fundamental Travelling Salesman Problem (TSP) on computational offloading location selection. The main specificity of the proposed approach is the use of imagery data. Thus, the paper executes a literature review to identify existing strategies. It further proposes a novel method utilizing the location-like imagery data to identify the most suitable computational location by executing the search for an identified route between locations using the proposed Deep Learning (DL) model. The model was evaluated and achieved MAE – 1,575, MSA – 10,119,205, R2 – 0.98 on the testing dataset, which outperforms or is comparable with other well-known architectures. Moreover, the training time is proven to be 2–10 times faster. Interestingly, the MAE values are relatively low compared to the target values that should be predicted (despite rather high MSE results), which is confirmed by the almost perfect R2 value. It is concluded that the proposed neural network can predict the target values, and this solution can be applied to real-world tasks.",Yes,"논문 초록에서 MAE, MSA, R2와 같은 정량적 평가 지표를 사용하여 딥러닝 모델의 성능을 평가했다고 명확히 언급하고 있습니다. 또한, 모델의 예측 정확도와 학습 시간에 대한 수치적 결과를 제시하여 정량적 평가를 실시했음을 알 수 있습니다."
A Research on the Vulnerabilities of PLC using Search Engine,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8939961,"The development and convergence of information and communication technologies have been leading to various studies on big data, artificial intelligence, internet of things, and smart cars to be introduced to our daily life. Especially, Smart factory which also base on ICT technology mentioned above are gradually applied to automation of intelligent manufacturing processes which is used to take place in a factory to drive down manufacturing costs and time to profit. Like governments that already encourage the introduction of smart factories, individuals and organizations are also considering introduction of smart factories. Smart factory requires modbus protocol to communicate and it must come with ICS, SCADA, PLC. These systems are greatly important in terms of security. However, using some of public website like Shodan makes it possible to search easily networks related to critical systems and devices. For safe and secure operation in smart factory, we need to raise awareness to these kind of security vulnerabilities in the ICS so that smart factories can cope with security accidents that might occur. In addition, for successfully introduction and activation of smart factories, security vulnerabilities must be reduced by using security measures and security devices should be applied for the ICS. As a baseline work for security improvement, we arrange the potential security vulnerabilities by conducting various real-world experiments and propose some security measures. Through this research, we expect to encourage security awareness of using smart factories which are undoubtedly important issue.",Yes,"논문은 스마트 공장과 관련된 보안 취약점에 대해 연구하며, 실험을 통해 잠재적 보안 취약점을 정리하고 보안 조치를 제안하는 내용을 포함하고 있습니다. 이는 정량적 평가를 수행했음을 시사하는 내용으로 보입니다."
AI-Powered Code Reviews: Leveraging Large Language Models,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10829223,"As the complexity and volume of software development continue to grow, the need for efficient and thorough code review processes becomes increasingly critical. This paper explores the integration of Large Language Models (LLMs), such as ChatGPT and Bard, into code review workflows to enhance software quality and security. By leveraging the natural language processing capabilities of LLMs, we aim to streamline the identification of code issues, detect potential security vulnerabilities, and provide developers with actionable feedback. Through a comprehensive analysis of current literature, case studies, and experimental data, this study evaluates the impact of AI-assisted code reviews on developer productivity and code quality. We also address the challenges and limitations of relying on LLMs, including context comprehension and potential biases. Our findings suggest that while LLMs offer significant advantages in automating and improving code reviews, they should complement rather than replace human expertise. This paper provides insights into best practices for integrating LLMs into development workflows, ultimately contributing to more robust and secure software systems.",Yes,"논문 초록에서 실험 데이터와 사례 연구를 통해 AI 도구의 영향을 평가했다고 명시되어 있어, 정량적 평가가 수행되었음을 알 수 있습니다. 이러한 분석은 정량적 방법을 활용한 평가를 포함하는 것으로 보입니다."
Deep Learning -Based Algorithm for MRI Lumbar Vertebrae Instance Segmentation,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10329828,"Magnetic resonance (MR) morphometric analysis of the spine plays crucial role in clinical practice for diagnosis various anomalies, including osteoporosis, age-related degenerative changes, etc. However, the current approach to MR morphometry relies on manual measurements by radiologists, which is a time-consuming process. Therefore, automating morphometric analysis is important to speed up the measurements and reduce the workload on radiologists. In order to achieve this, automated segmentation of the vertebrae can be implemented. This work proposes a deep learning (DL)-based algorithm for segmenting lumbar vertebrae in magnetic resonance (MR) images. The algorithm utilizes the Mask-RCNN deep convolutional neural network, which is a cutting-edge tool for multiple objects (instance) segmentation. The network was trained and evaluated on a dataset of MR images, consisting of 200 subjects (100 control and 100 patients with at least one deformed vertebrae). These images were carefully labelled. The trained Mask-RCNN model demonstrated exceptional segmentation performance on the test dataset. The median Dice similarity coefficient, a widely used metric for evaluating segmentation accuracy, was 0.95 for patients and 0.96 for controls. The results can be utilized to automate the assessment of lumbar vertebrae deformities, including the identification of deformity type (wedge-shaped or biconcave, etc.), as well as the determination of deformity grade.",Yes,논문 초록에서 딥러닝 알고리즘의 성능 평가를 위해 Dice 유사도 계수와 같은 정량적 지표를 사용하여 평가했다고 명시되어 있습니다. 이는 정량적 평가를 실시했음을 보여주는 명확한 증거입니다.
A Survey on RealSense: in context of Research and Application,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9225558,"RealSense technology is such a technology which is implemented for machines and device for measuring the capabilities of those apparatus. The capabilities are related to the perceptions of those machines and devices. This technology mainly learns a machine to understand the world with cogitation. RealSense technology introduces cameras to explore the environment with ins and out as it is parallel working with high definition cameras. This technology is used in many categories. Object detection, facial expression detection, shape measurement, image processing, and so on. Among all of the types, RealSense technology is used in huge amount for object detection. In this category real sense mainly focus on the object which is vitally important for understanding the full scene, and understanding the other aspect of the scene with which the object can be classify for better understanding. This paper mainly provides an overview of RealSense technique to the modern technology with its 3D visual functionalities adding the developed application which is published based on Microsoft Kinet and also with SR300 technology. Also this work can give a clear overview to the researchers about the fact that which domain of research is easier with this RealSense technology and in which domain they get more accuracy.",No,"초록에서는 RealSense 기술의 개요와 응용 분야에 대해 설명하고 있지만, 구체적인 정량적 평가 방법이나 실험 결과에 대한 언급은 포함되어 있지 않습니다. 따라서 논문이 정량적 평가를 실시하고 있다고 보기 어렵습니다."
Ensemble Similarity Measures for Clustering Terms,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5171010,"Clustering semantically related terms is crucial for many applications such as document categorization, and word sense disambiguation. However, automatically identifying semantically similar terms is challenging. We present a novel approach for automatically determining the degree of relatedness between terms to facilitate their subsequent clustering. Using the analogy of ensemble classifiers in machine learning, we combine multiple techniques like contextual similarity and semantic relatedness to boost the accuracy of our computations. A new method, based on Yarowskypsilas word sense disambiguation approach, to generate high-quality topic signatures for contextual similarity computations, is presented. A technique to measure semantic relatedness between multi-word terms, based on the work of Hirst and St. Onge is also proposed. Experimental evaluation reveals that our method outperforms similar related works. We also investigate the effects of assigning different importance levels to the different similarity measures based on the corpus characteristics.",No,"논문 초록에서는 여러 유사성 측정 기법들을 결합하여 용어 간 관련성 정도를 자동으로 결정하는 방법을 제시하고 있지만, 구체적인 정량적 평가 방법이나 실험을 통한 수치적 성과 측정에 대한 언급은 없습니다. 따라서, 정량적 평가를 실시했다고 보기 어렵습니다."
"Evaluation of PSE, STFT and probability coefficients for classifying two directions from EEG using radial basis function",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7435664,"EEG (Electroencephalography) is a recording of electrical activities of brain measured from scalp. Brain is a control center for almost all functions of body. As EEG originates from brain, it contains various components related to cognitive activities of brain. Hence, it also contains information regarding the motor functions associated with movement of the body. EEG is commonly recorded for purposes of diagnosis and research associated with diseases like epilepsy, seizures, sleep disorders etc. But apart from these applications it can also be used to map various motor movements being thought of. This may lead to development of landmark devices in the field of rehabilitation of physically challenged individuals. Here we intend to extract the features and classify the directions using EEG. At initial stage it is desired to classify two movements i.e. left and right, but the method can be extended for the classification of other directions as well. In present scenario the most suitable methods for classification problems can be developed using machine learning algorithms. In this work the features like probability co efficient, PSE (power spectral entropy) and STFT (Short Time Fourier Transform) are extracted and evaluated for their efficiency in classification. Radial Basis Function is used for classifying these features. The study shows probability co efficient and STFT have yielded about 60% accuracy in classifying raw EEG signals proving them advantageous over power spectral entropy.",Yes,"논문 초록에서 PSE, STFT, 확률 계수와 같은 특징들을 추출하고 이들의 분류 성능을 평가했다고 명시되어 있습니다. 또한, Radial Basis Function을 이용한 분류 결과의 정확도를 제시하며 정량적 평가가 수행되었음을 보여줍니다."
Research on factors analysis model of dualistic soil salinization sensitivity in typical northwestern arid area,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4423510,"Soil secondary salinization is one of the typical ecological side effects caused by land and water resources development in northwestern arid China. Factors that affect the occurrences and developments of salinization come from both natural conditions and human activities. Research on the mechanisms of salinization, build dynamic prediction model of salt accumulation and analyze sensitivities to different factors would supply effective references to the prediction and prevention of soil salinization. It is well known that related factors are always intertexture together, affecting each other, which result in multivariable, nonlinear and overall influences that work on the process of soil salinization. Artificial intelligence technologies may play important role in this domain. In this paper, genetic artificial neural network based model is built to simulate and evaluate soil salt accumulation and sensitivity of soil salinization. Example is taken from the Shule River watershed, typical arid area in northwestern China. Basic data of June 2000 are prepared depending on GIS and Remote Sensing. Precipitations, evaporations, groundwater levels, groundwater chemical analysis data and soil accumulation data are achieved and interpolated in the research area. Slope of the land are derived from DEM, MODIS images are used in the process of dealing with land use information. At the same time, landform and soil type are considered in model building. Soil salt accumulation is analyzed with its 8 influenced factors with verified models. Results showing that groundwater TDS is the most sensitive factor followed by groundwater level, evaporation and the depth of upper bed of clay. In most cases clay layers play key roles in soil salt accumulation, precipitation and slop have similar sensitivities. Results would have better research and application value in arid areas of northwestern China.",Yes,"논문은 토양 염분 축적과 민감도 평가를 위해 인공신경망 기반 모델을 구축하고 있으며, 이를 통해 정량적 평가를 수행하고 있음을 보여줍니다. 또한, 다양한 환경 변수와 데이터를 활용하여 모델의 성능을 검증하는 과정이 포함되어 있어 정량적 평가가 실시되고 있음을 알 수 있습니다."
A Deep Learning-based Approach for an Automated Vulnerability Detection in Source Code,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10385129,"With the advancements and significant increase in today’s software projects, software vulnerabilities have become a crucial and serious concern to the software industry. These software defects pose familiar cybersecurity threats and identifying potential vulnerable code is difficult because of various elements related to volume, diversity, and complexity. Traditionally, vulnerabilities in source code have been detected either statically by relying on expert knowledge, which is time consuming, or through dynamic analysis tools. However, lacking robust investigation of source code resulted in decreased efficacy of the existing solutions. In this respect, as an alternative to traditional source code detection methods, deep learning seems to have become an attractive solution. Thus, in this research work, we propose a deep learning-based neural networks approach to construct a function-level vulnerability analysis for an automated identification of vulnerabilities in source code. The proposed solution can handle source code vulnerability detection on function level without expert knowledge by utilizing deep learning convolutional neural networks (CNNs) and artificial neural networks (ANNs). To generate meaningful numerical feature representation of input source code functions, we have generated abstract syntax tree (AST). Moreover, we enhanced the deep learning neural network models through the selection of optimal parameter values and employing a validation methodology. To evaluate the performance of the proposed models we used a public dataset with verified vulnerability labels using various performance metrics such as Precision, Accuracy, F1-score, Recall and ROC-AUC. After conducting multiple experiments, the best result (Accuracy = 84.22%) was achieved using our ANN model.",Yes,"논문 초록에서 다양한 성능 지표(Precision, Accuracy, F1-score, Recall, ROC-AUC)를 사용하여 모델의 성능을 정량적으로 평가했다고 명시되어 있습니다. 이는 정량적 평가를 실시하고 있음을 보여줍니다."
LETS: A Label-Efficient Training Scheme for Aspect-Based Sentiment Analysis by Using a Pre-Trained Language Model,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9503416,"Recently proposed pre-trained language models can be easily fine-tuned to a wide range of downstream tasks. However, a large-scale labelled task-specific dataset is required for fine-tuning creating a bottleneck in the development process of machine learning applications. To foster a fast development by reducing manual labelling efforts, we propose a Label-Efficient Training Scheme (LETS). The proposed LETS consists of three elements: (i) task-specific pre-training to exploit unlabelled task-specific corpus data, (ii) label augmentation to maximise the utility of labelled data, and (iii) active learning to label data strategically. In this paper, we apply LETS to a novel aspect-based sentiment analysis (ABSA) use-case for analysing the reviews of the health-related program supporting people to improve their sleep quality. We validate the proposed LETS on a custom health-related program-reviews dataset and another ABSA benchmark dataset. Experimental results show that the LETS can reduce manual labelling efforts 2-3 times compared to labelling with random sampling on both datasets. The LETS also outperforms other state-of-the-art active learning methods. Furthermore, the experimental results show that LETS can contribute to better generalisability with both datasets compared to other methods thanks to the task-specific pre-training and the proposed label augmentation. We expect this work could contribute to the natural language processing (NLP) domain by addressing the issue of the high cost of manually labelling data. Also, our work could contribute to the healthcare domain by introducing a new potential application of NLP techniques.",Yes,"논문 초록에서 실험 결과를 통해 제안된 방법이 성능 향상과 효율성을 평가하는 정량적 평가를 실시했음을 명확히 언급하고 있습니다. 특히, manual labeling efforts의 감소와 다른 방법과의 비교를 통해 수치적 성과를 제시하고 있어 정량적 평가가 수행된 것으로 판단됩니다."
Wearable PPG sensor based alertness scoring system,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8037345,"Quantifying mental alertness in today's world is important as it enables the person to adopt lifestyle changes for better work efficiency. Miniaturized sensors in wearable devices have facilitated detection/monitoring of mental alertness. Photoplethysmography (PPG) sensors through Heart Rate Variability (HRV) offer one such opportunity by providing information about one's daily alertness levels without requiring any manual interference from the user. In this paper, a smartwatch based alertness estimation system is proposed. Data collected from PPG sensor of smartwatch is processed and fed to machine learning based model to get a continuous alertness score. Utility functions are designed based on statistical analysis to give a quality score on different stages of alertness such as awake, long sleep and short duration power nap. An intelligent data collection approach is proposed in collaboration with the motion sensor in the smartwatch to reduce battery drainage. Overall, our proposed wearable based system provides a detailed analysis of alertness over a period in a systematic and optimized manner. We were able to achieve an accuracy of 80.1% for sleep/awake classification along with alertness score. This opens up the possibility for quantifying alertness levels using a single PPG sensor for better management of health related activities including sleep.",Yes,"논문은 PPG 센서 데이터를 이용하여 연속적인 각성 점수를 제공하는 시스템을 제안하며, 그 성능 평가로 80.1%의 정확도를 보고하고 있다. 이는 정량적 평가를 실시하고 있음을 보여주는 명확한 증거이다."
Health and Environment Monitoring System for Viral Respiratory Diseases,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10306600,"The proposed system in this work is a contactless health and environment monitoring system designed after conducting a literature review on the most recent research on viral respiratory diseases and their impact on businesses, risk factors of a location, and surveillance of people for various safety measures and causes leading to its spread. The proposed system takes the form of an Android Mobile Application, designed to function as a safety entry checkpoint for various organizations, including businesses and educational institutions. It aims to detect viral respiratory diseases by leveraging the capabilities of a smartphone camera without requiring any additional external hardware specifications. Furthermore, the system incorporates users’ vaccination information, enabling a comprehensive assessment of health and safety. The key algorithms presented in this work focus on measuring critical body vital signs, including heart rate, temperature, and oxygen saturation (Oxygen saturation (SpO2)) levels. By utilizing advanced techniques such as mask detection and social distance monitoring, the system ensures the recognition of disease indicators and triggers appropriate actions to minimize the risk of transmission. To assess the safety of an area or environment, the proposed system employs the Euclidean distance metric and MobileNetV2, a state-of-the-art deep learning model. This combination enables real-time evaluation and analysis of the surroundings, providing crucial information for making informed decisions regarding the level of safety in a given location.",Yes,논문 초록에서 핵심 알고리즘과 시스템 성능 평가를 위해 유클리드 거리와 MobileNetV2 모델을 활용하여 실시간 평가를 수행한다고 언급되어 있습니다. 이는 정량적 평가가 이루어지고 있음을 시사합니다.
A Comparative Approach to Threshold Optimization for Classifying Imbalanced Data,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10061736,"For the practical application of a classifier, it is necessary to select an optimal output probability threshold to obtain the best classification results. There are many criteria one may employ to select a threshold. However, selecting a threshold will often involve trading off performance in terms of one metric for performance in terms of another metric. In our literature review of studies involving selecting thresholds to optimize classification of imbalanced data, we find there is an opportunity to expand on previous work for an in-depth study of threshold selection. Our contribution is to present a systematic method for selecting the best threshold value for a given classification task and its desired performance constraints. Just as a machine learning algorithm is optimized on some training data set, we demonstrate how a user-defined set of performance metrics can be utilized to optimize the classification threshold. In this study we use four popular metrics to optimize thresholds: precision, Matthews’ Correlation Coefficient, f-measure and geometric mean of true positive rate, and true negative rate. Moreover, we compare classification results for thresholds optimized for these metrics with the commonly used default threshold of 0.5, and the prior probability of the positive class (also known as the minority to majority class ratio). Our results show that other thresholds handily outperform the default threshold of 0.5. Moreover, we show that the positive class prior probability is a good benchmark for finding classification thresholds that perform well in terms of multiple metrics.",Yes,"논문 초록에서 네 가지 성능 지표(precision, Matthews’ Correlation Coefficient, f-measure, geometric mean)를 사용하여 임계값을 최적화하는 정량적 평가 방법을 제시하고 있음을 명확히 언급하고 있습니다. 또한, 다양한 임계값에 대한 성능 비교를 통해 정량적 평가를 수행하는 과정을 포함하고 있습니다."
GREAT- IQA: Integrating Global Perception and Local Task-Specific Information for CT Image Quality Assessment,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10403138,"Image quality assessment (IQA) is a crucial step for computed tomography (CT) system design and scanning protocol optimization. The lack of high-quality/high-dose and low-quality/low-dose CT image pairs makes only the no-reference IQA (NR-IQA) method available for clinical practice. Recently, deep learning (DL) techniques have been proven effective for CT IQA. However, applying DL-based methods to CT IQA faces two major challenges: 1) labels are noisy due to inter-observer variability and 2) IQA results fail to reflect the task-specific performance of CT images perfectly. In this work, we presented a novel NR-IQA model to integrate Global peRcEption and locAl Task-specific information for CT images, termed GREAT-IQA. First, we used a convolutional neural network to learn global perception-related features from training data, which leverages two objective IQA metrics, i.e. peak signal-to-noise ratio and structural similarity index, to reduce the inter-observer variability. Second, to more precisely quantify the task-specific performance of CT images, we considered two local diagnosis-related features of the chest and abdominal CT images: low-contrast detectability and edge sharpness, where contrast-to-noise ratio and maximum gradient and variability of gradients are used to measure them separately. Finally, the overall image quality is predicted by combining the global image assessment and local region of interest assessment components. By conducting experiments on a total of 1,600 degraded chest and abdominal CT images, reconstructed retrospectively with different doses and kernels, and evaluated with three experienced experts, this paper shows the proposed method outperforms the competing IQA methods, especially full-reference IQA methods.",Yes,"논문은 딥러닝 기반의 정량적 평가 방법을 제안하며, peak signal-to-noise ratio와 structural similarity index와 같은 객관적 지표를 활용하여 이미지 품질을 평가하고 있습니다. 또한, 실험을 통해 다양한 지표와 평가 방법을 정량적으로 비교하고 있어 정량적 평가를 실시하고 있음을 알 수 있습니다."
Fake Currency Detection using Image Processing,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10392045,"Advancements in color printing have led to a rise in the number of counterfeit currency notes being created and duplicated on a massive scale. In the past, it was very difficult to do this, but now anyone with a laser printer can easily do it. Due to the rise of fake notes, the number of counterfeit currency notes has increased significantly in India. This is a major issue that the country is facing due to its various problems such as black money and corruption. A system that can detect the fake currency notes in a fraction of the time is being developed. The proposed system will use image processing techniques to verify the authenticity of Indian currency notes. This method will involve extracting various features from the notes. Some of these include the Bleed Line, Water marking, Fluorescence, Security thread, Micro Lettering, and Identification mark. The proposed system is using software known as MATLAB. The Support vector machine is a supervised learning model that is used for extracting the notes' features. It is also used for analyzing data related to regression and classification. We have also tested the other methods related to this proposed work, such as the graphical black Box algorithm. The proposed system has various advantages, such as its high-performance speed and simplicity. It will be able to determine if the currency notes are real or fake. Its accuracy is also measured using the Confusion Matrix.",Yes,"논문 초록에서 ""Its accuracy is also measured using the Confusion Matrix""라는 문구를 통해 정량적 평가가 수행되고 있음을 알 수 있습니다. 또한, 다양한 검증 방법과 성능 평가 지표를 활용하여 시스템의 성능을 평가하는 것으로 보입니다."
Reliability analysis on case-study traffic sign convolutional neural network on APSoC,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8347234,"Deep learning has been widely used to solve computer vision applications such as autonomous cars and Advanced Driver Assistance Systems (ADAS). One of these computer vision applications is traffic sign recognition that plays an essential role in autonomous cars and ADAS. All-Programmable System-on-Chip (APSoC) is an excellent target platform for implementing ADAS applications due to its flexibility. However, as its Programmable Logic (PL) is implemented with SRAM cells and traffic sign recognition is a safety critical application, the reliability under radiation must be analyzed and hardening or mitigation techniques may be required. Thus, random and piled-up fault injections in the APSoC configuration bits were carried out as well as neutron-radiation experiments in order to evaluate the reliability of a Convolutional Neural Network (CNN). Comparison with related work shows that timing-multiplexing neural network architectures present an insignificantly higher Architecture Vulnerability Factor (AVF) than parallel pipelined architectures.",Yes,"논문 초록에서 신뢰성 분석을 위해 무작위 및 적재적소 결함 주입, 중성자 방사선 실험 등 다양한 정량적 평가 방법이 수행되었음을 언급하고 있습니다. 이러한 실험들은 CNN의 신뢰성을 수치적으로 평가하는 데 초점을 맞추고 있어 정량적 평가를 실시하고 있다고 볼 수 있습니다."
Extracting Keywords From Text Using NLP On Azure Virtual Machine,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10396295,"NLP methods (Natural Language Processing) are used in this project to approach fetching the all keywords by written content and are deployed on an Azure Virtual Machine (VM). Both texts summarization and information retrieval, keyword extraction is essential. The project seeks to create an accurate and efficient method for identifying and retrieving keywords from several sources text sources by leveraging the plus point of NLP libraries and tools. By utilizing Azure VM's scalability and computational power, the project provides reliable processing of significant amounts of text data. The project's conclusion provides a useful tool for improving document categorization, subject analysis, and content summarization, with the added benefit of utilizing cloud resources for top performance. As a way to determine distinctions between every single viewpoint of the individual by algorithms, we have considered numerous factors models and their implementation in this work. We initially learned how to convert PDF files to text before learning how to get keywords out of documents using a variety of algorithms, including RAKE YAKE TFIDF and modifying them in a way that ensures we receive the best-extracted keywords that relate to the document and aid in comprehending it. In the end, we evaluated various methods using mined keywords. Additionally, it gave us the ability to judge which algorithm was the most effective overall. Given the actual facts, we could make an educated judgment as to which method produces the best keywords.",Yes,"논문 초록에서 여러 알고리즘을 사용하여 키워드 추출 방법을 평가하고, 그 성능을 비교하는 과정을 언급하고 있습니다. 이는 정량적 평가를 실시했음을 시사하며, 다양한 방법의 효과를 수치적으로 분석했을 가능성이 높습니다."
An ANFIS Based Derivations of Inference Rules for Users’ Adoptions of Autonomous Vehicles,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9297811,"Autonomous Vehicles (AVs) have great potential and can improve transportation efficiency and safety through minimal manual intervention and optimized traffic control systems. Advances in artificial intelligence and real-time data processing technology have promoted the development of practical AVs. AV manufacturers are trying to understand the potential factors that may affect consumers' acceptance of autonomous vehicles. However, there is very little research on autonomous vehicles and consumers. In order to understand these factors, this research will use UTAUT 2, as a research framework to predict consumer intentions and behaviors. This research will first review the literature, invite experts to define and evaluate appropriate criteria and dimensions, and use the ANFIS is used to derive the decision rules, and the weights of the corresponding rules are compared. The resulting analysis can be used as a basis for predicting consumer acceptance of AVs in the future.",Yes,"논문 초록에서 ANFIS를 사용하여 의사결정 규칙을 도출하고, 규칙의 가중치를 비교하는 과정을 언급하고 있어 정량적 평가가 실시되고 있음을 알 수 있습니다. 이러한 방법은 데이터 기반의 수치적 분석과 평가를 포함하는 것으로 보입니다."
Instance Segmentation of Neuronal Nuclei Leveraging Domain Adaptation,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9622821,"The detection and localization of individual cell nuclei in dense neural scenes collected by microscopy traditionally depends on human-expert-intensive manual markup for training and evaluating automatic algorithms. These approaches are expensive, time-intensive, and require domain expertise. To develop automatic approaches, the annotated content needs to match the collection conditions (e.g. stain, cell-type) and small changes to these conditions often requires additional matching annotated content. Our approach leverages supervised domain adaptation approach with application to the instance segmentation of nuclei in the brain. The efficacy of this approach is demonstrated experimentally by characterizing the performance of adapting models learned on content not well matched to the target domain. Quantitative results demonstrate performance improvements relative to previous related work. High Performance Computing (HPC) applications of this technology include Human-in-the-Loop (HIL) retraining leveraging active learning or similar machine learning approaches.",Yes,"초록에서 ""Quantitative results demonstrate performance improvements""라는 문구를 통해 정량적 평가가 수행되었음을 명확히 언급하고 있습니다. 이는 실험을 통해 성능을 수치로 평가하고 있음을 의미합니다."
Deciphering Key Genes in Colon Cancer Through Deep Learning Techniques,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10670845,"Identification and prognostication of colon cancer hold pivotal significance for biomedical research studies. Cancer is a genetically related disease in which defective genes are prone to making changes in expression. So, detecting colon cancer at an early stage can contribute to increasing patient survival rates. In recent years, computer-aided diagnosis systems utilizing Deep Learning techniques have emerged for the accurate diagnosis of colon cancer in the healthcare sector. In this methodology, microarray analysis is utilized to reveal the characteristics of normal and diseased genes. In the research work, high-dimensional microarray colon cancer data are utilized to detect the cancer disease. The primary function of the research work is to develop a model using Deep Learning techniques to identify key genes associated with colon cancer and predict the disease. An unsupervised Autoassociator Dimensionality Reduction Technique (ADRT), is applied to identify significant biomarker genes while filtering out redundant and noisy genes present in the gene data. To predict colon cancer, Deep Neural Network classifier is utilized on the selected genes and the classifier’s performance is calculated using evaluation metrics. Finally, comparative analyses are performed before and after applying the dimensionality reduction technique. The experimental outcomes demonstrate that the research model after applying ADRT, significantly improves the detection analysis in terms of minimizing the dimensionality of the gene data and increasing the accuracy value. Moreover, the research model can be smoothly integrated into medical healthcare systems, facilitating the precise diagnosis of Colon cancer.",Yes,"논문은 Deep Learning 기법을 활용하여 모델을 개발하고, 그 성능을 평가하기 위해 평가 지표를 사용하여 정량적 평가를 실시하고 있음을 명확히 언급하고 있습니다. 따라서, 정량적 평가를 수행하는 것으로 판단됩니다."
Empirical Analysis of Sentence Embedding Techniques for Answer Retrieval in Marathi Question Answering,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9987436,"It is vital that any type of text can be portrayed in a machine-readable language so that it can be processed and interpreted. Text embeddings, which allow a machine to interpret any type of text by mathematically expressing it, naturally minimise this work. To extract the concept of interdependence across words or sentences, the degree of connection, synonym recognition, idea segmentation, selectional preferences, and analogies, text embedding are very useful. Using closest neighbor lookup of vectors, a vector representation of a text in a semantic vector space may be utilized for answer retrieval according to the vectors’ similarity and proximity. Traditional QA systems require a huge number of high-quality language-specific resources to perform multiple activities. The precision of several embedding techniques presently supporting Marathi, an Indo-Aryan language, is explored in this research. The performance of several sentence embedding algorithms is evaluated to select the most relevant and related answer text within the corpus given a natural language query in Marathi. Pragmatic tests are performed across supervised machine learning models to perform categorization and sentence embeddings in order to evaluate and compare the veracity of various embedding techniques. The proposed research findings concentrate on identifying the most effective embedding approaches from the restricted resources available for the Marathi language, laying the groundwork for future study in this language.",Yes,"초록에서 여러 문장 임베딩 알고리즘의 성능을 평가하는 실험이 언급되어 있으며, 이를 통해 정량적 평가가 수행되고 있음을 알 수 있습니다. 또한, 다양한 임베딩 기법의 유효성을 비교하는 실험적 분석이 포함되어 있어 정량적 평가의 실시를 확인할 수 있습니다."
Smart Career Guidance System,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9676408,"We have developed a career guidance system that helps those students who are about to begin their higher education. Most of the time, students are not aware of what career path to follow or which academic major is in accordance with their interests. The system analyzes students' skills, abilities, and interests and recommends the five fields which are most suitable for them. This project helps students identify a specific domain that fits their skills and interests. Smart Career Guidance System is a web-based application built on the Django framework. We have deployed various Machine Learning techniques and algorithms to mimic a one-on-one meeting with an experienced career counselor. The data was collected in the form of a questionnaire that was based on Holland Occupational Themes and the Theory of Multiple Intelligences. A total of 392 graduates completed this online survey. SMOTE oversampling is used to evaluate the machine learning classifiers since the data is highly imbalanced. We tested XGBoost and Random Forest classifiers for recommending the best-suited career options which furnish AUC-ROC performance scores of 0.9952 and 0.9963 respectively. A fine-tuned version of the Random Forest Classifier has successfully attained an AUC-ROC performance score of 0.9976 which indicates the minimal false-positive rate. Ms. Areej Kamal, Ms. Hadia Rafiq and Ms. Batul Naushad have collaboratively conducted all activities of the project including data collection and cleaning, literature review, testing of ML models and development of the final solution. Mr. Shahab Tahzeeb directed and supervised all phases of the project with his immense knowledge and expertise.",Yes,"논문 초록에서 머신러닝 기법을 활용하여 추천 시스템의 성능을 평가하는 과정이 언급되어 있으며, AUC-ROC 점수와 같은 정량적 지표를 사용하여 모델의 성능을 평가하고 있음을 보여줍니다. 이는 정량적 평가가 실시되고 있음을 의미합니다."
More Diverse Means Better: Multimodal Deep Learning Meets Remote-Sensing Imagery Classification,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9174822,"Classification and identification of the materials lying over or beneath the earth's surface have long been a fundamental but challenging research topic in geoscience and remote sensing (RS), and have garnered a growing concern owing to the recent advancements of deep learning techniques. Although deep networks have been successfully applied in single-modality-dominated classification tasks, yet their performance inevitably meets the bottleneck in complex scenes that need to be finely classified, due to the limitation of information diversity. In this work, we provide a baseline solution to the aforementioned difficulty by developing a general multimodal deep learning (MDL) framework. In particular, we also investigate a special case of multi-modality learning (MML)-cross-modality learning (CML) that exists widely in RS image classification applications. By focusing on “what,” “where,” and “how” to fuse, we show different fusion strategies as well as how to train deep networks and build the network architecture. Specifically, five fusion architectures are introduced and developed, further being unified in our MDL framework. More significantly, our framework is not only limited to pixel-wise classification tasks but also applicable to spatial information modeling with convolutional neural networks (CNNs). To validate the effectiveness and superiority of the MDL framework, extensive experiments related to the settings of MML and CML are conducted on two different multimodal RS data sets. Furthermore, the codes and data sets will be available at https://github.com/danfenghong/IEEE_TGRS_MDL-RS, contributing to the RS community.",Yes,"논문 초록에서 다양한 실험이 수행되었음을 언급하며, ""extensive experiments""라는 표현으로 정량적 평가가 이루어졌음을 시사합니다. 또한, 프레임워크의 효과와 우수성을 검증하기 위해 여러 실험이 진행된 것으로 보입니다."
Short term power load forecasting using Deep Neural Networks,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7876196,"Accurate load forecasting greatly influences the planning processes undertaken in operation centres of energy providers that relate to the actual electricity generation, distribution, system maintenance as well as electricity pricing. This paper exploits the applicability of and compares the performance of the Feed-forward Deep Neural Network (FF-DNN) and Recurrent Deep Neural Network (R-DNN) models on the basis of accuracy and computational performance in the context of time-wise short term forecast of electricity load. The herein proposed method is evaluated over real datasets gathered in a period of 4 years and provides forecasts on the basis of days and weeks ahead. The contribution behind this work lies with the utilisation of a time-frequency (TF) feature selection procedure from the actual “raw” dataset that aids the regression procedure initiated by the aforementioned DNNs. We show that the introduced scheme may adequately learn hidden patterns and accurately determine the short-term load consumption forecast by utilising a range of heterogeneous sources of input that relate not necessarily with the measurement of load itself but also with other parameters such as the effects of weather, time, holidays, lagged electricity load and its distribution over the period. Overall, our generated outcomes reveal that the synergistic use of TF feature analysis with DNNs enables to obtain higher accuracy by capturing dominant factors that affect electricity consumption patterns and can surely contribute significantly in next generation power systems and the recently introduced SmartGrid.",Yes,논문 초록에서 모델의 성능을 평가하기 위해 정확도와 계산 성능을 비교하는 실험이 수행되었음을 언급하고 있습니다. 이는 정량적 평가가 이루어지고 있음을 보여줍니다.
Cyber-Crime Detection: Experimental Techniques Comparison Analysis,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10033332,"Cyber-crime is one of the main problems the world face, and machine learning plays a key part in contemporary operating systems for giving better transformation in the security environment and cybercrime detection. While detecting cybercrimes is difficult, it is possible to gain advantages from machine learning to generate models to assist in predicting and detecting cybercrimes. The researchers have proven that the majority of the models can work effectively in identifying cybercrime, they can span from 70% to 90% in accuracy measuring. The objective of this research paper is to conduct experimental techniques comparison analysis for cyber-crime detection by reviewing all possible machine learning algorithms for automatic detection. The key focus of the study is on the use of eight classifiers models which are Logistic Regression (LR), Decision Tree (DT), K-nearest Neighbors (KNN), Support Vector Machine (SVM), Naive Bayes (NB), Random Forest (RF), eXtreme Gradient Boosting (XGBoost) and Multiple layer perception (MLP). From the experiment conducted, the high prediction came from MLP which is 96% accuracy of the cyber-crime methods based on existing cyber-crime data.",Yes,"논문 초록에서 여러 머신러닝 모델의 정확도를 측정하여 평가한 결과를 제시하고 있으며, 특히 각 모델의 성능을 수치로 나타내어 정량적 평가를 실시했음을 보여줍니다. 따라서, 이 논문은 정량적 평가를 수행하고 있다고 판단됩니다."
Designing an Empathy Training for Depression Prevention Using Virtual Reality and a Preliminary Study,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10108699,"As virtual reality (VR) is labeled by many as “an ultimate empathy machine,” immersive VR applications have the potential to assist in empathy training for mental healthcare such as depression [21]. In responding to the increasing numbers of diagnosed depression throughout COVID-19, a first-person VR adventure game called “Schwer” was designed and prototyped by the authors' research team to provide a social support environment for depression treatment. To continue the study and assess the training effectiveness for an appropriate level of empathy, this current article includes a brief survey on data analytics models and features to accumulate evidence for the next phase of the study, an interactive game-level design for the “Reconstruction” stage, and a preliminary study with data collection. The preliminary study was conducted with a post-game interview to evaluate the design of the levels and their effectiveness in empathy training. Results showed that the game was rated as immersive by all participants. Feedback on the avatar design indicated that two out of three of the non-player characters (NPCs) have made the intended effect. Participants showed mostly positive opinion towards their experienced empathy and provided feedback on innovative teleport mechanism and game interaction. The findings from the literature review and the results of the preliminary study will be used to further improve the existing system and add the data analytics model training. The long-term research goal is to contribute to the healthcare field by developing a dynamic AI-based biofeedback immersive VR system in assisting depression prevention.",No,"논문 초록에서는 데이터 분석 모델과 특징을 포함한 설계와 예비 연구를 언급하고 있지만, 구체적인 정량적 평가 방법이나 수치 데이터의 분석이 수행되었다는 명확한 언급은 없습니다. 따라서 정량적 평가를 실시했다고 보기 어렵습니다."
Optimization of Deep Neural Network Model for Embedded Applications: A Case Study of Retinal Vessels Segmentation,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10162079,"Medical science is an area where deep neural networks (DNNs) have been successfully applied for disease diagnosis based on image analysis. The accurate diagnosis of different eye diseases requires retinal vessels segmentation in retinal fundus image. The focus of this work is the improvement of innovative, lightweight deep learning (DL) models that can be used on embedded systems (ESs) for eye diseases diagnosis in the early stage at the point of care in clinics and general hospitals. This work aims to optimize the encoder-decoder-based architecture to show the possibility of porting a DL model onto ESs but without compromising on segmentation performance. The performance was evaluated based on open-source retinal image databases: DRIVE, and CHASE_DB1. The proposed model achieved encouraging evaluation metrics in addition to attributing a significantly lower number of parameters. Moreover, the proposed model outperformed the previous related works while its computational complexity is much lower.",Yes,"논문 초록에서 성능 평가를 위해 공개된 망막 이미지 데이터베이스를 활용하여 평가 지표를 제시하고 있으며, 모델의 성능과 효율성을 정량적으로 비교하는 평가를 실시한 것으로 보입니다. 따라서, 정량적 평가가 수행되고 있다고 판단됩니다."
A Novel Methodology for Improving Applications of Modern Predictive Modeling Techniques to Linked Data Sets Subject to Mismatch Error,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10486610,"In recent years, the rise of social media platforms such as Twitter/X has provided social scientists with a wealth of user-content data. Combining social media and survey data has the potential to produce a comprehensive source of information for social research. These data are often collected from multiple sources and combined by probabilistic record linkage. For the analysis of these linked data files, advanced machine learning techniques, such as random forests, boosting, and related ensemble methods, have become essential tools for survey methodologists and data scientists. There is, however, a potential pitfall in the widespread application of these techniques to linked data sets that needs more attention. Linkage errors such as mismatch and missed-match errors can distort the true relationships between variables and adversely alter the performance metrics routinely output by predictive modeling techniques, such as variable importance, confusion matrices, RMSE, etc. Thus, the actual predictive performance of these machine-learning techniques may not be realized. In this paper, we describe a methodology designed to adjust modern predictive modeling techniques for the presence of mismatch errors in linked data sets. The proposed approach, based on mixture modeling, is general enough to accommodate various predictive modeling techniques in a unified fashion. We evaluate the performance of our proposed methodology with simulations implemented in R. We conclude with recommendations for future work.",Yes,"논문 초록에서 제안된 방법론의 성능 평가를 위해 시뮬레이션을 통해 실험을 수행했다고 명시되어 있습니다. 또한, 다양한 예측 모델링 기법의 성능을 평가하는 내용이 포함되어 있어 정량적 평가가 실시되고 있음을 알 수 있습니다."
Multi-Sensory Stress Detection System,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10463214,"In the contemporary workplace, chronic stress is increasingly prevalent, bearing serious consequences such as health issues, workplace-related suicides, and fatalities. Addressing this urgent challenge, we present the “Multi-Sensory Stress Detection System,” a groundbreaking solution designed to proactively identify, analyze, and mitigate stress, thereby promoting a healthy work-life balance and preventing potential harm. Central to our strategy is the utilization of the WESAD (Wearable Stress and Affect Detection) dataset, capturing critical biological markers through wrist- and chest-worn (RespiBAN) devices. A robust preprocessing pipeline ensures data accuracy by transforming non-stationary data into a stationary format. We harness data-driven insights for stress detection using advanced Deep Learning Models, rigorously validated against existing research. The proposed CNN-based model achieves an accuracy of 98.73 %, underscoring the critical importance of precise stress detection in mitigating psychological impediments in an individual's life. This innovative technology carries significant implications for trauma recovery and workplace stress management, and it seamlessly integrates with the Internet of Things (IoT) to usher in a revolution in stress management in the contemporary environment. This innovation has broad applications in the healthcare industry, particularly for patients dealing with PTSD and autism.",Yes,논문 초록에서 CNN 기반 모델의 정확도(98.73%)와 같은 성능 지표를 제시하며 정량적 평가를 실시했음을 명확히 언급하고 있습니다. 이를 통해 연구의 성과를 수치로 평가하고 검증하는 정량적 평가가 수행된 것으로 판단됩니다.
Failure Modes or Not Failure Modes? Integrating Machine Learning in Aerospace Safety Assessment Processes,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10749313,"Although not yet a reality, recent developments have sparked interest in adopting machine learning (ML) across various aviation applications. Potential applications include control, health management, collision avoidance, and single pilot operations. However, integrating ML in aviation presents significant safety challenges due to its complex behavior compared to traditional software. This paper examines the impact of ML's uncertainty on aviation safety assessment processes, focusing on defining ML failure modes for learning-enabled components. Through a literature review and semantic analysis based on current aviation safety standards like ARP 4754A and its successor ARP 4754B, we identify ML-specific factors that contribute to failures of ML-enabled systems. Using a case study on multimodal visual navigation, this paper validates proposed failure modes and their contributions. Additionally, it demonstrates the application of traditional assessment methods to ML-enabled systems.",Yes,"논문 초록에서 ML의 실패 모드 정의와 검증을 위해 사례 연구를 수행하며, 전통적인 평가 방법을 ML 시스템에 적용하는 내용을 다루고 있어 정량적 평가를 실시하고 있음을 시사합니다. 따라서, 이 논문은 정량적 평가를 수행하는 것으로 판단됩니다."
Feedforward Neural Network Models for FPGA Routing Channel Width Estimation,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10855861,"Since interconnects play the increasingly important role in delay and area of the Fieldprogrammable gate array (FPGA) implementations, routing architecture design has become the focus of much work related to FPGA architecture development. This paper leverages feedforward neural networks to derive accurate models of the routing channel width in homogeneous FPGA architecture with two advanced intelligence learning techniques: Gradient-based learning algorithm (GLA) and Extreme learning machine (ELM). The resultant models can be used in the early stages of FPGA architecture development to facilitate fast design space exploration which is difficult to achieve in the traditional experiment-based method. The proposed models are evaluated by comparing the estimated channel widths to the real values generated from a CAD tool VTR over IWLS2005 benchmark circuits. Results show that the GLA model achieves the estimation accuracy 3.98% and the ELM model has the accuracy 3.91%, which show significant improvement over existing estimation approaches.",Yes,"논문 초록에서 모델의 성능을 평가하기 위해 추정된 채널 폭과 실제 값 간의 차이를 비교하는 정량적 평가를 실시했다고 명시되어 있습니다. 또한, 두 모델의 정확도 수치를 제시하여 평가 결과를 수치로 제시하고 있어 정량적 평가가 수행된 것으로 판단됩니다."
Learning Style Identification Using Semisupervised Self-Taught Labeling,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10415253,"Education is a dynamic field that must be adaptable to sudden changes and disruptions caused by events like pandemics, war, and natural disasters related to climate change. When these events occur, traditional classrooms with traditional or blended delivery can shift to fully online learning, which requires an efficient learning environment that meets students’ needs. While learning management systems support teachers’ productivity and creativity, they typically provide the same content to all learners in a course, ignoring their unique learning styles. To address this issue, we propose a semisupervised machine learning approach that detects students’ learning styles using a data mining technique. We use the commonly used Felder-Silverman learning style model and demonstrate that our semisupervised method can produce reliable classification models with few labeled data. We evaluate our approach on two different courses and achieve an accuracy of 88.83% and 77.35%, respectively. Our work shows that educational data mining and semisupervised machine learning techniques can identify different learning styles and create a personalized learning environment.",Yes,"논문 초록에서 학습 스타일 분류의 정확도를 제시하며, 정량적 평가를 통해 성능을 측정했음을 보여줍니다. 특히, 두 과정에서의 정확도 수치를 제공하여 정량적 평가가 실시되었음을 알 수 있습니다."
Joint Front–Edge–Cloud IoVT Analytics: Resource-Effective Design and Scheduling,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9817449,"A tremendous amount of visual data are bing collected by the Internet of Video Things (IoVT) systems in which ubiquitous cameras deployed in cities enable new applications in the domains of smart transportation and public security. However, the limited resources in terms of communication, computing, and caching (3C) in the conventional cellular network make it challenging to adopt centralized artificial intelligence (AI) to conduct real-time video-based data analytics. In this work, based on the 5G network architecture with edge servers, a three-phase resource-effective solution is proposed to perform surveillance operations in a large-scale wireless IoVT. The proposed strategy integrates front-end cameras with simple on-chip neural networks performing real-time object-of-interest segmentation, edge servers, and cloud servers with AI functionality carrying out image-based target recognition and video-based target analytics tasks. More importantly, we design the optimal 3C strategy to achieve the best video analytics performance constrained by computing offload ratio, network resource allocation and video-related parameters. Extensive simulations with deep neural networks implemented both at the front-end cameras and in the cloud server have validated the effectiveness of the proposed solution.",Yes,"논문 초록에서 제안된 방법이 정량적 평가를 위해 ""extensive simulations""을 수행했다고 명시되어 있으며, 딥 뉴럴 네트워크의 성능 검증과 최적 3C 전략의 효과 검증이 포함되어 있어 정량적 평가를 실시하고 있음을 알 수 있습니다."
Existing Tower Infrastructure Classification and Analysis for 5G Implementation in Jakarta Area Using Machine Learning Models,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10335369,"The Ministry of Communication and Informatics plans to construct infrastructure for fifth-generation network deployment in Indonesia. However, their readiness to support 5G systems should be evaluated. There is non-standalone architecture for 5G network related to the use of existing towers. The NSA architecture enables the use of towers that meet the 5G specification. Machine learning can be used to classify these towers quickly. Based on working frequency on the existing tower data, this research conduct tower classification using machine learning models to get the tower's quantity that are ready for the tower's non-standalone architecture and visualize the data on the open street map to evaluate the network needed in the area. The considered area for the tower data is Jakarta Area. The data shows 839 towers need to be upgraded to the fifth-generation frequency. The data also shows 1152 towers that are ready for the fifth-generation network. This result can benefit the operator in estimating the investment of the tower to be ready for the new technology and impact the CAPEX view to construct the new tower.",Yes,"논문 초록에서 머신러닝 모델을 사용하여 타워를 분류하는 과정을 언급하며, 이를 통해 정량적 평가를 수행하고 있음을 알 수 있습니다. 또한, 타워의 수와 준비 상태를 수치로 제시하여 정량적 분석이 이루어지고 있음을 보여줍니다."
DivGroup: A Diversified Approach to Divide Collection of Patterns into Uniform Groups,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8546203,"Similarity based grouping of patterns has been explored profusely under the well celebrated clustering paradigm in pattern recognition and machine learning. In clustering, objects in the same cluster are similar to each other and objects belonging to different clusters are dissimilar in a corresponding sense. However, it is not rare to come across situations where instead of a similarity based grouping, forming groups of diverse objects is needed. Resource allocation across different parts of an organization, performing cross-validation splits of dataset with class imbalance, heterogeneous or mixed ability partitioning of students, etc. are the applications of grouping which require each group to contain diverse set of patterns. Moreover, these applications also demand different groups to be similar to each other in some sense. In this work, we propose a generic framework for partitioning a collection of patterns into a set of groups such that the above two criteria are fulfilled. To the best of our knowledge, this is the first work to propose such a framework irrespective of any particular application. Towards this end, it turns out that finding an optimal solution to the problem that we developed is NP Hard. So we Propose an approximate solution for the same. We conduct experiments on both synthetic and real world datasets to evaluate the performance of the proposed algorithm. We show the merit of the algorithm by comparing the results with some related state-of-the-art baseline methods.",Yes,"논문 초록에서 제안된 알고리즘의 성능을 평가하기 위해 실험을 수행했다고 명시되어 있으며, 실험은 합성 데이터와 실제 데이터셋을 대상으로 진행되었다고 언급되어 있습니다. 이는 정량적 평가가 이루어졌음을 의미합니다."
eXplainable Reinforcement Learning Using Introspection in a Competitive Scenario,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10814839,"Reinforcement learning (RL) is inspired by behavioral psychology and helps solve problems where there is no previous data; that is, the agent learns through trial and error by interacting with the environment. Explainable RL aims to solve problems related to trust and transparency that people without technical knowledge might have about these systems. This work proposes a novel explainable reinforcement learning approach based on introspection in Deep Q-network and Proximal Policy Optimization algorithms. The integration of the introspection method empowers RL agents to assess the probability of success in a game, solely based on the Q-values obtained. In this regard, the agent will be able to measure how high the chance of winning for each available action during the game using the value function approximation’s output. Finally, the introspection-based agents could win several rounds during training, being more competitive than their opponents in different game moments. The computed probabilities of success, showed that although the agent was able to complete a reasonable number of games and generated strategies to win, the agent could not maintain a constant rhythm and learning process.",Yes,"논문 초록에서 RL 에이전트의 성공 확률을 평가하는 정량적 지표인 성공 확률을 계산하는 방법을 제시하고 있으며, 이를 통해 에이전트의 성능을 수치로 평가하고 있음을 알 수 있습니다. 따라서, 정량적 평가를 실시하고 있다고 판단됩니다."
Exploiting 2D Coordinates as Bayesian Priors for Deep Learning Defect Classification of SEM Images,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9453405,"Deep Learning approaches have revolutionized in the past decade the field of Computer Vision and, as a consequence, they are having a major impact in Industry 4.0 applications like automatic defect classification. Nevertheless, additional data, beside the image/video itself, is typically never exploited in a defect classification module: this aspect, given the abundance of data in data-intensive manufacturing environments (like semiconductor manufacturing) represents a missed opportunity. In this work we present a use case related to Scanning Electron Microscope (SEM) images where we exploit a Bayesian approach to improve defect classification. We validate our approach on a real-world case study and by employing modern Deep Learning architectures for classification.",Yes,"The abstract mentions that the authors validate their approach on a real-world case study and employ modern Deep Learning architectures for classification, which typically involves quantitative evaluation metrics to assess performance. This indicates that some form of quantitative assessment is conducted in the study."
Experimenting With an Efficient Driver Behavior Dynamical Model Applicable to Simulated Lane Changing Tasks,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10658638,"We test an approach to modelling the car driver behaviour during simulated lane changing tasks, aiming to obtain a sufficiently precise model in the simplest possible form, namely, with a small number of parameters. Various applications of such models are available in the literature. Based on a recent review of the research to date, the cybernetic single-loop transfer function models employing McRuer’s theory are applied. The purpose of the presented method is to evaluate the optimal structure of the transfer function via cross-validation as a technique known from machine learning. The experiments utilize a driving simulator with in-house developed software; this configuration facilitates acquiring the data at the desired sampling frequency and in a manner that ensures the repeatability of the test process scenarios. Using the crossvalidation results, we evaluate the second-order model with a derivative state and a reaction delay component as an optimal structure for approximating the measured data, which originated from a set of measurements on 92 active drivers. Even though more complex driving tasks could require high-order models, driver’s control action during our specific experiment is described through only four parameters. The parameters are jointly determined by the current driver’s mental state and the testing conditions defined in our scenario. Since the parameters are related to his/her dynamical behaviour, they allow easier mutual comparison of the drivers than complex models with many parameters. The results are verified via establishing a relationship to the multi-loop model presented in the recent literature. The larger dataset enables evaluating the confidence intervals of the drivers’ parameters which is inconvenient with 4 to 10 drivers commonly presented in the relevant sources.",Yes,"논문은 교차 검증(cross-validation)을 통해 모델의 구조를 평가하고, 실험 데이터를 이용하여 파라미터를 정량적으로 추정하는 과정을 포함하고 있습니다. 또한, 여러 운전자 데이터를 분석하여 신뢰 구간을 평가하는 등 정량적 평가를 수행하고 있음을 명확히 제시하고 있습니다."
Image Dehazing Assessment: A Real-World Dataset and a Haze Density-Aware Criteria,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10366874,"Full-reference image dehazing quality assessment (FR-IDQA) evaluates the visual quality of a dehazed image by measuring its differences with a clear reference. The existing FR-IDQA methods are not convincing due to the lack of well-aligned datasets of hazy and clear image pairs and the limited hand-crafted features make it difficult to simulate the complicated perception by the human visual system (HVS). In this work, we build a real-world image dataset, namely RW-Haze, which comprises natural hazy images and their well-aligned clear references. Each clear image is paired with several hazy images with diverse haze levels from slight to heavy. Meanwhile, the existing FR-IDQA works evaluate the dehazed image quality in a global manner, without considering local haze distributions in the original hazy image. Actually, the perceived haze in a natural hazy image is not uniformly distributed, and the haze density varies with scene depth. Based on this priori observation, we design a haze density-aware convolutional neural network (CNN), namely DehIQA, for FR-IDQA. It adopts transfer learning to alleviate the issue of lacking sufficient labeled data. Specifically, we divide image dehazing assessment into two tasks. The source task is to classify unpaired clear and hazy images, which enforces the deep network to learn haze-related features. The target task is image quality assessment, which is achieved by transferring the trained model for the source task to the target task. Considering the fact that the perceived distortion in a dehazed image is also not uniform, we present a haze density-aware mechanism into DehIQA, which assigns different weights for different local regions in a dehazed image in terms of the dark channel of the original hazy image. Extensive experimental results show that DehIQA outperforms the state-of-the-art (SOTA) works on the benchmark dataset and achieves better consistency with human perceptions.",Yes,"논문은 정량적 평가를 위해 딥러닝 기반의 평가 모델(DehIQA)을 설계하고, 이를 통해 이미지 dehazing 품질을 수치적으로 평가하는 방법을 제시하고 있습니다. 또한, 실험을 통해 기존 방법보다 우수한 성능을 보여주며, 정량적 평가의 구체적인 수행이 명확히 드러납니다."
Dual consistency loss for contour-aware segmentation in medical images,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10340931,"Medical image segmentation is a paramount task for several clinical applications, namely for the diagnosis of pathologies, for treatment planning, and for aiding image-guided surgeries. With the development of deep learning, Convolutional Neural Networks (CNN) have become the state-of-the-art for medical image segmentation. However, issues are still raised concerning the precise object boundary delineation, since traditional CNNs can produce non-smooth segmentations with boundary discontinuities. In this work, a U-shaped CNN architecture is proposed to generate both pixel-wise segmentation and probabilistic contour maps of the object to segment, in order to generate reliable segmentations at the object’s boundaries. Moreover, since the segmentation and contour maps must be inherently related to each other, a dual consistency loss that relates the two outputs of the network is proposed. Thus, the network is enforced to consistently learn the segmentation and contour delineation tasks during the training. The proposed method was applied and validated on a public dataset of cardiac 3D ultrasound images of the left ventricle. The results obtained showed the good performance of the method and its applicability for the cardiac dataset, showing its potential to be used in clinical practice for medical image segmentation.Clinical Relevance— The proposed network with dual consistency loss scheme can improve the performance of state-of-the-art CNNs for medical image segmentation, proving its value to be applied for computer-aided diagnosis.",Yes,"논문 초록에서 제안된 방법이 정량적 평가를 위해 실험을 수행했음을 시사하는 문구가 포함되어 있습니다. 특히, ""The results obtained showed the good performance of the method""라는 표현을 통해 성능 평가가 이루어졌음을 알 수 있습니다."
Work in Progress: Congestion Control in mmWave Fluctuating Scenarios in 5G-A/6G,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10811159,"The development of the next generation of cellular networks, 5G-Advanced and 6G (5G-A/6G), offers higher speeds, sub-millisecond latency, and providing wider coverage, which are key to meeting the requirements of new and demanding applications. As such, there are several challenges in managing and leveraging this opportunity to ensure that channel conditions do not impact the application due to mobility and obstructions. 5G introduces the use of millimeter wave (mmWave), and the commercial deployment of this technology brings to light the issues related to propagation and mobility in high-frequency bands, and their impact on applications has begun to be studied by exploring the response of the congestion control algorithms (CCAs) in representative scenarios. However, the highly variable channel conditions in mmWave require that they be defined as fluctuating bandwidth scenarios. It is necessary to determine how the transport layer can take advantage of the maximum available capacity and not affect the applications, and whether the network promises are fulfilled. This work aims to design and evaluate a CCA capable of efficiently adapting to the fluctuating bandwidth of extreme condition scenarios of 5G-A/6G mobile networks and to compare it with the state-of-the-art algorithms. As a first result, a set of simulation-based evaluation using 5GLENA was discussed. A combination of CCAs and different radio link control (RLC) buffer sizes allows us to highlight the importance of defining appropriate metrics and including convergence times as part of the evaluation performance of the algorithms. Algorithms such as HighSpeed and New Reno are among the slowest to converge, while BBR is the fastest. The analysis and characterization of the algorithms will allow us to define the requirements for designing an Machine Learning (ML) based algorithm with optimal performance and better convergence times.",Yes,"논문 초록에서 다양한 평가 지표와 시뮬레이션 기반 평가를 통해 알고리즘의 성능을 정량적으로 분석하고 있음을 명확히 언급하고 있습니다. 특히, 여러 알고리즘의 수렴 시간과 성능 비교를 통해 정량적 평가를 실시하고 있음을 알 수 있습니다."
Channel Selection Using Machine Learning,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10463321,"The channel plays an important role in any wireless communication system. If there exists only one channel between the transmitter and the receiver, if the link fails, then the communication cannot be established. The reliability of communication can be improved by introducing multiple communication channels. Not only the number of channels but also the type of channels being used has an impact on the system. Although there have been few works done in this direction, works related to long distances have not been given importance. Further, manual channel switching is the recommended choice, but manual switching is greatly impacted by the people involved in the mechanism and may not be accurate all the time. Keeping these in view, this paper proposes a channel selection mechanism based on Wi-Fi and LoRa (Long Range) technologies. The advantage is that this mechanism takes into account both radio technologies to choose the best channel for the given conditions. Further, machine learning-based techniques are introduced to learn the best channel to use based on historical data, which helps in achieving automatic channel selection. This will be particularly useful in dynamic environments, where the channel conditions can change frequently. To validate the proposed concept, various experiments are carried out and from the experimental results, it is observed that the KNN algorithm achieves good performance.",Yes,"논문 초록에서 머신러닝 기반 기법을 도입하여 최적의 채널을 선택하는 과정을 언급하고 있으며, 실험을 통해 성능을 검증했다고 명시되어 있습니다. 이는 정량적 평가가 수행되었음을 시사합니다."
A Comprehensive Cybersecurity Resilience Framework Augmenting Smart Grid Stability,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10744380,"Smart grids have emerged as intelligent systems comprising efficient sensor technology for effective power transmission and distribution. These critical modern infrastructures for energy distribution have been facing escalating cybersecurity threats. This research presents a novel cybersecurity framework for the mitigation and prevention of such attacks. The framework proposed involves a machine learning based defense mechanism that assists in enhancing the grid’s reliability even further against potential attacks. The research uses a computer simulated setting to evaluate cybersecurity attack scenarios and their effects, on grid operations and overall system security. This article provides a review of existing literature on the cybersecurity challenges that modern smart grids encounter along with the strategies used to counter these threats. The developed framework serves as a cybersecurity solution that employs mathematical methods to bolster grid stability and management identify anomalies and prevent potential cyber-attacks. The framework also leverages Machine Learning models to refine its operations and enhance its ability to identify risks effectively. The results indicate that this innovative approach surpasses methods in reducing cybersecurity risks of this nature. The effectiveness of the proposed cybersecurity model, in mitigating cyber threats within grids is further validated by its detection accuracy rate.",Yes,"논문은 머신러닝 기반 방어 메커니즘과 수학적 방법을 활용하여 사이버보안 위협을 평가하고 있으며, 그 효과를 검증하기 위해 시뮬레이션을 통한 정량적 평가를 실시하고 있습니다. 또한, 검증 결과의 정확도와 성능 향상에 대한 수치적 지표를 제시하여 정량적 평가가 이루어지고 있음을 보여줍니다."
Identifying IT Purchases Anomalies in the Brazilian Government Procurement System Using Deep Learning,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7838233,"The Department of Research and Strategic Information (DIE), from the Brazilian Office of the Comptroller General (CGU), is responsible for investigating potential problems related to federal expenditures. To pursue this goal, DIE regularly has to analyze large volumes of data to search for anomalies that can reveal suspicious activities. With the growing demand from the citizens for transparency and corruption prevention, DIE is constantly looking for new methods to automate these processes. In this work, we investigate IT purchases anomalies in the Federal Government Procurement System by using a deep learning algorithm to generate a predictive model. This model will be used to prioritize actions carried out by the office in its pursuit of problems related to this kind of purchases. The data mining process followed the CRISP-DM methodology and the modeling phase tested the parallel resources of the H2O tool. We evaluated the performance of twelve deep learning with auto-encoder models, each one generated under a different set of parameters, in order to find the best input data reconstruction model. The best model achieved a mean squared error (MSE) of 0.0012775 and was used to predict the anomalies over the test file samples.",Yes,논문 초록에서 여러 딥러닝 모델의 성능 평가를 위해 평균 제곱 오차(MSE)를 사용하여 정량적 평가를 실시했음을 명확히 언급하고 있습니다. 이는 모델의 예측 정확도를 수치로 측정하는 정량적 평가의 수행을 보여줍니다.
A Contactless Method for Measuring Unbalanced Loading of Utility Transformer,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8940787,"Three phase unbalancing remains a serious power quality issue in overhead power distribution lines. Variation of the load is a major contributor in unbalancing. This paper reports a contactless method with a minimum number of magnetic field sensors for measuring unbalance loading of the distribution network. The network is developed in Simulink based on parameters of a typical Pakistan distribution network. This paper also discusses about the orientation of magnetic field sensor so that the results are not affected by any field. The optimal location of sensors will help the system to differentiate between balanced and unbalanced loading. Sensor placement system was developed through MATLAB programming. Another contribution in this paper is the use of a pattern recognition technique instead of the current reconstruction algorithm commonly found in the literature review. With the help of pattern recognition based machine learning, the system is able to predict the unbalance loading of distribution lines.",Yes,"논문 초록에서 패턴 인식 기반 머신러닝을 활용하여 불평형 부하를 예측하는 방법을 제시하고 있으며, 이는 정량적 평가를 수행하는 것으로 보입니다. 또한, 센서 배치와 관련된 최적화 및 예측 결과에 대한 분석이 포함되어 있어 정량적 평가가 이루어지고 있음을 시사합니다."
Hierarchical Knee Image Synthesis Framework for Generative Adversarial Network: Data From the Osteoarthritis Initiative,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9775719,"Medical images synthesis is useful to address persistent issues such as the lack of training data diversity and inflexibility of traditional data augmentation faced by medical image analysis researchers when developing their deep learning models. Generative adversarial network (GAN) can generate realistic image to overcome the abovementioned problems. We proposed a GAN model with hierarchical framework (HieGAN) to generate high-quality synthetic knee images as a prerequisite to enable effective training data augmentation for deep learning applications. During the training, the proposed framework embraced attention mechanism before the 256 ×256 scale in generator and discriminator to capture salient information of knee images. Then, a novel pixelwise-spectral normalization configuration was implemented to stabilize the training performance of HieGAN. We evaluated the proposed HieGAN on large scale knee image dataset by using Am Score and Mode Score. The results showed that HieGAN outperformed all relevant state-of-art. Hence, HieGAN can potentially serve as an important milestone to promote future development of more robust deep learning models for knee image segmentation. Future works should extend the image synthesis evaluation to clinical-related Visual Turing Test and synthetic data augmentation for deep learning segmentation task.",Yes,"논문 초록에서 Am Score와 Mode Score를 사용하여 HieGAN의 성능을 정량적으로 평가했다고 명시되어 있습니다. 이러한 평가는 정량적 평가의 일환으로, 모델의 성능을 수치로 측정하는 방법입니다."
Revisiting the Efficacy of Image-Based Recognition of Arabic Handwriting: The Case of Whole Scripts,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10525737,"Recognizing handwritten scripts by machine learning has a tremendous number of applications in the automation of industry. Moreover, the datasets for such kind of applications in the Arabic language are heterogeneous and sometimes unusable, despite the potential benefit to millions of users who write in Arabic. Our study shows that segmenting the composing letters of handwritten words in Arabic and representing them as images do not enhance or benefit an accurate recognition of handwritten Arabic scripts, thus hindering many industrial applications from being migrated or localized to Arabic-speaking countries like Egypt. In this work, we question the limited use of general-purpose image-based machine learning approaches for categorizing offline Arabic handwritten scripts from heterogeneous datasets of letters and words. The paper reviews some of the existing approaches and proposes novel methods to improve word segmentation. Nevertheless, our findings indicate that these methods yield consistently low accuracy. We argue about the need for future research to not only improve the accuracy of recognizing offline handwritten Arabic scripts but also re-evaluate current treat-ments.",Yes,"논문 초록에서 ""our findings indicate that these methods yield consistently low accuracy""라는 표현을 통해 정량적 평가가 수행되었음을 알 수 있습니다. 또한, 여러 방법을 비교하고 그 성과를 수치로 평가하는 과정이 포함되어 있음을 시사합니다."
Multi-Class Classification of Upper Limb Movements With Filter Bank Task-Related Component Analysis,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10135081,"The classification of limb movements can provide with control commands in non-invasive brain-computer interface. Previous studies on the classification of limb movements have focused on the classification of left/right limbs; however, the classification of different types of upper limb movements has often been ignored despite that it provides more active-evoked control commands in the brain-computer interface. Nevertheless, few machine learning method can be used as the state-of-the-art method in the multi-class classification of limb movements. This work focuses on the multi-class classification of upper limb movements and proposes the multi-class filter bank task-related component analysis (mFBTRCA) method, which consists of three steps: spatial filtering, similarity measuring and filter bank selection. The spatial filter, namely the task-related component analysis, is first used to remove noise from EEG signals. The canonical correlation measures the similarity of the spatial-filtered signals and is used for feature extraction. The correlation features are extracted from multiple low-frequency filter banks. The minimum-redundancy maximum-relevance selects the essential features from all the correlation features, and finally, the support vector machine is used to classify the selected features. The proposed method compared against previously used models is evaluated using two datasets. mFBTRCA achieved a classification accuracy of 0.4193 ± 0.0780 (7 classes) and 0.4032 ± 0.0714 (5 classes), respectively, which improves on the best accuracies achieved using the compared methods (0.3590 ± 0.0645 and 0.3159 ± 0.0736, respectively). The proposed method is expected to provide more control commands in the applications of non-invasive brain-computer interfaces.",Yes,논문 초록에서 분류 성능을 평가하기 위해 정확도(accuracy)를 측정하는 정량적 평가를 실시했음을 명확히 언급하고 있습니다. 이는 다양한 실험 결과와 비교를 통해 제안된 방법의 성능을 수치로 평가하는 정량적 평가가 수행되었음을 보여줍니다.
An Intelligent Calibration Testing of Electricity Meter using XGBoost for Manufacturing 4.0,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10127767,"The manufacturing company with a core business of manufacturing electricity meters has a testing system for the metrology industry, namely calibration testing. The part of calibration testing on an electricity meter is the verification test, which uses the method of comparing it to the standard meter test bench to calculate the accuracy error of the measurement. However, the problem is that carrying out this test requires a long cycle time, and it is difficult to increase production capacity without adding a standard meter calibration test bench which has an expensive investment. The smart factory concept that supports industry 4.0 can open up opportunities for research on information technology using artificial intelligence with machine learning models to solve this problem with the idea of creating intelligent testing. This research requires data collection on a calibration test bench machine, then processed to find model predictions so that they can be implemented into an intelligent test using the XGBoost Regression with Hyperparameter Tuning and Optimization methods as the Goal of this Research. In the results of this research, the evaluation of the XGBoost using the Hyperparameter Tuning and Optimization method, which is implemented in this case, could improve the accuracy and RMSE data testing modelling comparing other scenario models as defined before in the literature review. So, this can be an excellent solution to be applied in metrology manufacturing, especially verification tests in Manufacturing Calibration Testing on Electricity Meter, which is faster and low-investment testing with the implementation of an Intelligent Manufacturing Calibration Test.",Yes,논문 초록에서 XGBoost 회귀 모델과 하이퍼파라미터 튜닝 및 최적화 방법을 사용하여 데이터를 평가하고 모델 성능을 정량적으로 측정하는 내용을 언급하고 있습니다. 이는 정량적 평가를 실시하고 있음을 의미합니다.
Modeling of cognition using EEG: A review and a new approach,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6129270,"Understanding the secrets underlying the brain functioning would be the noble achievement of this era. Learning how brain learns would be the milestone to guide the researchers of artificial intelligence, neurology and psychology. With the advent of “Integrate and Fire” model of neuron proposed about a hundred years ago, the brain research has picked up its pace in the study of different aspects of brain functionality. Many cognitive architectures have been proposed with an aim of simulating and understanding human cognition. On the other hand, many technologies have emerged that can measure the parameters of the brain activity. Among them, Electroencephalogram (EEG) stands as a reliable tool in the study of brain functioning. Simplified wireless EEGs are readily available now which can send data recorded by its electrodes to a computer for further processing. We have chosen this tool to detect different aspects of cognition and to predict the brain functioning behind it. A lot of studies from the past two decades have already revealed varying EEG patterns related to cognition. In this paper, we have proposed to extract different features from visual, tactile, auditory and psychomotor stimuli to work on different cognitive aspects such as memory, emotion, arousal, fatigue and distraction and to investigate its affect on the EEG. A methodology to model cognitive functions by relating the varying event related potential, brain waves, spectral density and latency in EEG outcomes are then related with the stimuli features to predict the cognitive state of mind.",Yes,"논문 초록에서 EEG 데이터를 이용하여 다양한 인지적 측면을 분석하고, 이를 기반으로 인지 상태를 예측하는 방법론을 제시하고 있습니다. 또한, EEG의 다양한 특징(이벤트 관련 전위, 뇌파, 스펙트럼 밀도, 잠복기 등)을 활용하여 정량적 평가를 수행하는 내용을 포함하고 있어 정량적 평가를 실시하고 있다고 판단됩니다."
SmartFire Car: An Image Processing and Artificial Intelligence-Based Fire Detection and Extinguishing System,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10456422,"In this work, we present a novel image processing and artificial intelligence-based autonomous vehicle system for swift fire detection and suppression. The suggested approach offers a unique and economical option, especially for developing nations, to properly tackle fire-related threats in crowded residential spaces and outdoors. The algorithm used by the system, the Haar cascade, is effective in spotting fire in real-time video feeds. After detecting and determining the ideal stopping distance from the fire, the SmartFire car begins to effectively and efficiently extinguish it. To put the proposed theoretical system to the test in actual practical settings, we developed our prototype. The capacity of the SmartFire prototype to measure distances from the fire source and continue operating amid several fire sources has been used to evaluate its effectiveness. To make the system reliable and efficient, its limitations, such as the smallest fire size needed for detection, have also been examined. This work has the potential to significantly contribute to the modernization of the traditional fire-fighting system, particularly in developing countries, leading to more effective fire-handling capabilities.",Yes,논문 초록에서 시스템의 성능을 평가하기 위해 실험을 통해 프로토타입의 거리 측정 능력과 여러 화재원에서의 작동 여부를 검증했다고 언급하고 있습니다. 이는 정량적 평가를 실시했음을 시사합니다.
Comparative Analysis of Deep Learning Methods in the Realm of Sentiment Analysis,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10075107,"Recent advances in deep learning have suggested number of methods which can be employed in several domains. Text classification is one of the most common natural language processing tasks and have given relevant results at the level of text classification to perform sentiment analysis. This paper compares the efficacy of different algorithms used to perform sentiment analysis. The comparison offers a global vision to contribute to a relevant system that can evaluate the different types of sentiment analysis by a Corpus (restaurant reviews). In our study we have used word embedding techniques to compare the efficacy of the simple RNN., LSTM., and BERT neural networks in the context of sentiment analysis. This research indicates that the use of BERT and LSTM yields the better outcomes., although BERT requires a longer training period.",Yes,"논문 초록에서 여러 딥러닝 알고리즘의 성능을 비교하는 실험이 수행되었음을 언급하며, 이를 위해 다양한 평가 방법을 사용했음을 시사합니다. 따라서 정량적 평가가 실시된 것으로 판단됩니다."
Implementation Vulnerability Analysis: A case study on ChaCha of SPHINCS,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9426079,"Deployment of Post Quantum Cryptography(PQC) primitives ensures forward secrecy for today's communication against tomorrow's quantum adversary. However, these primitives have to be realized in conventional hardware, which may be vulnerable to side-channel attacks. Therefore, vulnerability analysis of these primitives is essential before deployment. In this paper, a NIST favoured digital signature primitive- SPHINCS is taken for analysis. ChaCha and BLAKE are ciphers that form the building blocks of SPHINCS. These ciphers are based on Addition, Rotation, and XOR(ARX) operations. The literature review has shown ARX ciphers to be vulnerable against implementation attacks. In this work, an effective countermeasure for the aforementioned building blocks is explored. This is achieved through the following: Parallel Prefix Adders are taken for addition operation in these ciphers instead of the native adder in Electronic Design Automation(EDA) tools. Distinct profiles are created which include the cipher using a particular adder with its best-suited implementation style. An optimized version of Threshold Implementation(TI) is adopted on the profiles as a countermeasure for the attacks on the unprotected implementations. Finally, we evaluate the protected profiles' resistance using Test Vector Leakage Assessment(TVLA) and Deep learning techniques. Such an analysis that follows a generic framework will be straightforward to automate. We believe this will serve to be useful for standardization of Threshold Schemes.",Yes,"논문 초록에서 Test Vector Leakage Assessment(TVLA)와 딥러닝 기법을 사용하여 보호된 프로파일의 저항성을 평가하는 과정을 언급하고 있어, 정량적 평가가 실시되고 있음을 알 수 있습니다."
Lightweight and Efficient Convolutional Neural Network for Road Scene Semantic Segmentation,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10053967,"Recently, Intelligent Transportation Systems (ITS) have become one of the most important fields of research topics, while it provides advanced road scene monitoring. Actually, computer vision is one of the most widely used fields in ITS, while it offers various tasks, such as object detection, image classification, and segmentation. Besides, Convolutional Neural Networks (CNNs) have shown their effectiveness in deep learning tasks, particularly in computer vision. In fact, road scene semantic segmentation task is a critical and fateful issue that can be addressed using CNN which requires effective precision as well as fewer parameters. The majority of related work on road scene segmentation proposes models that focus on one aspect, the precision, or the parameters requirement, which makes it hard to use in real-time applications when the precision is not a priority. To solve this issue, we propose a new network based on an encoder-decoder architecture, which compromises the precision with fewer parameters. Our proposed model is trained from scratch using only 0.64M parameters. The experiments are evaluated on the popular CamVid dataset, and the results show that our proposed CNN achieves better performance with fewer parameter resources.",Yes,"논문 초록에서 제안된 모델의 성능 평가를 위해 실험이 수행되었으며, 실험 결과를 통해 제안된 CNN이 더 적은 파라미터로 더 나은 성능을 달성했다고 언급하고 있습니다. 이는 정량적 평가가 실시되었음을 의미합니다."
Ionospheric Scintillation Forecasting Using Machine Learning,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10640525,"This study explores the use of historical data from Global Navigation Satellite System (GNSS) scintillation monitoring receivers to predict the severity of amplitude scintillation, a phenomenon where electron density irregularities in the ionosphere cause fluctuations in GNSS signal power. These fluctuations can be measured using the S4 index, but real-time data is not always available. The research focuses on developing a machine learning (ML) model that can forecast the intensity of amplitude scintillation, categorizing it into low, medium, or high severity levels based on various time and space-related factors. Among six different ML models tested, the XGBoost model emerged as the most effective, demonstrating a remarkable 77% prediction accuracy when trained with a balanced dataset. This work underscores the effectiveness of machine learning in enhancing the reliability and performance of GNSS signals and navigation systems by accurately predicting amplitude scintillation severity.",Yes,"논문 초록에서 다양한 기계 학습 모델을 사용하여 신호 세기의 강도를 예측하는 정량적 평가를 실시했다고 명확히 언급하고 있습니다. 특히, XGBoost 모델의 예측 정확도(77%)를 제시하며 성능 평가를 수행했음을 알 수 있습니다."
Towards a Distributed Framework for Multi-Agent Reinforcement Learning Research,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9286212,"Some of the most important publications in deep reinforcement learning over the last few years have been fueled by access to massive amounts of computation through large scale distributed systems. The success of these approaches in achieving human-expert level performance on several complex video-game environments has motivated further exploration into the limits of these approaches as computation increases. In this paper, we present a distributed RL training framework designed for super computing infrastructures such as the MIT SuperCloud. We review a collection of challenging learning environments-such as Google Research Football, StarCraft II, and Multi-Agent Mujoco- which are at the frontier of reinforcement learning research. We provide results on these environments that illustrate the current state of the field on these problems. Finally, we also quantify and discuss the computational requirements needed for performing RL research by enumerating all experiments performed on these environments.",Yes,"논문 초록에서 ""We provide results on these environments""와 ""we also quantify and discuss the computational requirements""라는 표현이 있어, 정량적 평가를 실시하고 있음을 알 수 있습니다. 이는 실험 결과와 계산 요구량을 수치로 평가하고 있음을 시사합니다."
Neural Joint Entropy Estimation,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9903402,"Estimating the entropy of a discrete random variable is a fundamental problem in information theory and related fields. This problem has many applications in various domains, including machine learning, statistics, and data compression. Over the years, a variety of estimation schemes have been suggested. However, despite significant progress, most methods still struggle when the sample is small, compared to the variable’s alphabet size. In this work, we introduce a practical solution to this problem, which extends the work of McAllester and Statos. The proposed scheme uses the generalization abilities of cross-entropy estimation in deep neural networks (DNNs) to introduce improved entropy estimation accuracy. Furthermore, we introduce a family of estimators for related information-theoretic measures, such as conditional entropy and mutual information (MI). We show that these estimators are strongly consistent and demonstrate their performance in a variety of use cases. First, we consider large alphabet entropy estimation. Then, we extend the scope to MI estimation. Next, we apply the proposed scheme to conditional MI estimation, as we focus on independence testing tasks. Finally, we study a transfer entropy (TE) estimation problem. The proposed estimators demonstrate improved performance compared to existing methods in all of these setups.",Yes,"논문 초록에서 제안된 방법들이 다양한 정보 이론적 측정값(예: 엔트로피, 조건부 엔트로피, 상호 정보, 전이 엔트로피)을 정량적으로 평가하는 데 사용되고 있음을 명확히 언급하고 있습니다. 또한, 이러한 평가들이 성능 비교와 검증을 위해 수행되고 있음을 시사하므로, 정량적 평가를 실시하고 있다고 판단됩니다."
SitPose: Real-Time Detection of Sitting Posture and Sedentary Behavior Using Ensemble Learning With Depth Sensor,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10901866,"Poor sitting posture can lead to various work-related musculoskeletal disorders (WMSDs). Office employees spend approximately 81.8% of their working time seated, and sedentary behavior can result in chronic diseases such as cervical spondylosis and cardiovascular diseases. To address these health concerns, we present SitPose, a sitting posture and sedentary detection system utilizing the latest Kinect depth camera. The system tracks 3-D coordinates of bone joint points in real-time and calculates the angle values of related joints. We established a dataset containing six different sitting postures and one standing posture, totaling 33409 data points, by recruiting 36 participants. We applied several state-of-the-art machine learning algorithms to the dataset and compared their performance in recognizing the sitting poses. Our results show that the ensemble learning model based on the soft voting mechanism achieves the highest F1 score of 98.1%. Finally, we deployed the SitPose system based on this ensemble model to encourage better sitting posture and to reduce sedentary habits.",Yes,"논문 초록에서 여러 머신러닝 알고리즘을 적용하여 성능을 비교하는 과정이 언급되어 있으며, 특히 앙상블 학습 모델의 F1 점수와 같은 정량적 평가 지표를 제시하고 있습니다. 이는 정량적 평가를 실시하고 있음을 보여줍니다."
Sentiment Analysis with Deep Learning Methods for Performance Assessment and Comparison,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10544219,"The activity of obtaining and evaluating perspectives of individuals, feelings, mindsets of others, views, and so on, toward various things including subjects, goods, and ideas is known as sentiment analysis (SA), often called sentiment mining (SM). People are producing massive quantities of thoughts and feedback regarding goods, offerings, and daily operations as a result of the quick expansion of using online applications like blogs, social media platforms, and web pages. Companies, government agencies, and institutions can collect and evaluate general population attitudes along with opinions using sentiment analysis to acquire business insight and improve decision-making. The paper represents a complete research on sentiment analysis based on DL (deep learning) approaches to give researchers an idea of the evaluation of feelings and associated disciplines. This research represents the previous studies of emotional analysis and illustrates the methodology of our work. The methodology explains data extraction, data preprocessing, text preprocessing, feature extraction, feature selection, and so on. The dataset applied in the study is an IMDb movie reviews dataset containing equal amounts of samples for training and testing. Then, we discussed sentiment analysis techniques which are Simple Neural Networks (SNN), Convolutional Neural Networks (CNN), and Recurrent Neural Networks (RNN). Using the methods, the outcome states that the simple neural network model generates an accuracy of 74.99% and a Convolutional Neural Network of 85.79%. Besides, the Recurrent Neural Network shows 86.46% which is the highest one. Furthermore, based on the results of the confusion matrix, we investigated the optimum model to attain the highest precision, recall, and F1 score.",Yes,"논문 초록에서 다양한 딥러닝 기법을 사용하여 감성 분석의 성능을 평가하고 있으며, 정확도, 정밀도, 재현율, F1 점수와 같은 정량적 지표를 제시하고 있습니다. 이러한 내용은 정량적 평가를 실시하고 있음을 보여줍니다."
Mutual Learning-Based Framework for Enhancing Robustness of Code Models via Adversarial Training,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10764905,"Deep code models (DCMs) have achieved impressive accomplishments and have been widely applied to various code-related tasks. However, existing studies show that some DCMs have poor robustness, and even small noise in the input data can lead to erroneous outputs. This phenomenon can seriously hinder the application of these DCMs in real-world scenarios. To address this limitation, we propose MARVEL, a mutual learning-based framework for enhancing the robustness of DCMs via adversarial training. Specifically, MARVEL initializes two identical DCMs, one of which receives Gaussian-distorted data and performs adversarial training, and the other receives the clean data. Then these two DCMs work together to not only fit the true labels but also fit each other’s internal parameters. Our intuition is that the DCM can enhance robustness by training noisy data, while the DCM achieves accurate prediction performance by learn the clean data. Their mutual learning enables the DCM to balance both robustness and predictive performance.We selected three popular DCMs, five open-source datasets, and three state-of-the-art attack methods to evaluate the performance of MARVEL on 45 (3×5×3) downstream tasks composed of their combinations. Additionally, we set two of the state-of-the-art robustness enhancement techniques as baselines. The experimental results show that MARVEL significantly enhances the robustness of DCMs across all 45 tasks. In 43 out of 45 tasks, MARVEL outperforms the two baselines with an average improvement of 15.33% and 31.88%, respectively. At the same time, MARVEL can maintain the inherent accuracy with an error margin within +-2.43% compared to the original DCMs.CCS CONCEPTS• Software and its engineering → Search-based software engineering; • Computing methodologies → Artificial intelligence.",Yes,"논문 초록에서 다양한 실험을 통해 성능 평가를 수행했음을 보여주며, 특히 정량적 지표인 성능 향상률과 오차 범위 등을 제시하고 있습니다. 이는 정량적 평가가 실시되고 있음을 의미합니다."
Brain-Computer Interface Controlled Functional Electrical Stimulation: Evaluation With Healthy Subjects and Spinal Cord Injury Patients,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9764729,"This work presents the design, implementation, and feasibility evaluation of a Motor Imagery (MI) based Brain-Computer Interface (BCI) developed to control a Functional Electrical Stimulation (FES) device. The aim of this system is to assist the upper limb motor recovery of patients with spinal cord injury (SCI). With this BCI-controlled FES system, the user performs open and close MI with either the left or right hand, which if detected is used to provide visual feedback and electroestimulation to muscles in the forearm to perform the corresponding grasping movement. The system was evaluated with seven healthy subjects (HS group) and two SCI patients (SC group) in several experimental sessions across different days. Each experimental session consisted of a training routine devoted to collect calibration EEG data to train the BCI machine learning model, and of a validation routine devoted to validate system in online operation. The online system validation showed an accuracy of the recognition of the MI task that ranged between 78% and 81% for HS participants and between 63% and 93% for SCI participants. Additionally, the time taken by the BCI system to trigger the FES device ranged between 7.05 and 7.29 s for HS participants and between 8.43 s and 13.91 s for SCI participants. Finally, significant negative correlations were observed ( r=−0.418 , p=0.024 and r=−0.437 , p=0.018 for left and right hand MI conditions, respectively) between the online BCI performance with a quantitative EEG parameter based on event-related desynchronization/synchronization analysis. The results of this work indicate the feasibility of the proposed BCI coupled to a FES device to be used for SCI patients with a moderate level of disability and provides evidence of the functionality of the proposed BCI system in a motor rehabilitation context.",Yes,"논문 초록에서는 BCI 시스템의 인식 정확도, 반응 시간, 그리고 EEG 파라미터와의 상관관계 등 정량적 평가 지표를 제시하고 있습니다. 이러한 수치와 통계적 분석을 통해 시스템의 성능을 평가하고 있음을 알 수 있습니다."
Train a Robot to Climb Staircase Using Vision-Base System,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9930098,"Currently, robots are used for different types of work, such as the manufacturing industry, healthcare, and the hotel industry. According to the current epidemic situation, the usage of robots was increased because of the need to reduce human interaction. As a result, they have to walk around the workplace, because of that, they may have to climb staircases. The world has many types of robots. Here the selected robot is a humanoid. This proposal is concerned with how to detect the staircase, count steps, get dimensions of it, and move the robot on it by keeping body balance. First, want to know what the objects are, then walk. The identified images from the image sensors will get as input. The technology stack that is used for image analysis is a method related to computer vision in deep learning. Other than that, while climbing the stairs robot needs to identify whether the staircase is over or not. Here we introduce a new concept: get the number of steps required to climb before climbing the stairs. It is related to how humans identify things by seeing and making decisions. The need to take the dimensions of the stairs is that when considering the stairs, they have their height, width, and range. Therefore, it is imperative to calculate the dimensions of each staircase separately. Creating a balance system similar to human balance is a great advantage in robotics. To implement such a system, there is an upright pose controller to allow the robot to walk stably by preventing tilting of the robot during walking on uneven floor. In general, for us to do that we need to calculate the global inclination of the floor is a key factor. It can be measured with a 2-axis accelerator meter, and it is installed in the inertial sensor.",No,"The abstract describes the development of a vision-based system for stair detection, step counting, and robot movement, but it does not mention performing any quantitative evaluation or measurement of performance metrics."
Energy Consumption Prediction using Data Stream Learning for Commercial Buildings,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9145123,"Smart cities should be built on harmonious relationships with the environment, with rational measures to use environmental resources in many ways. Resources essential to human life such as water and energy must have special attention. With the advance of technologies use, human being becomes one of the main promoters of information and solutions for smart cities. Stream machine learning is an approach where data becomes available sequentially, called data stream, which adapts the prediction model with fixed window-sized data stream. The objective of this work is to analyze the effectiveness of buildings energy consumption using stream learning. To achieve this goal, MOA11Massive Online Analysis tool was used to evaluate the performance of the selected stream learning algorithms on an an open database. Batch algorithms were also used as testbed, to analyze the performance of stream algorithms related to them. Our work shows that stream learning can show good results in this scenario.",Yes,"논문 초록에서 ""evaluate the performance of the selected stream learning algorithms""라는 표현을 통해 정량적 평가가 수행되고 있음을 알 수 있습니다. 또한, MOA11Massive Online Analysis 도구를 사용하여 알고리즘의 성능을 평가하는 과정이 언급되어 있어, 정량적 평가가 포함된 것으로 판단됩니다."
Improve Toulmin's Argumentation Model Using Naïve Bayes Theory in Medical Applications,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10107947,"The field of argument in artificial intelligence significantly increased the results in the practical working group. The problem of inconsistency in treatments is one of the most important challenges in the field of medicine in the world. This paper is used to improve the argument of Toulmin's model when dealing with conflicting problems in medicine using naive Bayes' theory as qualifier in toulmin's model. inference rules were used to relate the patient's symptoms to the use of therapies, which eventually led to the diagnosis of therapies, where many features of each drug component were used to compete between supporting the drug and attacking it and then making the decision using the naïve Bayes technique about whether or not to give the drug based on the features of treatment and the features of the patient. The dataset collected from the Iraqi educational hospitals and it annotated by a team of experts working in the medical field. For testing proposed system used 200 samples for two diseases (100 sample for hypertension disease and 100 samples for angina pectoris disease). The accuracy achieved in angina pectoris and hypertension diseases were 95% and 94%, respectively, using the confusion matrix method to evaluate the results of the proposed model.",Yes,"논문 초록에서 Naïve Bayes 이론을 사용하여 의학적 데이터에 대한 정량적 평가를 수행했음을 명확히 언급하고 있습니다. 또한, 실험을 통해 정확도(95%와 94%)를 측정하여 모델의 성능을 정량적으로 평가한 점이 이를 뒷받침합니다."
Optimizing Ocular Disease Detection: A Deep Learning Approach with VGG19 and InceptionV3,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10808478,"Early detection and treatment are especially important as global eye diseases including diabetic retinopathy, glaucoma, age-related macular degeneration, and cataracts create major public health issues. Ophthalmology has changed as recent advancements in Deep Learning (DL) and medical imaging allow accurate and fast ailment diagnosis. This work investigates fundus images-based automated categorization of ocular diseases using VGG19 architecture and InceptionV3. Combining two DL approaches InceptionV3 transfer learning model, well-known for their performance in image recognition applications, and VGG19, a deep neural network noted for depth and accuracy in visual classification—the approach followed InceptionV3 showed an 89.44% accuracy after being trained and evaluated using a 5,000 patient record Ocular Disease intelligence recognition (ODIR) dataset including color fundus images and diagnostic keywords; VGG19 shown a higher accuracy of 94.95%, so implying its improved performance in disease categorization. VGG19 proves to outperform InceptionV3 in accuracy, and loss by being able to generalize over numerous patient demographics and imaging modalities. Most importantly for early intervention and improved patient outcomes in clinical settings, our comparison analysis underlines VGG19's accuracy and resilience in automated illness diagnosis.",Yes,"논문은 VGG19와 InceptionV3 모델을 사용하여 ocular disease를 자동으로 분류하는 과정에서 정확도(accuracy)를 측정하고 있으며, 89.44%와 94.95%의 정량적 성과 지표를 제시하고 있습니다. 이러한 성과 평가는 정량적 평가를 실시했음을 보여줍니다."
Cardiac MR Images Segmentation For Identification Of Cardiac Diseases Using Fuzzy Based Approach,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9214080,"The proposed research work presents image segmentation of cardiac MRI Images of ventricle segmentation. Most important task in image analysis is Segmentation of Images. Data Mining and Machine Learning approaches are now a day very much used for Left Ventricle Segmentation on Cardiac System which efficiently uses different kind of algorithms. There are various measuring tools to evaluate the chest pain, cardiac function, neurologic deficits, by Cardiac System. Today the cardiac related diseases are increasing too much in our society. So, earlier identification of disease is crucial for urgent treatment of cardiac diseases. Doctors are providing their suggestion on the basis of manual inspection with MRI and CT scans. Here, the task is based on technical work with morphological, threshold based segmentation and fuzzy based edge detection approach is applied for better classification of diseases. The task is used to classify cardiac arrhythmia cases, abnormal cardiac cases, left ventricular cases problems. So specifically medical based image segmentation consists higher impotency which betterment the organs localizations for betterment of the quality of the diagnosis and crucial works and become crucial stages for evaluation of functionality of heart failure with pre existing approaches. Here, the the performance produces by this method is more than 90% of accuracy for detection and classification of cardiac diseases. Some of the statistical parameter are basically MSE, PSNR, MAE etc are significantly performs better for the fuzzy based approach with better quality performance of MR images.",Yes,"논문 초록에서 다양한 정량적 평가 지표인 MSE, PSNR, MAE 등을 사용하여 제안된 방법의 성능을 평가했다고 명시되어 있습니다. 이러한 지표들은 정량적 평가를 실시하고 있음을 보여줍니다."
A Privacy-Preserving-Based Secure Framework Using Blockchain-Enabled Deep-Learning in Cooperative Intelligent Transport System,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9505613,"Cooperative Intelligent Transport System (C-ITS) is a promising technology that aims to improve the traditional transport management systems. In C-ITS infrastructure Autonomous Vehicles (AVs) communicate wirelessly with other AVs, Road Side Units (RSUs) and Traffic Command Centres (TCCs) using an open channel Internet. However, the use of the Internet brings inherent vulnerabilities related to privacy (e.g., adversary performing inference and data poisoning attacks), and security (e.g., AVs can be compromised using advanced hacking techniques) issues and prevents the faster realization of C-ITS applications. To address these challenges, this paper presents a privacy-preserving-based secure framework to provide both privacy and security in C-ITS infrastructure. The proposed framework provides two level of security and privacy using blockchain and deep learning modules. First, a blockchain module is designed to securely transmit the C-ITS data between AVs–RSUs-TCCs, and a smart contract-based enhanced Proof of Work (ePoW) technique is designed to verify data integrity and mitigate data poisoning attacks. Second, a deep-learning module is designed that includes Long-Short Term Memory-AutoEncoder (LSTM-AE) technique for encoding C-ITS data into a new format to prevent inference attacks. The encoded data is used by the proposed Attention-based Recurrent Neural Network (A-RNN), for intrusive events recognition in C-ITS infrastructure. The proposed A-RNN is trained using Truncated Backpropagation Through Time (BPTT) algorithm. The framework is further validated and tested using two publicly available ToN-IoT and CICIDS-2017 datasets. The proposed framework is compared with peer privacy-preserving intrusion detection techniques, and the result shows the effectiveness of the proposed framework over several state-of-the-art techniques in both blockchain and non-blockchain systems.",Yes,논문 초록에서 제안된 프레임워크의 성능을 검증하기 위해 공개 데이터셋(Ton-IoT 및 CICIDS-2017)을 사용하여 실험과 검증을 수행했다고 명시되어 있습니다. 이는 정량적 평가가 이루어졌음을 의미합니다.
Deep Ensemble-Based Classifier for Transfer Learning in Rotating Machinery Fault Diagnosis,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9730901,"Nowadays, intelligent models can correctly detect faults by analysing signals from rotating machinery. However, most of the studies are run in controlled environments and the performance in industrial real-world environments is not yet fully validated. Hence, a suitable tool to implement fault diagnosers is transfer learning, this topic is under development and challenges persist. This paper proposes a framework for creating accurate 1D-CNN based fault classifiers that can be transferred between different rotating machines and working conditions. Multiple Bayesian processes select architecture parameters and hyperparameters, which minimize a loss function related to their transferability to other machines and to the same machine under different operating conditions (such as load and engine speed). The resulting model is fitted to heterogeneous fault diagnosis data resulting in a 1D-CNN ensemble that improves the performance of the unitary model. Subsequently, the transfer learning capability of the ensemble is analyzed on two source data sets using function and parameter based transfer. The results are compared with classical fault diagnosis classifiers. Finally, additional transfer operations on five target domain datasets validate our framework on limited labeled samples and allow interpretation of the ensemble results. The ultimate goal is to find an ensemble that can generalize fault diagnosis on rotating machinery for easy implementation and update in industrial settings.",Yes,"논문 초록에서는 여러 Bayesian 프로세스와 손실 함수를 이용한 정량적 평가가 언급되어 있으며, 성능 비교를 위해 기존의 고전적 분류기와의 성능 차이를 분석하는 내용이 포함되어 있습니다. 이는 정량적 평가가 수행되고 있음을 시사합니다."
Web-derived Emotional Word Detection in social media using Latent Semantic information,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8004881,"Public sentiment permeated through social media is usually regarded as an important measure for public opinion monitoring, policy making, and so forth. However, the deluge of user-generated content in web, especially in social platform, causes great challenge to public sentiment analysis tasks. Therefore, Web-derived Emotional Word Detection (WEWD) is proposed as a fundamental tool aims to alleviate this problem. Most previous works on WEWD focus on rules, syntax, and sentence structures, a few utilize semantic information which has the potential to further increase the accuracy and efficiency of WEWD. In this paper, we propose a Global-Local Latent Semantic (GLLS) framework for WEWD to make a full use of latent semantic information with the help of multiple sense word embedding technology. We devise two computational WEWD models, called Ensemble GLLS (EGLLS) and Deep GLLS (DGLLS). EGLLS exploits an ensemble learning way to fuse the global and local latent semantics while DGLLS takes advantage of deep neural network. We also design an old-new corpus enrich technique to help increase the effectiveness of the overall training and detecting process. To the best of our knowledge, this is the first work which applies multiple sense word embedding and deep neural network in WEWD related tasks. Experiments on real datasets demonstrate the effectiveness of the proposed idea and methods.",Yes,"논문은 두 가지 계산 모델인 Ensemble GLLS (EGLLS)와 Deep GLLS (DGLLS)를 제안하며, 이들 모델을 통해 감정 단어 감지의 성능을 정량적으로 평가하는 실험을 수행하고 있음을 시사합니다. 또한, 실험 결과를 통해 제안된 방법의 효과를 검증하는 과정이 포함되어 있어 정량적 평가를 실시하고 있다고 판단됩니다."
Channel Charting: Locating Users Within the Radio Environment Using Channel State Information,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8444621,"We propose channel charting (CC), a novel framework in which a multi-antenna network element learns a chart of the radio geometry in its surrounding area. The channel chart captures the local spatial geometry of the area so that points that are close in space will also be close in the channel chart and vice versa. CC works in a fully unsupervised manner, i.e., learning is only based on channel state information (CSI) that is passively collected at a single point in space, but from multiple transmit locations in the area over time. The method then extracts channel features that characterize large-scale fading properties of the wireless channel. Finally, the channel charts are generated with tools from dimensionality reduction, manifold learning, and deep neural networks. The network element performing CC may be, for example, a multi-antenna base-station in a cellular system and the charted area in the served cell. Logical relationships related to the position and movement of a transmitter, e.g., a user equipment (UE), in the cell, can then be directly deduced from comparing measured radio channel characteristics to the channel chart. The unsupervised nature of CC enables a range of new applications in UE localization, network planning, user scheduling, multipoint connectivity, hand-over, cell search, user grouping, and other cognitive tasks that rely on CSI and UE movement relative to the base station, without the need of information from global navigation satellite systems.",Yes,"논문 초록에서 채널 특성 정보를 활용하여 무감독 방식으로 채널 차트를 생성하는 과정을 설명하고 있으며, 이를 통해 정량적 평가가 수행될 가능성이 높습니다. 또한, 차트 생성과 관련된 도구들이 차원의 축소와 머신러닝 기법을 포함하고 있어, 정량적 분석이 핵심적인 역할을 하는 것으로 보입니다."
An approach using machine learning and public data to detect traffic jams,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9498622,"With the growth of large cities, it becomes necessary to overcome several challenges related to infrastructure. In this context, urban mobility, including transportation systems, is a key topic. It is known that more efficient traffic management makes cities more efficient as a whole, improving the quality of life of their residents and tourists. A common problem that arises concerns traffic jams, encompassing their detection and management. With proper traffic jam detection, it is possible to implement traffic management methods to prevent long-term occurrences or even notify drivers to avoid specific locations. Some traffic jam detection solutions use sensors spread across cities, while others are based on sensors in drivers' smartphones. These approaches have limitations related mainly to the information reliability or to the cost and complexity of implementation. In this work, we propose an approach using Machine Learning techniques applied to public data of transportation systems to detect urban traffic jams. The proposed approach is evaluated using the publicly available GPS data from the buses of the Rio de Janeiro/Brazil transportation system and traffic jam events posted on Twitter by the Rio de Janeiro City Hall.",Yes,"논문 초록에서 머신러닝 기법을 적용하여 교통 체증을 감지하는 방법을 제시하고 있으며, 이를 평가하기 위해 공개된 GPS 데이터와 트위터의 교통 체증 이벤트 데이터를 사용했다고 명시되어 있습니다. 이는 정량적 평가를 수행했음을 시사합니다."
A Framework for IoT Based Appliance Recognition in Smart Homes,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9551993,"Internet of Things (IoT) technologies will play an important role in enabling the smart grid achieving its goals in monitoring, protecting, and controlling by incorporating sensors, actuators, and metering devices while supporting various network functions and system automation. In this regard, home energy management systems (HEMS) enable customers efficiently use energy by managing their consumption, providing feedback information and improving control of major appliances. This work proposes a novel framework for IoT based appliance recognition in smart homes. It consists of two parts: training framework and inference framework. The proposed framework allows incorporating different loads in the monitoring system and enables selecting and testing specific parameters related to dataset configuration, feature extraction, and classifier model setting. The work contributes by developing an easy-to-use tool that allows customization of the training/prediction parameters according to the user criterion. Once the data and all its parameters are loaded, a novel feature extraction algorithm is used to obtain a total of ten statistical features. For the classification task, three machine learning models are included: a feed-forward neural network, a long short-term memory and a support vector machine. In addition, the user can apply a set of techniques to handle imbalanced classes, and also measure the influence of the selected features in the classifiers’ prediction by performing a feature importance analysis.",Yes,"논문 초록에서 다양한 머신러닝 모델과 특징 추출 알고리즘을 사용하여 데이터를 분석하고 평가하는 과정을 언급하고 있어 정량적 평가를 실시하고 있음을 알 수 있습니다. 이러한 방법들은 일반적으로 성능 측정과 평가를 포함하므로, 정량적 평가가 수행되고 있다고 판단됩니다."
Bridging the Gap Between Voltage Over-Scaling and Joint Hardware Accelerator-Algorithm Closed-Loop,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9353544,"Voltage over-scaling (VOS) optimizes energy while causing timing errors due to an unsustainable clock frequency. Many algorithms, such as in multimedia and machine learning applications, are capable of tolerating such errors. VOS has never been investigated in hardware accelerators running closed-loop algorithms. As the errors impact most decisions and actions in the subsequent steps, closed-loops dynamically change the execution flow. Timing errors should be evaluated by an accurate gate-level simulation, but a large gap still remains: how these timing errors propagate from the underlying hardware all the way up to the entire algorithm run, where they just may degrade the performance and quality of service of the application at stake? This paper tackles this issue showing a framework for VOS investigation, embracing any kind of application. Our framework simulates the VOS-induced timing errors at gate-level, dynamically linking the hardware result with the algorithm and vice versa during the evolution of the runtime of the application. The state-of-the-art VOS literature for video encoding application fails to assess the ultimate impacts of VOS-induced timing errors, as current works open the encoding loops. Unlike those, our work investigates the ultimate impact of a hardware accelerator dynamically carrying through to the video encoder all VOS-induced timing errors and preserving the full compliance to the standard. We employ a parallel sum of absolute differences (SAD) hardware accelerator as a case study. We assess the performance of the overall encoder under varying timing guardbands. Next, it is demonstrated that, under VOS, the ultimate impact in compression efficiency is related to the video’s motion intensity. Additionally, the advantages of timing guardband controlled reduction are clearly quantified in our results by virtue of the framework. Reducing at maximum 9.5% the clock frequency, energy savings (up to 16.5% in energy/operation) are achieved in SAD for video compression.",Yes,"논문 초록에서 VOS로 인한 타이밍 오류를 정량적으로 평가하기 위해 게이트 레벨 시뮬레이션과 성능 평가를 수행하는 프레임워크를 제시하고 있으며, 이를 통해 에너지 절감과 성능 영향을 수치로 분석하고 있기 때문입니다."
A measurement method for intrusion detection in cyber IoT data stealing attacks,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10175888,"The low complexity levels of IoT devices increase vulnerability and expose low-cost devices to possible cyber at-tacks, especially voted to data breaches. The adoption of machine learning algorithms to overcome such an issue onboard could result in an extensive use of their hardware capabilities, possibly limiting their primary goal in the network they are involved. To this aim, the paper proposes a gateway-like detection system, based on the usage of lightweight and open-source measurement software and a very straightforward rule-based detector, to implement on very low-cost devices to prevent intrusion for data stealing purposes. The advantage of the proposed solution is its applicability to different data streams, from interactive to asyn-chronous traffic typologies, and the simplicity of the detection mechanism: no specific hardware-related compatibility issues, very low memory footprint, and CPU usage burden, allowing the procedure to safely work in background mode and no need to decrypt data content, warranting privacy to the user. The adopted traffic measurement software is CICFlowMeter and the rule-based detector is implemented in Python language. Obtained performance highlights a 98.1% accuracy and 96.4% sensitivity in test conditions, keeping the running time significantly lower than most common machine learning techniques. To quantify the impact on the execution time, several experiments were carried out on a very popular processing system (i.e. Raspberry PI), and in some cases, one order of magnitude has been gained concerning machine learning techniques.",Yes,"논문 초록에서 98.1%의 정확도와 96.4%의 민감도를 언급하며 성능 평가를 수행했음을 보여줍니다. 또한, 여러 실험을 통해 실행 시간에 대한 정량적 측정도 실시하였음을 알 수 있습니다."
Dual-Mode Multispectral Imaging System for Food and Agricultural Product Quality Estimation,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10444559,"Multispectral imaging (MSI) coupled with artificial intelligence (AI), machine-learning (ML), and signal-processing techniques work as a feasible alternative for laboratory testing, especially in food quality control. Most of the recent related research has been focused on reflectance MSI but a system with both reflectance and transmittance capabilities would be ideal for a wide array of specimen types including solid and liquid samples. In this article, a device that includes a dedicated reflectance mode and a dedicated transmittance mode is proposed. Dual-mode operation where fast switching between two modes is facilitated. An innovative merged mode is introduced in which both reflectance and transmittance information of a specimen are combined to form a higher-dimensional dataset with more features. Spatial and temporal variations of measurements are analyzed to ensure the quality of measurements. The concept is validated using a standard color palette, and specific case studies are done for standard food samples such as turmeric powder and coconut oil proving the validity of proposed contributions. The classification accuracy of standard color palette testing was over 90% and the accuracy of coconut oil adulteration was over 95%. while the merged mode was able to provide the best accuracy of 99% for the turmeric adulteration. A linear functional mapping was done for coconut oil adulteration with an R2 value of 0.9558.",Yes,"논문 초록에서 정량적 평가를 위해 분류 정확도와 R2 값을 제시하며, 다양한 식품 샘플에 대한 정량적 분석 결과를 보고하고 있습니다. 이는 정량적 평가를 실시하고 있음을 명확히 보여줍니다."
Machine Learning Approaches and Analysis for Bangla Music Genre Classification,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10464795,"The challenge of classifying the genres of Bangla music has been given a machine learning based technique in this study. This paper has explored the use of feature extraction techniques for selecting highly co-related features and evaluated the performance of gradient boosting classifiers, CatBoost, and XGBoost, on a comprehensive Bangla music dataset. Our paper's proposed method achieves remarkable accuracy scores of 74% using CatBoost and XGBoost. This study emphasizes how machine learning approaches have enormous promise to address the difficult job of classifying genres in Bangla music. By using advanced feature extraction techniques and powerful gradient boosting classifiers,the proposed method were able to achieve promising results in this challenging task. The implications of the work can be extended to the development of intelligent music rec-ommendation systems and automated music tagging, facilitating enhanced user experiences in exploring and discovering Bangla music genres. As the field of machine learning continues to evolve, this research contributes valuable insights and avenues for future advancements in music genre classification and related domains.",Yes,"논문 초록에서 다양한 기계 학습 기법(Gradient Boosting, CatBoost, XGBoost)을 사용하여 성능 평가를 실시했다고 명확히 언급하고 있습니다. 또한, 정확도와 같은 정량적 성과 지표를 제시하여 정량적 평가를 수행했음을 알 수 있습니다."
Color-aware Exposure Correction for Endoscopic Imaging using a Lightweight Vision Transformer,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10600785,"Endoscopy is a widely used imaging technique for diagnosing diseases in hollow organs. However, endoscopic images often suffer from limited visibility and can be affected by many imaging artifacts, such as those related to under or overexposure, which can hamper the performance of AI-based diagnostic tools. Addressing this issue is challenging; thus, most previous work has focused on enhancing underexposed images. In this contribution, we propose an extension to the objective function and deep neural network layers of the IAT Vision Transformer model (Illumination Adaptive Transformer), designed initially for enhancing lowlight or ill-exposed images from natural scenes. Our approach specifically targets exposure correction in endoscopic imaging to preserve color and fine-scale details. First, an extra color normalization layer inside the IAT model has been integrated into the model, and secondly, the objective function has been extended with a Laplacian Pyramid Loss to evaluate different image patches, whereas a histogram-aware loss (HistoLoss) has been used to preserve the color quality of the enhanced endoscopic image, both of these combined allow for the output images not only to improve quantitatively but also qualitative wise. We evaluate our method on the Endo4IE dataset and demonstrate significant improvements over a previous method (Endo-LMSPEC) tailored specifically to endoscopic imaging. Compared with the state-of-the-art (Endo-LMSPEC), our approach achieves an SSIM increase of 2.3% and PSNR increase of 0.523 dB for overexposed images, along with an increase of 2.7% and 1.458 dB improvement in PSNR for underexposure, all while employing only ≈ 90k parameters and running at an inference time of ≈ 74 FPS, outperforming existing state-of-the-art methods on the same dataset and objective.",Yes,"논문 초록에서 Laplacian Pyramid Loss와 histogram-aware loss (HistoLoss)와 같은 평가 지표를 활용하여 이미지 품질을 정량적으로 평가하고 있음을 명확히 언급하고 있습니다. 또한, PSNR과 SSIM과 같은 정량적 지표의 향상도를 제시하여 평가를 실시하고 있음을 보여줍니다."
Scaling Uncertainty Quantification From Patches to Scenes Through Discontinuity-Aware Stitching,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10486921,"Reconstructing spatially continuous 2-D fields out of their individually derived building blocks typically introduces artifacts that decrease the overall perceptual quality of the field. Machine learning (ML) applications encounter such a challenge when patching a U-net-like architecture output. Numerous techniques have been developed to mitigate this problem. Yet, few are informed scalable solutions. The present work manages the stitching of Unet-inferred images using Bayesian deep learning (BDL) probabilistic output. The ability to preserve a Bayesian prediction’s variance while effectively reducing the artifacts within a patched scene is presented through an example of predicting a field related to atmospheric radiance. In areas of high variance, adjacent patches of inferred atmospheric radiances may significantly vary in magnitude, leading to large undesirable spatial gradients in the combined (patched) product. Multiple weighted aggregation strategies and weighting schema are surveyed to investigate how to efficiently decrease artificial gradients in large images constructed by stitching several small predictions while maintaining naturally occurring gradients expected to appear in the mosaiced image. Structural similarity (SSIM) Index and visual information fidelity (VIF) are used to evaluate the perceptual quality of the resultant images and confirm the successful employment of Bayesian U-nets with well-calibrated uncertainty, yielding geospatial images with fewer artifacts than naive methods. Log-linear pooling (LLP) proved to be the optimal aggregation strategy tested for fusing patch uncertainties by retaining per-pixel Gaussian distributions and scaling uncertainties in a principled manner to maintain calibration across the spatial map.",Yes,"논문 초록에서 구조적 유사도 지수(SSIM)와 시각 정보 충실도(VIF)와 같은 정량적 평가 지표를 사용하여 결과물의 품질을 평가했다고 명시되어 있습니다. 또한, 다양한 집계 전략의 성능을 비교하는 과정에서 정량적 평가 방법이 활용된 것으로 보입니다."
Autoencoder-Based Anomaly Detection in Network Traffic,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10720411,"Due to the continuously increasing number of resources and data availability in the cloud, the threats related to the security of computer networks and IT systems are critical. Threat detection systems based on deep neural networks and anomaly detection are trained on data related to normal activity so that the network can recognize unusual patterns and behaviours in the event of an attack or an attempt to infiltrate a given IT infrastructure. This paper presents the results of developing a neural network based on an autoencoder for anomaly detection in network packet data. The network was trained on data from the HIKARI-2021 dataset. The autoencoder aims to learn representations of normal network traffic and associate this type of traffic with a minimal reconstruction error. The obtained results were compared with those achieved by authors of other works. High accuracy and sensitivity were achieved at the cost of rather low precision, resulting in many false-positive results. A simple algorithm based on a single threshold value proved efficient but limited in terms of effectiveness. This problem can be resolved by changing the method of calculating the individual components of the vector, using only a subset of features, and deriving multiple vectors, one for each class separately, which has been described and analyzed in more detail.",Yes,"논문 초록에서 네트워크 성능 평가를 위해 정확도, 민감도, 정밀도와 같은 정량적 지표를 사용했다고 명시되어 있습니다. 또한, 다른 연구와 비교하는 과정에서 수치적 평가 결과를 제시했음을 알 수 있습니다."
Data-Driven Estimation of Flowing Bottom-Hole Pressure in Petroleum Wells Using Long Short-Term Memory,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10903375,"Monitoring bottom-hole pressure (BHP) during flowing periods in petroleum wells is critically important for reservoir management, formation evaluation, lift optimization, and flow assurance. The advent of Permanent Downhole Gauges (PDGs) has changed paradigms regarding the availability and accessibility of this information. However, the costs associated with installing or replacing these gauges can sometimes be prohibitive. In this work, we propose a data-driven framework to fill the information gap when PDG data is unavailable. We used surface measurement data and wellhead gauge readings as inputs and train machine learning methods to accomplish this task. We implemented and evaluated several configurations of Long Short-Term Memory (LSTM) and compared their results with non-deep learning methods as Multi-Layer Perceptron (MLP) Neural Networks and Ridge Regression, taking as case study a real dataset from an offshore oilfield in the Brazilian Pre-salt. We show that our framework can provide reliable estimated values of flowing BHP, with error metrics MAPE and SMAPE consistently under 3%. We highlight the following main contributions: (1) the utilization of time-related data; (2) the development of a framework applicable across a wide range of reservoir and flow conditions; and (3) the potential for practical applications, including real-time monitoring.",Yes,"논문 초록에서 여러 머신러닝 방법을 사용하여 흐름 하단압력(BHP)의 추정값을 정량적으로 평가하는 과정이 언급되어 있습니다. 특히, MAPE와 SMAPE와 같은 오류 지표를 통해 평가 결과를 제시하고 있어 정량적 평가를 실시하고 있음을 알 수 있습니다."
Deep learning for virtual metrology: Modeling with optical emission spectroscopy data,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8065905,"Virtual Metrology is one of the most prominent Advanced Process Control applications in Semiconductor Manufacturing. The goal of Virtual Metrology is to provide estimations of quantities that are important for production and to assess process quality, but are costly or impossible to be measured. Virtual Metrology solutions are based on Machine Learning approaches. The bottleneck of developing Virtual Metrology solutions is generally the feature extraction phase that can be time-consuming, and can deeply affect the estimation performance. In particular, in presence of data with additional dimensions, such as time, feature extraction is typically performed by means of heuristic approaches that may pick features with poor predictive capabilities. In this work, we propose the usage of modern Deep Learning approaches to bypass manual feature extraction and to provide high-performance automatic Virtual Metrology modules. The proposed methodology is tested on a real industrial dataset related to Etching. The dataset at hand contains Optical Emission Spectroscopy data and it is paradigmatic of the feature extraction problem under examination.",Yes,"논문 초록에서 제안된 딥러닝 방법이 가상 계측(Virtual Metrology) 성능 평가를 위해 실험 데이터에 대한 평가를 수행하는 것으로 보입니다. 특히, ""The proposed methodology is tested on a real industrial dataset""라는 문구를 통해 정량적 평가가 이루어졌음을 알 수 있습니다."
Integrating Computational Thinking Into the Curricula to Bridge the Skill Gap in Engineering Education,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10892914,"This work-in-progress research-to-practice paper presents an intervention on integrating computational thinking modules into a software engineering course. The national consensus on the significance of computational thinking has prompted the expansion of related educational initiatives over the past decade. Since the definition of computational thinking by Wing in 2006, this concept has gained significant attention within the educational community. Particularly this surge of interest has led to extensive research into its conceptual foundations and subsequent integration into educational curricula since 2013. National initiatives have since emerged to incorporate computational thinking into the educational system. Furthermore, as artificial intelligence and computing systems become increasingly integrated into daily life, there is a growing demand from industries for a workforce and graduates adept at critical thinking and problem-solving. Aligned with this national movement, our study presents a two-year institutional initiative, aimed at integrating computational thinking into the software engineering program. The software engineering discipline extensively involves design thinking and problem-solving skills. However, we noticed that these higher-level skills are not imparted early in the program to teach students this method of thinking and approaching problems. To bridge this skill gap, we developed a set of computational thinking modules and integrated them into a gateway course in the software engineering program. Over two years, we implemented this intervention in an introductory-level course and evaluated its impact on students' computational thinking skills by analyzing their responses to a standard Computational Thinking Assessment survey. The results showed significant improvement in most components. These early findings underscore the effectiveness of integrating these computational thinking modules into the gateway courses, regardless of the specific course topic. A notable feature of these modules is their adaptability to diverse engineering courses, suggesting broader applicability across disciplines. Moving forward, our research aims to expand the integration of the computational thinking modules into various courses in other institutes across the nation and analyze their impact on student performance.",Yes,논문 초록에서 학생들의 계산적 사고 능력을 평가하기 위해 표준화된 Computational Thinking Assessment 설문조사를 사용하여 그 영향을 분석했다고 명시되어 있습니다. 이는 정량적 평가가 실시되고 있음을 보여줍니다.
Forecasting the load flow of Engine Driven Pump based on Light Gradient Boosting Machine Model,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9574553,"The flow rate of aircraft hydraulic system is one of the important parameters to measure the performance of aircraft. The stability of flow rate of hydraulic pipeline is related to the safety of hydraulic system and even aircraft flight. Aiming at the problem that it is difficult to measure the load flow of aircraft hydraulic system, a prediction method based on ensemble learning for the load flow of Engine Driven Pump (EDP) is proposed. According to the different working conditions of EDP, the Light Gradient Boosting Machine (LightGBM) model is established. Through Particle Swarm Optimization algorithm optimizes the super parameters of LightGBM algorithm, and realizes the regression prediction mode. Finally, compared with the multiple linear regression, random forest, experimental results indicate that the proposed model obviously can improve the prediction accuracy.",Yes,"논문 초록에서 Light Gradient Boosting Machine (LightGBM) 모델을 이용한 예측 방법을 제시하며, 실험 결과를 통해 예측 정확도를 비교하는 내용을 포함하고 있습니다. 이는 정량적 평가를 실시하고 있음을 보여줍니다."
An Attention Based Approach for Sentiment Analysis of Food Review Dataset,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9225637,"Sentiment Analysis is a technique related to text analysis and natural language processing used to detect various types of insights or information from a portion of text. Over the past few years, researchers have done many works regarding this. In Bangladesh, many online services like-e-com become very popular day by day. One of them is online food delivery services. We can order various foods of our choice from online and sometimes people gives reviews based on that food. Those reviews are usually discarded as unstructured data which of them have no work in further. In this piece of research focus primarily on those unstructured data to analyze them in a correct manner to find insight into customers' behavior and their reactions on those online platforms. To do this experiment first we collect data from websites. Later deep learning-based techniques applied here. For baseline structure, we have used both CNN and LSTM models. Then for improving the model accuracy an attention mechanism applied followed by CNN which gives us 98.45% accuracy. We've also evaluated our model performances with some evaluation metrics also. From them, CNN based attention model gives a higher f1-score of 0.93.",Yes,"논문 초록에서 딥러닝 기반 기법과 함께 평가 지표인 F1-score를 언급하며 모델 성능을 정량적으로 평가했다고 명시되어 있습니다. 또한, CNN과 LSTM 모델의 성능 비교와 정확도 수치를 제공하여 정량적 평가를 실시하고 있음을 알 수 있습니다."
Effective Heart Disease Prediction Using Hybridmachine Learning,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9388635,"Machine learning based heart disease prediction is presented in this research work. Heart related diseases increases everyday throughout the world due to stress, high blood pressure, family backgrounds, etc., Early prediction helps to prevent serious issues due to heart diseases. Classification approaches are widely used to analyse medical data to prevent major issues. Real time large medical data are evaluated through data mining applications to control, contradict and manage large data and make use of it to predict the risk factors. This research work is also aims to diagnose heart disease through support vector machine (SVM) and genetic algorithm (GA) as a data analytic approach. Experimental results demonstrate the superior performance of proposed approach in predicting heart disease.",Yes,"논문 초록에서 실험 결과를 통해 제안된 방법의 성능이 입증되었음을 언급하며, 이는 정량적 평가가 수행되었음을 시사합니다. 구체적인 성능 평가 방법이나 수치에 대한 언급은 없지만, 실험 결과를 통해 평가가 이루어진 것으로 보입니다."
Deep Residual Convolutional and Recurrent Neural Networks for Temperature Estimation in Permanent Magnet Synchronous Motors,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8785109,"Most traction drive applications using permanent magnet synchronous motors (PMSMs) lack accurate temperature monitoring capabilities so that safe operation is ensured through expensive, oversized materials at the cost of its effective utilization. Classic thermal modeling is conducted with e.g. lumped-parameter thermal networks (LPTNs), which help to estimate internal component temperatures rather precisely but also require expertise in choosing model parameters and lack physical interpretability as soon as their degrees of freedom are curtailed in order to meet the real-time requirement. In this work, deep recurrent and convolutional neural networks with residual connections are empirically evaluated for their feasibility on the sequence learning task of predicting latent high-dynamic temperatures inside PMSMs, which, to the authors' best knowledge, has not been elaborated in previous literature. In a highly utilized PMSM for electric vehicle applications, the temperature profile in the stator teeth, winding, and yoke as well as the rotor's permanent magnets are modeled while their ground truth is available as test bench data. A model hyperparameter search is conducted sequentially via Bayesian optimization across different random number generator seeds in order to evaluate model training consistency and to find promising topologies as well as optimization strategies systematically. It has been found that the mean squared error and maximum absolute deviation performances of both, deep recurrent and convolutional neural networks with residual connections, meet those of LPTNs, without requiring domain expertise for their design. Code is available at [1] to assist related work.",Yes,논문은 딥러닝 모델의 성능 평가를 위해 평균 제곱 오차와 최대 절대 편차와 같은 정량적 지표를 사용하여 평가하고 있음을 명시하고 있습니다. 이러한 지표들은 모델의 예측 정확도를 수치로 측정하는 정량적 평가 방법에 해당합니다.
Applying Neural Networks to detect the failures of turbines in thermal power facilities,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5373231,"Due to the growing demand on electricity, how to improve the efficiency of equipment has become one of the critical issues in a thermal power plant. Related works reported that efficiency and availability depend heavily on high reliability and maintainability. Recently, the concept of e-maintenance has been introduced to reduce the cost of maintenance. In e-maintenance systems, the intelligent fault detection system plays a crucial role for identifying failures. Machine learning techniques are at the core of such intelligent systems and can greatly influence their performance. Applying these techniques to fault detection makes it possible to shorten shutdown maintenance and thus increase the capacity utilization rates of equipment. Therefore, this work applies Back-propagation Neural Networks (BPN) to analyze the failures of turbines in thermal power facilities. Finally, a real case from a thermal power plant is provided to evaluate the effectiveness.",Yes,"논문 초록에서 ""apply Back-propagation Neural Networks (BPN) to analyze the failures""라는 표현을 통해 신경망을 이용한 정량적 평가가 수행되고 있음을 알 수 있습니다. 또한, ""a real case from a thermal power plant is provided to evaluate the effectiveness""라는 문장도 평가를 위한 실증적 분석이 포함되어 있음을 시사합니다."
Whole brain volume and cortical thickness based automatic classification of Wilson’s disease,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8914413,"Wilson's disease (WD) is a progressive autosomal-recessive genetic disorder of copper metabolism that can induce cognitive, physical and psychiatric symptoms. Despite the wide use of machine learning methods in neuroimaging analysis, WD-related research has been very rare. In this work, we proposed and validated an efficient pipeline for an automated WD classification based on whole brain segmentation volumes and cortical thicknesses obtained from T1-weighted magnetic resonance images (MRIs). Three well-known supervised machine learning algorithms, including support vector machine (SVM), linear discriminant analysis (LDA), and logistic regression (LR), were evaluated and compared in the setting of WD classification. A total of 51 images, including 27 acquired from WD patients and 24 from age-matched healthy controls, were used in the validation analysis. Univariate feature selection was conducted to eliminate non-relevant features and retain features contributing to the classification performance. Two nested leave-one-out cross validations were adopted, with the inner folder used for optimal parameter estimation and the outer folder for classification performance evaluation. Experimental results showed that when employing volume features, SVM significantly outperformed both LDA and LR, yielding an overall accuracy of 96.1%, a sensitivity of 92.6% and a specificity of 100%. LR could also reach such best classification performance when using a combination of volumes and thicknesses as input features. This study provides a new non-invasive tool (MRI-based) for an automated detection of WD.",Yes,"논문 초록에서 Support Vector Machine, Linear Discriminant Analysis, Logistic Regression 등 여러 기계 학습 알고리즘을 평가하고 있으며, 정량적 평가 지표인 정확도, 민감도, 특이도 등을 제시하고 있습니다. 이는 정량적 평가를 실시하고 있음을 보여줍니다."
Learning instance greedily cloning naive Bayes for ranking,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1565680,"Naive Bayes (simply NB) (Langley et al., 1992) has been widely used in machine learning and data mining as a simple and effective classification algorithm. Since its conditional independence assumption is rarely true, researchers have made a substantial amount of effort to improve naive Bayes. The related research work can be broadly divided into two approaches: eager learning and lazy learning, depending on when the major computation occurs. Different from eager approach, the key idea for extending naive Bayes from the lazy approach is to learn a naive Bayes for each testing example. In recent years, some lazy extensions of naive Bayes have been proposed. For example, SNNB, LWNB, and LBR. All are aiming at improving the classification accuracy of naive Bayes. In many real-world machine learning and data mining applications, however, an accurate ranking is more desirable than an accurate classification. Responding to this fact, we present a lazy learning algorithm called instance greedily cloning naive Bayes (simply IGCNB) in this paper. Our motivation is to improve naive Bayes' ranking performance measured by AUC (Bradley, 1997; Provost and Fawcett, 1997). We experimentally tested our algorithm, using the whole 36 UCI datasets recommended by Weka, and compared it to C4.4 (Provost and Domingos, 2003), NB (Langley et al., 1992), SNNB (Xie, 2002) and LWNB (Frank, 2003). The experimental results show that our algorithm outperforms all the other algorithms used to compare significantly in yielding accurate ranking.",Yes,"논문 초록에서 AUC(Area Under the Curve)를 이용한 정량적 평가를 실시했다고 명시되어 있으며, 실험을 통해 제안된 알고리즘의 성능을 비교 분석하는 내용이 포함되어 있습니다. 따라서 정량적 평가가 수행된 것으로 판단됩니다."
Combining Metamorphic Testing and Machine Learning to Enhance OpenStreetMap,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10490297,"Metamorphic testing (MT) is a useful tool to test systems where an oracle is not available. MT relies on the definition of metamorphic relations (MR), that is, certain properties that relate a set of inputs and the set of outputs produced by the system under test (SUT) as response to these inputs. Usually, a violation of an MR implies that the SUT is faulty. However, some work on MT accepts, for certain SUTs, that the violation of an MR almost always is a symptom of an error but assumes the potential existence of false positives. This is the case, for instance, of our recent work where we applied MT to improve OpenStreetMap (OSM). Our MRs were able to uncover a large amount of errors in all the analyzed maps but we suffered the presence of a nonnegligible number of false positives. Therefore, an expert had to manually check the suspicious elements identified by our MRs. If we analyze large maps, then this manual task is unfeasible. In this article we solve the main limitation of our previous approach: we accurately and automatically discard false positives. Our new framework combines MT, along the same lines of our previous work, and machine learning. Specifically, we provide three models, one for each MR, based on the random forest model. The models were extensively trained with real data obtained from the application of MRs to maps of cities located in different continents. In order to evaluate the usefulness of our models, we tested them using different cities, in countries that were not considered in the training set. The results were very good: accuracy of the models is never lower than 0.90, it is usually much higher and in many situations reaches 1.0. The computation of the F1-scores yielded similar results.",Yes,"논문 초록에서 머신러닝을 활용하여 정량적 평가(모델의 정확도와 F1-score 등 성능 지표)를 수행한 내용을 명확히 언급하고 있습니다. 특히, 모델의 정확도와 F1-score를 계산하여 평가한 점이 정량적 평가의 실시를 보여줍니다."
Özgeçmişlerde varlık isimlerinin tanınması Named entity recognition in resumes,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10296807,"Named entity recognition (NER) is used to extract information from various documents and texts such as names and dates. It is important to extract education and work experience information from resumes in order to filter them. Considering the fact that all information in a resume has to be entered to the company’s system manually, automatizing this process will save time of the companies. In this study, a deep learning-based semi-automatic named entity recognition system has been implemented with a focus on resumes in the field of IT. Firstly, resumes of employees from five different IT related fields have been annotated. Six transformer based pre-trained models have been adapted to named entity recognition problem using the annotated data. These models have been selected among popular models in the natural language processing field. The obtained system can recognize eight different entity types which are city, date, degree, diploma major, job title, language, country and skill. Models used in the experiments are compared using micro, macro and weighted F1 scores and the performance of the methods was evaluated. Taking these scores into account for test set the best micro and weighted F1 score is obtained by RoBERTa and the best macro F1 score is obtained by Electra model.",Yes,"논문 초록에서 여러 모델의 성능을 평가하기 위해 micro, macro, weighted F1 점수와 같은 정량적 지표를 사용했다고 명시되어 있습니다. 이는 정량적 평가를 실시하고 있음을 보여줍니다."
AcouSense: A Deep Learning Based Real-Time Acoustic Triggering System,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9673469,"In this era of technology, people use Headphones continuously during their work hours. To enhance the user experience, most of the headphones are equipped with a noise cancellation feature that completely wipes out any sound in the vicinity. Due to this, many users could not listen to external sounds around their surroundings. Recent data shows that such situations have led to major accidents and loss of life in the recent past. In this paper, we have proposed a novel methodology to tackle the problem in real time. Based on the research, we have collected 20 words that people often say during any emergency situation, known as the Attention words. The proposed methodology cautions the Headphone user whenever an attention word is uttered by people in the surroundings. This approach is also found out to be useful for deaf people who often find themselves in alerting circumstances due to their inability to hear. We have divided the target people into two categories: People using headphones while doing their chores and people with hearing disabilities. A unique solution in accordance with the methodology is proposed for each category of people. Based on the methodology, a prototype deep learning-based Convolutional Neural Network (CNN) is developed. The 10-layer CNN architecture is trained on the dataset of the attention word formed using the Google Speech Command Dataset. The deep learning model is further evaluated on the public dataset to review the accuracy of the model in a noisy environment. The CNN model gave a good accuracy of 91 %. The trained deep learning model is tested using a micro-controller which is further embedded into a headphone. The system activates its vibration module after listening to the attention word.",Yes,"논문 초록에서 10-layer CNN 모델을 개발하고, 이를 평가하기 위해 공개 데이터셋에서 정확도를 측정하는 등 정량적 평가를 실시한 내용을 언급하고 있습니다. 이러한 평가 과정은 모델의 성능을 수치로 측정하는 정량적 평가의 전형적인 예입니다."
Towards Personalized Real-time Cardiodynamic Status Monitoring: Multi-scale Modeling of the Heart Sound,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9602890,"Cardiovascular diseases have been known as one of the diseases with an increasing number over the years and great intensity that led to enormous concern being attracted to a non-invasive heart sound detection technology. Knowledge in heart auscultation steadily becomes a pivotal work in this modern technology era. Moreover, in the presence of multiple scales of mathematical analysis allowing the stimulation on how the cardiac function at the whole-organ scope, this causes interest to developed monitoring of the cardio-dynamics activity on both patients and non-patients to measure their health status. In this study, we developed heart sound sensing with a cardio-dynamics recording system as a multi-scale model of the heart role, which allowed us to explore whether it can contribute to a new comprehension on health care of patients in a large population. We are mostly focusing on several aspects such as the concept of heart sounds and the link between cardiovascular dynamic and heart sounds; some technologies related to the processing and analysis of heart sound signals, containing segmentation, denoising, feature extraction also classification; and the deep learning algorithm employment in the heart sound managing and processing. At the beginning, we found that the estimation of the model parameters from heart sound with cardiac function at the whole organ scale and prognosis scores were very consistent. Since the employed multi-scale mathematical system are predictive. So here in this paper, we further illustrate the potential of the system upon the individualized planning of cardiac health and treatment in a case of cardiovascular disease.",Yes,"논문은 심장 소리 신호의 처리, 분석, 특징 추출, 분류 등 다양한 정량적 평가 방법을 활용하고 있으며, 모델 파라미터 추정과 예측 성능 평가를 수행하고 있음을 보여줍니다. 이러한 내용은 정량적 평가를 실시하고 있음을 명확히 나타냅니다."
TASA: Temporal Attention With Spatial Autoencoder Network for Odor-Induced Emotion Classification Using EEG,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10528328,"The olfactory system enables humans to smell different odors, which are closely related to emotions. The high temporal resolution and non-invasiveness of Electroencephalogram (EEG) make it suitable to objectively study human preferences for odors. Effectively learning the temporal dynamics and spatial information from EEG is crucial for detecting odor-induced emotional valence. In this paper, we propose a deep learning architecture called Temporal Attention with Spatial Autoencoder Network (TASA) for predicting odor-induced emotions using EEG. TASA consists of a filter-bank layer, a spatial encoder, a time segmentation layer, a Long Short-Term Memory (LSTM) module, a multi-head self-attention (MSA) layer, and a fully connected layer. We improve upon the previous work by utilizing a two-phase learning framework, using the autoencoder module to learn the spatial information among electrodes by reconstructing the given input with a latent representation in the spatial dimension, which aims to minimize information loss compared to spatial filtering with CNN. The second improvement is inspired by the continuous nature of the olfactory process; we propose to use LSTM-MSA in TASA to capture its temporal dynamics by learning the intercorrelation among the time segments of the EEG. TASA is evaluated on an existing olfactory EEG dataset and compared with several existing deep learning architectures to demonstrate its effectiveness in predicting olfactory-triggered emotional responses. Interpretability analyses with DeepLIFT also suggest that TASA learns spatial-spectral features that are relevant to olfactory-induced emotion recognition.",Yes,"논문 초록에서 TASA 모델이 다양한 정량적 평가 방법을 사용하여 성능을 검증했다고 명시되어 있습니다. 특히, 기존 딥러닝 아키텍처와 비교 평가를 수행하며, 실험 결과의 효과성을 보여주는 평가 지표들이 활용된 것으로 보입니다."
Visual Quality Inspection of Pomegranate Crop Using a Novel Dataset and Deep Learning,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9854435,"Grading and quality assessment of fruits is an important post-harvest management tool to define the appropriate use of the harvested fruit and reasonable pricing. In this work, the performance of 14 well-known deep learning models is evaluated in a pomegranate quality assessment. The models are trained with a novel image dataset including three quality classes of pomegranate fruit related to their postharvest intended use. Reported results indicated quality classification performances of up to 94.12% for MobileNet model. Experimental results reveal that transfer learning could provide promising results in fruit sorting problems with limited data.",Yes,"논문은 14개의 딥러닝 모델을 평가하는 과정에서 성능 지표를 사용하여 정량적 평가를 실시하고 있음을 보여줍니다. 또한, 품질 분류 성능이 구체적인 수치(94.12%)로 보고되어 있어 정량적 평가가 수행된 것을 알 수 있습니다."
Advances in High-Resolution Non-Destructive Defect Detection and Localization Enhanced by Intelligent Signal Processing,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10691271,"In development and production of microelectronics products the assessment of the condition of either the full component or only specific parts is of high relevance. To allow for screening and monitoring and to leave the part unaltered the inspection techniques are required to operate non-destructively. While this allows for full-cover final inspection it also enables repetitive monitoring beneficial for the exploration of material interactions, potential subsequent defect formations and consequently for failure isolation. With increasing complexity inherent in advancing microelectronic technologies, high reliability, robustness and thus, successful failure analysis is essential. The correspondingly shrinking feature sizes and the involvement of heterogeneous materials highly challenge existing techniques. Furthermore, the interpretation of the acquired data becomes increasingly difficult requiring specifically skilled operating personal. In previous studies machine learning (ML) approaches have been developed and evaluated for their ability to analyze signals acquired by scanning acoustic microscopy (SAM) with the goal of automated defect detection, characterization, and failure isolation. The present paper investigates different ML architectures to analyze the time signals after transformation into the spectral- and wavelet domains. Results showed that 2D CNNs analyzing the acquired acoustic signals in the wavelet domain representation performed best, however at the expense of additional computational effort. Furthermore, ML-based analysis was explored for its potential to locate and isolate electrically active defects in the depth-dimension based on thermal emissions using lock-in thermography (LIT). Obtained LIT-related results are promising, however require further research to fully enfold its potential. It was further found that transfer properties of the inspection tools interfere with the defect specific signal features and thus so far tie the trained models to the specific equipment used. Future work should therefore focus on removing the specific tool related transfer characteristics of the equipment from the measurement data to allow for intra-tool compatibility and thus a more generalized application. (Abstract)",Yes,"논문 초록에서 머신러닝(ML) 아키텍처를 활용하여 신호 분석을 수행하는 내용이 언급되어 있으며, 정량적 평가를 통해 최적의 분석 방법을 찾고 성능을 비교하는 과정이 포함되어 있다고 보여집니다. 따라서, 정량적 평가가 실시되고 있다고 판단됩니다."
A Performance Evaluation on Distance Measures in KNN for Mobile Malware Detection,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8820510,"Most of the related works on mobile malware detection for Android Operating System (OS) that are based on machine learning often use classifiers' default settings, and focus on opting either the optimal features or classifier. Even if this approach is understandable and it has proven to provide valuable results classifiers different hyper-parameters should be configured properly in order to achieve classifier's best performance. Thus, this paper investigates the performance of one of the most simple machine learning classifier, such as K Nearest Neighbor (KNN), considering its different hyper-parameters with emphasis on different distance measures. The authors have performed an extensive comparison using various well known distance measures over the Drebin data set. Results show that the proper choice of the distance measure can provide a significant enhancement to the classification accuracy. Specifically, the Euclidean distance that is mostly used for KNN is not the optimal option, instead other distance measures i.e., Hamming, CityBlock, can boost classifier's performance in the context of mobile malware detection. For instance, CityBlock can improve KNN false positive rate up to 33% in comparison to the Euclidean distance.",Yes,"논문 초록에서 다양한 거리 측정을 사용하여 KNN의 성능을 정량적으로 평가한 결과를 제시하고 있으며, 실험을 통해 성능 향상 정도를 수치로 보여주고 있기 때문에 정량적 평가를 실시하고 있다고 판단됩니다."
MDLF: A Multi-View-Based Deep Learning Framework for Individual Trip Destination Prediction in Public Transportation Systems,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9605211,"Understanding and predicting each individual’s real-time travel destination given the origin information in urban public transportation systems is crucial for personalized traveler recommendation, targeted demand management, dynamic traffic operations and so on. Existing methods are often based on modeling the regular travel patterns through analyzing the long-term personal travel information. They are suitable for destination prediction of individual regular trips with regular travel patterns, but may not work well for occasional trips with strong randomness and uncertainty, especially for the individuals with a few historical travel data. In this paper, we focus on more challenging issue about destination prediction of occasional trips. We design a general Multi-View Deep Learning Framework (MDLF) based on the data-driven insight that a location where a user will destine to is not only related to the user’s own travel preference to the location, but also influenced by crowd’s travel preference and the region’s characteristics of the location under certain spatiotemporal contexts. The destination of an individual’s occasional trip can be predicted by combining all these complementary influencing factors. The novelty of MDLF is mainly reflected in two aspects. The first is the effective feature extraction from multiple and complementary views. The second is that a CNN (Recurrent Neural Network) based deep learning component for predicting each occasional trip’s destination by calculating a moving trend score for each possible destination. We evaluate the MDLF based on two real-world smart card datasets collected by AFC (Automatic Fare Collection) Systems. The experimental results demonstrate the superiority of MDLF against other competitors.",Yes,"논문 초록에서 ""evaluate""라는 표현과 함께 제안된 딥러닝 프레임워크의 성능을 검증하는 실험이 언급되어 있습니다. 이는 정량적 평가를 실시하고 있음을 시사하며, 실험 결과를 통해 제안 방법의 우수성을 입증하는 것으로 보입니다."
Speech-based Evaluation of Emotions-Depression Correlation,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9927758,"Early detection of depression symptoms is fundamental to limit the onset of further associated behavioural disorders, such as psychomotor or social withdrawal. The combination of Artificial Intelligence and speech analysis revealed the existence of objectively measurable physical manifestations for early detection of depressive symptoms, constituting a valid support to evaluate these signals. To push forward the research state-of-art, this aim of this paper is to understand quantitative correlations between emotional states and depression by proposing a study across different datasets containing speech of both depressed/non-depressed people and emotional-related samples. The relationship between affective measures and depression can, in fact, a support to evaluate the presence of depression state. This work constitutes a preliminary step of a study whose final aim is to pursue AI-powered personalized medicine by building sophisticated Clinical Decision Support Systems for depression, as well as other psychological disorders.",Yes,"논문 초록에서 감정 상태와 우울증 간의 정량적 상관관계를 이해하기 위해 다양한 데이터셋을 활용한 연구를 제안하고 있으며, 이는 정량적 평가를 실시하고 있음을 시사합니다. 또한, AI와 음성 분석을 통해 객관적으로 측정 가능한 신체적 징후를 탐구하는 점도 정량적 평가의 수행을 의미합니다."
Predicting user comfort level using machine learning for Smart Grid environments,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5759178,"Smart Grid with Time-of-Use (TOU) pricing brings new ways of cutting costs for energy consumers and conserving energy. It is done by utilities suggesting the user ways to use devices to lower their energy bills keeping in mind its own benefits in smoothening the peak demand curve. However, as suggested in previous related research, user's comfort need must be addressed in order to make the system work efficiently. In this work, we validate the hypothesis that user preferences and habits can be learned and user comfort level for new patterns of device usage can be predicted. We investigate how machine learning algorithms specifically supervised machine learning algorithms can be used to achieve this. We also compare the prediction accuracies of three commonly used supervised learning algorithms, as well as the effect that the number of training samples has on the prediction accuracy. Further more, we analyse how sensitive prediction accuracies yielded by each algorithm are to the number of training samples.",Yes,"초록에서 세 가지 슈퍼바이즈드 머신러닝 알고리즘의 예측 정확도를 비교하는 내용이 언급되어 있어, 정량적 평가가 수행되고 있음을 알 수 있습니다. 이는 구체적인 성능 평가와 관련된 실험적 분석이 포함되어 있음을 시사합니다."
Semantic Attention-guided Day-to-Night Image Translation Network,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10422093,"Perception tasks are critical for an autonomous driving system. In recent years, advancements in deep learning have enabled highly accurate perception. However, conquering perception tasks in poor visibility environments remains challenging. One of the main reasons is that most of the existing datasets are concentrated on visually clear environments. This makes it difficult to train deep learning-based perception models in limited visibility environments. Building a new dataset requires significant time and human resources, and annotating data from adverse visibility environments is even more challenging. To address these problems, many image translation methods have been proposed to translate annotated daytime images into nighttime ones to build a nighttime dataset without annotation. In this paper, we present an unsupervised day-to-night image translation network for generating synthetic data. Our proposed method extracts semantic information from input images. The extracted information is then applied to the image-to-image translation network as spatial attention maps. We conduct experiments to evaluate the proposed method. The experimental results show that our method outperforms the related works both qualitative and quantitative.",Yes,"논문 초록에서 ""실험을 수행하여 제안된 방법을 평가하였다""라고 언급하며, 정량적 평가가 이루어졌음을 시사합니다. 또한, ""양적 및 질적"" 평가를 통해 성능을 비교했다고 명시되어 있어 정량적 평가가 실시된 것으로 판단됩니다."
DeepAid: A Mobile Cognitive Aid System with Compacted Deep Learning,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8560137,"This paper presents DeepAid, a mobile system assisting cognitive decline patients. Existing designs of such systems suffer low accuracies for the recognition and long latencies for the interaction two major issues. DeepAid leverages deep learning to solve both issues at the same time. Deep learning naturally leads to high-accuracy object recognition. If it can further execute on the local device directly, the latency can be satisfied as well since frequent data transmission to the server in prior approaches can be avoided. The major contribution of this paper is to instrument the possibility that deep learning can be compact so as to achieve a good trade-off between accuracy and resource consumption, with the design of task decomposition and network scale minimization. To validate the effectiveness of DeepAid, we implement a series of experiments and compare with other related work. In the final, the DeepAid can achieve about 97% accuracy in object recognition with about 90ms time delay.",Yes,"논문 초록에서 DeepAid의 성능을 검증하기 위해 일련의 실험을 수행했다고 명시되어 있으며, 객체 인식 정확도와 시간 지연과 같은 정량적 평가 지표를 제시하고 있습니다. 따라서, 정량적 평가를 실시하고 있다고 판단됩니다."
Bindi: Affective Internet of Things to Combat Gender-Based Violence,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9780201,"The main research motivation of this article is the fight against gender-based violence and achieving gender equality from a technological perspective. The solution proposed in this work goes beyond currently existing panic buttons, needing to be manually operated by the victims under difficult circumstances. Instead, Bindi, our end-to-end autonomous multimodal system, relies on artificial intelligence methods to automatically identify violent situations, based on detecting fear-related emotions, and trigger a protection protocol, if necessary. To this end, Bindi integrates modern state-of-the-art technologies, such as the Internet of Bodies, affective computing, and cyber–physical systems, leveraging: 1) affective Internet of Things (IoT) with auditory and physiological commercial off-the-shelf smart sensors embedded in wearable devices; 2) hierarchical multisensorial information fusion; and 3) the edge-fog-cloud IoT architecture. This solution is evaluated using our own data set named WEMAC, a very recently collected and freely available collection of data comprising the auditory and physiological responses of 47 women to several emotions elicited by using a virtual reality environment. On this basis, this work provides an analysis of multimodal late fusion strategies to combine the physiological and speech data processing pipelines to identify the best intelligence engine strategy for Bindi. In particular, the best data fusion strategy reports an overall fear classification accuracy of 63.61% for a subject-independent approach. Both a power consumption study and an audio data processing pipeline to detect violent acoustic events complement this analysis. This research is intended as an initial multimodal baseline that facilitates further work with real-life elicited fear in women.",Yes,"논문은 데이터셋 WEMAC를 사용하여 공포 분류 정확도와 같은 정량적 평가를 실시하고 있으며, 다양한 데이터 융합 전략의 성능을 수치로 제시하고 있습니다. 또한, 파워 소비와 오디오 데이터 처리 파이프라인에 대한 분석도 포함되어 있어 정량적 평가가 수행되고 있음을 알 수 있습니다."
Continual Learning for Multivariate Time Series Tasks with Variable Input Dimensions,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9679108,"We consider a sequence of related multivariate time series learning tasks, such as predicting failures for different instances of a machine from time series of multi-sensor data, or activity recognition tasks over different individuals from multiple wearable sensors. We focus on two under-explored practical challenges arising in such settings: (i) Each task may have a different subset of sensors, i.e., providing different partial observations of the underlying ‘system’. This restriction can be due to different manufacturers in the former case, and people wearing more or less measurement devices in the latter (ii) We are not allowed to store or re-access data from a task once it has been observed at the task level. This may be due to privacy considerations in the case of people, or legal restrictions placed by machine owners. Nevertheless, we would like to (a) improve performance on subsequent tasks using experience from completed tasks as well as (b) continue to perform better on past tasks, e.g., update the model and improve predictions on even the first machine after learning from subsequently observed ones. We note that existing continual learning methods do not take into account variability in input dimensions arising due to different subsets of sensors being available across tasks, and struggle to adapt to such variable input dimensions (VID) tasks. In this work, we address this shortcoming of existing methods. To this end, we learn task-specific generative models and classifiers, and use these to augment data for target tasks. Since the input dimensions across tasks vary, we propose a novel conditioning module based on graph neural networks to aid a standard recurrent neural network. We evaluate the efficacy of the proposed approach on three publicly available datasets corresponding to two activity recognition tasks (classification) and one prognostics task (regression). We demonstrate that it is possible to significantly enhance the performance on future and previous tasks while learning continuously from VID tasks without storing data.",Yes,"초록에서 제안된 방법은 여러 실험을 통해 성능을 정량적으로 평가하는 것으로 보입니다. 특히, ""evaluate the efficacy""라는 표현과 함께 여러 공개 데이터셋을 이용한 성능 향상 검증이 언급되어 있어, 정량적 평가를 실시하고 있음을 알 수 있습니다."
